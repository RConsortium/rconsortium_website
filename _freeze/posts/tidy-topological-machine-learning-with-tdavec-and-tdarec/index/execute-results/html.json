{
  "hash": "0fd03a4dd143cf52a3e93b255b90e4ca",
  "result": {
    "markdown": "---\ntitle: \"Tidy topological machine learning with TDAvec and tdarec\"\ndescription: \"Topological data analysis (TDA) is increasingly integrated into machine learning. This project introduces two R packages—TDAvec and tdarec—to bridge TDA with the Tidymodels ecosystem, offering efficient persistent homology vectorization and tidy ML pipelines.\"\nauthor: \"Jason Cory Brunson, Alexsei Luchinsky, Umar Islambekov\"\nformat: html\neditor: visual\nimage: \"front-image.png\"\nimage-alt: tdarec is now available on CRAN banner graphic\nbibliography: tdarec-blog.bib\ndate: \"06/04/2025\"\n---\n\n\n## The Pitch\n\nTopological data analysis (TDA) is a pretty mature discipline at this point, but in the last several years its assimilation into machine learning (ML) has really taken off. Based on our experience, the plurality of experimental TDA tools are written in Python, and naturally Python is home to most of these applications.\n\nThat's not to say that there are no R packages for TDA-ML. [{TDAkit}](https://github.com/kisungyou/TDAkit), [{TDApplied}](https://github.com/shaelebrown/TDApplied), and others provide tools for specific self-contained analyses and could be used together in larger projects. As with the broader R ecosystem, though, their integration can require some additional work. The combination of several low-level libraries and compounding package dependencies has also made this toolkit fragile, with several packages temporarily or permanently archived.\n\nMeanwhile, the [Tidymodels](https://www.tidymodels.org/) package collection has enabled a new generation of users, myself (JCB) included, to build familiarity and proficiency with conventional ML. By harmonizing syntax and smoothing pipelines, Tidymodels makes it quick and easy to adapt usable code to new data types, pre-processing steps, and model families. By using wrappers and extractors, it also allows seasoned users to extend their work beyond its sphere of convenience.\n\nWe therefore think that Tidymodels is an ideal starting point for a more sustained and interoperable collection for TDA-ML in R. Since much of the role of TDA in ML has been to extract and vectorize features from spatial, image, and other high-dimensional data, we present an extension to [{recipes}](https://recipes.tidymodels.org/) for just this purpose. Assembling a comprehensive, general-purpose toolkit is a long-term project. Our contribution is meant to spur that project on.\n\n## The Packages\n\nWe present two packages: {TDAvec}, an interface to several efficient feature vectorizations, and {tdarec}, a {recipes} + [{dials}](https://dials.tidymodels.org/) extension that integrates these vectorizations into Tidymodels. First, though, we need to introduce persistent homology and how it can be computed with R.\n\n### Computations of persistent homology\n\nIn predictive modeling, [**persistent homology**](https://en.wikipedia.org/wiki/Persistent_homology) (PH) is the workhorse of TDA.[^1] In a nutshell, it measures topological patterns in data---most commonly clusters and enclosures---by the range of resolutions through which they persist. Several packages interface to lower-level libraries that compute PH for various data structures---all accept point clouds and distance matrices, but other structures are accepted where noted:\n\n[^1]: Exploratory modeling is another story.\n\n-   [{TDA}](https://doi.org/10.48550/arXiv.1411.1830) [@Fasy2022] interfaces to the Dionysus, PHAT, and GUDHI libraries and also accepts functions and rasters;\n-   [{ripserr}](https://tdaverse.github.io/ripserr/) [@Wadhwa2025], a spinoff from [{TDAstats}](https://joss.theoj.org/papers/10.21105/joss.00860), interfaces to the Ripser and Cubical Ripser C++ libraries and also accepts rasters;\n-   [{TDApplied}](https://joss.theoj.org/papers/10.21105/joss.06321) [@Brown2024] calls {TDA} and {TDAstats} but also interfaces with Python Ripser; and\n-   [{rgudhi}](https://lmjl-alea.github.io/rgudhi/) [@Stamm2023] interfaces to Python GUDHI.\n\nHere is an example using the most mature package, {TDA}, to compute the PH for an alpha filtration of a sample from a torus:\n\n\n::: {.cell hash='index_cache/html/TDA_7eaf8542218f62a9e0e9f953b750f166'}\n\n```{.r .cell-code}\nx <- TDA::torusUnif(n = 200, a = 1, c = 2)\npd <- TDA::alphaComplexDiag(x, maxdimension = 2)\nplot(pd$diagram, asp = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/TDA-1.png){width=672}\n:::\n:::\n\n\nWe rely for now on {ripserr} to compute PH, but a near-term upgrade will incorporate {TDA} as well.\n\n### Vectorizations of persistent homology\n\nVectorization is a crucial step to bridge TDA and ML. Numerous methods have been proposed, and research shows that ML performance on a specific task can depend strongly on the chosen method. Therefore, it is highly desirable to compare several approaches to a given problem and select the one found to be best-suited to it.\n\nAlthough most proposed vectorization methods are available in free software, they are scattered across various R and Python packages. This complicates the comparison process, as researchers must search for available methods and adapt their code to the interface of each specific implementation. The goal of [{TDAvec}](https://cran.r-project.org/package=TDAvec) [@Luchinsky2025] is to address this issue.\n\nWe (AL and UI) have consolidated all currently available vectorizations (of which we are aware) and implemented them in a single R library. Some of these vectorizations are parameter-free, but others rely on one or several hyperparameters. For ease of comparison, we also use a consistent interface, with a common camelcase naming convention, e.g. `computePersistenceLandscape()`. Additionally, several new vectorization methods developed by our group are also available within the TDAvec framework.\n\nHere, for example, is how to compute the tropical coordinates proposed by @Kalisnik2019 and a coarse vectorization of our own persistence block transformation [@Chan2022] for the degree-1 layer of the persistence diagram above:\n\n\n::: {.cell hash='index_cache/html/TDAvec_a1930a18ca02221a2decbad2de2eefbc'}\n\n```{.r .cell-code}\nlibrary(TDAvec)\ncomputeTropicalCoordinates(pd$diagram, homDim = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         F1          F2          F3          F4          F5          F6 \n  0.9092459   1.7922661   2.3573061   2.8300092  10.5079390   6.7579761 \n         F7 \n195.6041952 \n```\n:::\n\n```{.r .cell-code}\nxy_seq <- seq(0, 1.5, .5)\ncomputePersistenceBlock(\n  pd$diagram, homDim = 2,\n  xSeq = xy_seq, ySeq = xy_seq\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  0.5314592  0.3107023  0.0000000  0.3198161 51.2358099 57.8900117  0.0000000\n[8] 61.8427360 74.8155150\n```\n:::\n:::\n\n\nNotably, all vectorizations are written in C++ and exposed to R using {Rcpp}. We also utilize the Armadillo package for various matrix operations, which makes all computations extremely fast and efficient.\n\n### Tidy machine learning with persistent homology\n\n{recipes} is the pre-processing arm of Tidymodels; mostly it provides `step_*()` functions that pipe together as recipe specifications, to later be applied directly to data or built into workflows. {dials} provides tuning functions for these steps as well as for model families provided by {parsnip}.\n\n[{tdarec}](https://tdaverse.github.io/tdarec/) provides two primary families of steps:\n\n1.  Steps to *calculate persistent homology from data*, which share the naming pattern `step_pd_*()` for **p**ersistence **d**iagram. These steps rely on the engines above and are scoped according to the underlying mathematical object encoded in the data: Currently the {ripserr} engine handles point clouds (encoded as coordinate matrices or distance matrices) and rasters (encoded as numerical arrays). These steps accept list-columns of data sets and return list-columns of persistence diagrams.\n2.  Steps to *transform and vectorize persistence diagrams*, which share the naming pattern `step_vpd_*()` for **v**ectorized **p**ersistence **d**iagram. These steps rely on {TDAvec} and are scoped as there by transformation. They accept list-columns of persistence diagrams and return numeric columns (sometimes flattened from matrix output, e.g. multi-level persistence landscapes) that can be used by most predictive model families.\n\nHere is how to incorporate PH (using the default Vietoris--Rips filtration) and the persistence block transformation above into a pre-processing recipe:\n\n\n::: {.cell hash='index_cache/html/tdarec_6125666d5f18147ec07e3e9ef4ff120a'}\n\n```{.r .cell-code}\nsuppressMessages(library(tdarec))\ndat <- tibble(source = \"torus\", sample = list(x))\nrecipe(~ sample, data = dat) |> \n  step_pd_point_cloud(sample, max_hom_degree = 2) |> \n  step_pd_degree(sample_pd, hom_degrees = 2) |> \n  step_vpd_persistence_block(\n    sample_pd_2,\n    hom_degree = 2, xseq = xy_seq\n  ) -> rec\n# Note: This code demonstrates the recipe structure\n# In practice, you would need to ensure all required packages are installed\n# and the data is properly formatted\n```\n:::\n\n\nThe code chunk uses the additional step `step_pd_degree()` to extract degree-specific layers from multi-degree persistence diagrams; in this case, we are interested in vectorizing only 2-dimensional features. Despite this, we must also specify the degree of the features we want in the persistence block step.\n\n## The Potential\n\nMany methods remain to be built into these tools, which will only reach their full potential through user feedback. Two issues in particular, [additional vectorizations](https://github.com/uislambekov/TDAvec/issues/3) for {TDAvec} and [additional engines](https://github.com/tdaverse/tdarec/issues/2) for {tdarec}, may remain open---or, ahem, persist---into the foreseeable future. We welcome bug reports, feature requests, and code contributions from the community!\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}