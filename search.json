[
  {
    "objectID": "codeofconduct.html",
    "href": "codeofconduct.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "The R Consortium and its working groups are dedicated to providing a harassment-free experience for participants at all of our events, whether they are held in person or virtually. R Consortium events are working conferences intended for professional networking and collaboration within the open source community. They exist to encourage the open exchange of ideas and expression and require an environment that recognizes the inherent worth of every person and group. While at R Consortium events or related ancillary or social events, any participants, including members, speakers, attendees, volunteers, sponsors, exhibitors, booth staff and anyone else, should not engage in harassment in any form.\nThis Code of Conduct may be revised at any time by The R Consortium and the terms are non-negotiable. Your registration for or attendance at any R Consortium event, whether it’s held in person or virtually, indicates your agreement to abide by this policy and its terms.\n\n\nAll event participants, whether they are attending an in-person event or a virtual event, are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior and applicable laws.\n\n\n\nHarassment will not be tolerated in any form, whether in person or virtually, including, but not limited to, harassment based on sex, gender, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held. Harassment includes the use of abusive, offensive or degrading language, intimidation, stalking, harassing photography or recording, inappropriate physical contact, sexual imagery and unwelcome sexual advances or requests for sexual favors. Any report of harassment at one of our events, whether in person or virtual, will be addressed immediately. Participants asked to stop any harassing behavior are expected to comply immediately. Anyone who witnesses or is subjected to unacceptable behavior should notify a conference organizer at once.\nExhibitors should not use sexualized images, activities, or other material in their booths and must refrain from the use of sexualized clothing, uniforms, costumes, or otherwise creating a sexualized environment. Speakers should not use sexual language, images, or any language or images that would constitute harassment as defined above in their talks.\nIndividuals who participate (or plan to participate) in R Consortium events, whether its an in-person event or a virtual event, should conduct themselves at all times in a manner that comports with both the letter and spirit of this policy prohibiting harassment and abusive behavior, whether before, during or after the event. This includes statements made in social media postings, on-line publications, text messages, and all other forms of electronic communication.\n\n\n\nIf a participant engages in harassing behavior, whether in person or virtually, the conference organizers may take any action they deem appropriate depending on the circumstances, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nIf a participant (or individual wishing to participate in an R Consortium event, in-person and/or virtual), through postings on social media or other online publications or another form of electronic communication, engages in conduct that violates this policy, whether before, during or after a R Consortium event, the R Consortium may take appropriate corrective action, which could include imposing a temporary or permanent ban on an individual’s participation in future R Consortium events, events, working groups, trainings or other activities.\n\n\n\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact a member of the conference staff immediately. You are also encouraged to contact abuse@r-consortium.org.\n\n\n\nOur staff has taken incident response training and responds to harassment reports quickly and thoroughly. As referenced above, if a participant engages in harassing behavior, whether in-person or virtually, the conference organizers may take any action they deem appropriate, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund, depending on the circumstances. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nConference staff will also provide support to victims, including, but not limited to:\n\nProviding an Escort\nContacting Hotel/Venue Security or Local Law Enforcement\nBriefing Key Event Staff For Response/Victim Assistance\nAnd otherwise assisting those experiencing harassment to ensure that they feel safe for the duration of the conference.\n\n\n\n\nIf you are planning to attend an upcoming event, whether in-person or virtually and have concerns regarding another individual who may be present, please contact conduct@r-consortium.org. Precautions will be taken to ensure your comfort and safety, including, but not limited to providing an escort, prepping onsite event staff, keeping victim and harasser from attending the same talks/social events and providing onsite contact cell phone numbers for immediate contact."
  },
  {
    "objectID": "codeofconduct.html#committed-to-a-safe-and-inclusive-environment-for-the-r-consortium-community",
    "href": "codeofconduct.html#committed-to-a-safe-and-inclusive-environment-for-the-r-consortium-community",
    "title": "Code of Conduct",
    "section": "",
    "text": "The R Consortium and its working groups are dedicated to providing a harassment-free experience for participants at all of our events, whether they are held in person or virtually. R Consortium events are working conferences intended for professional networking and collaboration within the open source community. They exist to encourage the open exchange of ideas and expression and require an environment that recognizes the inherent worth of every person and group. While at R Consortium events or related ancillary or social events, any participants, including members, speakers, attendees, volunteers, sponsors, exhibitors, booth staff and anyone else, should not engage in harassment in any form.\nThis Code of Conduct may be revised at any time by The R Consortium and the terms are non-negotiable. Your registration for or attendance at any R Consortium event, whether it’s held in person or virtually, indicates your agreement to abide by this policy and its terms.\n\n\nAll event participants, whether they are attending an in-person event or a virtual event, are expected to behave in accordance with professional standards, with both this Code of Conduct as well as their respective employer’s policies governing appropriate workplace behavior and applicable laws.\n\n\n\nHarassment will not be tolerated in any form, whether in person or virtually, including, but not limited to, harassment based on sex, gender, sexual orientation, disability, physical appearance, body size, race, age, religion or any other status protected by laws in which the conference or program is being held. Harassment includes the use of abusive, offensive or degrading language, intimidation, stalking, harassing photography or recording, inappropriate physical contact, sexual imagery and unwelcome sexual advances or requests for sexual favors. Any report of harassment at one of our events, whether in person or virtual, will be addressed immediately. Participants asked to stop any harassing behavior are expected to comply immediately. Anyone who witnesses or is subjected to unacceptable behavior should notify a conference organizer at once.\nExhibitors should not use sexualized images, activities, or other material in their booths and must refrain from the use of sexualized clothing, uniforms, costumes, or otherwise creating a sexualized environment. Speakers should not use sexual language, images, or any language or images that would constitute harassment as defined above in their talks.\nIndividuals who participate (or plan to participate) in R Consortium events, whether its an in-person event or a virtual event, should conduct themselves at all times in a manner that comports with both the letter and spirit of this policy prohibiting harassment and abusive behavior, whether before, during or after the event. This includes statements made in social media postings, on-line publications, text messages, and all other forms of electronic communication.\n\n\n\nIf a participant engages in harassing behavior, whether in person or virtually, the conference organizers may take any action they deem appropriate depending on the circumstances, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nIf a participant (or individual wishing to participate in an R Consortium event, in-person and/or virtual), through postings on social media or other online publications or another form of electronic communication, engages in conduct that violates this policy, whether before, during or after a R Consortium event, the R Consortium may take appropriate corrective action, which could include imposing a temporary or permanent ban on an individual’s participation in future R Consortium events, events, working groups, trainings or other activities.\n\n\n\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns relating to harassment, please contact a member of the conference staff immediately. You are also encouraged to contact abuse@r-consortium.org.\n\n\n\nOur staff has taken incident response training and responds to harassment reports quickly and thoroughly. As referenced above, if a participant engages in harassing behavior, whether in-person or virtually, the conference organizers may take any action they deem appropriate, ranging from issuance of a warning to the offending individual to expulsion from the conference with no refund, depending on the circumstances. The R Consortium reserves the right to exclude any participant found to be engaging in harassing behavior from participating in any further R Consortium events, working groups, trainings or other activities.\nConference staff will also provide support to victims, including, but not limited to:\n\nProviding an Escort\nContacting Hotel/Venue Security or Local Law Enforcement\nBriefing Key Event Staff For Response/Victim Assistance\nAnd otherwise assisting those experiencing harassment to ensure that they feel safe for the duration of the conference.\n\n\n\n\nIf you are planning to attend an upcoming event, whether in-person or virtually and have concerns regarding another individual who may be present, please contact conduct@r-consortium.org. Precautions will be taken to ensure your comfort and safety, including, but not limited to providing an escort, prepping onsite event staff, keeping victim and harasser from attending the same talks/social events and providing onsite contact cell phone numbers for immediate contact."
  },
  {
    "objectID": "all-projects/funded-projects.html",
    "href": "all-projects/funded-projects.html",
    "title": "Recipients of ISC Grants",
    "section": "",
    "text": "Recipients of ISC Grants\n2024 (group 2)\n\nR-Universe: towards a unifying infrastructure and global catalog for the wider R ecosystem\nAmbiorix - A web framework for R\nDeepRHealth – A Deep Learning Toolkit for Healthcare Predictive Modeling\nCpp11armadillo: An ‘Armadillo’ Interface (C++)\naggreCAT: An R package for mathematical aggregation of expert elicitation data\nCOVID-19 Data Hub\nLaunching the Probaverse\n\n2024 (group 1)\n\nModular, interoperable, and extensible topological data analysis in R\nISO 19115-3 standard implementation in geometa R package\nR-multiverse for production\nCritical Updates to Biostrings\nSetting up igraph for success in the next decade\n{geotargets}: Enabling geospatial workflow management with {targets}\n\n2023 (group 2)\n\nTranslating R to Nepali\nRStats Mastodon Server\nTooling for internationalization of R help pages\nCausal Inference in a Box\nAccessibility Enhancements for the R Journal\nTaking r-universe to the next level\nR Kafka Client\n\n2023 (group 1)\n\nThe future of DBI (extension 1)\nSecure TLS Communications for R\nvolcalc: Calculate predicted volatility of chemical compounds\nautotest: Automated testing of R packages\napi2r: An R Package for Auto-Generating R API Clients\n\n2022 (group 2)\n\nD3po: R Package for Easy Interactive D3 Visualization With Shiny\nTooling and Guidance for Translations of Markdown-Based R Content  Quarto, R Markdown\nOnline Submission and Review Infrastructure for the R Journal\nUpgrading SatRdays Website Template\nBuilding the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure\n\n2022 (group 1)\n\nIterdatasampler: Expanding the lterdatasampler package\nFemr: Finite Element Method for Solving PDEs in R\nContinuing to Improve R’s Ability to Visualise and Explore Missing Values\nDengue Data Hub\n\n2021 (group 2)\n\nPreparing CRAN for the Retirement of rgdal, rgeos and maptools\nR Package for the ICESat-2 Altimeter Data\nThe Future of DBI\nData Science and Machine Learning Training Workshop Using R Programming Language\n\n2021 (group 1)\n\nAccounting/Auditing Gap-Analysis\nExtendr - Rust extensions for R.\nGoogle Earth Engine with R\nImproving Translations in R\nMinimizing wastage of blood products\nR for Engineering Applications\nSetting up an R-Girls-Schools Network\ndeposits: Deposit Research Data Anywhere\n\n2020 (group 2)\n\nDevelopment and maintenance of the Windows build infrastructure (Top level project proposal)\nInteractive visualisations in R via R-to-JavaScript-transpilation\n\n2020 (group 1)\n\nConsolidating R-Ladies Global organisational guidance and wisdom\nDatabase interoperability for spatial objects in R\nHTTP testing in R Book\nMATTER 2.0: larger-than-memory data for R\nSpatiotemporal Data and Analytics\nThe RECON COVID-19 challenge: leveraging the R community to improve COVID-19 analytics resources\nsftrack v1.0: Stable API for a broad adoption\n\n2019 (group 2)\n\nAn External R Sampling Profiler\nCVXR\nFlipbooks\nR Package Risk Assessment Application\nRcppDeepState, a simple way to fuzz test compiled code in R packages\nSymbolic mathematics in R with SymPy\nTidy spatial networks in R\nd3po: R package for easy interactive D3 visualization with Shiny\nwebchem: accessing chemical information from the web\n\n2019 (group 1)\n\nEnhancing usability of sample size calculations and power analyses in R with a Task View page and accompanying tutorials\nExpanding the ‘metaverse’; an R ecosystem for meta-research\nR-global: analysing spatial data globally\nsftraj: A central class for tracking and movement data\n\n2018 (group 2)\n\nCatalyzing R-hub adoption through R package developer advocacy\nData-Driven Discovery and Tracking of R Consortium Activities\nEditorial assistance for the R Journal\nLicensing R - Guidelines and tools\nNext-generation text layout in grid and ggplot2\nStrengthening of R in support of spatial data infrastructures management : geometa and ows4R R packages\nSymbolic Formulae for Linear Mixed Models\nserveRless\n\n2018 (group 1)\n\nA unified platform for missing values methods and workflows\nDeveloping Tools and Templates for Teaching Materials\nMaintaining DBI\nOngoing infrastructural development for R on Windows and MacOS\nPSI application for collaboration to create online R package validation repository\nProposal to Create an R Consortium Working Group Focused on US Census Data\nhistoRicalg – Preserving and Transfering Algorithmic Knowledge\n\n2017 (group 2)\n\nAn Earth data processing backend for testing and evaluating stars\nFuture Minimal API: Specification with Backend Conformance Test Suite\nQuantities for R\nRefactoring and updating the SWIG R module\n\n2017 (group 1)\n\nAdding Linux Binary Builders to CRAN\nAn infrastructure for building R packages on MacOS Abstract with homebrew\nConference Management System for R Consortium Supported Conferences\nContinued Development of the R API for Distributed Computing\nEstablishing DBI\nForwards Workshops for Women and Girls\nJoint profiling of native and R code\nSchool of Data Material Development\nstars: Scalable, spatiotemporal tidy arrays for R\n\n2016 (group 2)\n\nInteractive data manipulation in mapview\nR Documentation Task Force\n\n2016 (group 1)\n\nA unified framework for Distributed Computing in R\nImproving DBI\nR Implimentation Optimization Tooling (RIOT) Workshops\nRL10N: R Localization Proposal\nSatRDays\nSimple Features for R\nSoftware Carpentry R Instructor Training"
  },
  {
    "objectID": "all-projects/2017-group-1.html",
    "href": "all-projects/2017-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAdding Linux Binary Builders to CRAN\nAn infrastructure for building R packages on MacOS Abstract with homebrew\nConference Management System for R Consortium Supported Conferences\nContinued Development of the R API for Distributed Computing\nEstablishing DBI\nForwards Workshops for Women and Girls\nJoint profiling of native and R code\nSchool of Data Material Development\nstars: Scalable, spatiotemporal tidy arrays for R\n\n\n\n\nFunded:\n$15,000\nProposed by:\nDirk Eddelbuettel\nSummary:\nThis project proposes to take the creation of binary Linux packages to the next level by providing R-Hub and eventually CRAN with the ability to deliver directly installable binary packages with properly-resolved dependencies. This will allow large-scale automated use of CRAN packages anywhere: laptops, desktops, servers, cluster farms and cloud-based deployments. The project would like to hear from anyone who could possibly host a dedicated server in a rack for long term use.\n\n\n\nFunded:\n$12,000\nProposed by:\nJeroen Ooms\nSummary:\nWhen installing CRAN packages, Windows and MacOS users often rely on binary packages that contain precompiled source code and any required external C/C++ libraries. By eliminating the need to setup a full compiler environment or manage external libraries this tremendously improves the usability of R on these platforms. Our project will improve the system by adapting the popular homebrew system to facilitate static linking of external libraries\n\n\n\nFunded:\n$32,000\nProposed by:\nHeather Turner\nWebsite:\nhttps://github.com/satrdays\nSummary:\nThis project will evaluate a number of open source conference management systems to assess their suitability for use with useR! and satRdays. Test versions of these systems will be set up to test their functionality and ease of use for all roles (systems administrator, local organizer, program chair, reviewer, conference participant). A system will be selected and a production system set up, with a view to be ready for useR! 2018 and future satRdays events.\n\n\n\nFunded:\n$15,000\nProposed by:\nMichael Lawrence\nWebsite:\nhttps://wiki.r-consortium.org/view/Distributed_Computing_Working_Group and https://github.com/vertica/ddR/wiki/Design\nSummary:\nThe ISC’s Distributed Computing Working Group explores ways of enabling distributed computing in R. One of its outputs, the CRAN package ddR, defines an idiomatic API that abstracts different distributed computing engines, such as DistributedR and potentially Spark and TensorFlow. The goal of the project is to enable R users to interact with familiar data structures and write code that is portable across distributed systems. The working group will use this R Consortium grant to fund an internship to help improve ddR and implement support for one or more additional backends. Please contact Michael Lawrence to apply or request additional information.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nGetting data in and out of R is an important part of a statistician’s or data scientist’s work. If the data reside in a database, this is best done with a backend to DBI, R’s native DataBase Interface. The ongoing “Improving DBI” project supports the specification of DBI, both in prose and as an automated test, and also the adaptation of the `RSQLite` package to these specs. This follow-up project aims at implementing modern, fully spec-compliant DBI backends to two major open-source RDBMS, MySQL/MariaDB and PostgreSQL.\n\n\n\nFunded:\n$25,000\nProposed by:\nDianne Cook\nWebsite:\nhttps://forwards.github.io/edu/workshops/\nSummary:\nThe proportion of female package authors and maintainers has remained persistently low, at best at 15%, despite 20 years of the R project’s existence. This project will conduct a grassroots effort to increase the participation of women in the R community. One day package development workshops for women engaged in research will be held in Melbourne, Australia and Auckland, New Zealand in 2017, and at locations yet to be determined in the USA and Europe in 2018. Additionally, one day workshops for teenage girls focused on building Shiny apps will be developed to encourage an interest in programming. These will be rolled out in the same locations as the women’s workshops. All materials developed will be made available under a Creative Commons share-alike license on the Forwards website (http://forwards.github.io).\n\n\n\nFunded:\n$11,000\nProposed by:\nKirill Müller\nWebsite:\nhttps://github.com/krlmlr/profile and https://cran.r-project.org/web/packages/profile/index.html\nSummary:\nR has excellent facilities for profiling R code: the main entry point is the [`Rprof()`](https://www.rdocumentation.org/packages/utils/versions/3.3.2/topics/Rprof) function that starts an execution mode where the R call stack is sampled periodically, optionally at source line level, and written to a file. Profiling results can be analyzed with `summaryRprof()`, or visualized using the `profvis`, `aprof`, or `GUIProfiler` packages. However, the execution time of native code is only available in bulk, without detailed source information. This project aims at bridging this gap with a drop-in replacement to `Rprof()` that records call stacks and memory usage information at both R and native levels, and later commingles them to present a unified view to the user.\n\n\n\nFunded:\n$11,200\nProposed by:\nHeidi Seibold\nSummary:\nSchool of Data is a network of data literacy practitioners, both organizations and individuals, implementing training and other data literacy activities in their respective countries and regions. Members of School of Data work to empower civil society organizations (CSOs), journalists, civil servants and citizens with the skills they need to use data effectively in their efforts to create better, more equitable and more sustainable societies Our R consortium will develop learning materials about R for journalists, with a focus on making them accessible and relevant to journalists from various countries. As a consequence, our content will use country-relevant examples and will be translated in several languages (English, French, Spanish, German).\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://cran.r-project.org/web/packages/stars/index.html\nSummary:\nSpatiotemporal and raster data often come as dense, two-dimensional arrays while remote sensing and climate model data are often presented as higher dimensional arrays. Data sets of this kind often do not fit in main memory. This project will make it easier to handle such data with R by using dplyr-style, pipe-based workflows, and also consider the case where the data reside remotely, in a cloud environment. Questions and offers to support are welcome through issues at: https://github.com/edzer/stars"
  },
  {
    "objectID": "all-projects/2017-group-1.html#funded-isc-grants-2017-1",
    "href": "all-projects/2017-group-1.html#funded-isc-grants-2017-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAdding Linux Binary Builders to CRAN\nAn infrastructure for building R packages on MacOS Abstract with homebrew\nConference Management System for R Consortium Supported Conferences\nContinued Development of the R API for Distributed Computing\nEstablishing DBI\nForwards Workshops for Women and Girls\nJoint profiling of native and R code\nSchool of Data Material Development\nstars: Scalable, spatiotemporal tidy arrays for R\n\n\n\n\nFunded:\n$15,000\nProposed by:\nDirk Eddelbuettel\nSummary:\nThis project proposes to take the creation of binary Linux packages to the next level by providing R-Hub and eventually CRAN with the ability to deliver directly installable binary packages with properly-resolved dependencies. This will allow large-scale automated use of CRAN packages anywhere: laptops, desktops, servers, cluster farms and cloud-based deployments. The project would like to hear from anyone who could possibly host a dedicated server in a rack for long term use.\n\n\n\nFunded:\n$12,000\nProposed by:\nJeroen Ooms\nSummary:\nWhen installing CRAN packages, Windows and MacOS users often rely on binary packages that contain precompiled source code and any required external C/C++ libraries. By eliminating the need to setup a full compiler environment or manage external libraries this tremendously improves the usability of R on these platforms. Our project will improve the system by adapting the popular homebrew system to facilitate static linking of external libraries\n\n\n\nFunded:\n$32,000\nProposed by:\nHeather Turner\nWebsite:\nhttps://github.com/satrdays\nSummary:\nThis project will evaluate a number of open source conference management systems to assess their suitability for use with useR! and satRdays. Test versions of these systems will be set up to test their functionality and ease of use for all roles (systems administrator, local organizer, program chair, reviewer, conference participant). A system will be selected and a production system set up, with a view to be ready for useR! 2018 and future satRdays events.\n\n\n\nFunded:\n$15,000\nProposed by:\nMichael Lawrence\nWebsite:\nhttps://wiki.r-consortium.org/view/Distributed_Computing_Working_Group and https://github.com/vertica/ddR/wiki/Design\nSummary:\nThe ISC’s Distributed Computing Working Group explores ways of enabling distributed computing in R. One of its outputs, the CRAN package ddR, defines an idiomatic API that abstracts different distributed computing engines, such as DistributedR and potentially Spark and TensorFlow. The goal of the project is to enable R users to interact with familiar data structures and write code that is portable across distributed systems. The working group will use this R Consortium grant to fund an internship to help improve ddR and implement support for one or more additional backends. Please contact Michael Lawrence to apply or request additional information.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nGetting data in and out of R is an important part of a statistician’s or data scientist’s work. If the data reside in a database, this is best done with a backend to DBI, R’s native DataBase Interface. The ongoing “Improving DBI” project supports the specification of DBI, both in prose and as an automated test, and also the adaptation of the `RSQLite` package to these specs. This follow-up project aims at implementing modern, fully spec-compliant DBI backends to two major open-source RDBMS, MySQL/MariaDB and PostgreSQL.\n\n\n\nFunded:\n$25,000\nProposed by:\nDianne Cook\nWebsite:\nhttps://forwards.github.io/edu/workshops/\nSummary:\nThe proportion of female package authors and maintainers has remained persistently low, at best at 15%, despite 20 years of the R project’s existence. This project will conduct a grassroots effort to increase the participation of women in the R community. One day package development workshops for women engaged in research will be held in Melbourne, Australia and Auckland, New Zealand in 2017, and at locations yet to be determined in the USA and Europe in 2018. Additionally, one day workshops for teenage girls focused on building Shiny apps will be developed to encourage an interest in programming. These will be rolled out in the same locations as the women’s workshops. All materials developed will be made available under a Creative Commons share-alike license on the Forwards website (http://forwards.github.io).\n\n\n\nFunded:\n$11,000\nProposed by:\nKirill Müller\nWebsite:\nhttps://github.com/krlmlr/profile and https://cran.r-project.org/web/packages/profile/index.html\nSummary:\nR has excellent facilities for profiling R code: the main entry point is the [`Rprof()`](https://www.rdocumentation.org/packages/utils/versions/3.3.2/topics/Rprof) function that starts an execution mode where the R call stack is sampled periodically, optionally at source line level, and written to a file. Profiling results can be analyzed with `summaryRprof()`, or visualized using the `profvis`, `aprof`, or `GUIProfiler` packages. However, the execution time of native code is only available in bulk, without detailed source information. This project aims at bridging this gap with a drop-in replacement to `Rprof()` that records call stacks and memory usage information at both R and native levels, and later commingles them to present a unified view to the user.\n\n\n\nFunded:\n$11,200\nProposed by:\nHeidi Seibold\nSummary:\nSchool of Data is a network of data literacy practitioners, both organizations and individuals, implementing training and other data literacy activities in their respective countries and regions. Members of School of Data work to empower civil society organizations (CSOs), journalists, civil servants and citizens with the skills they need to use data effectively in their efforts to create better, more equitable and more sustainable societies Our R consortium will develop learning materials about R for journalists, with a focus on making them accessible and relevant to journalists from various countries. As a consequence, our content will use country-relevant examples and will be translated in several languages (English, French, Spanish, German).\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://cran.r-project.org/web/packages/stars/index.html\nSummary:\nSpatiotemporal and raster data often come as dense, two-dimensional arrays while remote sensing and climate model data are often presented as higher dimensional arrays. Data sets of this kind often do not fit in main memory. This project will make it easier to handle such data with R by using dplyr-style, pipe-based workflows, and also consider the case where the data reside remotely, in a cloud environment. Questions and offers to support are welcome through issues at: https://github.com/edzer/stars"
  },
  {
    "objectID": "all-projects/2016-group-1.html",
    "href": "all-projects/2016-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nA unified framework for Distributed Computing in R\nImproving DBI\nR Implimentation Optimization Tooling (RIOT) Workshops\nRL10N: R Localization Proposal\nSatRDays\nSimple Features for R\nSoftware Carpentry R Instructor Training\n\n\n\n\nFunded:\n$10,000\nProposed by:\nMichael Lawrence\nWebsite:\nhttps://github.com/RConsortium/Distributed-Computing-WG\nSummary:\nMany Big Data platforms expose R-based interfaces that lack standardization and are therefore difficult to learn. This project will develop a common framework to simplify and standardize how users program distributed applications in R, ultimately reducing duplication of effort.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nDatabase access is an important cornerstone of the R ecosystem, but today’s specifications – data type transformation, return values, error conditions – remain vague and result in data analysis errors. This project aims to improve database access in R so that porting code is simplified and less prone to error.\n\n\n\nFunded:\n$10,000\nProposed by:\nMark Hornick\nWebsite:\nhttps://riotworkshop.github.io/\nSummary:\nRIOT 2016 is a one-day workshop to unite R language developers, identify R language development and tooling opportunities, increase involvement of the R user community and more.\n\n\n\nFunded:\n$10,000\nProposed by:\nRichard Cotton\nWebsite:\nhttps://github.com/RL10N/RL10N and https://libraries.io/github/RL10N\nSummary:\nAlthough the R language is used globally, very few R packages are available in languages other than English. The RL10N project will make it easier for R developers to include translations in their own packages.\n\n\n\nFunded:\n$10,000\nProposed by:\nStephanie Locke\nWebsite:\nhttps://github.com/satrdays\nSummary:\n“SatRDays” are community-led, regional conferences to support collaboration, networking and innovation within the R community. Initially three events will be hosted, with plans for additional meet-ups as the R user base grows.\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://github.com/r-spatial/sf/\nSummary:\nUsing the “Simple Features” standard supported by the Open Geospatial Consortium and the International Organization for Standardization, this tool will simplify analysis on modern geospatial data.\n\n\n\nFunded:\n$10,000\nProposed by:\nLaurent Gatto\nWebsite:\nSummary:\nThis two-day in-person training course will introduce the basics of R programming and address the growing demand for training resources for the R language."
  },
  {
    "objectID": "all-projects/2016-group-1.html#funded-isc-grants-2016-1",
    "href": "all-projects/2016-group-1.html#funded-isc-grants-2016-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nA unified framework for Distributed Computing in R\nImproving DBI\nR Implimentation Optimization Tooling (RIOT) Workshops\nRL10N: R Localization Proposal\nSatRDays\nSimple Features for R\nSoftware Carpentry R Instructor Training\n\n\n\n\nFunded:\n$10,000\nProposed by:\nMichael Lawrence\nWebsite:\nhttps://github.com/RConsortium/Distributed-Computing-WG\nSummary:\nMany Big Data platforms expose R-based interfaces that lack standardization and are therefore difficult to learn. This project will develop a common framework to simplify and standardize how users program distributed applications in R, ultimately reducing duplication of effort.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nDatabase access is an important cornerstone of the R ecosystem, but today’s specifications – data type transformation, return values, error conditions – remain vague and result in data analysis errors. This project aims to improve database access in R so that porting code is simplified and less prone to error.\n\n\n\nFunded:\n$10,000\nProposed by:\nMark Hornick\nWebsite:\nhttps://riotworkshop.github.io/\nSummary:\nRIOT 2016 is a one-day workshop to unite R language developers, identify R language development and tooling opportunities, increase involvement of the R user community and more.\n\n\n\nFunded:\n$10,000\nProposed by:\nRichard Cotton\nWebsite:\nhttps://github.com/RL10N/RL10N and https://libraries.io/github/RL10N\nSummary:\nAlthough the R language is used globally, very few R packages are available in languages other than English. The RL10N project will make it easier for R developers to include translations in their own packages.\n\n\n\nFunded:\n$10,000\nProposed by:\nStephanie Locke\nWebsite:\nhttps://github.com/satrdays\nSummary:\n“SatRDays” are community-led, regional conferences to support collaboration, networking and innovation within the R community. Initially three events will be hosted, with plans for additional meet-ups as the R user base grows.\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://github.com/r-spatial/sf/\nSummary:\nUsing the “Simple Features” standard supported by the Open Geospatial Consortium and the International Organization for Standardization, this tool will simplify analysis on modern geospatial data.\n\n\n\nFunded:\n$10,000\nProposed by:\nLaurent Gatto\nWebsite:\nSummary:\nThis two-day in-person training course will introduce the basics of R programming and address the growing demand for training resources for the R language."
  },
  {
    "objectID": "all-projects/isc-working-groups.html",
    "href": "all-projects/isc-working-groups.html",
    "title": "ISC Working Groups",
    "section": "",
    "text": "ISC working groups provide the mechanism through which the ISC can explore, fund, and manage large collaborative projects. There are primary two modes of collaboration that may make a proposal well suited to be a WG:\n\nThe advice or collaboration of subject matter experts is required to decide the merit or feasibility of a project.\nThe work required for the project requires the skills not possessed by a single individual, or the amount of work required is more than can be accomplished by a single person in a reasonable amount of time.\n\n\n\nYour project will be:\n\nVetted by the relevant experts\nSanctioned by the R Consortium\nReceive the attention of the R Foundation\nBecome visible to the greater R Community\nAdministrative support from the R Consortium\n\n\n\n\nMany working groups are open for anyone. Please see the R Consortium Public Calendar for the next WG meeting you might want to attend.\n\n\n\nCensus: Is developing package recommendations, and other materials for working with census data.\nHealth Technology Assessment (HTA): To cultivate a more collaborative and unified approach to Health Technology Assessment (HTA) analytics work that leverages the power of R to enhance transparency, efficiency, and consistency, accelerating the delivery of innovative treatments to patients.\nMarshaling and Serialization in R: Developing standard practices for marshalling and unmarshalling of R objects. Involve identifying current problems, raising awareness, coming up with technical solutions, which might require additions to base R.\nMultilingual R Documentation: Support multilingual documentation in R.\nR7 Package: Object-Oriented Programming. The R7 package is a new OOP system designed to be a successor to S3 and S4. It has been designed and implemented collaboratively by the R Consortium Object-Oriented Programming Working Group, which includes representatives from R-Core, BioConductor, RStudio/tidyverse, and the wider R community.\nR Certification: Is working to establish a common certification program for proficiency in R.\nR Repositories: Collaboratively exploring how to support, maintain, and improve the tooling for R package distribution.\nR Tables for Regulatory Submission (RTRS): Develop standards for creating tables that meet the requirements of FDA submission documents.\nR Validation Hub: Working to devise a standard for validating packages for the regulated Pharmaceutical industry and create a online repository that will be free to use.\nSubmissions: Focus on IT and platform challenges that must be addressed in order to make “all R” regulatory submissions.\n\n\nActive working groups have public mailing lists to facilitate discussions.\n\n\n\n\nhistoRicalg: This project aims to document and test older Fortran and C and other code that is still essential to the R ecosystem, possibly creating all-R reference codes, hopefully by teaming older and younger workers so knowledge can be shared for the future.\nFuture-proof native APIs for R: Is working to assess current native API usage, gather community input, and work towards an easy-to-understand, consistent and verifiable API that will drive R language adoption.\nR IDEA: Now a Top Level Project. R Community Diversity and Inclusion is a group broadly considering how the R Consortium can best encourage and support diversity and inclusion in the R Community.\nUnified Framework for Distributed Computing in R: Exploring the feasibility of developing a common framework to standardize the programming of distributed applications in R.\nDistributed Computing: Endorse the design of a common abstraction for distributed data structures in R.\n\n\n\nR / Business: R users from different areas of business and financial services collaborating on events and advocacy of R.\nCode Coverage: Develop a tool that addresses feature and platform limitations of existing tools. Helping to improve R software quality through the development of a code coverage tool and promoting the use of code coverage more systematically within the R ecosystem.\n\n\n\n\n\nThe purpose of ISC working groups is to organize collaborative projects under governance of the ISC. Membership in ISC working groups is in principle open to anyone from the R Community who desires to participate. There is no requirement that membership in working groups be restricted to individuals who are employed by R Consortium member companies. Working groups are expected to undertake projects that will bring benefits to the R Community.\n\n\n\nR Consortium Working Groups are authorized by the Infrastructure Steering Committee and operate in accordance with the R Consortium By-Laws and the Charter of the ISC.\nThe ISC may disband a working group at any time at its sole discretion.\n\n\n\nWorking groups may or may not receive funding from the ISC according to the needs of the working group and the budget of the ISC. Budgeting periods are aligned with the R Consortium budgeting year, from January 1 to December 31.\nIf a working group receives funding from the ISC members can manage this budget and dispose of available funds for purposes and projects that have been previously determined by the ISC to be in the scope of the working group’s charter. Spending that represents a significant part of the working group’s budget must be approved by the Executive Director.\nWorking groups may not solicit funds from outside sources without permission of the ISC or the R Consortium’s Executive Director. This includes applying for grants organizations outside of the R Consortium.\nWorking groups may supplement their budgets with income from conferences or other activities. Working groups may not spend in excess of their R Consortium budget grant plus income collected to date without authorization in the form of an additional budget grant from the R Consortium.\nAny income generated by working groups from conferences or activities in excess of the amount to cover the working group’s expenses will be returned to the R Consortium’s general fund at the end of the budgeting period. It is expected that working groups will request a budget each year that is commensurate with the expected income earned and the activities planned for that year.\n\n\n\nWorking group members are expected to represent the best interests of the R Consortium at all times, being cognizant that their activities and behavior reflect directly on the reputation of the R Consortium.\nNo member of a working group, including its leader, may enter into any financial relationship, or legal contract that pertains to their role as a working group member.\nWhen speaking at conferences or other venues about work accomplished by a working group, working group members must properly attribute the work to the working group and promote the R Consortium and working group brand when appropriate.\n\n\n\nWorking groups are required to operate transparently in full public view to the greatest extent possible. This does not preclude holding smaller invitation-only working sessions or “executive” when privacy is warranted.\nWorking groups must keep minutes for all substantial meetings and place the meeting minutes in an appropriate folder of the GitHub repository allocated to the working group. Exceptions to this practice require the approval of the ISC or the Executive Director.\nAll working group activities must be in accordance with city, state and federal laws. Working group members should be regularly reminded that their activities must:\n\ncomply with United States Antitrust laws\nbe conducted according to the R Consortium Code of Conduct\ncomply with appropriate international regulations such as the GDPR regulations of the European Union"
  },
  {
    "objectID": "all-projects/isc-working-groups.html#benefits-of-forming-an-isc-working-group",
    "href": "all-projects/isc-working-groups.html#benefits-of-forming-an-isc-working-group",
    "title": "ISC Working Groups",
    "section": "",
    "text": "Your project will be:\n\nVetted by the relevant experts\nSanctioned by the R Consortium\nReceive the attention of the R Foundation\nBecome visible to the greater R Community\nAdministrative support from the R Consortium"
  },
  {
    "objectID": "all-projects/isc-working-groups.html#join-a-working-group",
    "href": "all-projects/isc-working-groups.html#join-a-working-group",
    "title": "ISC Working Groups",
    "section": "",
    "text": "Many working groups are open for anyone. Please see the R Consortium Public Calendar for the next WG meeting you might want to attend."
  },
  {
    "objectID": "all-projects/isc-working-groups.html#active-working-groups",
    "href": "all-projects/isc-working-groups.html#active-working-groups",
    "title": "ISC Working Groups",
    "section": "",
    "text": "Census: Is developing package recommendations, and other materials for working with census data.\nHealth Technology Assessment (HTA): To cultivate a more collaborative and unified approach to Health Technology Assessment (HTA) analytics work that leverages the power of R to enhance transparency, efficiency, and consistency, accelerating the delivery of innovative treatments to patients.\nMarshaling and Serialization in R: Developing standard practices for marshalling and unmarshalling of R objects. Involve identifying current problems, raising awareness, coming up with technical solutions, which might require additions to base R.\nMultilingual R Documentation: Support multilingual documentation in R.\nR7 Package: Object-Oriented Programming. The R7 package is a new OOP system designed to be a successor to S3 and S4. It has been designed and implemented collaboratively by the R Consortium Object-Oriented Programming Working Group, which includes representatives from R-Core, BioConductor, RStudio/tidyverse, and the wider R community.\nR Certification: Is working to establish a common certification program for proficiency in R.\nR Repositories: Collaboratively exploring how to support, maintain, and improve the tooling for R package distribution.\nR Tables for Regulatory Submission (RTRS): Develop standards for creating tables that meet the requirements of FDA submission documents.\nR Validation Hub: Working to devise a standard for validating packages for the regulated Pharmaceutical industry and create a online repository that will be free to use.\nSubmissions: Focus on IT and platform challenges that must be addressed in order to make “all R” regulatory submissions.\n\n\nActive working groups have public mailing lists to facilitate discussions."
  },
  {
    "objectID": "all-projects/isc-working-groups.html#completed-working-groups",
    "href": "all-projects/isc-working-groups.html#completed-working-groups",
    "title": "ISC Working Groups",
    "section": "",
    "text": "histoRicalg: This project aims to document and test older Fortran and C and other code that is still essential to the R ecosystem, possibly creating all-R reference codes, hopefully by teaming older and younger workers so knowledge can be shared for the future.\nFuture-proof native APIs for R: Is working to assess current native API usage, gather community input, and work towards an easy-to-understand, consistent and verifiable API that will drive R language adoption.\nR IDEA: Now a Top Level Project. R Community Diversity and Inclusion is a group broadly considering how the R Consortium can best encourage and support diversity and inclusion in the R Community.\nUnified Framework for Distributed Computing in R: Exploring the feasibility of developing a common framework to standardize the programming of distributed applications in R.\nDistributed Computing: Endorse the design of a common abstraction for distributed data structures in R."
  },
  {
    "objectID": "all-projects/isc-working-groups.html#inactive-working-groups",
    "href": "all-projects/isc-working-groups.html#inactive-working-groups",
    "title": "ISC Working Groups",
    "section": "",
    "text": "R / Business: R users from different areas of business and financial services collaborating on events and advocacy of R.\nCode Coverage: Develop a tool that addresses feature and platform limitations of existing tools. Helping to improve R software quality through the development of a code coverage tool and promoting the use of code coverage more systematically within the R ecosystem."
  },
  {
    "objectID": "all-projects/isc-working-groups.html#isc-regulations-and-guidelines",
    "href": "all-projects/isc-working-groups.html#isc-regulations-and-guidelines",
    "title": "ISC Working Groups",
    "section": "",
    "text": "The purpose of ISC working groups is to organize collaborative projects under governance of the ISC. Membership in ISC working groups is in principle open to anyone from the R Community who desires to participate. There is no requirement that membership in working groups be restricted to individuals who are employed by R Consortium member companies. Working groups are expected to undertake projects that will bring benefits to the R Community.\n\n\n\nR Consortium Working Groups are authorized by the Infrastructure Steering Committee and operate in accordance with the R Consortium By-Laws and the Charter of the ISC.\nThe ISC may disband a working group at any time at its sole discretion.\n\n\n\nWorking groups may or may not receive funding from the ISC according to the needs of the working group and the budget of the ISC. Budgeting periods are aligned with the R Consortium budgeting year, from January 1 to December 31.\nIf a working group receives funding from the ISC members can manage this budget and dispose of available funds for purposes and projects that have been previously determined by the ISC to be in the scope of the working group’s charter. Spending that represents a significant part of the working group’s budget must be approved by the Executive Director.\nWorking groups may not solicit funds from outside sources without permission of the ISC or the R Consortium’s Executive Director. This includes applying for grants organizations outside of the R Consortium.\nWorking groups may supplement their budgets with income from conferences or other activities. Working groups may not spend in excess of their R Consortium budget grant plus income collected to date without authorization in the form of an additional budget grant from the R Consortium.\nAny income generated by working groups from conferences or activities in excess of the amount to cover the working group’s expenses will be returned to the R Consortium’s general fund at the end of the budgeting period. It is expected that working groups will request a budget each year that is commensurate with the expected income earned and the activities planned for that year.\n\n\n\nWorking group members are expected to represent the best interests of the R Consortium at all times, being cognizant that their activities and behavior reflect directly on the reputation of the R Consortium.\nNo member of a working group, including its leader, may enter into any financial relationship, or legal contract that pertains to their role as a working group member.\nWhen speaking at conferences or other venues about work accomplished by a working group, working group members must properly attribute the work to the working group and promote the R Consortium and working group brand when appropriate.\n\n\n\nWorking groups are required to operate transparently in full public view to the greatest extent possible. This does not preclude holding smaller invitation-only working sessions or “executive” when privacy is warranted.\nWorking groups must keep minutes for all substantial meetings and place the meeting minutes in an appropriate folder of the GitHub repository allocated to the working group. Exceptions to this practice require the approval of the ISC or the Executive Director.\nAll working group activities must be in accordance with city, state and federal laws. Working group members should be regularly reminded that their activities must:\n\ncomply with United States Antitrust laws\nbe conducted according to the R Consortium Code of Conduct\ncomply with appropriate international regulations such as the GDPR regulations of the European Union"
  },
  {
    "objectID": "all-projects/rugsprogram.html",
    "href": "all-projects/rugsprogram.html",
    "title": "R User Group Grants",
    "section": "",
    "text": "R User Group Grants\nThis page describes how to apply for grants to support R user groups.\nFor any problems or information, please email operations@r-consortium.org\n\n\n2025 RUGs Program\nThe RUGs mission is to facilitate the person-to-person exchange of knowledge in small group settings on a global scale. We continue to believe that the most effective way for people to learn from and about each other, and to set and accomplish common goals is to meet face-to-face on a regular basis. Nevertheless, occasional virtual meetings are acceptable.\nRUGs grants are intended to help people form enduring R user group communities. Active user groups may apply for grants once every calendar year.\nThese grants do not include support for software development or technical projects. Grants to support the R ecosystem’s technical infrastructure are awarded and administered through the ISC Grant Program, which issues a call for proposals two times each year.\n\n📌 Find your local R User Group here\n\n\n\nDuration of the 2025 RUGs Program\nThe 2025 RUGs Program will open on March 1, 2025, and close at midnight PST on September 30, 2025. We reserve the right to close the grant window earlier than anticipated based on the number of applications.\n\n\nHow to apply for a RUGs Program Grant\nTo apply for a grant fill out this form.\n\n\nRequirements\nTo be eligible for a RUGs grant, a user group must:\n\nGroup Organizer must have at least five people in the R User Group\nHave R as a primary focus\nAdhere to the Code of Conduct published on the R Consortium website\nAgree to participate in the RUGs meetup.com Pro program and use their meetup.com site to announce and track meetings\nAcknowledge the R Consortium as a sponsor and display the R Consortium logo on the group’s website\nAgree to write at least two blog posts per year about their group’s activities for possible publication on the R Consortium Blog\nComply with the instructions by completing a W9 Form (US-based groups only) or Wire Transfer form (Groups based outside of the US)\nAgree to the above in a grant agreement via DocuSign\n\n\n\nStructure\nR user groups grants under the RUGs 2025 program come in two parts:\n\nR user groups that are not already participating in the RUGs meetup.com Pro account will be enrolled into this program. The R Consortium will pay the group’s meetup.com fees for twelve months after acceptance into the program. Thereafter, the R Consortium will continue to pay meetup.com dues for participating groups as long as the groups comply with the requirements above, remain active, continue to meet at least once every three months, and use meetup.com to schedule and announce meetings. User group organizers do not need to re-apply for meetup.com Pro account participation if the group’s meetup.com account remains active.\nCash grants typically vary between $500 and $1,250 and depend on group size and special needs.\n\n\n\n\nGeneral Requirements\n\nMust agree to write 2 blog posts a year\nPost photos of their meetings onto Meetup.com as appropriate\nUpload available material to the R Consortium GitHub Repository\n\n\n\nRUGs Grant Amounts and Groups’ Responsibilities\nBrand new R User Group\n\nThe group receives a grant of $500 and membership in Meetup pro\nThe group must show 5 people committed to the group\nR Consortium will provide the blog link and best practice guide\nThe group must agree to write two blog posts per year\n\nTo get a grant of up to $750, all of the above plus:\n\nThe group must meet at least 1 time every 3 months\nThe group must have more than 25 people at the meeting\nThe group must have photos of the meeting\nThe group must show R Consortium Sponsorship\n\nTo get a grant of up to $1,250, all of the above plus:\n\nThe group must meet at least twice every 3 months\nThe group must have more than 50 people at the meeting\nThe group should provide presentations available for others (The R Consortium will host on GitHub)\n\n\nNotes\n\nR-Ladies maintains a separate meetup.com Pro account. R-Ladies groups must apply directly to R-Ladies for acceptance into their program. They will not be automatically entered into the RUGs meetup.com Pro account.\nThe R Consortium maintains the right to terminate the RUG’s Pro program at any time. Additionally, The R Consortium has the right to terminate a group’s participation in the meetup.com Pro program if they do not comply with the requirements specified in the Code of Conduct.\nIf you are seeking information for a conference, please email your prospectus to marketing@r-consortium.org.\n\n\n\nAlso, note that any training materials developed with R Consortium funds must be made publicly available with an open source license.\n\n\nHow to Apply for a RUGs Grant\nApply for a grant by filling out this form."
  },
  {
    "objectID": "all-projects/2018-group-2.html",
    "href": "all-projects/2018-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nCatalyzing R-hub adoption through R package developer advocacy\nData-Driven Discovery and Tracking of R Consortium Activities\nEditorial assistance for the R Journal\nLicensing R - Guidelines and tools\nNext-generation text layout in grid and ggplot2\nStrengthening of R in support of spatial data infrastructures management : geometa and ows4R R packages\nSymbolic Formulae for Linear Mixed Models\nserveRless\n\n\n\n\nFunded:\n$46,050\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://blog.r-hub.io\nSummary:\nAfter the continuing technical progress of R-hub over the last two years, this project aims at catalizing its adoption by R package developers of all levels through developer advocacy. Indeed, R-hub is currently a successful and very valuable project, but it is not documented thoroughly, which hinders its wider adoption by package developers. This project shall answer this concern by three main actions: improving R-hub documentation, making R-hub better known in the community and making the R-hub web site more attractive to, and easier to use by, R developers and users via the ingestion of METACRAN services and the creation of a R-hub blog.\n\n\n\nFunded:\n$5,250\nProposed by:\nBenaiah Chibuokem Ubah\nWebsite:\nhttps://benubah.github.io/r-community-explorer/rugs.html\nSummary:\nThis project proposes an infrastructure that provides a data-driven approach to render the yearly activities of the R Consortium, by deploying web pages for discovering and tracking ISC Funded Projects, RUGS and Marketing activities. These pages are planned to appear like dashboards summarizing activities in interactive tables and charts, presenting several views, trends and insights to what R Consortium has achieved over time. The project hopes that presenting these achievements in a data-driven manner to the R community, the data science community and prospective R Consortium members will promote greater transparency, productivity and community inclusiveness around R Consortium activities.\n\n\n\nFunded:\n$50,000\nProposed by:\nDianne Cook\nWebsite:\nhttps://rjpilot.netlify.app/\nSummary:\nThis project supports the operation of the R Journal. There are two aspects, one is to fund an editorial assistant to send reminders about reviews, and assist with typesetting and copyediting issues. The second part is to explore updating the technical operations of the journal production.\n\n\n\nFunded:\n$6,000\nProposed by:\nColin Fay\nWebsite:\nhttps://github.com/ThinkR-open/isc-proposal-licence/ and https://thinkr-open.github.io/licensing-r/intro.html#getting-a-more-global-idea and https://github.com/ThinkR-open/isc-proposal-licence/blob/master/proposal_licence.md\nSummary:\nLicensing is a vital part of Open Source. It provides guidelines for interacting with a program, and for making code accessible and reusable (or not). It provides a way to make code open source, in a way one wants to share it, protecting how it will be used and reused. Licensing is also challenging and complex: there are a lot of available licenses, and the choice is influenced by how you import and interact with elements from other packages and/or programs.\nWith this project, we propose to explore and document the current state of open source licenses in R, and to decipher compatibility and incompatibly elements inside these licenses, to help developers chose the best suited licence for their project.\n\n\n\nFunded:\n$25,000\nProposed by:\nClaus Wilke\nWebsite:\nhttps://wilkelab.org/gridtext/\nSummary:\nText is a key component of any data visualization. We need to label axes and legends, we need to annotate or highlight specific data points, and we need to provide plot titles and captions. The R graphics package ggplot2 provides numerous features to customize the labeling and annotation of plots, but ultimately it is limited by the current capabilities of the underlying graphics libary it uses, grid. Grid can draw simple text strings or mathematical expressions (via plotmath) in different colors, sizes, and fonts. However, it lacks functionality for changing formatting within a string (e.g., draw a single word in italics or in a different color), and it also cannot draw text boxes, where the text is enclosed in a box with defined margins, padding, or background color. This project will support the development of a new package, gridtext, that will alleviate these text formatting limitations. The project will also support efforts to make these new capabilities available from within ggplot2.\n\n\n\nFunded:\n$20,000\nProposed by:\nEmmanuel Blondel\nWebsite:\nSummary:\nThe project aims to strengthen the role of R in support of Spatial Data Infrastructures (SDI) management, through major enhancements of the geometa R package which offers tools for reading and writing ISO/OGC geographic metadata, including ISO 19115, 19110, and 19119 through the ISO 19139 XML format. This also extends to the Geographic Markup Language (GML - ISO 19136) used for describing geographic data. The use of geometa in combination with publication tools such as ows4R ( https://cran.r-project.org/package=ows4R ) and geosapi (https://cran.r-project.org/package=geosapi) fosters the use of R software to ease the management and publication of metadata documents and related datasets in web catalogues, and then allows to move forward with a real R implementation of spatial data management plans based on FAIR (Findable, Accessible Interoperable and Reusable) principles.\nThe workplan includes several activities such as working on the completeness of the ISO 19115 (ISO 19115-1 and 19115-2) data model in geometa, functions to read/write multilingual metadata documents, and an increased metadata validation capability with a validator targeting the EU INSPIRE directive. Finally, functions will be made available to convert between geometa ISO/OGC metadata objects and other known metadata objects such as NetCDF-CF and EML (Ecological Metadata Language) to foster metadata interoperability. By providing these R tools, we seek to facilitate the work of spatial data (GIS) managers, but also data scientists, whatever the thematic domain, whose daily tasks consist in handling data, describing them with metadata and publishing datasets.\n\n\n\nFunded:\n$6,000\nProposed by:\nEmi Tanaka\nWebsite:\nSummary:\nSymbolic model formulae define the structural component of a statistical model in an easier and often more accessible terms for practitioners. The earlier instance of symbolic model formulae for linear models was applied in Genstat with further generalisation by Wilkinson and Rogers (1973). Chambers and Hastie (1993) describe the symbolic model formulae implementation for linear models in the S language which remains much the same in the R language (Venables et al. 2018).\nLinear mixed models (LMMs) are widely used across many disciplines (e.g. ecology, psychology, agriculture, finance etc) due to its flexibility to model complex, correlated structures in the data. While the symbolic formula of linear models generally have a consistent representation and evaluation rule as implemented in stats::formula, this is not the case for LMMs. The inconsistency of symbolic formulae arises mainly in the representation of random effects, with the additional need to specify the variance-covariance structure of the random effects as well as structure of the associated model matrix that governs how the random effects are mapped to (groups of) the observational units. The differences give rise to confusion of equivalent model specification in different R-packages.\nThe lack of consistency in symbolic formula and model representation across mixed model software motivates the need to formulate a unified symbolic model formulae for LMMs with: (1) extension of the evaluation rules described in Wilkinson and Rogers (1973); and (2) ease of comprehension of the specified model for the user. This symbolic model formulae can be a basis for creating a common API to mixed models with wrappers to popular mixed model R-packages, thereby achieving a similar feat to parsnip R-package (Kuhn 2018) which implements a tidy unified interface to many predictive modelling functions (e.g. random forest, logistic regression, survival models etc).\nWe would like to find out what are your experiences with fitting linear mixed model in R! Please fill out the survey below to help us understand your problems: https://docs.google.com/forms/d/e/1FAIpQLSeblEoPtDmPS-dH2dmsHjLxLuKl19UY1JdmTrZux-AUSq3N7Q/viewform?usp=sf_link\n\n\n\nFunded:\n$10,000\nProposed by:\nChristoph Bodner, Florian Schwendinger, Thomas Laber\nWebsite:\nhttps://github.com/harlecin/serverless\nSummary:\nR is a great language for rapid prototyping and experimentation, but putting an R model in production is still more complex and time-consuming than it needs to be. With the growing popularity of serverless computing frameworks such as AWS Lambda and Azure Functions we see a a huge chance to allow R developers to more easily deploy their code into production. We want to build an R package called ‘serverless’ to allow R users to easily deploy scripts and custom R packages to AWS Lambda and in a second step to Azure Functions. Our main goal is to build a user-friendly cloud agnostic wrapper that can be extended to include additional cloud providers later on. We want to build on the work already done for deploying R functions to AWS Lambda by Philipp Schirmer and on the work already done by Neal Fultz and Gergely Daróczi on a gRPC client/server for R, which is necessary for Azure Functions. If you like our idea and want to help us, feel free to reach out to us on Github at https://github.com/harlecin/serverless\nBest,\nChristoph, Florian and Thomas"
  },
  {
    "objectID": "all-projects/2018-group-2.html#funded-isc-grants-2018-2",
    "href": "all-projects/2018-group-2.html#funded-isc-grants-2018-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nCatalyzing R-hub adoption through R package developer advocacy\nData-Driven Discovery and Tracking of R Consortium Activities\nEditorial assistance for the R Journal\nLicensing R - Guidelines and tools\nNext-generation text layout in grid and ggplot2\nStrengthening of R in support of spatial data infrastructures management : geometa and ows4R R packages\nSymbolic Formulae for Linear Mixed Models\nserveRless\n\n\n\n\nFunded:\n$46,050\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://blog.r-hub.io\nSummary:\nAfter the continuing technical progress of R-hub over the last two years, this project aims at catalizing its adoption by R package developers of all levels through developer advocacy. Indeed, R-hub is currently a successful and very valuable project, but it is not documented thoroughly, which hinders its wider adoption by package developers. This project shall answer this concern by three main actions: improving R-hub documentation, making R-hub better known in the community and making the R-hub web site more attractive to, and easier to use by, R developers and users via the ingestion of METACRAN services and the creation of a R-hub blog.\n\n\n\nFunded:\n$5,250\nProposed by:\nBenaiah Chibuokem Ubah\nWebsite:\nhttps://benubah.github.io/r-community-explorer/rugs.html\nSummary:\nThis project proposes an infrastructure that provides a data-driven approach to render the yearly activities of the R Consortium, by deploying web pages for discovering and tracking ISC Funded Projects, RUGS and Marketing activities. These pages are planned to appear like dashboards summarizing activities in interactive tables and charts, presenting several views, trends and insights to what R Consortium has achieved over time. The project hopes that presenting these achievements in a data-driven manner to the R community, the data science community and prospective R Consortium members will promote greater transparency, productivity and community inclusiveness around R Consortium activities.\n\n\n\nFunded:\n$50,000\nProposed by:\nDianne Cook\nWebsite:\nhttps://rjpilot.netlify.app/\nSummary:\nThis project supports the operation of the R Journal. There are two aspects, one is to fund an editorial assistant to send reminders about reviews, and assist with typesetting and copyediting issues. The second part is to explore updating the technical operations of the journal production.\n\n\n\nFunded:\n$6,000\nProposed by:\nColin Fay\nWebsite:\nhttps://github.com/ThinkR-open/isc-proposal-licence/ and https://thinkr-open.github.io/licensing-r/intro.html#getting-a-more-global-idea and https://github.com/ThinkR-open/isc-proposal-licence/blob/master/proposal_licence.md\nSummary:\nLicensing is a vital part of Open Source. It provides guidelines for interacting with a program, and for making code accessible and reusable (or not). It provides a way to make code open source, in a way one wants to share it, protecting how it will be used and reused. Licensing is also challenging and complex: there are a lot of available licenses, and the choice is influenced by how you import and interact with elements from other packages and/or programs.\nWith this project, we propose to explore and document the current state of open source licenses in R, and to decipher compatibility and incompatibly elements inside these licenses, to help developers chose the best suited licence for their project.\n\n\n\nFunded:\n$25,000\nProposed by:\nClaus Wilke\nWebsite:\nhttps://wilkelab.org/gridtext/\nSummary:\nText is a key component of any data visualization. We need to label axes and legends, we need to annotate or highlight specific data points, and we need to provide plot titles and captions. The R graphics package ggplot2 provides numerous features to customize the labeling and annotation of plots, but ultimately it is limited by the current capabilities of the underlying graphics libary it uses, grid. Grid can draw simple text strings or mathematical expressions (via plotmath) in different colors, sizes, and fonts. However, it lacks functionality for changing formatting within a string (e.g., draw a single word in italics or in a different color), and it also cannot draw text boxes, where the text is enclosed in a box with defined margins, padding, or background color. This project will support the development of a new package, gridtext, that will alleviate these text formatting limitations. The project will also support efforts to make these new capabilities available from within ggplot2.\n\n\n\nFunded:\n$20,000\nProposed by:\nEmmanuel Blondel\nWebsite:\nSummary:\nThe project aims to strengthen the role of R in support of Spatial Data Infrastructures (SDI) management, through major enhancements of the geometa R package which offers tools for reading and writing ISO/OGC geographic metadata, including ISO 19115, 19110, and 19119 through the ISO 19139 XML format. This also extends to the Geographic Markup Language (GML - ISO 19136) used for describing geographic data. The use of geometa in combination with publication tools such as ows4R ( https://cran.r-project.org/package=ows4R ) and geosapi (https://cran.r-project.org/package=geosapi) fosters the use of R software to ease the management and publication of metadata documents and related datasets in web catalogues, and then allows to move forward with a real R implementation of spatial data management plans based on FAIR (Findable, Accessible Interoperable and Reusable) principles.\nThe workplan includes several activities such as working on the completeness of the ISO 19115 (ISO 19115-1 and 19115-2) data model in geometa, functions to read/write multilingual metadata documents, and an increased metadata validation capability with a validator targeting the EU INSPIRE directive. Finally, functions will be made available to convert between geometa ISO/OGC metadata objects and other known metadata objects such as NetCDF-CF and EML (Ecological Metadata Language) to foster metadata interoperability. By providing these R tools, we seek to facilitate the work of spatial data (GIS) managers, but also data scientists, whatever the thematic domain, whose daily tasks consist in handling data, describing them with metadata and publishing datasets.\n\n\n\nFunded:\n$6,000\nProposed by:\nEmi Tanaka\nWebsite:\nSummary:\nSymbolic model formulae define the structural component of a statistical model in an easier and often more accessible terms for practitioners. The earlier instance of symbolic model formulae for linear models was applied in Genstat with further generalisation by Wilkinson and Rogers (1973). Chambers and Hastie (1993) describe the symbolic model formulae implementation for linear models in the S language which remains much the same in the R language (Venables et al. 2018).\nLinear mixed models (LMMs) are widely used across many disciplines (e.g. ecology, psychology, agriculture, finance etc) due to its flexibility to model complex, correlated structures in the data. While the symbolic formula of linear models generally have a consistent representation and evaluation rule as implemented in stats::formula, this is not the case for LMMs. The inconsistency of symbolic formulae arises mainly in the representation of random effects, with the additional need to specify the variance-covariance structure of the random effects as well as structure of the associated model matrix that governs how the random effects are mapped to (groups of) the observational units. The differences give rise to confusion of equivalent model specification in different R-packages.\nThe lack of consistency in symbolic formula and model representation across mixed model software motivates the need to formulate a unified symbolic model formulae for LMMs with: (1) extension of the evaluation rules described in Wilkinson and Rogers (1973); and (2) ease of comprehension of the specified model for the user. This symbolic model formulae can be a basis for creating a common API to mixed models with wrappers to popular mixed model R-packages, thereby achieving a similar feat to parsnip R-package (Kuhn 2018) which implements a tidy unified interface to many predictive modelling functions (e.g. random forest, logistic regression, survival models etc).\nWe would like to find out what are your experiences with fitting linear mixed model in R! Please fill out the survey below to help us understand your problems: https://docs.google.com/forms/d/e/1FAIpQLSeblEoPtDmPS-dH2dmsHjLxLuKl19UY1JdmTrZux-AUSq3N7Q/viewform?usp=sf_link\n\n\n\nFunded:\n$10,000\nProposed by:\nChristoph Bodner, Florian Schwendinger, Thomas Laber\nWebsite:\nhttps://github.com/harlecin/serverless\nSummary:\nR is a great language for rapid prototyping and experimentation, but putting an R model in production is still more complex and time-consuming than it needs to be. With the growing popularity of serverless computing frameworks such as AWS Lambda and Azure Functions we see a a huge chance to allow R developers to more easily deploy their code into production. We want to build an R package called ‘serverless’ to allow R users to easily deploy scripts and custom R packages to AWS Lambda and in a second step to Azure Functions. Our main goal is to build a user-friendly cloud agnostic wrapper that can be extended to include additional cloud providers later on. We want to build on the work already done for deploying R functions to AWS Lambda by Philipp Schirmer and on the work already done by Neal Fultz and Gergely Daróczi on a gRPC client/server for R, which is necessary for Azure Functions. If you like our idea and want to help us, feel free to reach out to us on Github at https://github.com/harlecin/serverless\nBest,\nChristoph, Florian and Thomas"
  },
  {
    "objectID": "all-projects/2023-group-1.html",
    "href": "all-projects/2023-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nThe future of DBI (extension 1)\nSecure TLS Communications for R\nvolcalc: Calculate predicted volatility of chemical compounds\nautotest: Automated testing of R packages\napi2r: An R Package for Auto-Generating R API Clients\n\n\n\n\nFunded:\n$10,000\nProposed by:\nKirill Müller\nSummary:\nThis proposal mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Keeping compatibility with the evolving ecosystem (OS, databases, R itself, other packages) is vital for the long-term success of the project.\n\n\n\nFunded:\n$10,000\nProposed by:\nCharlie Gao\nSummary:\nThe project aims to implement secure connections with a TLS layer for encrypted communications in distributed systems used by statisticians and data scientists. The current lack of secure communication tools restricts the use of existing R packages for long-running tasks to trusted local networks, posing security risks in compromised or untrusted environments. The proposed solution addresses this gap by providing encryption and authentication of endpoints, ensuring data security in line with industry standards.\n\n\n\nFunded:\n$12,265\nProposed by:\nKristina Riemer\nSummary:\nThis ISC funded project focuses on the development of the volcalc R package, which automates the estimation of compound volatility based on their chemical structure. The package streamlines the process by downloading chemical structure data, parsing it to identify functional groups, and utilizing the SIMPOL.1 algorithm to predict volatility using functional groups and molecular weight. The compounds are then assigned volatility categories based on a reference environment. This project aims to enhance the package by expanding its compatibility to work with any chemical compound with structural information from various databases. Additionally, improvements in testing and documentation will be implemented to enhance the reliability of the package.\n\n\n\nFunded:\n$3,000\nProposed by:\nMark Padgham\nSummary:\nThe project aims to develop an R package to automate property-based testing procedures in R, building upon the existing “typetracer” package. The new package will utilize “typetracer” to infer properties of function parameters and systematically mutate or randomize these properties to facilitate automated testing. The package will inherit the GPL-3 license from its predecessor and will be submitted to CRAN for wider dissemination. This initiative aligns with the goal of promoting efficient and reliable testing practices within the R community.\n\n\n\nFunded:\n$15,750\nProposed by:\nJon Harmon\nSummary:\nThis project aims to develop an R package called api2r, which will automate the creation of R package structures for APIs that adhere to the OpenAPI Specification (OAS). By leveraging the OAS as a foundation, api2r will significantly reduce the time and effort required to build API clients in R. This initiative hopes to have a widespread impact within the R community, benefiting data scientists, researchers, and developers who regularly interact with diverse APIs. To ensure its functionality and effectiveness, the development process will involve generating packages based on at least three authentic OpenAPI specifications."
  },
  {
    "objectID": "all-projects/2023-group-1.html#funded-isc-grants-2023-1",
    "href": "all-projects/2023-group-1.html#funded-isc-grants-2023-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nThe future of DBI (extension 1)\nSecure TLS Communications for R\nvolcalc: Calculate predicted volatility of chemical compounds\nautotest: Automated testing of R packages\napi2r: An R Package for Auto-Generating R API Clients\n\n\n\n\nFunded:\n$10,000\nProposed by:\nKirill Müller\nSummary:\nThis proposal mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Keeping compatibility with the evolving ecosystem (OS, databases, R itself, other packages) is vital for the long-term success of the project.\n\n\n\nFunded:\n$10,000\nProposed by:\nCharlie Gao\nSummary:\nThe project aims to implement secure connections with a TLS layer for encrypted communications in distributed systems used by statisticians and data scientists. The current lack of secure communication tools restricts the use of existing R packages for long-running tasks to trusted local networks, posing security risks in compromised or untrusted environments. The proposed solution addresses this gap by providing encryption and authentication of endpoints, ensuring data security in line with industry standards.\n\n\n\nFunded:\n$12,265\nProposed by:\nKristina Riemer\nSummary:\nThis ISC funded project focuses on the development of the volcalc R package, which automates the estimation of compound volatility based on their chemical structure. The package streamlines the process by downloading chemical structure data, parsing it to identify functional groups, and utilizing the SIMPOL.1 algorithm to predict volatility using functional groups and molecular weight. The compounds are then assigned volatility categories based on a reference environment. This project aims to enhance the package by expanding its compatibility to work with any chemical compound with structural information from various databases. Additionally, improvements in testing and documentation will be implemented to enhance the reliability of the package.\n\n\n\nFunded:\n$3,000\nProposed by:\nMark Padgham\nSummary:\nThe project aims to develop an R package to automate property-based testing procedures in R, building upon the existing “typetracer” package. The new package will utilize “typetracer” to infer properties of function parameters and systematically mutate or randomize these properties to facilitate automated testing. The package will inherit the GPL-3 license from its predecessor and will be submitted to CRAN for wider dissemination. This initiative aligns with the goal of promoting efficient and reliable testing practices within the R community.\n\n\n\nFunded:\n$15,750\nProposed by:\nJon Harmon\nSummary:\nThis project aims to develop an R package called api2r, which will automate the creation of R package structures for APIs that adhere to the OpenAPI Specification (OAS). By leveraging the OAS as a foundation, api2r will significantly reduce the time and effort required to build API clients in R. This initiative hopes to have a widespread impact within the R community, benefiting data scientists, researchers, and developers who regularly interact with diverse APIs. To ensure its functionality and effectiveness, the development process will involve generating packages based on at least three authentic OpenAPI specifications."
  },
  {
    "objectID": "all-projects/2024-group-2.html",
    "href": "all-projects/2024-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nR-Universe: towards a unifying infrastructure and global catalog for the wider R ecosystem\nAmbiorix - A web framework for R\nDeepRHealth – A Deep Learning Toolkit for Healthcare Predictive Modeling\nCpp11armadillo: An ‘Armadillo’ Interface (C++)\naggreCAT: An R package for mathematical aggregation of expert elicitation data\nCOVID-19 Data Hub\nLaunching the Probaverse\n\n\n\n\nFunded:\n$40,950\nProposed by:\nJeroen Ooms, Noam Ross\nSummary:\nR-Universe is a rapidly evolving platform that fills a need for modern, scalable, user-friendly publishing in the R ecosystem. At first glance, it serves as a global catalog of software, articles, and datasets found on CRAN, BioConductor, as well as self-published repositories. It aids discovery through a powerful search engine that indexes and ranks all content using\nR specific criteria, and by cross referencing related projects based on authorship and topics. For each package, extensive information is made available through attractive webpages and APIs that include rendered documentation, health and activity metrics, binaries and installation instructions, and a wealth of other material to learn about a project and get started using it.\nFor developers, R-universe serves as a publication platform providing a fully automated pipelinemfor testing, building, and publishing R packages. In this sense R-universe can be seen as a meta-repository and common infrastructure for both individuals or organizations to manage custom R package repositories using their own approach to curation, release management, and quality control. The build system is based on the inherently scalable GitHub Actions infrastructure, making it easy to maintain and extend. This way R-Universe enhances R’s promise as a multi-repository-by-design ecosystem, reducing the barrier to entry for groups of all scales.\n\n\n\nFunded:\n$5,000\nProposed by:\nKennedy Mwavu\nSummary:\nThis proposal seeks funding to advance the ambiorix R web framework, addressing the critical gap in the R ecosystem for a robust, feature-rich, and production-ready web application framework.\n\n\n\nFunded:\n$5,000\nProposed by:\nJunyi Gao\nSummary:\nDeepRHealth is a deep learning library specifically designed for healthcare applications in R. Based on the common healthcare data analytics pipelines and modelling benchmarks, the toolkit will have four main modules: EHR database module, prediction task module, healthcare DL core module, and EHR code mapping module.\n\n\n\nFunded:\n$8,830\nProposed by:\nMauricio Vargas Sepulveda\nSummary:\ncpp11armadillo was initiated by Mauricio Vargas while needing an integration between R and Armadillo (C++) compatible with the header-only package cpp11. For the first cpp11armadillo version, we focused on the correctness and safety of templates that facilitate sending data from R to C++ and vice versa. The plan is to finish a new cpp11armadillo version focus on speed optimization and maintaining the goal of a lower coding effort from the final user.\nWe aim to provide a high quality package oriented to user that require to use linear algebra operations.\nThe ultimate aim of the project is to produce a package that provides speed and helps to address some bottlenecks in R without compromising safety.\n\n\n\nFunded:\n$1,000\nProposed by:\nDavid Wilkinson\nSummary:\nWe are developing the aggreCAT R package as an accessible, user-friendly, open source mathematical aggregation software for elicited expert judgements. Initially developed for purpose as part of the repliCATS (Collaborative Assessment of Trustworthy Science) project within the international DARPA-SCORE program, we are currently in the process of updating the package to be a more general and widely-applicable aggregation package. The aggreCAT package provides a suite of 29 aggregation methods, including those available in existing software, that explore different approaches to mathematical aggregation from straight-forward arithmetic calculations to Bayesian statistical models. In addition we provide extra functionality such as plotting and performance evaluation against known outcomes. The aggreCAT package fills a large void in open software for aggregating elicited judgements, providing enormous benefit to researchers and decision makers across any field of research.\n\n\n\nFunded:\n$1,000\nProposed by:\nEmanuele Guidotti\nSummary:\nIn March 2020, I started “COVID-19 Data Hub” – a project to provide the research community with a unified dataset by collecting worldwide fine-grained case data merged with exogenous variables to better understand COVID-19.\nThe project was initiated via the R package COVID19, designed to harmonize data from several sources. In April 2020, the project was funded by the Canadian Institute for Data Valorization IVADO. The project won the CovidR contest in May, it was presented at the European R Users Meeting in June, and has been supported by the R Consortium since 2021.\nTo date, the database provides the daily time series of COVID-19 cases, deaths, recovered people, tests, vaccinations, and hospitalizations for more than 230 countries, 760 regions, and 12,000 lower-level administrative divisions. The geographical entities are associated with identifiers to match with hydrometeorological, geospatial, and mobility data, among others. By unifying the access to the data, this work makes it possible to study the pandemic on its global scale with high resolution, taking into account within-country variations, nonpharmaceutical interventions, and environmental and exogenous variables.\nOverall, the R package COVID19 is one of the most downloaded packages related to the pandemic and the corresponding data have been downloaded over 6 million times.\n\n\n\nFunded:\n$5,000\nProposed by:\nVincenzo Coia\nSummary:\nThe probaverse is a free, open source, and permissive suite of packages in R whose mission is to facilitate the exploration of the full space of possible outcomes in an analysis. It elevates probability distributions as tangible objects that realistically represent data / systems, workable through a principled grammar. It is inspired by the tidyverse, but for distributions.\nThis project is about refactoring the distribution object in distionary, the foundation of the probaverse, which defines the distribution object and its evaluation, and to submit the package to CRAN, due to its importance in the overall probaverse workflow."
  },
  {
    "objectID": "all-projects/2024-group-2.html#funded-isc-grants-2024-2",
    "href": "all-projects/2024-group-2.html#funded-isc-grants-2024-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nR-Universe: towards a unifying infrastructure and global catalog for the wider R ecosystem\nAmbiorix - A web framework for R\nDeepRHealth – A Deep Learning Toolkit for Healthcare Predictive Modeling\nCpp11armadillo: An ‘Armadillo’ Interface (C++)\naggreCAT: An R package for mathematical aggregation of expert elicitation data\nCOVID-19 Data Hub\nLaunching the Probaverse\n\n\n\n\nFunded:\n$40,950\nProposed by:\nJeroen Ooms, Noam Ross\nSummary:\nR-Universe is a rapidly evolving platform that fills a need for modern, scalable, user-friendly publishing in the R ecosystem. At first glance, it serves as a global catalog of software, articles, and datasets found on CRAN, BioConductor, as well as self-published repositories. It aids discovery through a powerful search engine that indexes and ranks all content using\nR specific criteria, and by cross referencing related projects based on authorship and topics. For each package, extensive information is made available through attractive webpages and APIs that include rendered documentation, health and activity metrics, binaries and installation instructions, and a wealth of other material to learn about a project and get started using it.\nFor developers, R-universe serves as a publication platform providing a fully automated pipelinemfor testing, building, and publishing R packages. In this sense R-universe can be seen as a meta-repository and common infrastructure for both individuals or organizations to manage custom R package repositories using their own approach to curation, release management, and quality control. The build system is based on the inherently scalable GitHub Actions infrastructure, making it easy to maintain and extend. This way R-Universe enhances R’s promise as a multi-repository-by-design ecosystem, reducing the barrier to entry for groups of all scales.\n\n\n\nFunded:\n$5,000\nProposed by:\nKennedy Mwavu\nSummary:\nThis proposal seeks funding to advance the ambiorix R web framework, addressing the critical gap in the R ecosystem for a robust, feature-rich, and production-ready web application framework.\n\n\n\nFunded:\n$5,000\nProposed by:\nJunyi Gao\nSummary:\nDeepRHealth is a deep learning library specifically designed for healthcare applications in R. Based on the common healthcare data analytics pipelines and modelling benchmarks, the toolkit will have four main modules: EHR database module, prediction task module, healthcare DL core module, and EHR code mapping module.\n\n\n\nFunded:\n$8,830\nProposed by:\nMauricio Vargas Sepulveda\nSummary:\ncpp11armadillo was initiated by Mauricio Vargas while needing an integration between R and Armadillo (C++) compatible with the header-only package cpp11. For the first cpp11armadillo version, we focused on the correctness and safety of templates that facilitate sending data from R to C++ and vice versa. The plan is to finish a new cpp11armadillo version focus on speed optimization and maintaining the goal of a lower coding effort from the final user.\nWe aim to provide a high quality package oriented to user that require to use linear algebra operations.\nThe ultimate aim of the project is to produce a package that provides speed and helps to address some bottlenecks in R without compromising safety.\n\n\n\nFunded:\n$1,000\nProposed by:\nDavid Wilkinson\nSummary:\nWe are developing the aggreCAT R package as an accessible, user-friendly, open source mathematical aggregation software for elicited expert judgements. Initially developed for purpose as part of the repliCATS (Collaborative Assessment of Trustworthy Science) project within the international DARPA-SCORE program, we are currently in the process of updating the package to be a more general and widely-applicable aggregation package. The aggreCAT package provides a suite of 29 aggregation methods, including those available in existing software, that explore different approaches to mathematical aggregation from straight-forward arithmetic calculations to Bayesian statistical models. In addition we provide extra functionality such as plotting and performance evaluation against known outcomes. The aggreCAT package fills a large void in open software for aggregating elicited judgements, providing enormous benefit to researchers and decision makers across any field of research.\n\n\n\nFunded:\n$1,000\nProposed by:\nEmanuele Guidotti\nSummary:\nIn March 2020, I started “COVID-19 Data Hub” – a project to provide the research community with a unified dataset by collecting worldwide fine-grained case data merged with exogenous variables to better understand COVID-19.\nThe project was initiated via the R package COVID19, designed to harmonize data from several sources. In April 2020, the project was funded by the Canadian Institute for Data Valorization IVADO. The project won the CovidR contest in May, it was presented at the European R Users Meeting in June, and has been supported by the R Consortium since 2021.\nTo date, the database provides the daily time series of COVID-19 cases, deaths, recovered people, tests, vaccinations, and hospitalizations for more than 230 countries, 760 regions, and 12,000 lower-level administrative divisions. The geographical entities are associated with identifiers to match with hydrometeorological, geospatial, and mobility data, among others. By unifying the access to the data, this work makes it possible to study the pandemic on its global scale with high resolution, taking into account within-country variations, nonpharmaceutical interventions, and environmental and exogenous variables.\nOverall, the R package COVID19 is one of the most downloaded packages related to the pandemic and the corresponding data have been downloaded over 6 million times.\n\n\n\nFunded:\n$5,000\nProposed by:\nVincenzo Coia\nSummary:\nThe probaverse is a free, open source, and permissive suite of packages in R whose mission is to facilitate the exploration of the full space of possible outcomes in an analysis. It elevates probability distributions as tangible objects that realistically represent data / systems, workable through a principled grammar. It is inspired by the tidyverse, but for distributions.\nThis project is about refactoring the distribution object in distionary, the foundation of the probaverse, which defines the distribution object and its evaluation, and to submit the package to CRAN, due to its importance in the overall probaverse workflow."
  },
  {
    "objectID": "all-projects/2023-group-2.html",
    "href": "all-projects/2023-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nTranslating R to Nepali\nRStats Mastodon Server\nTooling for internationalization of R help pages\nAccessibility Enhancements for the R Journal\nTaking r-universe to the next level\nR Kafka Client\n\n\n\n\nFunded:\n$1,000\nProposed by:\nBinod Jung Bogati, R User Group Nepal\nSummary:\nThis project aims to bridge language gaps within the R community by translating essential R resources into Nepali. This inclusivity will attract diverse talents and perspectives, fostering innovation and growth within the community. We are working with the R User Group Nepal community for a series of Translation hackathons and follow-up meetings. This initiative started before the R Project Sprint 2023 with the assistance of the R User Group Nepal.\n\n\n\nFunded:\n$1,306.80\nProposed by:\nDan Wilson, The Data Collective Consulting Pty Ltd\nSummary:\nTo help create a place for social connection to the broad R community that isn’t focussed on any specific subgroup of r users, we’d like funding to help establish an RStats Mastodon server. The goal would be to be funded for the first year with a grant from the R Consortium and develop a pathway for user funding like other Mastodon servers.\n\n\n\nFunded:\n$20,800\nProposed by:\nElio Campitelli\nSummary:\nWe propose a system in which either package maintainers or community members could create translation modules of specific packages. Users would then be able to install those translation modules and browse their documentation. By default, help() would display the documentation in the user’s preferred language if available, and fall-back to the canonical documentation otherwise. It would also include a link to the canonical documentation and warnings if translations are not up to date.\n\n\n\nFunded:\n$5,000\nProposed by:\nMalcolm Barrett\nSummary:\nIn response to a growing demand for accessible and comprehensive educational resources in causal inference within the R community, we propose the development of a Causal Inference In a Box course. Leveraging a “teach the teacher” model and building on the successful Data Science in a Box template, we will provide instructional materials, including slide decks, lab exercises, and assessments, all meticulously designed to facilitate effective learning. Additionally, we are committed to ensuring inclusivity by offering alternative formats for diverse learning preferences. This comprehensive course, supported by dedicated pedagogical software tools, will revolutionize how practitioners approach causal inference in the R environment, ultimately enhancing the quality and reliability of their research and analyses.\n\n\n\nFunded:\n$4,000\nProposed by:\nDianne Cook\nSummary:\nThe plan for the use of this funding is to check and enhance the accessibility of published R Journal articles, and to develop tools to help authors and editors ensure that new R Journal articles are at the cutting edge of accessibility. Checking the published articles will involve manual work to read each article and add meaningful alt text to each image. Screen reader accessibility will be checked using available screen readers, with advice from team member Jonathan Godfrey. Jonathan has already used the screen reader JAWS to read a sample of articles converted from the legacy format and confirms that he can now access 90% of the R Journal content as opposed to 10% previously! We will also work closely with the current editors of the R Journal to assist with checking new submissions, especially those produced with the legacy template. This will also help ensure that new articles have accessible content, with appropriate alt text.\n\n\n\nFunded:\n$40,000\nProposed by:\nJeroen Ooms, rOpenSci\nSummary:\nWe are interested to collaborate with the R consortium to make R-universe a top-level ISC in order to get a variety of stakeholders involved, grow adoption and community ownership, and to be able to guarantee the continued availability of the service to the R community. R-universe has the potential to become the central place where one can find everything the R community has to offer, complementing CRAN with open infrastructure that can continuously be adapted to new needs. Moreover, existing r-hub containers for extra checks can be integrated to make these tools more accessible. We hope to become a flagship project for the consortium, and an example of a mutually beneficial collaboration between its members and the R community.\n\n\n\nFunded:\n$24,000\nProposed by:\nAndreas Neudecker, INWT Statistics GmbH\nSummary:\nThe goal of this project is to create a robust and efficient Kafka client library for R that supports essential functionalities to communicate with a Kafka cluster. The proposed Kafka client for R will be built by creating a wrapper around the C++ librdkafka library, which is maintained and developed by Confluent which was founded by the original developers of Kafka. This approach is already common and produces reliable and stable releases in multiple other programming languages (Python, Rust, Go, …). There are packages for the major linux package managers (Debian, RPM, Gentoo) and it also runs on MacOS X and Windows."
  },
  {
    "objectID": "all-projects/2023-group-2.html#funded-isc-grants-2023-2",
    "href": "all-projects/2023-group-2.html#funded-isc-grants-2023-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nTranslating R to Nepali\nRStats Mastodon Server\nTooling for internationalization of R help pages\nAccessibility Enhancements for the R Journal\nTaking r-universe to the next level\nR Kafka Client\n\n\n\n\nFunded:\n$1,000\nProposed by:\nBinod Jung Bogati, R User Group Nepal\nSummary:\nThis project aims to bridge language gaps within the R community by translating essential R resources into Nepali. This inclusivity will attract diverse talents and perspectives, fostering innovation and growth within the community. We are working with the R User Group Nepal community for a series of Translation hackathons and follow-up meetings. This initiative started before the R Project Sprint 2023 with the assistance of the R User Group Nepal.\n\n\n\nFunded:\n$1,306.80\nProposed by:\nDan Wilson, The Data Collective Consulting Pty Ltd\nSummary:\nTo help create a place for social connection to the broad R community that isn’t focussed on any specific subgroup of r users, we’d like funding to help establish an RStats Mastodon server. The goal would be to be funded for the first year with a grant from the R Consortium and develop a pathway for user funding like other Mastodon servers.\n\n\n\nFunded:\n$20,800\nProposed by:\nElio Campitelli\nSummary:\nWe propose a system in which either package maintainers or community members could create translation modules of specific packages. Users would then be able to install those translation modules and browse their documentation. By default, help() would display the documentation in the user’s preferred language if available, and fall-back to the canonical documentation otherwise. It would also include a link to the canonical documentation and warnings if translations are not up to date.\n\n\n\nFunded:\n$5,000\nProposed by:\nMalcolm Barrett\nSummary:\nIn response to a growing demand for accessible and comprehensive educational resources in causal inference within the R community, we propose the development of a Causal Inference In a Box course. Leveraging a “teach the teacher” model and building on the successful Data Science in a Box template, we will provide instructional materials, including slide decks, lab exercises, and assessments, all meticulously designed to facilitate effective learning. Additionally, we are committed to ensuring inclusivity by offering alternative formats for diverse learning preferences. This comprehensive course, supported by dedicated pedagogical software tools, will revolutionize how practitioners approach causal inference in the R environment, ultimately enhancing the quality and reliability of their research and analyses.\n\n\n\nFunded:\n$4,000\nProposed by:\nDianne Cook\nSummary:\nThe plan for the use of this funding is to check and enhance the accessibility of published R Journal articles, and to develop tools to help authors and editors ensure that new R Journal articles are at the cutting edge of accessibility. Checking the published articles will involve manual work to read each article and add meaningful alt text to each image. Screen reader accessibility will be checked using available screen readers, with advice from team member Jonathan Godfrey. Jonathan has already used the screen reader JAWS to read a sample of articles converted from the legacy format and confirms that he can now access 90% of the R Journal content as opposed to 10% previously! We will also work closely with the current editors of the R Journal to assist with checking new submissions, especially those produced with the legacy template. This will also help ensure that new articles have accessible content, with appropriate alt text.\n\n\n\nFunded:\n$40,000\nProposed by:\nJeroen Ooms, rOpenSci\nSummary:\nWe are interested to collaborate with the R consortium to make R-universe a top-level ISC in order to get a variety of stakeholders involved, grow adoption and community ownership, and to be able to guarantee the continued availability of the service to the R community. R-universe has the potential to become the central place where one can find everything the R community has to offer, complementing CRAN with open infrastructure that can continuously be adapted to new needs. Moreover, existing r-hub containers for extra checks can be integrated to make these tools more accessible. We hope to become a flagship project for the consortium, and an example of a mutually beneficial collaboration between its members and the R community.\n\n\n\nFunded:\n$24,000\nProposed by:\nAndreas Neudecker, INWT Statistics GmbH\nSummary:\nThe goal of this project is to create a robust and efficient Kafka client library for R that supports essential functionalities to communicate with a Kafka cluster. The proposed Kafka client for R will be built by creating a wrapper around the C++ librdkafka library, which is maintained and developed by Confluent which was founded by the original developers of Kafka. This approach is already common and produces reliable and stable releases in multiple other programming languages (Python, Rust, Go, …). There are packages for the major linux package managers (Debian, RPM, Gentoo) and it also runs on MacOS X and Windows."
  },
  {
    "objectID": "all-projects/2021-group-1.html",
    "href": "all-projects/2021-group-1.html",
    "title": "Funded ISC Grants (2021-1)",
    "section": "",
    "text": "Funded ISC Grants (2021-1)\nThe R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAccounting/Auditing Gap-Analysis\nExtendr - Rust extensions for R.\nGoogle Earth Engine with R\nImproving Translations in R\nMinimizing wastage of blood products\nR for Engineering Applications\nSetting up an R-Girls-Schools Network\ndeposits: Deposit Research Data Anywhere\n\n\n\nAccounting/Auditing Gap-Analysis\nFunded:\n$7,000\nProposed by:\nFelix Schildorfer\nSummary:\nThere are more and more accountants and auditors who want to start using R and dig into data science. They usually have particular tasks on hand that they want to complete, facilitate, or automate. While they often have some basic stats skills and may be some coding basics, understanding the R landscape and relating tasks and processes to locate and use relevant R packages and tutorials is an extreme challenge. While other areas like finance or pharmaceuticals already have extensive infrastructure to support R newcomers (Working Groups, Courses, Task Views, etc.) accounting and auditing do not. This becomes an obstacle for such professionals - which find the “coding” part difficult on their own but doing so without any support or knowing the appropriate package becomes a nightmare.\nThis is why R Business put together this project with the aim to gauge the landscape of what functionalities are available for Auditors in the R ecosystem and how the existing functionalities can be mapped to routine accounting/auditing tasks. We will complete a systematic survey of the CRAN-ecosystem for accounting/auditing tasks to establish a mapping and identify gaps. The project will contribute to the development of the R Business ISC working group by attracting interested accounting/auditing professionals, industry bodies and R community members. This will then in turn lead to increased use of R/RStudio, development new application domains for data science, and enhancement of the quality of accounting/auditing services.\n\n\nExtendr - Rust extensions for R.\nFunded:\n$15,000\nProposed by:\nAndy Thomason\nSummary:\nRust extension framework for R.\n\n\nGoogle Earth Engine with R\nFunded:\n$5,500\nProposed by:\nCesar Luis Aybar Camacho\nSummary:\nGoogle Earth Engine (GEE) is the most popular and advanced cloud platform designed for planetary-scale environmental data analysis. Its multi-petabyte data catalog and computation services are just accessed via Python and JavaScript client libraries. In order to facilitate its use within R, six months ago, rgee was released on CRAN using reticulate to wrap the GEE Python API. Although rgee provides a familiar interface and simple integration to other R packages (e.g., sf, raster, dplyr), the lack of tutorials and examples makes it difficult for new users to adopt.\nThe main goal of this project is to leverage the documentation. For this purpose, three main tasks have been proposed: (1) create a new version of rgee with support for shiny and markdown, (2) create rgeeExtra, which extends the functionalities of rgee, and finally write (3) rgeebook, a reference book with best practices and examples of GEE API usage.\n\n\nImproving Translations in R\nFunded:\n$0\nProposed by:\nMichael Chirico\nSummary:\nThis project will provide a better formalization of translation procedures for R to be more sustainable and more scalable. In the process, it will broaden the inclusivity of R by growing the sub-community of R users comfortable producing translations and extending the reach of the R project to more non-English audiences.\n\n\nMinimizing wastage of blood products\nFunded:\n$11,200\nProposed by:\nBalasubramanian Narasimhan\nSummary:\nGuan et al. 2017 (Proc Natl Acad Sci U S A 114 (43): 11368–73) used two years worth of data to formulate and solve an optimization problem to predict platelet usage and minimize waste. Two open-source R packages were developed for this purpose:\n- Platelet Inventory Prediction or pip (https://github.com/bnaras/pip) a package that is the core ML prediction engine that uses a given set of features described in the above publication\n- Stanford Blood Center Platelet Inventory Prediction or SBCpip (https://github.com/bnaras/SBCpip) that was customized to the data workflow at SHC. SBCpip was meant to be site specific.\nThere have been a number of requests from sites wishing to deploy the software locally. The current project will generalize the model, generalize it to address more blood products with different shelf lives, provide customizations for local use, and create easily deployable solutions.\n\n\nR for Engineering Applications\nFunded:\n$3,000\nProposed by:\nBenaiah Chibuokem Ubah\nSummary:\nR for Engineering Applications is a proposed project with the aim to attract engineers and diversify the use of the R language to the broad engineering domain – electrical, electronic, communications, robotics, etc engineering. The idea is similar to such projects as R in Finance, R in Insurance, BioConductor (R in Bio-informatics), R in Environmental Statistics, etc.\n\n\nSetting up an R-Girls-Schools Network\nFunded:\n$5,000\nProposed by:\nDr. Razia Ghani\nSummary:\nGlobally, women, especially from deprived socio-economic and diverse ethnic backgrounds, are under-represented in data science. A major factor is that data science does not feature in the school curriculum which means that teachers are unaware of the enhancements data science can bring to learning and development in and beyond the school. We propose an ongoing project, called R-Girls-School Network (short name R-Girls) to address this and are keen to link up with others.\nWe are a multi-disciplinary team that includes an educationalist, subject teachers, a data scientist and administrator who will begin to develop and implement a data science curriculum using R in Green Oak Academy – an inner-city school in the UK serving girls from deprived, ethnically diverse backgrounds aged 11-16 years; independently rated as Good with Outstanding for Behaviour and Attitudes.\nSince GOA follows the UK national curriculum, which is used in 10,000+ schools and 160 countries, our work will have a broad appeal. In due course we will develop ready-to-use bite-sized learning materials (10-15 mins) for teachers of core subjects (maths, statistics, science, geography) to use via RStudio cloud. The lessons will be tested with teachers and pupils and then incorporated into the school timetable across all five-year groups (age 11-16 years), culminating in an R-Data Story project and in due course, an annual R-Girls virtual conference open to any girl and girls’ school in the world.\nR-GS will be supported by a website for showcasing the work of pupils and sharing resources.\n\n\ndeposits: Deposit Research Data Anywhere\nFunded:\n$16,000\nProposed by:\nMark Padgham\nSummary:\nPublicly depositing datasets associated with published research is becoming more common, partly due to journals increasingly requiring data sharing, and partly though more general and ongoing cultural changes in relation to data sharing. Yet data sharing is often seen as time consuming, particularly in order to meet the expectations of individual data repositories. While documentation and training can help get users familiar with processes of data sharing, browser-based data and metadata submission workflows can only be so fast, are not easily reproduced, and do not facilitate regular or automated updates of data and metadata. Better programmatic tools can transform data sharing from a mountainous climb into a pit of success.\nThis project will develop a unified interface to many different research data repositories, and which will function along the lines of dplyr through “verbs” that work identically across many “backend” data repositories. The package will initially provide access to a few of the most common data repositories, yet will implement a modular/plugin system to enable users to contribute their own plugins to extend functionality to other repositories. Users will be able to authenticate, prepare data and metadata, and finally to submit, fetch, and browse data."
  },
  {
    "objectID": "all-projects/index.html",
    "href": "all-projects/index.html",
    "title": "Goal of ISC Grants Program",
    "section": "",
    "text": "The goal of the Infrastructure Steering Committee (the ISC) is to support projects that broadly help the R community. This might be software development, developing new teaching materials, documenting best practices, standardizing APIs or doing research. Currently, the ISC chiefly provides financial support for projects proposed by individuals or teams who have the skills to carry out the work, but we can also provide administrative support, promotion and some collaboration tools for groups who would like to study more ambitious projects.\nThe ISC generally funds two grant cycles per year. Cumulatively, we have awarded over $750k in community development grants over 5 years.\nInterested in strengthening the R community? Submit a Proposal. Please note, grants from the R Consortium are not adjusted to accommodate for internal institutional overhead.\n\n\nFor activities that are well defined and scoped, yet require funding to help bring to fruition, the ISC has established a grant fund. Twice yearly, the ISC awards grants for projects such as code development, workshops, infrastructure, and other projects to help sustain the R community.\nYou can learn more about the in-progress and completed funded projects. If you have a project needing funding, learn more about the grant funding process.\n\n\n\nFor community projects of importance to the R community and needing long-term support by R Consortium, the project and ISC can consider the project for long-term status. This gives the project guaranteed funding for 3 years, along with a voting seat on the ISC. Projects looking for this status will need to justify to the ISC why the project needs long-term funding, as well as submit a 3-year plan and budget for consideration. Top level projects get priority access to grant funds available.\nFour projects are currently Top Level Projects:\n\nDBI\nR-Ladies\nR User Group Support Program (RUGS)\nR-Universe\n\nPrevious Top Level Projects"
  },
  {
    "objectID": "all-projects/index.html#funded-projects",
    "href": "all-projects/index.html#funded-projects",
    "title": "Goal of ISC Grants Program",
    "section": "",
    "text": "For activities that are well defined and scoped, yet require funding to help bring to fruition, the ISC has established a grant fund. Twice yearly, the ISC awards grants for projects such as code development, workshops, infrastructure, and other projects to help sustain the R community.\nYou can learn more about the in-progress and completed funded projects. If you have a project needing funding, learn more about the grant funding process."
  },
  {
    "objectID": "all-projects/index.html#top-level-projects",
    "href": "all-projects/index.html#top-level-projects",
    "title": "Goal of ISC Grants Program",
    "section": "",
    "text": "For community projects of importance to the R community and needing long-term support by R Consortium, the project and ISC can consider the project for long-term status. This gives the project guaranteed funding for 3 years, along with a voting seat on the ISC. Projects looking for this status will need to justify to the ISC why the project needs long-term funding, as well as submit a 3-year plan and budget for consideration. Top level projects get priority access to grant funds available.\nFour projects are currently Top Level Projects:\n\nDBI\nR-Ladies\nR User Group Support Program (RUGS)\nR-Universe\n\nPrevious Top Level Projects"
  },
  {
    "objectID": "all-projects/2024-group-1.html",
    "href": "all-projects/2024-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nModular, interoperable, and extensible topological data analysis in R\nISO 19115-3 standard implementation in geometa R package\nR-multiverse for production\nCritical Updates to Biostrings\nSetting up igraph for success in the next decade\n{geotargets}: Enabling geospatial workflow management with {targets}\n\n\n\n\nFunded:\n$18,000\nProposed by:\nCory Brunson and Aymeric Stamm\nSummary:\nThe goal of this project is to seamlessly integrate popular techniques from topological data analysis (TDA) into common statistical workflows in R. The expected benefit is that these extensions will be more widely used by non-specialist researchers and analysts, which will create sufficient awareness and interest in the community to extend the individual packages and the collection.\n\n\n\nFunded:\n$13,750\nProposed by:\nEmmanuel Blondel\nSummary:\nThe present project enhances the geometa package for handling the new ISO 19115-3 geographic information standard as part of its object-oriented data model developed with R6. The user community, especially data managers working in research national institutes and international organizations, will take advantage of the features to start adopting the new standard for managing their geographic metadata, progressively promoted in Geographic information management web platforms, especially those from the OpenSource Geospatial Foundation (OSGeo) such as GeoNetwork, PyCSW or GeoNode.\n\n\n\nFunded:\n$20,000\nProposed by:\nWill Landau\nSummary:\nThe implementation of R-multiverse to date has been both straightforward and achievable. It builds directly upon the proven technologies of R-universe and GitHub Actions. By the end of the milestones, the entire project will be in a ready state to be launched to the public as a production solution for non-CRAN non-Bioconductor packages.\n\n\n\nFunded:\n$8,000\nProposed by:\nAidan Lakshman, University of Pittsburgh\nSummary:\nBiostrings is a core Bioconductor package providing efficient containers for storing, manipulating, and analyzing biological sequences. Biostrings is the method to access biological sequence data in R; nearly every analysis working with genomic data depends on the Biostrings package to handle sequencing data.\nThis project proposes to clear out accumulated technical debt by addressing open issues, implementing robust tests for long-term sustainability, improving user experience, and adding features that will keep Biostrings relevant for modern sequencing technologies. For end-users, this will result in numerous bugfixes, a host of new features to support genomic analyses, and a variety of performance improvements to bolster R as one of the top programming languages for bioinformatics. For developers, this will make the Biostrings package more sustainable, allowing for more community contribution and faster bug resolution in the future.\n\n\n\nFunded:\n$16,000\nProposed by:\nMaëlle Salmon, cynkra\nSummary:\nThis project is aimed at improving the quality of igraph codebase itself and of the user interface (messages including error messages, documentation indicating the status of exported functions). It has the goal of improving the user-friendliness of the installation from source.\n\n\n\nFunded:\n$15,912\nProposed by:\nEric Scott, University of Arizona\nSummary:\nThe goal of this project is to create a package that makes using targets for geospatial analysis in R as seamless as possible. To that end, geotargets will provide custom functions for defining geospatial targets that take care of translating and saving R objects for the user. In addition, the project will provide vignettes demonstrating how to use various geospatial R packages with targets. Where appropriate, the project will identify contributions to existing R packages to make them easier to use with targets and geotargets."
  },
  {
    "objectID": "all-projects/2024-group-1.html#funded-isc-grants-2024-1",
    "href": "all-projects/2024-group-1.html#funded-isc-grants-2024-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nModular, interoperable, and extensible topological data analysis in R\nISO 19115-3 standard implementation in geometa R package\nR-multiverse for production\nCritical Updates to Biostrings\nSetting up igraph for success in the next decade\n{geotargets}: Enabling geospatial workflow management with {targets}\n\n\n\n\nFunded:\n$18,000\nProposed by:\nCory Brunson and Aymeric Stamm\nSummary:\nThe goal of this project is to seamlessly integrate popular techniques from topological data analysis (TDA) into common statistical workflows in R. The expected benefit is that these extensions will be more widely used by non-specialist researchers and analysts, which will create sufficient awareness and interest in the community to extend the individual packages and the collection.\n\n\n\nFunded:\n$13,750\nProposed by:\nEmmanuel Blondel\nSummary:\nThe present project enhances the geometa package for handling the new ISO 19115-3 geographic information standard as part of its object-oriented data model developed with R6. The user community, especially data managers working in research national institutes and international organizations, will take advantage of the features to start adopting the new standard for managing their geographic metadata, progressively promoted in Geographic information management web platforms, especially those from the OpenSource Geospatial Foundation (OSGeo) such as GeoNetwork, PyCSW or GeoNode.\n\n\n\nFunded:\n$20,000\nProposed by:\nWill Landau\nSummary:\nThe implementation of R-multiverse to date has been both straightforward and achievable. It builds directly upon the proven technologies of R-universe and GitHub Actions. By the end of the milestones, the entire project will be in a ready state to be launched to the public as a production solution for non-CRAN non-Bioconductor packages.\n\n\n\nFunded:\n$8,000\nProposed by:\nAidan Lakshman, University of Pittsburgh\nSummary:\nBiostrings is a core Bioconductor package providing efficient containers for storing, manipulating, and analyzing biological sequences. Biostrings is the method to access biological sequence data in R; nearly every analysis working with genomic data depends on the Biostrings package to handle sequencing data.\nThis project proposes to clear out accumulated technical debt by addressing open issues, implementing robust tests for long-term sustainability, improving user experience, and adding features that will keep Biostrings relevant for modern sequencing technologies. For end-users, this will result in numerous bugfixes, a host of new features to support genomic analyses, and a variety of performance improvements to bolster R as one of the top programming languages for bioinformatics. For developers, this will make the Biostrings package more sustainable, allowing for more community contribution and faster bug resolution in the future.\n\n\n\nFunded:\n$16,000\nProposed by:\nMaëlle Salmon, cynkra\nSummary:\nThis project is aimed at improving the quality of igraph codebase itself and of the user interface (messages including error messages, documentation indicating the status of exported functions). It has the goal of improving the user-friendliness of the installation from source.\n\n\n\nFunded:\n$15,912\nProposed by:\nEric Scott, University of Arizona\nSummary:\nThe goal of this project is to create a package that makes using targets for geospatial analysis in R as seamless as possible. To that end, geotargets will provide custom functions for defining geospatial targets that take care of translating and saving R objects for the user. In addition, the project will provide vignettes demonstrating how to use various geospatial R packages with targets. Where appropriate, the project will identify contributions to existing R packages to make them easier to use with targets and geotargets."
  },
  {
    "objectID": "members.html#platinum-members",
    "href": "members.html#platinum-members",
    "title": "R Consortium",
    "section": "Platinum Members",
    "text": "Platinum Members"
  },
  {
    "objectID": "members.html#silver-members",
    "href": "members.html#silver-members",
    "title": "R Consortium",
    "section": "Silver Members",
    "text": "Silver Members"
  },
  {
    "objectID": "newsletters/newsletters.html",
    "href": "newsletters/newsletters.html",
    "title": "Newsletters",
    "section": "",
    "text": "Check out our previous Newsletters and stay tuned for future ones!"
  },
  {
    "objectID": "newsletters/newsletters.html#whats-happening-in-the-r-consortium",
    "href": "newsletters/newsletters.html#whats-happening-in-the-r-consortium",
    "title": "Newsletters",
    "section": "",
    "text": "Check out our previous Newsletters and stay tuned for future ones!"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "",
    "text": "Welcome to the R Consortium’s Q3 2024 Newsletter!\nThis quarter has been packed with exciting updates, innovative projects, and global community initiatives that are shaping the future of R.\nBig news! The R Submissions Working Group successfully completed the “Pilot 3 Submission” which is testing the concept that an R-language based submission package for ADaMs and TLFs can meet the needs and the expectations of the FDA reviewers, including assessing code review and analyzing reproducibility. This is great progress! See the Submissions Working Group section below for more details.\nAnd there’s more! From the appointment of our new Executive Director, Terry Christiani, to the launch of our new Quarto website there’s a lot to dive into!\nWe’ve also seen impressive progress in our technical working groups, and we continue to support R User Groups across the globe.\nWhether you’re interested in the latest package developments, upcoming webinars, or community stories, there’s something here for everyone.\nLet’s explore what’s new in the R world!\n\n\n\nNew Executive Director\nNew Quarto Website\nBuilding Extended R Packages to Improve R Infrastructure\nTechnical Projects and Working Groups\nR Consortium Webinars\nEmpowering R User Groups Globally with R Consortium’s Support!\n\n\n\n\nWe are excited to announce that Terry Christiani has been appointed as the new Executive Director of the R Consortium! The board of directors affirmed Terry’s selection during our August 2024 board meeting, following a thorough process in which a dedicated selection committee interviewed candidates and provided recommendations. We look forward to Terry’s leadership in guiding the R Consortium’s initiatives and supporting the global R community.\n“I have been involved in supporting the R language and its users for many years and am so excited to have the opportunity to work with the R Consortium. The consortium is supporting important work across multiple industries. I hope to ensure that we continue to build on past successes and create more opportunities for R users to deliver valuable insights and analyses for their organizations.”\n—Terry Christiani, Executive Director, R Consortium\n\n\n\nThe R Consortium has a new website based on Quarto, the open source technical publishing system. Quarto allows easy embedding of R code examples as well as R-based interactive charts. Most of the R community already publishes documents in Quarto, making it easier to accept community contributions for blogs and technical documents.\nThe URL is the same: www.r-consortium.org. The older site is archived at archive.r-consortium.org.\n\n\n\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R ecosystem. We seek to accomplish this by funding projects that will improve the technical infrastructure of R.\nThere are two open application grant cycles each year. The latest round of the R Consortium’s Call for Proposals officially ended on October 1st, 2024.\nWe want to extend a huge thank you to everyone who submitted proposals. Each submission plays a pivotal role in strengthening the R ecosystem, and we are thrilled to see such innovative ideas pour in.\nAs we eagerly anticipate the announcement of the newly funded projects, we reflect on our mission to support and enhance the technical infrastructure behind R. Past initiatives have made significant contributions, including:\n\nTesting DBI and improving key open-source database backends\nEnhancements to critical packages such as mapview and sf\nImproving R translations to expand accessibility\nContinued infrastructure development for R on Windows and macOS\n\nStay tuned for the upcoming announcement of the new projects that will continue to drive the evolution of R’s technical foundation!\n\n\nUnlocking Chemical Volatility: How the volcalc R Package is Streamlining Scientific Research\n\nEnhancing R: The Vision and Impact of Jan Vitek’s MaintainR Initiative\n\nSecure TLS Connections in {nanonext} and {mirai} Facilitating High-Performance Computing in the Life Sciences\n\nBuilding Data Highways: Kirill Müller’s Journey in Enhancing R’s Database"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#main-sections-at-a-glance",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#main-sections-at-a-glance",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "",
    "text": "New Executive Director\nNew Quarto Website\nBuilding Extended R Packages to Improve R Infrastructure\nTechnical Projects and Working Groups\nR Consortium Webinars\nEmpowering R User Groups Globally with R Consortium’s Support!"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#new-executive-director",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#new-executive-director",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "",
    "text": "We are excited to announce that Terry Christiani has been appointed as the new Executive Director of the R Consortium! The board of directors affirmed Terry’s selection during our August 2024 board meeting, following a thorough process in which a dedicated selection committee interviewed candidates and provided recommendations. We look forward to Terry’s leadership in guiding the R Consortium’s initiatives and supporting the global R community.\n“I have been involved in supporting the R language and its users for many years and am so excited to have the opportunity to work with the R Consortium. The consortium is supporting important work across multiple industries. I hope to ensure that we continue to build on past successes and create more opportunities for R users to deliver valuable insights and analyses for their organizations.”\n—Terry Christiani, Executive Director, R Consortium"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#new-r-consortium-quarto-website",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#new-r-consortium-quarto-website",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "",
    "text": "The R Consortium has a new website based on Quarto, the open source technical publishing system. Quarto allows easy embedding of R code examples as well as R-based interactive charts. Most of the R community already publishes documents in Quarto, making it easier to accept community contributions for blogs and technical documents.\nThe URL is the same: www.r-consortium.org. The older site is archived at archive.r-consortium.org."
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#building-extended-r-packages-to-improve-r-infrastructure",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#building-extended-r-packages-to-improve-r-infrastructure",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "",
    "text": "A major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R ecosystem. We seek to accomplish this by funding projects that will improve the technical infrastructure of R.\nThere are two open application grant cycles each year. The latest round of the R Consortium’s Call for Proposals officially ended on October 1st, 2024.\nWe want to extend a huge thank you to everyone who submitted proposals. Each submission plays a pivotal role in strengthening the R ecosystem, and we are thrilled to see such innovative ideas pour in.\nAs we eagerly anticipate the announcement of the newly funded projects, we reflect on our mission to support and enhance the technical infrastructure behind R. Past initiatives have made significant contributions, including:\n\nTesting DBI and improving key open-source database backends\nEnhancements to critical packages such as mapview and sf\nImproving R translations to expand accessibility\nContinued infrastructure development for R on Windows and macOS\n\nStay tuned for the upcoming announcement of the new projects that will continue to drive the evolution of R’s technical foundation!\n\n\nUnlocking Chemical Volatility: How the volcalc R Package is Streamlining Scientific Research\n\nEnhancing R: The Vision and Impact of Jan Vitek’s MaintainR Initiative\n\nSecure TLS Connections in {nanonext} and {mirai} Facilitating High-Performance Computing in the Life Sciences\n\nBuilding Data Highways: Kirill Müller’s Journey in Enhancing R’s Database"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#submissions-working-group",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#submissions-working-group",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "Submissions Working Group",
    "text": "Submissions Working Group\n\nPilot 3 complete!\nThe R Consortium is pleased to announce the successful completion of the Pilot 3 Submission which extended the work done in Pilots 1 and 2 by generating the ADaM datasets. The complete FDA response letter is available here.\nThe objective of the R Consortium R Submission Pilot 3 Project is to test the concept that an R-language based submission package for ADaMs and TLFs can meet the needs and the expectations of the FDA reviewers, including assessing code review and analyzing reproducibility. All submission materials and communications from this pilot are publicly available, with the aim of providing a working example for future R-language based FDA submissions. This is an FDA-industry collaboration through the non-profit organization R Consortium.\nA pilot 3 overview presentation during the 2024 R/medicine conference is available on YouTube.\n\n\nPilot 4 submission on Sept 20\nAs a next step, the R Consortium R Submission Working Group initiated submission pilot 4, to explore the use of novel technologies such as Linux containers and web assembly to bundle a Shiny application into a self-contained package, facilitating a smoother process of both transferring and executing the application.\nPilot 4 is being cited in a recent Nature paper (paywall)."
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#census-working-group",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#census-working-group",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "Census Working Group",
    "text": "Census Working Group\nThe U.S. Census Bureau is the premier source of data about America’s people, places and economy. This makes the Bureau a natural source of information for data analysts. R programmers who start working with Census Data, however, often run into two problems:\n\nUnderstanding what data the Census Bureau publishes.\nUnderstanding what packages on CRAN are available to help with their project.\n\nThe Census working group released a second version of their guide “A Guide to Working with Census Data in R.” The guide aims to help R programmers who are confronted with these problems. Check out the full guide here: https://github.com/RConsortium/censusguide.\nKey updates include:\n\nRevamped the section on Data Dissemination to remove reference to the (now deprecated) American Fact Finder and instead point people to the (new) data.census.gov.\nNew to working with the Census API? Check out the tutorials and resources linked in the API section to learn more and get started.\nUpdated the list of R packages listed in the guide to reflect not just new download stats but also new packages published since the initial version.\nExpanded the list of programs and datasets Census provides, including links to learn more about them.\n\nOur working group welcomes feedback! We are still working on adding tutorials and other package/training related resources to the guide, so readers have more to look forward to with the next update."
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#marshaling-and-serialization-in-r",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#marshaling-and-serialization-in-r",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "Marshaling and Serialization in R",
    "text": "Marshaling and Serialization in R\nThe R Consortium ISC Working Group on Marshaling and Serialization in R started in May 2024. This working group aims at developing standard practices for marshaling and unmarshaling of R objects.\nThis will involve identifying current problems, raising awareness, and coming up with technical solutions. This may require additions to base R. For example, one solution might be to introduce support for serialize() and unserialize() to call registered hook functions whenever certain types of objects are encountered, which then could marshall and unmarshall those objects.\nMore information can be found here: https://github.com/RConsortium/marshalling-wg"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#multilingual-r-documentation",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#multilingual-r-documentation",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "Multilingual R Documentation",
    "text": "Multilingual R Documentation\nThe Multilingual R Documentation working group started in June 2024. There was a virtual meeting to set the stage, and in person meetings during R Dev Day @ PLUS. Its lead presented the project at useR! 2024.\nWe have a working package and ideas for improvement. There’s a few PRs from collaborators under review and even an example of real world use of the package: a French translation of the torchvision documentation. We have this repository and a channel in the R Consortium Slack that anyone is welcome to join to participate."
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#r7-package---design-refining",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#r7-package---design-refining",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "R7 Package - Design refining",
    "text": "R7 Package - Design refining\nThe Object-Oriented Programming (OOP) working group continues to refine the design and functionality of the package through active discussions within the group and the community at large.\nThe long-term goal of this project is to merge S7 in to base R. For now, you can experiment by installing it from CRAN:\ninstall.packages(\"S7\")"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#r-validation-hub",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#r-validation-hub",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "R Validation Hub",
    "text": "R Validation Hub\nThe R Validation Hub is a collaboration to support the adoption of R within a biopharmaceutical regulatory setting.\nThe R Validation Hub enhanced their website this summer to improve navigation. Please take some time to check it out and send feedback: https://www.pharmar.org/\nThe R Validation solutions for the validation of R packages quantify the “risk” of R packages with several metrics {riskmetric} and provide a user-friendly, full-fledged R Shiny app as a central hub to gauge the “risk” of packages {riskassessment}.\nFor {riskassessment} the R Validation Hub is announcing the release of two new features:\n\nAutomate “risk decisions” based on {riskmetric} quality assessment values.\nNew module called the “Function Explorer” which allows users to explore any function exported from a package in one easy-to-use interface.\n\nSpecial thanks to Glaxo-Smith Kline (GSK) contributors for donating this code!\nFor more details about our new features, read our blog post: https://www.pharmar.org/posts/news/updates-aug-2024/\nFrom the R Validation Hub:\n“Our roadmap for the app is going scoreless. Most organizations don’t really make actionable decisions from {riskmetric}’s overall package score. It can sometimes deter our attention from the more meaningful quality metrics or even lead to unnecessary confusion or bias. As such, we want Admin users to make the decision whether they want this quantitative metric to be displayed in the app at all. Stay tuned!”\n\nCollecting regulatory package lists\nWe’ve asked a few pharmaceutical organizations what R Packages have qualified for late stage analysis. We were encouraged by the transparent effort companies like Roche made: https://insightsengineering.github.io/rvalidationhub-packages/\n\n\nReg R Repo: first pilot released\nThe Regulatory R Repository working group released its first pilot this summer, a repository of R packages with pre-calculated risk metrics: https://github.com/pharmaR/pharmapkgs\nWe are working on a second release with more advanced features: risk metrics calculated on a container image and the generation of a validation report for each R package on the repository."
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2024-Newsletter.html#get-in-touch-with-the-r-consortium",
    "href": "newsletters/R-Consortium-Q3-2024-Newsletter.html#get-in-touch-with-the-r-consortium",
    "title": "R Consortium Q3 2024 Newsletter",
    "section": "Get in Touch with the R Consortium!",
    "text": "Get in Touch with the R Consortium!\nFollow us on social media or contact us here: https://r-consortium.org/about/contact.html"
  },
  {
    "objectID": "blog/guidelines.html",
    "href": "blog/guidelines.html",
    "title": "Blog Guidelines",
    "section": "",
    "text": "The R Consortium blog will serve as a channel for the members, ISC grant recipients and the community at large to broadcast to a wide audience how their work and engagement is growing opportunities for the R language for data science and statistical computing.\nThis may include summaries of how leading institutions, companies and developers are using, developing and advancing R.\nThose involved with developing, maintaining, distributing, and using R software are encouraged to contribute to the blog.\nGuest posts from the R Consortium community at large or projects funded by the ISC that enhance R and support users are welcomed. Updates about R-related conferences (including useR!), meetings (including SatRDays and RLadies), local user groups worldwide, new working groups or programs for R language certification and training are of interest. Other topics would certainly be considered, but it should be something of interest to the broader R community.\nAccepted blog posts are at the sole discretion of the R Consortium."
  },
  {
    "objectID": "blog/guidelines.html#r-consortium-blog-overview",
    "href": "blog/guidelines.html#r-consortium-blog-overview",
    "title": "Blog Guidelines",
    "section": "",
    "text": "The R Consortium blog will serve as a channel for the members, ISC grant recipients and the community at large to broadcast to a wide audience how their work and engagement is growing opportunities for the R language for data science and statistical computing.\nThis may include summaries of how leading institutions, companies and developers are using, developing and advancing R.\nThose involved with developing, maintaining, distributing, and using R software are encouraged to contribute to the blog.\nGuest posts from the R Consortium community at large or projects funded by the ISC that enhance R and support users are welcomed. Updates about R-related conferences (including useR!), meetings (including SatRDays and RLadies), local user groups worldwide, new working groups or programs for R language certification and training are of interest. Other topics would certainly be considered, but it should be something of interest to the broader R community.\nAccepted blog posts are at the sole discretion of the R Consortium."
  },
  {
    "objectID": "blog/guidelines.html#quality",
    "href": "blog/guidelines.html#quality",
    "title": "Blog Guidelines",
    "section": "Quality",
    "text": "Quality\nWe are looking for posts that teach and give value to our community. Blogs should include the meta-narrative that “R is a fast-growing language for statistical computing and graphics” and “the R Consoritum supports the worldwide community of users, maintainers and developers of R software.”\nGuest posts must be vendor neutral, though it may mention vendors involved in specific deployment or adoption paths, or their hosting of an in-person event or speaking at an event, or other indications of meaningful participation in the community. It shouldn’t feel like an advertisement for your product, services or company though. Your post must be your content, but can be published elsewhere on the Internet with permission from that website. All content should have a byline (preferably by a company engineer) and be published under Creative Commons with Attribution, so you’re welcome to re-publish on your own blog.\nThe most interesting posts are those that teach or show how to do something in a way maybe others haven’t thought of. Good blog posts show hurdles that were encountered and explain how they were overcome (not that everything is rainbows and unicorns). When showing upstreaming of a patch fixing an issue for others, link back to the Github issue, so readers can follow along. We don’t avoid critical commentary or broad issues, but approach them with sensitivity, professionalism and tact in a way that is beneficial and positive for the community. It would be helpful to the R Consortium to discuss how to choose between different technologies and how to accommodate different legacy issues and cloud platforms.\nBe interesting and inspiring!"
  },
  {
    "objectID": "blog/guidelines.html#promotion",
    "href": "blog/guidelines.html#promotion",
    "title": "Blog Guidelines",
    "section": "Promotion",
    "text": "Promotion\nYour blog will be shared on R Consortium’s Twitter channel. Please feel free to retweet or share. Don’t forget to share your work on your own social channels and favorite news aggregator sites. Suggested sites: Twitter, LinkedIn, Reddit, Hacker News, DZone, TechBeacon. Plus industry sites like: https://www.r-bloggers.com/about/, rweekly.org and reddit.com/r/rstats."
  },
  {
    "objectID": "blog/guidelines.html#how-to-submit-for-consideration",
    "href": "blog/guidelines.html#how-to-submit-for-consideration",
    "title": "Blog Guidelines",
    "section": "How to submit for consideration",
    "text": "How to submit for consideration\nPlease submit the blog post or a brief summary and the topic of the post to r-marketing@lists.r-consortium.org (with the Subject line: “Proposed Blog: BLOG TITLE”) for consideration. The PR team will review your submission in a timely manner and provide the green light to draft the entire article or provide feedback on next steps. If you are submitting an article or presentation that already exists, please send it in its entirety with a note on the expressed permission from the owner of content. Once your submission has been approved, it will be added to our blog publishing calendar and a publish date will be provided, so you may plan to promote accordingly through your personal and company social media channels. Blog posts should be no longer than 1,000 words and no shorter than 300 words. Diagrams, code examples or photos are strongly encouraged.\nThis document last updated July 17, 2024"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "R Consortium",
    "section": "",
    "text": "Want to contribute to the R Consortium blog? Please review our Blog Post Guidelines.\nR Consortium blog archive (2015-2024)\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 6, 2025\n\n\nA new year and the same, unwavering commitment\n\n\nTerry Christiani\n\n\n\n\nMar 3, 2025\n\n\nPromoting R in Nigeria: How Unilorin R User Group is Making an Impact\n\n\nR Consortium\n\n\n\n\nFeb 28, 2025\n\n\nR Submissions Working Group: Pilot 5 Launch and more!\n\n\nR Consortium\n\n\n\n\nFeb 13, 2025\n\n\nSeville R Users Group: R’s Role in Optimization Research and Stroke Prevention\n\n\nR Consortium\n\n\n\n\nFeb 6, 2025\n\n\nConnecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building\n\n\nR Consortium\n\n\n\n\nJan 29, 2025\n\n\nNew R User Group in Thailand is Building Awareness of R\n\n\nR Consortium\n\n\n\n\nJan 23, 2025\n\n\nR en Buenos Aires: New Generations Working to Strengthen the Community\n\n\nR Consortium\n\n\n\n\nJan 17, 2025\n\n\nTransforming Academic Research with R in Santa Rosa, Argentina\n\n\nR Consortium\n\n\n\n\nJan 15, 2025\n\n\nA Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams\n\n\nJoe Zhu, Leena Khatri, Emily de la Rua, Edoardo Mancini, Kangjie Zhang, Daphne Grasselly\n\n\n\n\nJan 7, 2025\n\n\nUser-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready\n\n\nJasmine Daly, Beni Altmann\n\n\n\n\nDec 30, 2024\n\n\nIntroducing R to Malawi: A Community in the Making\n\n\nR Consortium\n\n\n\n\nDec 27, 2024\n\n\nNavigating Economic Challenges Through Community: The Journey of R-Ladies Buenos Aires\n\n\nR Consortium\n\n\n\n\nDec 23, 2024\n\n\nBooks, Beginners, and Big Ideas: Beatriz Milz on Fostering R-Ladies São Paulo’s Vibrant Community\n\n\nR Consortium\n\n\n\n\nDec 13, 2024\n\n\nMoving forward to meet new challenges in 2025\n\n\nTerry Christiani\n\n\n\n\nDec 3, 2024\n\n\nEmpowering Girls in Data Science: The R-Girls-School Network Initiative\n\n\nR Consortium\n\n\n\n\nDec 3, 2024\n\n\nR-Universe Named R Consortium’s Newest Top Level Project\n\n\nR Consortium\n\n\n\n\nDec 2, 2024\n\n\nEmpowering Data Science in Mexico: R-Ladies Querétaro on Inclusivity and Growth\n\n\nR Consortium\n\n\n\n\nNov 12, 2024\n\n\nBridging the Real-Time Gap: How INWT is Bringing Apache Kafka to the R Ecosystem\n\n\nR Consortium\n\n\n\n\nNov 4, 2024\n\n\nHealth Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA\n\n\nR Consortium\n\n\n\n\nNov 1, 2024\n\n\nReviving Sheffield R User Group and Building Tools for Thyroid Cancer Prediction\n\n\nR Consortium\n\n\n\n\nOct 30, 2024\n\n\nStreamlining API Integration: Jon Harmon’s Journey with the api2r Package\n\n\nR Consortium\n\n\n\n\nOct 23, 2024\n\n\nConectaR, Podcasts, and Datathons: How the San Carlos R User Group in Costa Rica is Connecting Latin America’s Data Lovers\n\n\nR Consortium\n\n\n\n\nOct 18, 2024\n\n\nEndophytes, Oaks, and R: How R-Ladies Morelia is Cultivating Science and Community in Morelia, Mexico\n\n\nR Consortium\n\n\n\n\nOct 16, 2024\n\n\nThe U.S. Federal Reserve quarterly model in R\n\n\nGuest Blog Post\n\n\n\n\nOct 15, 2024\n\n\nEmpowering Dengue Research Through the Dengue Data Hub: R Consortium Funded Initiative\n\n\nR Consortium\n\n\n\n\nOct 14, 2024\n\n\nR/Pharma 2024, Virtual, October 29-November 1, Includes New Dedicated Asia-Pacific (APAC) Track\n\n\nR Consortium\n\n\n\n\nOct 9, 2024\n\n\nUsing R to Submit Research to the FDA: Pilot 4 Successfully Submitted to FDA Center for Drug Evaluation and Research\n\n\nR Consortium\n\n\n\n\nOct 8, 2024\n\n\nCakes, Code, and Community: Rasmus Bååth’s Secret to Reviving the CopenhagenR UseR Group\n\n\nR Consortium\n\n\n\n\nOct 1, 2024\n\n\nAnnouncing the Health Technology Assessment (HTA) Working Group\n\n\nR Consortium\n\n\n\n\nSep 23, 2024\n\n\nUnlocking Chemical Volatility: How the volcalc R Package is Streamlining Scientific Research\n\n\nR Consortium\n\n\n\n\nSep 20, 2024\n\n\nFree Boba Tea and Technical R Topics Lure Young Learners to New Brunei R User Group\n\n\nR Consortium\n\n\n\n\nSep 12, 2024\n\n\nEmpowering Data Science: How R is Transforming Research in Cameroon\n\n\nR Consortium\n\n\n\n\nSep 10, 2024\n\n\nThank You, Joseph Rickert: A Legacy of Leadership and Innovation in the R Community\n\n\nR Consortium\n\n\n\n\nSep 6, 2024\n\n\nR-Ladies Bariloche in Argentina: Fostering a Different Approach to Leadership\n\n\nR Consortium\n\n\n\n\nAug 30, 2024\n\n\nThe 2024 ISC Grant Program will begin Accepting Applications Soon!\n\n\nR Consortium\n\n\n\n\nAug 27, 2024\n\n\nR4SocialScience: Empowering Social Science Research with R in India\n\n\nR Consortium\n\n\n\n\nAug 26, 2024\n\n\nNews from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA\n\n\nR Consortium\n\n\n\n\nAug 20, 2024\n\n\nBuilding Bridges in Haifa, Israel: How the New R User Group in Haifa is Establishing a Diverse R Community\n\n\nR Consortium\n\n\n\n\nAug 12, 2024\n\n\nA New R Community in Ahmedabad, India, focused on Clinical Research and Pharmaceutical Industries\n\n\nR Consortium\n\n\n\n\nAug 2, 2024\n\n\nR Consortium Grants Committee Announces New Chair\n\n\nR Consortium\n\n\n\n\nAug 1, 2024\n\n\nPharma RUG: The Rise of R in China’s Pharmaceutical Industry\n\n\nR Consortium\n\n\n\n\nJul 26, 2024\n\n\nR-Ladies Rome: Empowering Women in Data Science Through Collaboration and Innovation\n\n\nR Consortium\n\n\n\n\nJul 22, 2024\n\n\nEmpowering the R Community: Insights from Myles Mitchell of the Leeds Data Science Group\n\n\nR Consortium\n\n\n\n\nJul 12, 2024\n\n\nKolkata R User Group: A Rich History with Statistics\n\n\nR Consortium\n\n\n\n\nJul 3, 2024\n\n\nDiving into R with Isabella Velasquez: Perspectives from R-Ladies Seattle\n\n\nR Consortium\n\n\n\n\nJul 2, 2024\n\n\nR Consortium’s Submission Working Group: Advancing R for Regulatory Success at PharmaSUG 2024\n\n\nR Consortium\n\n\n\n\nJun 25, 2024\n\n\nR Addicts Paris: Promoting Diversity in R\n\n\nR Consortium\n\n\n\n\nJun 24, 2024\n\n\nThe Crucial Role of Release Control in R for Healthcare Organizations\n\n\nGuest Blog Post\n\n\n\n\nJun 17, 2024\n\n\nBridging the Digital Divide: Umar Isah Adam on Expanding R Access for Kano, Nigeria Students\n\n\nR Consortium\n\n\n\n\nJun 11, 2024\n\n\nKeith Karani Wachira: Leading the Dekut R Community in Kenya and Innovating with R\n\n\nR Consortium\n\n\n\n\nJun 4, 2024\n\n\nFull-time Korea R User Group Founder Victor Lee Sees AI Future for R and Quarto Textbooks\n\n\nR Consortium\n\n\n\n\nMay 30, 2024\n\n\nR4HR in Buenos Aires: Leveraging R for Dynamic HR Solutions\n\n\nR Consortium\n\n\n\n\nMay 29, 2024\n\n\nEnhancing Clinical Trial Data Sharing with R Consortium’s R Submissions Working Group\n\n\nR Consortium\n\n\n\n\nMay 29, 2024\n\n\nOne More Step Forward: The R Consortium Submission Working Group’s Presentation to Swissmedic on Regulatory Submission using R and Shiny\n\n\nGuest Authors\n\n\n\n\nMay 24, 2024\n\n\nCollaborative Growth: The Botswana R User Group and Regional Partnerships\n\n\nR Consortium\n\n\n\n\nMay 16, 2024\n\n\nGergely Daróczi’s Journey: Empowering R Users in Hungary\n\n\nR Consortium\n\n\n\n\nMay 15, 2024\n\n\nEnhancing R: The Vision and Impact of Jan Vitek’s MaintainR Initiative\n\n\nR Consortium\n\n\n\n\nMay 14, 2024\n\n\nTackling Hurdles: Embracing Open Source Packages in Pharmaceutical Research\n\n\nR Consortium\n\n\n\n\nMay 13, 2024\n\n\nThe Evolution of Melbourne’s Business Analytics and R Business User Group\n\n\nR Consortium\n\n\n\n\nApr 30, 2024\n\n\nR/Medicine is coming June 10-14, 2024 – See Top Five R Medicine Talks from Previous Years\n\n\nR Consortium\n\n\n\n\nApr 26, 2024\n\n\nBridging Gaps: Tunis R User Group’s Journey in Democratizing R in Bioinformatics\n\n\nR Consortium\n\n\n\n\nApr 19, 2024\n\n\nNavigating R’s Impact in Vienna: Insights from the Finance and Pharmaceutical Sectors\n\n\nR Consortium\n\n\n\n\nApr 18, 2024\n\n\nBuilding Data Highways: Kirill Müller’s Journey in Enhancing R’s Database\n\n\nR Consortium\n\n\n\n\nApr 15, 2024\n\n\nDecade of Data: Celebrating 10 Years of Innovation at the New York R Conference\n\n\nR Consortium\n\n\n\n\nApr 10, 2024\n\n\nThe Impact of R on Academic Excellence in Manchester, UK\n\n\nR Consortium\n\n\n\n\nApr 8, 2024\n\n\nEARL Early Bird Tickets Are Now Available!\n\n\nR Consortium\n\n\n\n\nApr 5, 2024\n\n\nR/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced\n\n\nR Consortium\n\n\n\n\nApr 4, 2024\n\n\nUnlocking Financial Insights: Join Us at the R Finance Conference\n\n\nR Consortium\n\n\n\n\nMar 28, 2024\n\n\nEmpowering R Enthusiasts: SatRDays London 2024 Unveiled\n\n\nR Consortium\n\n\n\n\nMar 27, 2024\n\n\nAligning Beliefs and Profession: Using R in Protecting the Penobscot Nation’s Traditional Lifeways\n\n\nR Consortium\n\n\n\n\nMar 26, 2024\n\n\nElevate Your R Community with the 2024 RUGS Grant Program\n\n\nR Consortium\n\n\n\n\nMar 19, 2024\n\n\nOffa R Users Group: Empowering Data-Driven Education in Nigeria\n\n\nR Consortium\n\n\n\n\nMar 13, 2024\n\n\nR-Ladies Goiânia: Promoting Diversity and Inclusion in Local R Community\n\n\nR Consortium\n\n\n\n\nMar 12, 2024\n\n\nISC-funded Grant: Secure TLS Connections in {nanonext} and {mirai} Facilitating High-Performance Computing in the Life Sciences\n\n\nR Consortium\n\n\n\n\nMar 7, 2024\n\n\nThe Cleveland R User Group’s Journey Through Pandemic Adaptations and Baseball Analytics\n\n\nR Consortium\n\n\n\n\nMar 1, 2024\n\n\nApply Now! R Consortium Infrastructure Steering Committee (ISC) Grant Program Open for Proposals!\n\n\nR Consortium\n\n\n\n\nFeb 28, 2024\n\n\nThe R Consortium 2023: A Year of Growth and Innovation\n\n\nR Consortium\n\n\n\n\nFeb 27, 2024\n\n\nMoffitt Cancer Center Bio-Data Club’s New Chapter in Spatial Data Analysis and Enhanced Hackathon Collaboration\n\n\nR Consortium\n\n\n\n\nFeb 23, 2024\n\n\nRecap: R Validation Hub Community Meeting\n\n\nR Consortium\n\n\n\n\nFeb 21, 2024\n\n\nJoin our R/Medicine Webinar: Quarto for Reproducible Medical Manuscripts\n\n\nR Consortium\n\n\n\n\nFeb 20, 2024\n\n\nR-Ladies Cotonou – A Community that Makes R Accessible for French-Speaking African Women\n\n\nR Consortium\n\n\n\n\nFeb 14, 2024\n\n\nUnlocking the Power of R for Insurance and Actuarial Science: Webinar Series Recap\n\n\nR Consortium\n\n\n\n\nFeb 13, 2024\n\n\nAnn Arbor R User Group: Harnessing the Power of R and GitHub\n\n\nR Consortium\n\n\n\n\nFeb 12, 2024\n\n\nUnraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024\n\n\nR Consortium\n\n\n\n\nFeb 8, 2024\n\n\nR Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!\n\n\nR Consortium\n\n\n\n\nFeb 7, 2024\n\n\nImproving with R: Kylie Bemis Unveils Enhanced Signal Processing with Matter 2.4 Upgrade\n\n\nR Consortium\n\n\n\n\nFeb 6, 2024\n\n\nJoin Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch\n\n\nR Consortium\n\n\n\n\nFeb 2, 2024\n\n\nNatalia Andriychuk on RUGs, Pfizer R Center of Excellence, and Open Source Projects: Fostering R Communities Inside and Out\n\n\nR Consortium\n\n\n\n\nJan 30, 2024\n\n\nWebinar for R and Databases! How Oracle Machine Learning for R Helps with ML and Massive Datasets\n\n\nR Consortium\n\n\n\n\nJan 24, 2024\n\n\n2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities\n\n\nR Consortium\n\n\n\n\nJan 16, 2024\n\n\nSatellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package\n\n\nR Consortium\n\n\n\n\nJan 15, 2024\n\n\nRebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations\n\n\nR Consortium\n\n\n\n\nJan 10, 2024\n\n\nJoin “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year\n\n\nR Consortium\n\n\n\n\nJan 10, 2024\n\n\nR for Public Health Data Analysis in Karachi, Pakistana\n\n\nR Consortium\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "webinars/unlocking-insights-from-latinr.html#date-and-time-october-22-2024-9am-pacific-time",
    "href": "webinars/unlocking-insights-from-latinr.html#date-and-time-october-22-2024-9am-pacific-time",
    "title": "Unlocking Insights from LatinR: Collaboration and Innovation in Data Science Webinar",
    "section": "Date and time: October 22, 2024, 9am Pacific time",
    "text": "Date and time: October 22, 2024, 9am Pacific time\nJoin us for an exciting webinar featuring the co-founders and co-chair of LatinR, as they share insights into the vibrant R community in Latin America and the evolution of the LatinR conference over its past six editions. Discover the impact this conference has had on the regional and global R community, learn about the unique aspects of R usage in Latin America, and get a sneak peek into what to expect at the upcoming LatinR 2024 edition. Whether you’re an experienced R user or just starting out, this session will offer valuable perspectives and opportunities for engagement!\nPresentation used in the webinar available here.\nAgenda\n\nThe Evolution of LatinR and its Impact on the Community: LatinR’s history, the growth of the community, and the role of the conference in fostering international and regional collaboration.\nLatinR Success Stories and Featured Projects: conference format, examples of experts who came, workshops, and collaborative projects that have emerged from LatinR.\nFuture of LatinR: what we will see in the 2024 edition, future perspectives for LatinR, and how the community can get more involved."
  },
  {
    "objectID": "webinars/unlocking-insights-from-latinr.html#speakers",
    "href": "webinars/unlocking-insights-from-latinr.html#speakers",
    "title": "Unlocking Insights from LatinR: Collaboration and Innovation in Data Science Webinar",
    "section": "Speakers",
    "text": "Speakers\n\nYanina Bellini\n\nYanina shares her experience teaching computational skills and building welcoming communities of practice for programming scientists. She is one of the co-founders and chairs of LatinR. She is also the rOpenSci Community Manager and part of the R-Ladies Leadership Team. She has 30 years of experience in education and 24 years as a researcher.\n\n\nNatalia Da Silva\n\nNatalia is an Assistant Professor of Statistics at Universidad de la República in Montevideo, Uruguay, with a Ph.D. in Statistics from Iowa State University, whose research focuses on supervised learning, exploratory data analysis, statistical graphics, and reproducible research, and who co-founded LatinR, R-Ladies Montevideo, and the Montevideo R User Group (GURU), while also serving as an Associate Editor for Reproducibility at the Journal of the American Statistical Association.\n\n\nRiva Quiroga\n\nRiva Quiroga is a Linguist based in Valparaíso, Chile. She is one of the co-founders and chairs of LatinR, and part of the R-Ladies Global Team."
  },
  {
    "objectID": "webinars/containerization-and-r-for-reproducibility.html#abstract",
    "href": "webinars/containerization-and-r-for-reproducibility.html#abstract",
    "title": "Containerization and R for Reproducibility and More",
    "section": "Abstract",
    "text": "Abstract\nContainerization has become a dominant computing paradigm for computing in the past decade due to its many advantages: isolation and security, scalability and efficiency with lightweight containers sharing an operating kernel and resources, and portability across cloud computing providers. For the researcher, analyst, or R user, containers have applications ranging from reproducible analytical environments to packaging statistical code to use in web applications. I will discuss how biomedical researchers can make use of containerization technology, particularly the tools provided by the Rocker Project, which publishes powerful standardized containers for the R language."
  },
  {
    "objectID": "webinars/containerization-and-r-for-reproducibility.html#speaker",
    "href": "webinars/containerization-and-r-for-reproducibility.html#speaker",
    "title": "Containerization and R for Reproducibility and More",
    "section": "Speaker",
    "text": "Speaker\n\nNoam Ross is a computational disease ecologist and Executive Director of rOpenSci, a nonprofit dedicated to promoting open science and validating data science and computational methods. He is a core member of the Rocker Project, which maintains standardized containers for the R computer language. Noam’s work includes spearheading rOpenSci’s work in software peer review, developing a widely emulated system for leveraging the academic peer-review process coupled with state-of-the art automated code analysis to improve code quality in the scientific software in ecosystem, as well as using review as a mechanism for community building and training. His research interests and contributions span a wide range of topics, including disease ecology, zoonotic spillover, mechanistic modeling of disease dynamics, and non-parametric data science methods. His applied work includes creating early outbreak assessment models for the U.S. Defense Threat Reduction Agency, and modeling and forecasting for New York State’s COVID-19 emergency response. Noam holds a Ph.D. in theoretical ecology from the University of California-Davis and a B.Sc. from Brown University."
  },
  {
    "objectID": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html",
    "href": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html",
    "title": "R/Medicine: Quarto for Reproducible Medical Manuscripts",
    "section": "",
    "text": "Slides available here:\nQuarto Manuscript\nGithub – Quarto Manuscript\nManuscript:\nmine-cetinkaya-rundel.github.io/indo-rct\ngithub.com/mine-cetinkaya-rundel/indo-rct"
  },
  {
    "objectID": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html#summary",
    "href": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html#summary",
    "title": "R/Medicine: Quarto for Reproducible Medical Manuscripts",
    "section": "Summary ",
    "text": "Summary \nIn this talk, Mine Cetinkaya-Rundel, Professor of the Practice of Statistical Science at Duke University,  presents a new capability in Quarto that provides a straightforward and user-friendly approach to creating reproducible manuscripts that are publication-ready for submission to science journals. \nThis new feature, Quarto manuscripts, includes the ability to produce a bundled output containing a standardized journal format, source documents, source computations, referenced resources, and execution information into a single bundle that be ingested into journal review and production processes. \nIn this talk, we’ll demo how Quarto manuscripts work and how you can incorporate them into your current manuscript development process as well as touch on pain points in your current workflow that Quarto manuscripts help alleviate."
  },
  {
    "objectID": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html#speaker",
    "href": "webinars/r-medicine-quarto-for-reproducible-medical-manuscripts.html#speaker",
    "title": "R/Medicine: Quarto for Reproducible Medical Manuscripts",
    "section": "Speaker",
    "text": "Speaker\n\n\n\n\n\nMine Çetinkaya-Rundelis, is Professor of the Practice of Statistical Science and the Director of Undergraduate Studies in the Department of Statistical Science, as well as an affiliated faculty member in the Computational Media, Arts, and Cultures program at Duke University. Her work is dedicated to advancing innovation in statistics and data science pedagogy, focusing particularly on computing, reproducible research, student-centered learning, and open-source education. She emphasizes integrating computation into the undergraduate statistics curriculum, employing reproducible research methodologies, and analyzing real and complex datasets. In Spring 2024, she will be teaching STA 199 – Introduction to Data Science and Statistical Thinking, along with STA 313 – Advanced Data Visualization. Further details about her work can be explored below, or she can be found on Mastodon and Bluesky."
  },
  {
    "objectID": "webinars/escape-the-data-dungeon.html#summary",
    "href": "webinars/escape-the-data-dungeon.html#summary",
    "title": "Escape the Data Dungeon: Unlock Scalable R Analytics and ML",
    "section": "Summary",
    "text": "Summary\nTired of sluggish R data processing and limited Machine Learning (ML) options with large databases? Imagine swiftly predicting customer churn and deploying solutions with ease. Watch our in-depth Oracle Machine Learning for R (OML4R) webinar to learn more!\nKey topics included:\n\nSeamless In-Database Access: Jump straight into your data without the drag of extractions.\nScalable High-Performance Data Processing: Handle huge datasets effortlessly.\nIntegrated In-Database ML: Develop and deploy potent models right within your database.\nEffortless Production Deployment: Streamline your R scripts from development to production.\n\nFound out more about OML4R through practical examples in product bundling, demand forecasting, and customer churn prediction. Escape the data grind and transformed your R experience."
  },
  {
    "objectID": "webinars/escape-the-data-dungeon.html#speakers",
    "href": "webinars/escape-the-data-dungeon.html#speakers",
    "title": "Escape the Data Dungeon: Unlock Scalable R Analytics and ML",
    "section": "Speakers",
    "text": "Speakers\n\n\nMark Hornick, Senior Director, Oracle Machine Learning\nMark Hornick is senior director of product management for Oracle Machine Learning. Mark has more than 20 years of experience integrating and leveraging machine learning with Oracle software as well as working with internal and external customers to apply Oracle’s machine learning technologies. He has been involved with R technology for the past 15 years.  Mark is Oracle’s representative to the R Consortium and is an Oracle Adviser of the Analytics and Data Oracle User Community. He has been issued seven US patents. Mark holds a bachelor’s degree from Rutgers University and a master’s degree from Brown University, both in computer science. Follow him on Twitter @MarkHornick and connect on LinkedIn.\n\n\n\nSherry LaMonica, Consulting MTS, Oracle Machine Learning\nSherry is a member of the Oracle Machine Learning Product Management team. She has 20 years of software experience focused on enabling the commercial use of the open-source data analysis software systems with R and Python for data science and machine learning projects. She has worked with customers in fields as diverse as pharmaceutical research, financial analysis, manufacturing, and healthcare IT."
  },
  {
    "objectID": "webinars/escape-the-data-dungeon.html#the-r-adoption-series",
    "href": "webinars/escape-the-data-dungeon.html#the-r-adoption-series",
    "title": "Escape the Data Dungeon: Unlock Scalable R Analytics and ML",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series. If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/quantification-of-participation-risk-using-r-and-rshiny.html",
    "href": "webinars/quantification-of-participation-risk-using-r-and-rshiny.html",
    "title": "Quantification of Participation Risk using R and R Shiny",
    "section": "",
    "text": "Webinar held on December 12th, 2024, on Quantification of Participation Risk Using R and R Shiny. Presented by Raiffeisenlandesbank Oberösterreich (RLB OÖ), this session delved into the bank’s advanced risk management practices, highlighting how they leverage R and R Shiny for effective data visualization and risk assessment.\nSlides\nRepo\nAgenda Highlights:\n\nIntroduction to RLB OÖ: Overview of Austria’s leading regional bank, its strategic business fields, and its regional and international network.\nRisk Quantification Framework: Insight into the risk quantification process using R, focusing on participation risk and its challenges.\nApplication of R and R Shiny: Practical demonstration of R Shiny’s capabilities in visualizing and managing risk data, streamlining operations, and supporting decision-making.\nCase Study: Real-life applications in managing participation risk within a complex financial ecosystem.\n\nPresenters:\n\nGoran Lovric, LL.M., a seasoned expert with over 18 years of experience in national and international financial risk management, holding certifications such as Financial Risk Manager (GARP) and Professional Risk Manager (PRMIA).\n\nSimon Aigner, MSc, an Economic and Business Analytics professional at RLB OÖ, specializes in automating internal risk management processes using R, enhancing operational efficiency and minimizing risk exposure.\nThis webinar is a unique opportunity for finance professionals, data analysts, and R enthusiasts to gain hands-on insights into using R and R Shiny for sophisticated risk assessment. Don’t miss this chance to learn from industry experts about harnessing open-source tools in the financial sector!"
  },
  {
    "objectID": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#slide-deck-available",
    "href": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#slide-deck-available",
    "title": "Tidy Finance and Accessing Financial Data",
    "section": "Slide deck available:",
    "text": "Slide deck available:\nTidy Finance and Accessing Financial Data (PDF)"
  },
  {
    "objectID": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#summary",
    "href": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#summary",
    "title": "Tidy Finance and Accessing Financial Data",
    "section": "Summary",
    "text": "Summary\nThis webinar focuses on Tidy Finance and accessing financial data. Tidy Finance is an opinionated approach to empirical research in financial economics. It provided a fully transparent, open source code base in R and Python. The website provides the tools for students to learn about empirical applications based on a fully transparent code base and for instructors the materials for teaching the importance of reproducible research using tidy principles.\nChristoph Scheuch introduces Tidy Finance and illustrates the underlying principles. The webinar then focuses on accessing and managing financial data using R. It shows how to import different open source and proprietary data sets and organize them in a database."
  },
  {
    "objectID": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#agenda",
    "href": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#agenda",
    "title": "Tidy Finance and Accessing Financial Data",
    "section": "Agenda:",
    "text": "Agenda:\n\nIntroduction to Tidy Finance\nAccessing and Managing Financial Data\nWRDS & Other Data Providers\nQ&A Session"
  },
  {
    "objectID": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#speaker",
    "href": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#speaker",
    "title": "Tidy Finance and Accessing Financial Data",
    "section": "Speaker",
    "text": "Speaker\n\n\nChristoph Scheuch is the Head of Artificial Intelligence at the social trading platform wikifolio Financial Technologies AG. He is responsible for researching, designing, and prototyping of cutting-edge AI-driven products using R and Python. Before his focus on AI, he was responsible for product management and business intelligence at wikifolio Financial Technologies AG and an external lecturer at the Vienna University of Economics and Business, where he taught finance students how to manage empirical projects"
  },
  {
    "objectID": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#the-r-adoption-series",
    "href": "webinars/new-webinar-tidy-finance-and-accessing-financial-data.html#the-r-adoption-series",
    "title": "Tidy Finance and Accessing Financial Data",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series. If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#abstract",
    "href": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#abstract",
    "title": "Augmenting your Quarto website with Retrieval-Augmented Generation (RAG) using Select AI in Autonomous Database",
    "section": "Abstract",
    "text": "Abstract\nRetrieval augmented generation (RAG) combines vector search with generative AI – enabling more relevant and up-to-date responses from your large language model (LLM). In this session, we highlight augmenting a Quarto website to accept a natural language prompt and display the response generated using an LLM, text transformer, and vector store. Specifically, this scenario uses the Select AI and AI Vector Search features of Oracle Autonomous Database 23ai. Select AI automates vector index creation leveraging AI Vector Search directly in your database. Select AI automates the orchestration process to enable RAG. Our scenario leverages R Consortium content from blogs and their new Quarto website for the demonstration."
  },
  {
    "objectID": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#speakers",
    "href": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#speakers",
    "title": "Augmenting your Quarto website with Retrieval-Augmented Generation (RAG) using Select AI in Autonomous Database",
    "section": "Speakers",
    "text": "Speakers\n\n\nMark Hornick, Senior Director, Oracle Machine Learning\nMark Hornick is senior director of product management for Oracle Machine Learning. Mark has more than 20 years of experience integrating and leveraging machine learning with Oracle software as well as working with internal and external customers to apply Oracle’s machine learning technologies.\nHe has been involved with R technology for the past 15 years.  Mark is Oracle’s representative to the R Consortium and is an Oracle Adviser of the Analytics and Data Oracle User Community. He has been issued seven US patents. Mark holds a bachelor’s degree from Rutgers University and a master’s degree from Brown University, both in computer science. Follow him on Twitter @MarkHornick and connect on LinkedIn.\n\n\n\nSherry LaMonica, Consulting MTS, Oracle Machine Learning\nSherry is a member of the Oracle Machine Learning Product Management team. She has 20 years of software experience focused on enabling the commercial use of the open-source data analysis software systems with R and Python for data science and machine learning projects. She has worked with customers in fields as diverse as pharmaceutical research, financial analysis, manufacturing, and healthcare IT."
  },
  {
    "objectID": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#the-r-adoption-series",
    "href": "webinars/oracle-augmenting-your-quarto-website-with-rag-select-ai-autonomous-database.html#the-r-adoption-series",
    "title": "Augmenting your Quarto website with Retrieval-Augmented Generation (RAG) using Select AI in Autonomous Database",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series.\nIf there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/RMedicineWebinar.html",
    "href": "webinars/RMedicineWebinar.html",
    "title": "R/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package",
    "section": "",
    "text": "This webinar focused on the {ggsurvfit} R package, a tool designed to simplify the creation of time-to-event or survival analysis summary figures using {ggplot2}. It emphasized the package’s capability to produce high-quality, publication-ready Kaplan-Meier plots and other survival analysis figures with ease and efficiency. Overall, the webinar promised to be an informative session for statisticians, data analysts, and researchers interested in survival analysis, offering insights into how {ggsurvfit} could enhance their data visualization capabilities in R."
  },
  {
    "objectID": "webinars/RMedicineWebinar.html#speaker",
    "href": "webinars/RMedicineWebinar.html#speaker",
    "title": "R/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package",
    "section": "Speaker",
    "text": "Speaker\n\nDaniel D. Sjoberg (he/him) is a Software Engineer at Genentech. Previously, he was a Lead Data Science Manager at the Prostate Cancer Clinical Trials Consortium and a Senior Biostatistician at Memorial Sloan Kettering Cancer Center in New York City. He enjoys R package development, creating many packages available on CRAN, R-Universe, and GitHub. His research interests include adaptive methods in clinical trials, precision medicine, and predictive modeling. Daniel is the winner of the 2021 American Statistical Association (ASA) Innovation in Statistical Programming and Analytics award."
  },
  {
    "objectID": "posts/natalia-andriychuk-on-rugs-pfizer-r-center-of-excellence-and-open-source-projects-fostering-r-communities-inside-and-out/index.html",
    "href": "posts/natalia-andriychuk-on-rugs-pfizer-r-center-of-excellence-and-open-source-projects-fostering-r-communities-inside-and-out/index.html",
    "title": "Natalia Andriychuk on RUGs, Pfizer R Center of Excellence, and Open Source Projects: Fostering R Communities Inside and Out",
    "section": "",
    "text": "The R Consortium recently talked with Natalia Andriychuk, Statistical Data Scientist at Pfizer and co-founder of the RTP R User Group (Research Triangle Park in Raleigh, North Carolina), to get details about her experience supporting the Pfizer R community and starting a local R user group.\nShe started her R journey over 7 years ago, and since then, she has been passionate about open source development. She is a member of the Interactive Safety Graphics Task Force within the American Statistical Association Biopharmaceutical Safety Working Group, which is developing graphical tools for the drug safety community.\nNatalia Andriychuk at posit:conf 2023\nPlease share your background and involvement with the R community at Pfizer and beyond.\nFrom 2015 to 2022, I worked at a CRO (Contract Research Organization) in various roles, where I discovered my passion for Data Science after being introduced to R, JavaScript, and D3 by my talented colleagues. I became a part of an amazing team where I learned valuable skills.\nLater, when I began looking for new career opportunities, I knew that I wanted to focus on R. I sought a role that would deepen my R skills and further advance my R knowledge. This is how I came to join Pfizer in 2022 and became a part of the amazing team. I am a Statistical Data Scientist in the R Center of Excellence SWAT (Scientific Workflows and Analytic Tools) team.\nPfizer SWAT team at posit::conf2023 (left to right: Natalia Andriychuk, Mike K Smith, Sam Parmar, James Kim)\nThe R Center of Excellence (CoE) supports various business lines at Pfizer. We provide technical expertise, develop training on R and associated tools, promote best practices, and build a community of R users within Pfizer. Our community currently consists of over 1,200 members.\nI will present Pfizer’s R CoE progress and initiatives during the R Consortium R Adoption Series Webinar on February 8th at 3:00 pm EST.\nMy first introduction to the R community was through the posit::conf (previously known as rstudio::conf) in 2018. Attending the conference allowed me to witness the welcoming nature of the R community. Five years later, in 2023, I made it to the speakers’ list and presented at the posit::conf 2023. It was an incredible experience!\nI also follow several other avenues to connect with R community members. As the name suggests, I read R Weekly weekly and attend the Data Science Hangout led by Rachael Dempsey at Posit. Every Thursday, Rachael invites a data science community leader to be a featured guest and share their unique experiences with the audience. Fortunately, I was invited as a featured guest to one of the Posit Data Science Hangouts. I shared my experience organizing and hosting an internal R at Pfizer Hangout.\nCan you share your experience of starting the RTP (Research Triangle Park) R User Group?\nNicholas Masel and I co-organize the RTP R User Group in our area. We formed the RTP R User Group in 2023 and have held three meetings‌: meet-and-greet, social hour, and a posit::conf 2023 watch party.\nRTP R User Group Social Hour Gathering\nWe hope to expand and increase attendance at our meetups in 2024. We currently have approximately 74 members who joined the online meetup group, and we look forward to meeting all of them in person moving forward.\nCan you share what the R community is like in the RTP area?\nNicholas and I both work in the pharmaceutical industry, and thus far, our in-person user group meetings have predominantly included individuals from this field. However, we want to emphasize that our user group is open to everyone, regardless of industry or background.\nThe RTP area has great potential for a thriving R User Group. We are surrounded by three major universities (University of North Carolina at Chapel Hill, Duke University, and North Carolina State University), the growing high-technology community and a notable concentration of life science companies. We anticipate attracting more students in the coming year, especially those studying biostatistics or statistics and using R in their coursework. We also look forward to welcoming individuals from various industries and backgrounds to foster a rich and collaborative R user community.\nPlease share about a project you are working on or have worked on using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nI am an open source development advocate, believing in the transformative power of collaborative innovation and knowledge sharing. I am a member of the Interactive Safety Graphics (ISG) Task Force, part of the American Statistical Association Biopharmaceutical Safety Working Group. The group comprises volunteers from the pharmaceutical industry, regulatory agencies, and academia to develop creative and innovative interactive graphical tools following the open source paradigm. Our task force is developing a collection of R packages for clinical trial safety evaluation. The {safetyGraphics} package we developed provides an easy-to-use shiny interface for creating shareable safety graphics for any clinical study.\n{safetyGraphics} supports multiple chart types including web-based interactive graphics using {htmlwidgets}\nWe are preparing to share three new interactive visualizations we developed in 2023 during the upcoming ASA-DIA Safety Working Group Quarterly Scientific Webinar – Q1 2024 on January 30 (11:00 – 12:30 EST). Participating in the ISG Task Force has been an invaluable experience that allowed me to learn from talented data scientists and expand my professional network."
  },
  {
    "objectID": "posts/natalia-andriychuk-on-rugs-pfizer-r-center-of-excellence-and-open-source-projects-fostering-r-communities-inside-and-out/index.html#how-do-i-join",
    "href": "posts/natalia-andriychuk-on-rugs-pfizer-r-center-of-excellence-and-open-source-projects-fostering-r-communities-inside-and-out/index.html#how-do-i-join",
    "title": "Natalia Andriychuk on RUGs, Pfizer R Center of Excellence, and Open Source Projects: Fostering R Communities Inside and Out",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 65,000 members in 35 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/streamlining-api-integration-jon-harmons-journey-with-the-api2r-package/index.html",
    "href": "posts/streamlining-api-integration-jon-harmons-journey-with-the-api2r-package/index.html",
    "title": "Streamlining API Integration: Jon Harmon’s Journey with the api2r Package",
    "section": "",
    "text": "The R Consortium recently interviewed Jon Harmon, Principal Data Solutions Engineer at Atorus, about his ISC-funded project, api2r. Jon’s extensive experience working with APIs from platforms like Slack, YouTube, and LinkedIn, along with his leadership of the Data Science Learning Community (DSLC.io), inspired him to develop api2r to simplify the process of wrapping APIs in R. The package streamlines the creation of R packages for various APIs by leveraging the OpenAPI standard, making it easier for developers to integrate external services into their R workflows.\nJon discusses the challenges he faced during the package’s development, particularly around authentication and endpoint setup, and how api2r differs from other tools like {httr2} and {paws}.\nThe R Consortium funded this project.\nWhat inspired you to create the api2r package, and how do you envision benefiting the R community?\nI run the Data Science Learning Community (DSLC) at dslc.io, and through that, as well as some paid work, I frequently work with various APIs like Slack, YouTube, Zoom, LinkedIn, and different task management systems. I noticed that most of these are documented using the OpenAPI Specification or an older variant, which made it easier for me to read and write R code for them.\nHowever, I found myself repeatedly looking up how I had done similar tasks before, which made me realize it would be much easier if I created a tool to streamline this process. Since I love writing R packages, it felt natural to pursue this idea.\nIn terms of how the R community could benefit, I want to make it easier for others to wrap APIs in R so people can create packages for whatever tasks they might need.\nCan you elaborate on the challenges you foresee in implementing authentication and endpoint calls in the initial milestone (version 0.1.0)?\nI’ve actually moved past the initial milestone of setting up authentication, but it definitely presented—and continues to present—challenges. First, I ended up splitting the package into three parts. There’s rapid, which parses API descriptions into a standard object, nectar, which wraps the httr2 package to handle common tasks, and beekeeper, which is the main package. Nectar was particularly helpful because I was able to abstract the standard types of authentication into just a few simple wrappers. While httr2 handles much of the heavy lifting, it doesn’t guide you through what you need to find in the documentation. That’s where Nectar steps in, helping streamline the setup process.\nThat said, there are still ongoing challenges. Many sites don’t fully or correctly implement the OpenAPI Specification, making it difficult to find the necessary information. Even when they do, details on how to obtain an API key can be tricky to track down. I spent a lot of time trying to address this issue, although there’s no perfect solution. Fortunately, after I wrote my grant application, a new version of httr2 was released that simplifies a lot of these processes, which has been a big help.\nHow does the api2r package aim to address the inconsistencies and inefficiencies in the current process of wrapping APIs into R packages?\nOne thing I really wanted to focus on is the challenge of testing packages that wrap APIs. I’ve helped many people navigate this issue, as it’s easy for your package to get rejected from CRAN if the tests are not set up correctly or if they require an internet connection. To address this, I made sure that part of the automatic package building process includes generating a test suite that follows best practices for API testing.\nWith the Nectar package I mentioned earlier, it simplifies things by abstracting common setups—normally done with something like httr2—down to just what’s necessary, based on the API documentation. This creates a straightforward, one-to-one correspondence between what the API specifies and what you need to do, automatically generating a version of the package that handles this process smoothly.\nWhat are the key differences between the api2r package and other API-related tools like {httr}, {httr2}, and {paws}?\nPaws is actually a family of packages designed specifically for working with Amazon Web Services (AWS) APIs, which is just one use case. The goal of the API to R family of packages I created is to make it easier to write packages like Paws. Essentially, Paws could be a package you’d create using my tools.\nI extensively use httr2 (the updated version of httr), which helps simplify writing API calls.\nHowever, with httr2, you still have to manually piece everything together. The idea behind API to R is to take the API documentation and automatically build the httr2 calls for you, eliminating the need to manually complete all the intermediate steps.\nHow do you plan to engage the R community in the development and testing of the api2r package, and what role do you see for collaboration?\nI engage with many members of the R community on social media, primarily through Mastodon and LinkedIn, where I share updates about the packages I’m working on, like API to R. I also maintain websites for these packages, and you can visit beekeeper.api2r.org to find links to all of them. I keep everything up to date there.\nAs I mentioned earlier, I run the Data Science Learning Community at dslc.io, which now has over 19,000 members, with 400-500 active weekly. Most of our members are R users, and I regularly keep the group updated. We also host a monthly project club where members present their work, and I’ve presented about this project a few times. I’m also active on other R platforms like the ROpenSci Slack team and various Discord channels.\nThat being said, I’ve reached a point where I could use some help. I’d love for people to check out the GitHub repositories for these packages and share how they’re using them. If you encounter any bugs or have feedback, let me know. Just last week, I had an interaction on Mastodon where someone was working with a new API and asked if I could help. While we haven’t fully connected yet, I was able to send them the documentation to get started on creating the package and exploring what works and what doesn’t. It’s exciting to see where this could lead!\nWhat are your long-term goals for maintaining and expanding api2r, and how do you plan to ensure its sustainability in the R ecosystem?\nI strongly believe in developing everything openly, so the project is available on GitHub for anyone to explore. You can access it from the website. Since it’s public, people are free to use it however they like. If I don’t take the project in the direction they prefer, they can fork it and work on their own version.\nI also work closely with rOpenSci and other package developers to ensure that there’s a supportive community to keep things running. That said, if anyone is particularly interested in this package and its goals, I would really welcome an active collaborator or two to help manage and advance it. The standard we’re using—like the object version of the OpenAPI Specification—does evolve, and as APIs update, the package will need to adapt as well. My aim is to keep this project going long-term, and I don’t want it to rely entirely on me. Collaboration would be key to ensuring it grows and stays up to date.\nHow has it been working with the R Consortium? Would you recommend applying for an ISC grant to other R developers?\nThe R Consortium has been fantastic to work with—completely reasonable, transparent, and supportive at every step. The challenge for me, however, was that I seriously underestimated how much work this project would require. It wasn’t just about the difficulty; I also ended up going off on tangents that weren’t part of the original plan. Since the grant was milestone-based, there are still some milestones I haven’t reached, and that’s been tough to manage.\nI definitely recommend applying for an ISC grant if you’re working on something, but I would advise being very careful with how you structure your proposal. I got a bit stuck in my details, and now I’m at a point where I have to find extra time to work on it. There’s still some grant money left, but not enough to fully cover the remaining work. So, I tend to work on the project when I have a specific use for it and can justify the time.\nOverall, having the grant was incredibly helpful in giving me the time and space to explore this package, but it’s something to approach with caution regarding planning and execution."
  },
  {
    "objectID": "posts/streamlining-api-integration-jon-harmons-journey-with-the-api2r-package/index.html#about-isc-funded-projects",
    "href": "posts/streamlining-api-integration-jon-harmons-journey-with-the-api2r-package/index.html#about-isc-funded-projects",
    "title": "Streamlining API Integration: Jon Harmon’s Journey with the api2r Package",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nhttps://r-consortium.org/all-projects/"
  },
  {
    "objectID": "posts/pharma-rug-the-rise-of-r/index.html",
    "href": "posts/pharma-rug-the-rise-of-r/index.html",
    "title": "Pharma RUG: The Rise of R in China’s Pharmaceutical Industry",
    "section": "",
    "text": "PharmaRUG, China organizer Joe Zhu, spoke with the R Consortium about the growing R community and the increasing use of R in the pharmaceutical industry in China. The group has contributed to the pharmaceutical R community through several R packages. Since its establishment last year, the group has organized large-scale hybrid events. Joe also shared some tools and techniques for smoothly organizing and running hybrid events.\n\nPlease share about your background and involvement with the RUGS group.\nI have a PhD in statistics and studied in New Zealand for my undergraduate and postgraduate degrees in statistics. My PhD work focused on theoretical coalescent theory and probabilistic modeling for phylogenetics models. I also completed a postdoc at Oxford, focusing on statistical genomics for the human genome and malaria parasite genome projects. During this time, I developed open source software tools for statistical genomics, primarily using R as a front end and developing C++ software.\nFor the past four years, I’ve worked at Roche, where I started leading a major collaboration initiative in pharma three years ago. I’ve created TLG (table, listing, and figures) for regulatory submissions to the FDA. Throughout this initiative, we have open sourced around 30 software packages, including `formatters`, `rtables`, `rlistings` and `tern`. Last year, we submitted these packages to CRAN.\nAt first, we open sourced the project on GitHub and then submitted it to CRAN. I’m heavily involved in one of China’s R user groups, PharmaRUG. We use the group to share posts about developments in the area, and we organize events and conferences. In March last year, we hosted the first event with over 100 people on-site and around 100 online. The event covered topics like R package usage in the pharma industry. Later that year, we organized another event called “Open Source Clinical Reporting summeR“. \n\nLately, I have been busy organizing several events. I recently gave a talk (about R package dependencies as directed in acyclic graphs) at a conference hosted by the R community in China. Early next month, on August 1st, I will attend a pharma conference where I will conduct a workshop on good practices in software package development. The conference schedule is quite packed for me as I also have a session on how teams operate and collaborate within the Pharma industry to develop R packages. On the third day of the conference, I will organize a series of 11 data visualization talks, one of which is about Python. Most of the talks will focus on using R, except for one discussion on Python.\nCan you share what the R community is like in China? \n\nWe have opened up seats for students to join our events in the pharmaceutical industry. In the past, fewer than 20 students, mostly from academia, have joined us for these conferences. The events include big names like Roche, Johnson & Johnson, Novartis, Boehringer Ingelheim, and Sanofi and local companies such as Fosun, Hengrui, and Legend Biotech. There is a big R community in China across academia and industry. Our user group primarily focuses on the pharma industry. Our WeChat channel has nearly a thousand subscribers, and our group chat has almost 500 members. It’s a very active community. \nLater this year, we will collaborate with the “R in Pharma” for the October conference. Daniel Sabanes Bove and I have contacted Harvey and Phil, and we will organize an APAC track, including India, China, Japan, Australia, Singapore, and Korea. \nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nWe have created a GitHub account called PharmaRUG. We use this platform to share websites, posts, slides, and videos related to our events. The Pharma RUG 2024 conference was particularly successful this year, thanks to the support from the R Consortium. We also utilize WeChat groups to call for speakers and interact with others. In addition to GitHub and WeChat, we use Tencent Docs to share documents. This is particularly useful in China, where using company-specific platforms like Google or Microsoft can be hindered by firewalls. Tencent Docs works perfectly in China, making sharing and synchronizing documents easy.\nCan you share some valuable tips for organizing succesful Hybrid events?\n\nWe have a series of planning sessions where we actively communicate using WeChat. We meet at a community center where everyone is open, and we have preset meetings. We test the audio and everything beforehand. This is our second year organizing these events, so we have gained more experience. We are now familiar with the standards and know what needs to be done. For example, when two companies, like MNCs, use different systems, we find it better to use one shared system to ensure everything is synchronized.\nWe’ve found that Microsoft Teams is easy to use for setting up meetings and scheduling them ahead of time. For live demos, we recommend pre-recording the demos and taking questions. In the case of hybrid sessions with multiple locations, we prioritize asking and answering questions based on the primary and secondary locations, as well as online participation. If we cannot answer questions quickly, we host Q&A sessions afterward and share them online.\nI believe that for the event to be successful, timing is crucial. We must stick to the schedule because it’s a hybrid event. However, we should also allow for some flexibility when unexpected things come up. We haven’t created a YouTube account yet because YouTube isn’t accessible in China. One alternative could be setting up a Bilibili web page and account to share the videos. All our files are currently on GitHub, which is convenient. We need to trim the videos to smaller sizes to fit GitHub’s file size limits, maybe at four and a half speeds or similar.\nWhat trends do you currently see in R language and your industry?\nSo, SAS has dominated the software space for the Pharma industry for decades. While it used to be used for exploratory and research purposes, there have been successes with using Office to support missions in recent years. Roche also has success stories in this area. There are several initiatives, with PharmaVerse being a significant player. Roche is part of PharmaVerse, taking inspiration from the tidyverse multiverse concept. The end-to-end clinical reporting process is considered in this space, from data preparation to TLG generations. A lot has happened in the past three to four years, especially in China last year. There’s been significant development in China, and you can see a shift from SAS to R in the tools used. At the PharmaSUG meeting, which was previously dominated by SAS users, in the past few years, a quarter to one-third of the tools are using languages other than SAS. It’s clear that things are moving away from SAS towards software languages like R.\nThis year, I don’t have the complete statistics with me right now, but you do see a lot of topics. In my session, I’m sharing, and you know, many talks use visualization because it’s much likable. So, the trend is that R is becoming more acceptable than before, from PLCs to things in production. There are very high standards for codes and validation.\nIn the end, I would like to thank my dear friends and colleagues for their support and for making this happen\n\nYan Qiao, Associate Director of Scientific Programming, Beigene, \nBaoqin Li, China Head Clinical & Statical Programming, Johnson & Johnson\nDong Guo, China head of Stats Analyst, Eli-lilly&Company\nYun Ma, Director, clinical data Sciences, Boehringer Ingelheim (china) Investment Co.\nYanli Chang, Head of Data Operations China, Novartis\n\nHow do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/cakes-code-and-community-reviving-the-copenhagenr-user-group/index.html",
    "href": "posts/cakes-code-and-community-reviving-the-copenhagenr-user-group/index.html",
    "title": "Cakes, Code, and Community: Rasmus Bååth’s Secret to Reviving the CopenhagenR UseR Group",
    "section": "",
    "text": "Rasmus Bååth, the organizer of the CopenhagenR UseR Group, recently spoke to the R Consortium about his experience in organizing the group. After joining the Copenhagen R User Group in 2013, he took the lead in reviving the group in 2023 after a period of inactivity. Under his guidance, the group now focuses on industry-related topics, personal projects, and emerging tools like Quarto. Rasmus is dedicated to fostering a vibrant local R community through in-person meetups that encourage learning and collaboration.\nThe CopenhagenR UseR Group is hosting an exciting “Two Tools for Report Generation in R” event on October 3, 2024. The event will feature two presentations on using Sweave and Quarto for report generation, followed by discussions and networking at PROSA, København, Denmark.\nPlease share your background and involvement with the RUGS group.\nI currently work as a Data Science Manager at Normative.io. I’ve used R on and off for about 15 or 16 years. It all started when I was doing my bachelor’s in academia and needed to plot a histogram. At that time, plotting a histogram in Excel wasn’t easy, so my supervisor suggested trying out R. I gave it a shot and got hooked. After that, I pursued a PhD in cognitive science, where I used R extensively for statistical analysis.\nI used R for a lot of graphing during my academic years. After academia, I became a data scientist in the industry, and R was my preferred tool. I work with R and Python, depending on the job’s requirements. In 2013, there were no R meetups in the south of Sweden where I live. I found out about an R meetup in Copenhagen and decided to attend. There, I met Kenneth Rose, the organizer, who was full of energy and charisma. It was a fun group, so I started attending regularly despite the commute from Sweden to Copenhagen. Kenneth was very active and enthusiastic in running the meetup group.\nAfter a couple of years, the group’s activity declined. A new organizer revived the group, but COVID hit, ending the meetups. The group had been around for ten years by 2023, and I felt it was a shame to let it die. I decided to restart it, and now we have a small but active group. We enjoy discussing industry-related topics and personal projects.\nCan you share what the local R community is like?\nIt is the Copenhagen meetup group located in Denmark. However, I can speak for Denmark and Sweden since I live in Sweden. R is widely used in academia and is considered the language of choice for statistics. Python is more prevalent in the industry due to the large number of programmers who are familiar with the language. In Denmark, the pharmaceutical industry is significant. R is still widely used there due to its close ties to academia and the specific requirements for reporting, statistics, and visualization, in which R excels.\nDo you guys host online or in-person events?\nDuring the COVID-19 pandemic, we tried some online events, but creating a sense of community online with so much content is challenging. I believe online events are great, and people should consider them. However, we also recognize the need for in-person events. For those unable to attend, there is plenty of valuable content online. We don’t have the setup to record events, but we would consider doing so if feasible.\nYou have a Meetup titled “Two tools for report generation in R.” Can you share more on the topic covered? Why this topic?\nOur next meetup will focus on automatic reporting in R. We’ll have two speakers: Dmytro Perepolkin and an anonymous speaker. The anonymous speaker will present on Sweave, an older tool used to generate reports in R, while Dmytro will present on Quarto, a more recent and popular tool for combining R code and text. This meetup will depart from the usual topics, focusing on automatic reporting rather than visualization.\nI’m looking forward to our upcoming event. It will be a history lesson and a great opportunity to learn about a useful minimalistic tool (Sweave). I’m also excited about Quarto and the potential for new developments. We could have a Quarto meetup every year to stay updated with the latest advancements. The meetup will feature different presentations, including introductions to new tools and discussions about projects and code. It will be a great way to learn and connect with others in the field.\nWhat are some of the popular R-related topics in the group?\nThe topics we typically cover are where R is at its strongest. We often discuss personal projects, and although I wonder if they receive a great response, I love them. Additionally, we frequently explore new tools and libraries, particularly those related to dashboarding, Shiny, and visualization. Presentations are highly technical, and I’ve noticed that our audience may not be accustomed to text-heavy or math-intensive presentations. Therefore, topics such as statistics and statistics packages might not receive as much attention despite my interest in them. Surprisingly, machine learning is not a common focus at our meetups, as most speakers are more inclined towards visualization, reporting, and statistics rather than machine learning.\nDo you recommend any techniques for planning for or during the event? (GitHub, Zoom, other.) Can these techniques be used to make your group more inclusive to people who cannot attend physical events in the future?\nThere are three key components needed to get started with organizing an event. First, you need people who are interested in attending your event. It can be challenging if you’re in a small town or a location where it’s difficult to attract attendees. Second, you need to secure speakers who are willing to participate. Lastly, finding a suitable venue is crucial. Having a reliable and cost-free location for your event is essential. We were fortunate to secure a free venue through a union for IT workers in Copenhagen, which aligns with our goal of offering free courses without being tied to a specific company.\nFinding speakers can be challenging, but constantly contacting and asking for volunteers is the best approach. To make it easier for potential speakers, consider organizing events where multiple speakers can do shorter presentations, which may be less intimidating than a full-hour presentation. However, attracting speakers and attendees remains the most difficult aspect of organizing events. Nevertheless, securing a dependable venue is a great starting point.\nAnd then there are some small things. Make sure to make nice announcements. They need a nice picture. They need friendly text so that people feel welcome. That’s the minimal thing. And the other thing is, if it’s allowed in the meetup space, bring some cakes or cookies and have some snacks. If people know there will be a little bit of snacks, they’re more likely to show up. So it’s a small thing, but I think that helps. This meetup is in Copenhagen, and I’m from Sweden. However, Denmark and Copenhagen have a special relationship with beer. I distinctly remember my first Copenhagen meetup when Kenneth Rose was the organizer. Back then, he brought a big case of beer cans to each meetup, and everyone was having a nice time. I don’t say you need a beer at your meetup, but bringing drinks and snacks is always nice."
  },
  {
    "objectID": "posts/cakes-code-and-community-reviving-the-copenhagenr-user-group/index.html#how-do-i-join",
    "href": "posts/cakes-code-and-community-reviving-the-copenhagenr-user-group/index.html#how-do-i-join",
    "title": "Cakes, Code, and Community: Rasmus Bååth’s Secret to Reviving the CopenhagenR UseR Group",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn More!"
  },
  {
    "objectID": "posts/bridging-the-real-time-gap-how-inwt-is-bringing-apache-kafka-to-the-r-ecosystem/index.html",
    "href": "posts/bridging-the-real-time-gap-how-inwt-is-bringing-apache-kafka-to-the-r-ecosystem/index.html",
    "title": "Bridging the Real-Time Gap: How INWT is Bringing Apache Kafka to the R Ecosystem",
    "section": "",
    "text": "In a recent interview with the R Consortium, Andreas Neudecker, solution architect at INWT, a data and analytics company located in Berlin, Germany, shared insights into the motivation behind developing an Apache Kafka client for R and the challenges it aims to address within the R ecosystem. His company frequently builds models in both R and Python, often encountering the need for real-time data analytics from Kafka clusters. When a real-time fraud detection project required connecting to a Kafka cluster, the lack of a stable Kafka client for R forced them to switch to Python despite having an R-based model ready to go. This experience highlighted the gap in R’s real-time data processing capabilities. It inspired Andreas to develop a Kafka client for R, making it easier to access real-time data sources and potentially leveling the playing field with Python.\nTo get started using kafka right away, please reference this article by Andreas titled “Introducing the kafka R Package,” which covers an example to demonstrate how kafka works.\nGitHub repository: https://github.com/INWTlab/r-kafka\nInstallation from GitHub:\nThis ISC project was funded by the R Consortium.\nWhat motivated you to develop a Kafka client for R, and what specific challenges in the R ecosystem are you aiming to address with this project?\nWe typically build models in both R and Python, depending on our customers’ needs and preferences. Each language has different types of models available, so the choice between R and Python depends on the specific requirements. We handle both traditional batch processing and real-time analytics for our clients.\nMany of our customers use Kafka clusters for their real-time data. At one point, we faced a challenge where we needed to perform real-time analytics, but the data was stored in a Kafka cluster. The question became: how do we connect to the Kafka cluster?\nTo be more specific, we had a real-time fraud detection project where we needed to identify fraudulent patterns in a stream of transactions. We already had a model in R, and our initial plan was to continue using it to keep costs down. However, we realized there was no stable Kafka client available for R at the time. So, we were essentially forced to switch to Python to consume the data from Kafka, which wasn’t our preferred choice.\nIn the end, we developed a solution by having a Python consumer write data into an in-memory cache database, which allowed us to continue using our existing R model. The R process accessed the data from this cache database. This experience made it clear to us that having a Kafka client for R would have made the process much smoother. We’ve also heard from other companies who made the same choice—they opted for Python over R simply because Python had a Kafka client, and R didn’t.\nCould you explain how the R Kafka client will enhance real-time data analysis and processing capabilities within the R environment?\nIn many cases, there are solid reasons to train models in R. For example, some specific models are available in R that haven’t been developed in Python yet. Personally, I also find that I can develop much faster in R—it typically takes me less time to get a running prototype compared to Python.\nWhat I’ve noticed is that R is often used more for traditional batch processing or modeling, but there’s no real reason why it shouldn’t also be used for real-time applications. I believe that having a Kafka client for R could be a missing piece of the puzzle, making it easier to access real-time data sources.\nHow does the proposed solution compare to existing alternatives, such as using Python for Kafka communication in data pipelines?\nIt should essentially work the same way as it does in Python, since we’re using the same underlying C library. While we’re still in the early stages and don’t have all the capabilities of the Python client yet, the experience should feel pretty similar because of this shared foundation.\nWhat were the key insights from your initial benchmarking of the prototype, and how do they inform the project’s development goals?\nFirst, we created a proof of concept (PoC), which showed us that it’s definitely possible to write a proper Kafka client for R using the C library. As we moved on to building the first minimum viable product (MVP), we also did some basic benchmarking. The results showed that we were a bit slower than the Python client. To give you some numbers, we could consume or produce 1 million messages in about 20 seconds, while Python handled it in 10 seconds, so Python was faster in this case.\nHowever, I believe we could improve this with a better interface or some optimizations. That said, even with these numbers, the speed difference shouldn’t have a major impact in most real-world applications, because it’s not just about reading the data—it also involves processing, which takes additional time. So, even though the client isn’t quite as fast as Python’s, it’s still sufficient for most use cases.\nWhat is the significance of the Admin Client functionalities in managing Kafka infrastructure, and how do you plan to implement these within the R package?\nRight now, our client can handle the essential tasks of sending and receiving data. However, it would be great to add the ability to create and delete topics directly within R, as well as manage consumer group offsets. These are likely the most important additional features we need.\nWe plan to implement this in a way similar to how the Python Confluent package does it—by creating a separate class for admin tasks. Since the underlying functionality already exists in the C++ package, the process should be straightforward. We just need to create wrapper functions using Rcpp, write the documentation, and run the necessary tests, and then it should work as expected.\nHow has it been working with the R Consortium? Would you recommend applying for an ISC grant to other R developers?\nIt was a very straightforward and smooth process, with no unnecessary bureaucracy. Overall, it was a great experience, and we had a friendly and helpful contact person throughout. I would definitely recommend it if you have an idea—it’s a really good way to secure funding."
  },
  {
    "objectID": "posts/bridging-the-real-time-gap-how-inwt-is-bringing-apache-kafka-to-the-r-ecosystem/index.html#about-isc-funded-projects",
    "href": "posts/bridging-the-real-time-gap-how-inwt-is-bringing-apache-kafka-to-the-r-ecosystem/index.html#about-isc-funded-projects",
    "title": "Bridging the Real-Time Gap: How INWT is Bringing Apache Kafka to the R Ecosystem",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nhttps://r-consortium.org/all-projects/"
  },
  {
    "objectID": "posts/books-beginners-big-ideas-beatriz-milz-fostering-r-ladies-sao-paulo-community/index.html",
    "href": "posts/books-beginners-big-ideas-beatriz-milz-fostering-r-ladies-sao-paulo-community/index.html",
    "title": "Books, Beginners, and Big Ideas: Beatriz Milz on Fostering R-Ladies São Paulo’s Vibrant Community",
    "section": "",
    "text": "Beatriz Milz, a co-organizer of R-Ladies São Paulo, recently spoke with the R Consortium about the vibrant growth of the R community in São Paulo and its commitment to inclusivity and accessible learning. Beatriz shared insights into the group’s activities, from organizing popular in-person and online events to coordinating a book club focused on the newly translated R for Data Science in Portuguese. She also discussed the unique needs of R users in Brazil and how R-Ladies São Paulo supports beginners and advanced users through collaborative events and community-driven resources.\nPlease share your background and involvement with the RUGS group.\nMy background includes a bachelor’s degree in environmental management, a master’s in environmental analysis, and a PhD in environmental sciences. During my master’s program, my supervisor mentioned that I needed to learn R to analyze the data we were collecting. However, no one in the lab was familiar with R or able to assist me. I attempted to learn it independently, but that didn’t work well.\nEventually, my supervisor connected me with another professor, and a postdoc in his lab helped me with the analysis for my master’s dissertation. While that assistance was beneficial, I felt uncomfortable relying on others to conduct the analysis. After finishing my master’s and before starting my doctorate, I decided that I wanted to learn how to program so I wouldn’t have to depend so heavily on fellow researchers for data analysis.\nI started trying to learn R again after a friend mentioned the R-Ladies group. In 2018, I discovered that a new group was starting in São Paulo. I attended their first event, which was an incredible experience. Around that time, I began to learn R.\nIn São Paulo, we don’t just organize events; we also have a group on Telegram where we can communicate between events. It allowed me to ask for recommendations on learning materials, pose questions, and receive help from others in the group. This support was invaluable to my learning process.\nTwo months after getting involved, I began helping in the group. Initially, the group was relatively new, and one person mainly did most of the organizing tasks: Haydee Svab. She expressed a need for assistance, not just with R-related tasks but also with organizing events. So, I started to help, and I am still one of the co-organizers today, while Haydee remains the lead co-organizer.\nIt’s been six years since I began participating in the group, and I’m currently a postdoc involved in much work with R.\nCan you share what the R community is like in São Paulo?\nOur group consists of researchers from various fields who want to learn R or have already used it. Many journalists started using R a few years ago and joined our group. Now, these journalists often invite other journalists. We have many journalists who need to learn R to analyze public data from the government for their journalistic work in newspapers.\nWe also have many members with a background in Statistics. Since most university courses typically use R, students joining our group already have experience with it from their undergraduate studies. Additionally, many individuals from the industry use R for consultancy in various fields. I am currently doing a postdoc, but I also worked with consultants for two years, during which time I used R extensively.\nIn R-Ladies São Paulo, how many events are typically held each year?\nIt varies. This year, we hosted two in-person and many more online events—11. We held an average of 6.5 events per year. However, this year, we focused more on online events and had fewer in-person ones, mostly because booking venues for in-person events has been more difficult.\nRegarding your experience, are people more interested in online or in-person events?\nPeople engage more in in-person events. They look forward to attending these events because we usually have limited seats, which fill up quickly. We often have a waiting list for those who want to attend. If someone cancels, we can soon offer their spot to someone on the waiting list.\nOn the other hand, online events tend to have a different pattern of participation. Fewer people attend in real-time, but many engage later by watching the recorded sessions and leaving comments. This flexibility allows those who cannot participate live to catch up afterwards.\nWhile online events can have a broader impact on reaching a larger audience, in-person events typically draw more attendees at once. For instance, we have a YouTube channel where we post recordings of our online events. One particular event we held during the pandemic garnered 13,000 views, demonstrating significant engagement after the event. However, only some online events achieve that level of viewership; the median for recorded events is 330 views. Nevertheless, I see value in these recordings, as they provide material for those who want to engage later. Sometimes, people are simply not available to attend live.\nPlease provide us with an update on your group’s recent activities.\nI wanted to discuss a series of events related to the book club we’re hosting. In Brazil, we speak Brazilian Portuguese. An editorial group published the highly regarded book R for Data Science in Portuguese. The first edition is available only through purchase, but the English version is free online.\nSome communities have done volunteer translations; for instance, there is a Spanish version. When I learned that a second edition of the book was being written, I contacted the authors to ask if we could translate it into Portuguese with the community’s help. It took some time because the authors needed approval from O’Reilly, the publishing company producing the book.\nWe received confirmation that we could begin the translation. The book’s second edition has been translated and is now available in Portuguese! The translation team is not limited to the R Ladies community; it includes contributions from more than 20 people from different backgrounds.\nThis book club focuses on discussing the translated Portuguese version of the book. Since February, we have held online meetings to discuss the book chapters. Members from the R Ladies community present these discussions, allowing participants to ask questions and engage in dialogue. These events have been working well.\nI have been referencing this book whenever someone asks for material. Many people will already be familiar with it as we continue to promote it. We have also been using and sharing this resource extensively.\nNow, the book’s second edition is available in Portuguese online and for free, so anyone with an internet connection can access it. It is an excellent way to share knowledge for those who can afford to buy the book and for anyone with internet access, making it a valuable study resource.\nWhat are some trending topics from the group?\nOur events with introductory content attract more participants. It is likely because many attendees are either new to the subject or at an intermediate level, where they feel comfortable studying independently. The most popular topics are introductory sessions.\nHowever, when we asked participants about their interests in different topics, many wanted to learn about machine learning and other trending subjects like deep learning and artificial intelligence. The challenge is that we need more experienced individuals to teach these advanced topics. While many people are interested in these areas, organizing events around them can be more difficult due to the complexity involved.\nWhat techniques do you recommend for planning or conducting the event? (e.g., GitHub, Zoom, etc.) Can these techniques help make your group more inclusive for people unable to attend in-person events in the future?\nWe use StreamYard for our online events. The free version has proven helpful. Previously, when we hosted events on Zoom, we needed to edit recordings and upload them afterwards. This process often took a while, mainly because everyone was busy, and it delayed recording the events online. StreamYard has made the process easier for us, although it does offer less space for participant interaction.\nWe have a chat feature with StreamYard, but participants can also share their screens on Zoom. Therefore, the platform we choose depends on the kind of event we want to conduct. Participants must share their screens for some events, so we opt for Google Meet or Zoom.\nOne significant improvement has been our use of GitHub. We created issue templates as a to-do list for organizing our upcoming events. This system helps us remember everything we need to do.\nAdditionally, we have a blog that invites community members to contribute articles. It allows individuals to write about interesting topics regardless of expertise. Some people hesitate to present at events but feel comfortable writing blog posts. It serves as their first contribution or participation in our community, shifting them from just participants to active contributors.\nOverall, the blog is an excellent way to encourage people to make their first contributions."
  },
  {
    "objectID": "posts/books-beginners-big-ideas-beatriz-milz-fostering-r-ladies-sao-paulo-community/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/books-beginners-big-ideas-beatriz-milz-fostering-r-ladies-sao-paulo-community/index.html#how-do-i-build-an-r-user-group",
    "title": "Books, Beginners, and Big Ideas: Beatriz Milz on Fostering R-Ladies São Paulo’s Vibrant Community",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "",
    "text": "The Karachi R User Group, Pakistan, hosted its second event, “Unveiling the Power of R Shiny Dashboards,” on December 30, 2023. The R Consortium spoke with Uzair Aslam, the group’s founder, about the challenges of starting an R User Group in a budding R community. He also discussed his data analysis project for studying the health deficiencies experienced by the Pakistani population."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#please-share-about-your-background-and-your-involvement-in-the-r-community.",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#please-share-about-your-background-and-your-involvement-in-the-r-community.",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "Please share about your background and your involvement in the R Community.",
    "text": "Please share about your background and your involvement in the R Community.\nMy name is Uzair Aslam, and I did my BSc in Economics and Mathematics from the Institute of Business Administration (IBA), Karachi. I have a keen interest in data science, statistics, and econometrics. After graduating, I co-founded a consulting firm called StatDevs. I work with two developers to develop R and Shiny applications for our clients.\nAt StatDevs, we solve complex problems using data science solutions and data analytics. R is a core language for us, and we’re experienced in Python, too. However, we are focused on R because of its strengths in data analysis, data visualization, and the development of Shiny applications.\nMy motivation for starting this group came from watching online events of R user groups in the USA and Europe. I attended the presentations and listened to what R is capable of and how they are bringing R to their communities. I noticed much R activity on that side of the world, but nothing was happening on the Asian side. That is when I wanted to make people realize that they could use R for their data analysis in academia and industry so they can solve more problems.\nR User Group Distribution Around the World, from Ben Ubah’s R Community Explorer repo using the meetupr package to query Meetup API\nCurrently, regarding R users, there is a lack of community concept in Pakistan. Tech communities are not nurtured properly, not built properly, and they are not contained properly.\nI contacted the R consortium and shared my story of wanting to establish an R user group as the organizer to promote the language."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#can-you-share-what-the-r-community-is-like-in-pakistan",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#can-you-share-what-the-r-community-is-like-in-pakistan",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "Can you share what the R community is like in Pakistan?",
    "text": "Can you share what the R community is like in Pakistan?\nI have observed that R is used in academia, but not to the extent it should be. I have seen a couple of professors at IBA and some in Islamabad who use R but also use Stata and Excel for their academic purposes and data analysis. In terms of industry, Power BI and Excel are used extensively. This is because not many people know R’s data analysis and analytics capabilities. The acceptance of R is not realized due to the lack of awareness. Some academic researchers use R but may need more training to get the most out of what R offers them. Karachi R User Group aims to narrow down this gap."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#are-there-any-particular-challenges-you-have-faced-in-organizing-this-rug",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#are-there-any-particular-challenges-you-have-faced-in-organizing-this-rug",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "Are there any particular challenges you have faced in organizing this RUG?",
    "text": "Are there any particular challenges you have faced in organizing this RUG?\nIndeed, getting people to participate in this R user group has been a challenge. I held our first meetup myself last month in November, and only 4 or 5 people attended. I prepared for the meetup for about two weeks because I wanted an excellent introduction and everything, but fewer people showed up. Of those five people, one was my co-founder, and two were participating from the US and Brazil sides. There was only one person from Pakistan. This happens when you introduce something new in a place people are unaware of. My job is to continue this effort and tell people about the possibilities and opportunities of data analysis and consulting using R.\nAs we approach our second meetup, more people are showing interest, and the number is growing daily. I am not active on Instagram and very less active on Twitter. However, I use LinkedIn as my platform to reach people and Facebook. On Facebook, I have joined multiple groups, so I share information about the meetups in these groups. Lately, I have been realizing that I should use Twitter as well because I have seen more people promoting their R events on Twitter."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#you-have-a-meetup-on-unveiling-the-power-of-r-shiny-dashboards-can-you-share-more-on-the-topic-covered-why-this-topic",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#you-have-a-meetup-on-unveiling-the-power-of-r-shiny-dashboards-can-you-share-more-on-the-topic-covered-why-this-topic",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "You have a Meetup on “Unveiling the Power of R Shiny Dashboards,” can you share more on the topic covered? Why this topic?",
    "text": "You have a Meetup on “Unveiling the Power of R Shiny Dashboards,” can you share more on the topic covered? Why this topic?\nCurrently, we have 100 members in our user group, and the upcoming meetup is titled “Unveiling the Power of R Shiny Dashboards.” Jehangeer Aswani is the speaker for this event. Jehangeer is a professional freelancer on Upwork and is based in Islamabad. Due to his motivation and my idea, we started this R user group. He is one of the people I look to for motivation. He has a bachelor’s degree in Statistics and provides R Shiny consulting services.\nThis meetup is about the fundamental concepts of R Shiny. One may wonder why R Shiny is relevant when we have Power BI and Excel. Jehangeer will provide a hands-on experience with R Shiny applications. This will help participants understand why R Shiny is a better tool. In addition, this meetup will unlock the potential to transform data into captivating visualizations. Participants will also learn how to build R Shiny dashboards. They will get hands-on experience with a real-world application that can be used to solve a business case."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#please-share-about-a-project-you-are-working-on-or-have-worked-on-using-the-r-language.-goalreason-result-anything-interesting-especially-related-to-your-industry",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#please-share-about-a-project-you-are-working-on-or-have-worked-on-using-the-r-language.-goalreason-result-anything-interesting-especially-related-to-your-industry",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "Please share about a project you are working on or have worked on using the R language. Goal/reason, result, anything interesting, especially related to your industry?",
    "text": "Please share about a project you are working on or have worked on using the R language. Goal/reason, result, anything interesting, especially related to your industry?\nI used R for micro-analysis of the Public Health domain. I collaborated with a consultant in Karachi, Pakistan, named Jaweid Ishaque. We worked on a data analysis project for Indus Hospital and Health Networks, a large network of hospitals. The problem statement of the project was to create a broader understanding of the health deficiencies experienced by the Pakistani population, particularly in Punjab, Sindh, and Balochistan. This was a funded study that we conducted.\nI utilized a variety of data sets in this study. One of the data sets was the 2017 census data. Another data set was the Pakistan Social Living Measurement (SLM) 2019-2020 data set. I also used data from the Pakistan Maternal Mortality Survey (PMMS) and the Pakistan Demographic and Health Survey (PDHS). I obtained these data sets from the Pakistan Bureau of Statistics and open sources. I analyzed and explored the exact status of public health delivery and public health care at the country and provincial levels.\nI worked as a data analyst on this project. The consultant guided me throughout the study. I summarized and presented the current status of health parameters in terms of mortality, disease, incidence, and prevalence. We also compared these parameters to those of other countries, such as Bangladesh, India, Sri Lanka, and Nepal. With the help of R and its packages, I could extract, process, and clean the data sets from multiple sources using dplyr. I used ggplot to visualize the data. Finally, out of the 141 total districts, I identified the most disadvantaged districts in Pakistan in terms of Public Healthcare Delivery (PHC), Social Living Measurements (SLM), and Incidence Of Diseases (IOD). Our rigorous analysis narrowed the list of disadvantaged districts to around 35 districts in Pakistan. There were eighteen districts in lower Balochistan, ten in Sindh, and seven in Punjab. This study helped Indus Hospital And Health Networks deploy mobile health clinics to remote areas of Pakistan.\nI wrote and executed all of the analytical scripts for the data cleaning and analysis of the provided surveys in R. This allowed me to gain an overview and insights into the data, which I then reported to the stakeholders. I presented Indus Hospital Health Networks with a comprehensive overview of our seven to eight months of research. I generated Pakistan’s population parameters in these analyses, including birthplaces, provincial distributions, mortality rates, and stillbirth rates by provinces and districts.\nIn addition to the above, I have also started offering R training. I delivered an online course on R one year ago titled “R for Economics and Finance.” I instructed over 15 students from IBA and all over Pakistan in this online training course, which was solely based on R.\nStudents were delighted to learn about the practical applications of their economic and financial models, as they had previously only been taught theoretical courses in Universities. I conducted this training last year and will now conduct several R trainings in industry and academia.\nI will be conducting one of these trainings in February. This training will be titled “R for Data Science,” and students and industry professionals will attend it. I have begun working on this training to promote R as much as possible through our efforts.\nAs my commitment to advancing the use of R in data analysis and data science grows, I express gratitude to the R Consortium for their support on this transformative journey. Envisioning a significant impact on Pakistan, I am dedicated to constructing a vibrant open source community. The fruits of my efforts will manifest as I realize my vision: fostering open source data analytics and collaboration throughout Pakistan."
  },
  {
    "objectID": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#how-do-i-join",
    "href": "posts/r-for-public-health-data-analysis-in-karachi-pakistan/index.html#how-do-i-join",
    "title": "R for Public Health Data Analysis in Karachi, Pakistana",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 65,000 members in 35 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/free-boba-tea-and-technical-r-topics-lure-young-learners-to-new-brunei-r-user-group/index.html",
    "href": "posts/free-boba-tea-and-technical-r-topics-lure-young-learners-to-new-brunei-r-user-group/index.html",
    "title": "Free Boba Tea and Technical R Topics Lure Young Learners to New Brunei R User Group",
    "section": "",
    "text": "Haziq Jamil, the founder and organizer of the Brunei R User Group, recently spoke with the R Consortium. Haziq established the first R User Group in Brunei to promote R programming and create collaborative learning environments. Under his leadership, the group hosts monthly meetups and events to advance R skills across various sectors in Brunei. Through these efforts, Haziq aims to build a supportive and inclusive R community, encouraging both personal growth and data-driven innovation in the region.\nPlease share your background and involvement with the RUGS group.\nMy name is Haziq Jamil, and I am an Assistant Professor in Statistics at Universiti Brunei Darussalam, the leading higher education institution in Brunei. I have used R for almost ten years during my studies and on many personal and professional projects.\nThe Brunei R User Group was founded in February 2024, and I serve as its chair and founder. My role is to lead the group’s administration, oversee its overall direction and strategy, and ensure that its initiatives align with its mission of promoting R programming and fostering a supportive learning environment, focusing on community engagement and collaboration.\nCan you share what the R community is like in Brunei?\nThe R community in Brunei may be small, but it is growing thanks to the efforts of the Brunei R User Group. The group organizes monthly meetups and events to promote learning and development in R programming and advance its use across various fields in Brunei. These gatherings provide opportunities to expand the community by enhancing participants’ skills, offering a platform for networking with like-minded individuals, and engaging in practical applications such as data analysis, visualization, and spatial data techniques. By creating an inclusive R community, the group aims to support individual growth in Brunei and foster collaboration on data-driven R projects. Whether for students, professionals, or hobbyists, the group strives to provide a supportive space for learning, sharing insights, and driving innovation within the local R community.\nYou hosted a Meetup, “R&gt;aya with R,” in April. Can you share more about the topic? Why this topic?\nThe R User Group’s “R&gt;aya with R” Meetup in Brunei was a lively event that combined Hari Raya Aidilfitri’s (Eid-ul-Fitr) festive spirit with the exploration of R programming. To engage younger audiences, we offered free boba tea as a beverage during the session. The event featured informative sessions led by expert community members, each focusing on advanced topics relevant to different fields.\nOne of the critical presentations was on “Survival Analysis” by Dr. Elvynna Leong. She explained statistical techniques to predict the time until an event of interest, such as guests’ arrival at a Hari Raya open house. This topic is directly related to fields that depend on time-to-event data, such as healthcare or actuarial science.\nOne of the highlights was Wafid Sophian’s session on “Simulation Methods for Economic Analysis.” In this presentation, Wafid demonstrated how R can be used to simulate and analyze complex economic scenarios. The topic focused on modeling outcomes and making data-driven predictions. It was chosen due to its significance in finance and business analytics.\nDr. Eden Ng presented on “Mathematical Modeling of Evolutionary Biology,” showcasing how R can be used to model biological evolutionary processes. This session visualized the intersection of R programming and biology, thus emphasizing R’s utility in research areas such as genetics and evolutionary studies.\nThe event covered three topics in the areas of mathematics, economics, and biology. It was open to all individuals interested in learning about the capabilities and usage of the R language, regardless of whether they were beginners or experts.\nDo you recommend any techniques for planning for or during the event? (Github, Zoom, other.) Can these techniques be used to make your group more inclusive to people who cannot attend physical events in the future?\nFor planning and executing events like the “Analysing Spatial Data with R” event, the R&gt;aya Meetup, and the “Introduction to R” sessions, we utilized Github. To host R scripts, datasets, and event materials. Our participants can access and review the code before and after the event. It also provides a platform for issue tracking and version control to facilitate feedback and group collaboration. It helps those who can’t attend in person to engage and contribute to our Quarto Blog. To publish event summaries, key takeaways, and additional resources on the official Brunei R User Group blog. We hope to provide a centralized location for information and help remote participants catch up.\nPlease share any additional details you would like to include in the blog.\nAs the first R user group in Brunei, we are excited to promote the adoption and growth of R across various industries. Our mission goes beyond just hosting events—we are dedicated to creating and nurturing an inclusive R community and showcasing the power of R in numerous fields."
  },
  {
    "objectID": "posts/free-boba-tea-and-technical-r-topics-lure-young-learners-to-new-brunei-r-user-group/index.html#how-do-i-join",
    "href": "posts/free-boba-tea-and-technical-r-topics-lure-young-learners-to-new-brunei-r-user-group/index.html#how-do-i-join",
    "title": "Free Boba Tea and Technical R Topics Lure Young Learners to New Brunei R User Group",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more!!"
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "",
    "text": "Last year, Antonio Hegar of the R Glasgow user group shared the challenges of organizing an R user group in Glasgow. The group now regularly hosts events, attracting local R users and experts. Antonio shared with the R Consortium the group’s journey and anecdotes that have helped it to build momentum. He also shared his hopes for maintaining this momentum, with speakers lined up for the next three events.\nR Glasgow will be hosting their first event this year titled “Fake it Until You Make it: How and Why to Simulate Data” on January 25, 2024.\nAntonio also discussed his work with R for his PhD research in data analysis for healthcare. He spoke about the ever-evolving nature of R and some of the new developments that have been useful for his research."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#whats-new-with-the-glasgow-r-user-group-since-we-last-talked",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#whats-new-with-the-glasgow-r-user-group-since-we-last-talked",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "What’s new with the Glasgow R User Group since we last talked?",
    "text": "What’s new with the Glasgow R User Group since we last talked?\nAs we discussed the last time, one of the most pressing issues we faced as a local R user group was our lack of engagement with the community. This is particularly interesting given that both Glasgow and Edinburgh have their own R user groups. Both cities are only an hour apart, yet we weren’t seeing the same level of engagement as other groups in the UK.\nTo address this issue, we have been strategizing and holding several meetings. To summarize, we discussed improving our marketing and engagement with our audience. We also decided to hold one final meeting at the end of the year.\nBesides our internal meetings, we also hosted two R events. One of the group’s founders, Andrew Baxter, a postgraduate researcher at the University of Glasgow, has been instrumental in organizing these events. Because he works at the University of Glasgow, he has access to many resources, including physical venues and fellow academics, and this has been a major plus in facilitating our engagement.\nPreviously, I had been trying to do what other groups have done: finding random venues and hosting events there. However, this was not as effective as we had hoped.\nFrom the discussions that we had, as well as listening to our audience, we learned that people who are interested in working with R have very specific wants and needs. If these needs are not being met, then it is unlikely that people will be attracted to the group, and as such, we had to reframe our approach to attracting people.\nWe recognized it is key to have a specific venue. We now hold the vast majority of our meetings at the University of Glasgow. This seems to be very appealing to people, as they enjoy the academic setting. Furthermore, the University of Glasgow is well known and respected, not just in Scotland but across the world, and this adds weight to the appeal, and the reputation helps to draw people in.\nThe second thing that proved essential was consistency. Having a meeting for one month and then having a gap breaks the flow, and sends the wrong message to your audience. When people see that you are committed to what you want to do, they respond to that and are more likely to be engaged in the community.\nWe had a final meeting in December, and Andrew Baxter contacted Mike Smith, one of the local R Consortium representatives. He is based in Dublin, Ireland, but frequently travels back and forth to Scotland. He leveraged this network to recommend speakers and topics for the conference. This was particularly helpful in attracting people from industry, who are often interested in the latest developments in R. Mike has been a tremendous asset to the group since our meeting in December.\nA venue, people on the inside of the industry, and a consistent schedule have been the three key components. Three speakers have been lined up for early 2024: one for January, February, and March.\nWe will not have much difficulty finding additional speakers based on the academic and industrial contacts. At most, we must determine who will speak on which topic and when they will be available, which is not difficult. Based on the current situation, it does not appear that we will have any trouble maintaining momentum and keeping the meetings going."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#what-industry-are-you-currently-in",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#what-industry-are-you-currently-in",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "What industry are you currently in?",
    "text": "What industry are you currently in?\nI am a PhD student at Glasgow Caledonian University. My PhD research focuses on data science applied to health, specifically using machine learning to predict disease outcomes.\nI am interested in understanding why some people who experience an acute illness, such as COVID-19, develop long-term health problems. In some countries, up to 10% of people who contract COVID-19 never fully recover. These individuals may experience permanent shortness of breath, headaches, brain fog, joint pain, and other symptoms.\nI am currently researching how data science can be used to answer questions such as these, using large data sets from, for example, the NHS. R is the primary tool used for this research.\nWhen we last spoke, I was in the second year of my PhD. I am now in my third and final year. I should be submitting my dissertation before the end of this year. Balancing my commitments to R, my PhD work, and other activities is challenging, but I managed to pull it off."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#how-do-you-use-r-for-your-work",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#how-do-you-use-r-for-your-work",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "How do you use R for your work?",
    "text": "How do you use R for your work?\nI extensively use R. One of R’s most beneficial aspects is that it’s constantly evolving and expanding. As a result, it is impossible to master everything. You do not master R; rather, you master certain R areas relevant to your research or area of expertise. In my research, I found several medical statistics and biostatistics packages extremely useful. I was aware of a few of them but unaware of how many there were.\nFor instance, consider the following brief instance of a task that I began working on yesterday. In the context of medical data, particularly when analyzing health conditions, it is common for individuals to have multiple health conditions that are often linked. This often makes it more difficult for doctors to treat and for individuals to recover fully.\nIf I were to apply classical statistics using base R, this would be very time-consuming. However, I recently discovered that there are also medical statistical packages specifically designed for analyzing data for individuals with comorbidities. For example, if I wanted to analyze individuals suffering from diabetes, hypertension, cancer, obesity, or a combination of different diseases, I could do so using these packages.\nIn addition, it is possible to create a score that can be used to estimate the likelihood of a person who becomes ill and goes to the hospital, stays for a long time, or dies. It is possible to perform this task using regular statistics and programming in R, but it would be very tedious. In my case, I am working on a tight deadline and need to submit my work by a specific date. I believe the package I am speaking of is the comorbidity package in R. It was developed recently by researchers at the London School of Hygiene & Tropical Medicine and is an invaluable tool.\nI work with NHS data through a third-party organization that controls it and allows me access to it. Last year in December, they provided me with brief training and taught me how to access their data on a DBS SQL server using SQL queries embedded in R code.\nLearning about very niche packages, which are very content-specific or topic-specific, is very useful for researchers like myself. Integrating different programming languages is also useful because they are all merging into one. Python, Julia, R, and Java have a lot of cross-fertilization and use between the different programming and software development packages. If R continues to streamline its services to integrate other packages, it will be a win-win situation for everyone."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#what-is-the-r-community-like-in-glasgow-what-efforts-are-you-putting-in-to-keep-your-group-inclusive-for-all-participants",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#what-is-the-r-community-like-in-glasgow-what-efforts-are-you-putting-in-to-keep-your-group-inclusive-for-all-participants",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "What is the R Community like in Glasgow? What efforts are you putting in to keep your group inclusive for all participants?",
    "text": "What is the R Community like in Glasgow? What efforts are you putting in to keep your group inclusive for all participants?\nWe are not trying to cater to one specific level of expertise. The last meeting had a good mix of participants, including PhD students, undergraduates, people who have worked in finance and tech, software developers, and an individual from the R Consortium in Dublin, Ireland.\nThe group is open to everyone, and we are trying to mix participants with different needs, wants, and interests. It is understood that attendees will choose which events they would like to attend. Certain events will focus more on entry-level individuals beginning their R learning journey. For example, they are interested in learning what they can do with ggplot and the tidyverse.\nMid-level individuals, including graduate students, will also be targeted. A portion of these students are novices, but many are more experienced. They have a strong foundation in R and RStudio or Posit. However, they are now seeking to learn more advanced techniques, such as how to perform specific calculations. For instance, they may be working with quantitative or qualitative data and are now at the analysis stage of their research and wonder what to do next.\nFinally, there are a small number of highly experienced programmers who are interested in learning more about integrating specific features into a package. They may want to know how to create their packages and launch them. They are also interested in learning about Shiny and Quarto and how they can use these tools for their businesses or companies.\nMost individuals fall into the beginner or intermediate levels, but there are a few who are highly advanced and still interested in attending. As a result, most of the talks will be geared toward individuals with intermediate-level experience. This will ensure that the material is not too advanced for beginners but also not too basic for advanced learners."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#can-you-tell-us-about-a-recent-event-that-received-a-good-response-from-the-audience",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#can-you-tell-us-about-a-recent-event-that-received-a-good-response-from-the-audience",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "Can you tell us about a recent event that received a good response from the audience?",
    "text": "Can you tell us about a recent event that received a good response from the audience?\nOf the recent events that were particularly successful, I would like to highlight the one held in November last year. It was titled “Flex Dashboard: Displaying data with high impact using minimal code.” Erik Igelström, a researcher from the University of Glasgow, presented his use of R Shiny to display data from the Scottish government. The presentation was highly informative and demonstrated the potential of Shiny to present data in a user-friendly manner.\nThe meeting was attended by a representative from R Software in Ireland, who provided us with a wealth of information about industry developments, including the latest trends and upcoming projects. As a result of this meeting, 2023 was the most productive year for our R meetup.\nThe preceding meetups were not entirely unproductive, but the most recent one, held in November last year, laid the groundwork for the current initiatives."
  },
  {
    "objectID": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#you-have-a-meetup-titled-fake-it-until-you-make-it-how-and-why-to-simulate-data-on-25th-january-2024.-can-you-share-more-on-the-topic-covered-why-this-topic",
    "href": "posts/join-fake-it-until-you-make-it how-and-why-to-simulate-data first-glasgow-user-group-event-of-the-year/index.html#you-have-a-meetup-titled-fake-it-until-you-make-it-how-and-why-to-simulate-data-on-25th-january-2024.-can-you-share-more-on-the-topic-covered-why-this-topic",
    "title": "Join “Fake it Until You Make it: How and Why to Simulate Data” – First Glasgow User Group Event of the Year",
    "section": "You have a Meetup titled “Fake it Until You Make it: How and Why to Simulate Data” on 25th January 2024. Can you share more on the topic covered? Why this topic?",
    "text": "You have a Meetup titled “Fake it Until You Make it: How and Why to Simulate Data” on 25th January 2024. Can you share more on the topic covered? Why this topic?\nProfessor Lisa DeBruine will be presenting at this Meetup. She is a professor of psychology at the University of Glasgow in the School of Psychology and Neuroscience. She is a member of the UK Reproducibility Network and works in PsyTeachR. She has used the psych package extensively and many other good packages in R to conduct her psychological research. Her presentation will be on how to simulate data to prepare analyses for pre-registration.\nAs those who work with data know, it is sometimes counterproductive to work directly with the data itself. For example, if one is building a model, it is not advisable to use all of the data to build the model, especially if the data set is small. This is because there is a risk of over-fitting.\nGenerating dummy data for quantitative data is a well-known technique. However, generating dummy data for qualitative data is rare. This is because qualitative data is often unstructured and difficult to quantify. Professor Lisa DeBruine is an expert in generating dummy data for qualitative data.\nSPSS is a popular statistical software package used by sociologists, anthropologists, and psychologists. However, R is a more powerful and flexible tool that can perform a wider range of analyses. Learning to use R and the psych package can greatly simplify the process of conducting factor analysis. Additionally, R can be used to perform calculations and analyses that are impossible in SPSS.\nOur team is highly capable, and we have another team member who is particularly skilled in generating graphics and designing flyers. He has been responsible for creating the promotional material and has done an excellent job."
  },
  {
    "objectID": "posts/bridging-the-digital-divide-umar-isah-adam-on-expanding-r-access-for-kano-nigeria-students/index.html",
    "href": "posts/bridging-the-digital-divide-umar-isah-adam-on-expanding-r-access-for-kano-nigeria-students/index.html",
    "title": "Bridging the Digital Divide: Umar Isah Adam on Expanding R Access for Kano, Nigeria Students",
    "section": "",
    "text": "Umar Isah Adam, the founder and organizer of the R User Group Kano, Nigeria, spoke with the R Consortium during the pandemic about his efforts to engage the next generation of students in the R community. Recently, the R Consortium followed up with Umar to discuss the group’s progress over the past few years. He discussed the increasing acceptance and interest in R within academia. The user group is working with various colleges in Kano state to introduce R to students and teach them the fundamentals. Umar also shared his experience using R for managerial tasks related to student data. He hopes to persuade college management to use R for data handling instead of the current manual processes.\nPlease share your background and involvement with the RUGS group.\nMy name is Umar Isah Adam, and I’m from Kano State, Nigeria. I studied mathematics at the Federal University Dutse, Jigawa State. During my studies, I became interested in statistics and technology. One of my lecturers mentioned R as a statistical analysis tool, which piqued my interest. I learned it by researching online and watching videos. Later, a friend introduced me to R User Groups. I found that I was interested in R and noticed there wasn’t a group in Kano State, so I applied to start a chapter there, and it was approved.\nCan you share what the R community is like in Kano, Nigeria?\nThe use of R is relatively new in Kano State. Most academics in the area use SPSS in their work. It makes it challenging for R to gain traction in this environment. Despite the challenges, we have been making progress with the support of our user group. Currently, I work as an assistant lecturer at a college in Kano State. I recently organized a well-attended seminar for lecturers and students at the Kano State College of Education and Preliminary Studies. I also posted a video of the workshop on YouTube and have received requests for more information.\nThere’s room for improvement. We’ve received requests from academic institutions to host events or provide information about the power of R. However, we cannot do so now due to the nature of my work and inadequate funding. However, we plan to start a 10-week training session soon. It will likely be free, as we are collaborating with the Kano State College of Education and Preliminary Studies to organize it. R isn’t very popular here, and more than 70% of academicians need help understanding what it is and how to use it effectively. However, those introduced to it have shown a high interest in learning and utilizing it.\nWe aim to introduce R to the academic community, and after this, we plan to move on to another college and launch a new program. In summary, R is not widely known in our society, but we are progressing. There has been an increase in the acceptance of R and a growing interest from different people in academia, particularly in R. Many are interested. Still, there needs to be more awareness about it. Most people need to learn what R is and how to use it. Therefore, most of our upcoming programs will focus on introducing the R language.\nAdditionally, there is an issue with student access. Most of our students don’t have personal computers and can only access them on campus, usually at the ICT department. This lack of access also affects student engagement. However, among academics and lecturers in our colleges, there is growing interest in R.\nDo you host in-person or online events? How do you make your events inclusive?\nIt’s important to remember that online events became essential during the pandemic. However, due to internet connectivity issues, we avoid online meetings or events most of the time. As a result, our sessions are usually held offline. We have been hosting events within colleges and other institutions to make them easily accessible to students and academics. It is also more cost-effective and popular than hosting in private locations. Advertising these events has proven effective, as interested individuals are usually willing to attend when they see the advertisement.\nWe attempted to transfer between colleges, such as those owned by the state government. The majority of the data and processes are research-based. Therefore, we strive to incorporate more R programming aligned with academic requirements. We aim to limit topics to the use of R in academia to ensure that attendees feel more connected and can see the practical applications of using R. For instance, compared to using SPSS, where one often needs to use code or convert data into another format, with R, one can easily import data into the working environment and manipulate it as needed.\nPlease share about a project you are currently working on or have worked on using the R language. What is the goal/reason, result, or anything interesting, especially related to your industry?\nI usually demonstrate to people around me, including the school management, how easy it is to use R. For example, we need help with the examination office potentially losing some of their data. However, they have a backup on an external drive. I am importing the data from the old template to the new one in Excel format. I am also working on calculating the student results and offloading them into the new portal we have developed. Doing this job manually might take a month, but if I successfully create this program, it will complete the job in two to three days. It will demonstrate to the school management the importance and impact of using R.\nI am proposing to the college management to introduce a certified course of study on “Introduction to R” within the ICT department. Showcasing how this programming language can impact the working environment will help them understand the need for this course. Many students rely on fundamental analyses using questionnaires, frequency, and percentage without exploring visualization techniques. As a supervisor, I encourage using R for data analysis in student projects, as it provides a more comprehensive approach. However, many students need access to computers. Therefore, by offering this course, we can equip them with valuable skills and knowledge to benefit their future careers."
  },
  {
    "objectID": "posts/bridging-the-digital-divide-umar-isah-adam-on-expanding-r-access-for-kano-nigeria-students/index.html#how-do-i-join",
    "href": "posts/bridging-the-digital-divide-umar-isah-adam-on-expanding-r-access-for-kano-nigeria-students/index.html#how-do-i-join",
    "title": "Bridging the Digital Divide: Umar Isah Adam on Expanding R Access for Kano, Nigeria Students",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "",
    "text": "The R Consortium recently connected with Lampros Sp. Mouselimis, the creator of the ICESat2R package, discussing the ICESat-2 mission, a significant initiative in understanding the Earth’s surface dynamics. This NASA mission, utilizing the Advanced Topographic Laser Altimeter System (ATLAS), provides in-depth altimetry data, capturing Earth’s topography with unparalleled precision.\nMouselimis’ contribution, the ICESat2R package, is an R-based tool designed to streamline the analysis of ICESat-2 data. It simplifies accessing, processing, and visualizing the vast datasets generated by ATLAS, which emits 10,000 laser pulses per second to measure aspects like ice sheet elevation, sea ice thickness, and global vegetation biomass. This package enables users to analyze complex environmental changes such as ice-sheet elevation change, sea-ice freeboard, and vegetation canopy height more efficiently and accurately. The R Consortium funded this project.\nLampros Sp. Mouselimis is an experienced Data Analyst and Programmer who holds a degree in Business Administration and has received post-graduate training in Data Processing, Analysis, and Programming. His preferred programming language is R, but he can also work with Python and C++. As an open-source developer, you can find his work on GitHub With over a decade of experience in data processing using programming, he mainly works as a freelancer and runs his own business, Monopteryx, based in Greece. Outside of work, Lampros enjoys swimming, cycling, running, and tennis. He also takes care of two small agricultural fields that are partly filled with olive trees."
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#you-built-an-r-package-called-icesat2r-using-the-icesat-2-satellite.-do-you-consider-your-icesat2r-project-a-success",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#you-built-an-r-package-called-icesat2r-using-the-icesat-2-satellite.-do-you-consider-your-icesat2r-project-a-success",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "You built an R package called ICESat2R using the ICESat-2 satellite. Do you consider your ICESat2R project a success?",
    "text": "You built an R package called ICESat2R using the ICESat-2 satellite. Do you consider your ICESat2R project a success?\nICESat-2 R has 7,252 downloads, which, considering the smaller group of researchers who focus on using ICESat-2 data, qualifies it as a popular tool. It’s not as popular compared to some other remote sensing packages, but I believe it’s been a success based on two main points:\n\nContribution to the R users community: I hope that the R programmers who use the IceSat2R R package are now able to process altimetry data without any issues, and, if any, then I’ll be able to resolve these by updating the code in the GitHub and CRAN repositories.\nPersonal and Professional achievement: I applied for a grant to the R consortium, and my application was accepted. Moreover, I implemented the code by following the milestone timelines. Seeing a project through and providing it publicly is a success, I believe."
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#who-uses-icesat2r-and-what-are-the-main-benefits-any-unique-benefits-compared-to-the-python-and-julia-interfaces",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#who-uses-icesat2r-and-what-are-the-main-benefits-any-unique-benefits-compared-to-the-python-and-julia-interfaces",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "Who uses ICESat2R, and what are the main benefits? Any unique benefits compared to the Python and Julia interfaces?",
    "text": "Who uses ICESat2R, and what are the main benefits? Any unique benefits compared to the Python and Julia interfaces?\nThe users of the ICESat2R package can be professionals, researchers, or R programming users in general. I assume that these users could be:\n\nIce scientists, ecologists, and hydrologists (to name a few) who would be interested in the altimeter data to perform their research\nPublic authorities or military personnel, who, for instance, would like to process data related to high-risk events such as floods\nPolicy and decision-makers (the ICESat-2 data can be used, for instance, in resource management)\nR users that would like to “get their hands dirty” with altimeter data\n\nI am aware of the Python and Julia interfaces, and to tell the truth, I looked at the authors’ code bases before implementing the code, mainly because I wanted to find out the exact source they used to download the ICESat-2 data.\nBased on the current implementation, I would say that the benefits of the ICESat2R package are the following:\n\nThe R programming users can use NASA’s OpenAltimetry interface, which, as of December 2023, doesn’t require any credentials\nThe R package includes 3 Vignettes (Articles) and detailed documentation (Reference) for the implemented code"
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#what-is-an-interesting-example-of-using-icesat2r",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#what-is-an-interesting-example-of-using-icesat2r",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "What is an interesting example of using ICESat2R?",
    "text": "What is an interesting example of using ICESat2R?\nThere are many examples where the ICESat2R package can be used. For instance, a potential use case would be to display differences between a Digital Elevation Model (Copernicus DEM) and land-ice-height ‘ICESat-2’ measurements. The next image shows the ICESat-2 land-ice-height in winter (green) and summer (orange) compared to a DEM,\nMore detailed explanations related to this use case exist in the Vignette ICESat-2 Atlas Products of the package."
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#were-there-any-issues-using-openaltimetry-api-the-cyberinfrastructure-platform-for-discovery-access-and-visualization-of-data-from-nasas-icesat-2-mission-note-currently-the-openaltimetry-api-website-appears-to-be-down",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#were-there-any-issues-using-openaltimetry-api-the-cyberinfrastructure-platform-for-discovery-access-and-visualization-of-data-from-nasas-icesat-2-mission-note-currently-the-openaltimetry-api-website-appears-to-be-down",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "Were there any issues using OpenAltimetry API (the “cyberinfrastructure platform for discovery, access, and visualization of data from NASA’s ICESat-2 mission”)? (NOTE: Currently, the OpenAltimetry API website appears to be down?)",
    "text": "Were there any issues using OpenAltimetry API (the “cyberinfrastructure platform for discovery, access, and visualization of data from NASA’s ICESat-2 mission”)? (NOTE: Currently, the OpenAltimetry API website appears to be down?)\nAt the beginning of October 2023, I was informed that the OpenAltimetry website (previously https://openaltimetry.org) has migrated to https://openaltimetry.earthdatacloud.nasa.gov/. I then contacted the support of the National Snow & Ice Data Center, which informed me about the migration of the API interface.\nCurrently, I have an open issue in my Github repo related to this migration. Once the OpenAltimetry API becomes functional again, I’ll submit the updated version of the ICESat2R package to CRAN."
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#in-your-blog-post-for-the-copernicusdem-package-you-showed-a-code-snippet-showing-how-it-loads-files-iterates-over-the-files-and-uses-a-for-loop-to-grab-all-the-data.-can-you-provide-something-similar-for-icesat2r",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#in-your-blog-post-for-the-copernicusdem-package-you-showed-a-code-snippet-showing-how-it-loads-files-iterates-over-the-files-and-uses-a-for-loop-to-grab-all-the-data.-can-you-provide-something-similar-for-icesat2r",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "In your blog post for the copernicusDEM package, you showed a code snippet showing how it loads files, iterates over the files, and uses a for-loop to grab all the data. Can you provide something similar for ICESat2R?",
    "text": "In your blog post for the copernicusDEM package, you showed a code snippet showing how it loads files, iterates over the files, and uses a for-loop to grab all the data. Can you provide something similar for ICESat2R?\nWhenever I submit an R package to CRAN, I include one (or more) vignettes that explain the package’s functionality. Once the package is accepted, I also upload one of the vignettes to my personal blog. This was the case for the CopernicusDEM R package,\n\nVignette\nBlog Post\n\nbut also for the ICESat2R package,\n\nVignette 1\nVignette 2\nVignette 3\nBlog Post"
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#the-current-version-of-icesat2r-on-cran-httpscran.r-project.orgpackageicesat2r-is-1.04.-are-you-still-actively-supporting-icesat2r-are-you-planning-to-add-any-major-features",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#the-current-version-of-icesat2r-on-cran-httpscran.r-project.orgpackageicesat2r-is-1.04.-are-you-still-actively-supporting-icesat2r-are-you-planning-to-add-any-major-features",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "The current version of IceSat2R on CRAN (https://CRAN.R-project.org/package=IceSat2R) is 1.04. Are you still actively supporting IceSat2R? Are you planning to add any major features?",
    "text": "The current version of IceSat2R on CRAN (https://CRAN.R-project.org/package=IceSat2R) is 1.04. Are you still actively supporting IceSat2R? Are you planning to add any major features?\nYes, I still actively support IceSat2R. I always respond to issues related to the package and fix potential bugs or errors. The NEWS page of the package includes the updates since the first upload of the code base to Github.\nI don’t plan to add any new features in the near future, but I’m open to pull requests in the Github repository if a user would like to include new functionality that could benefit the R programming community."
  },
  {
    "objectID": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#about-isc-funded-projects",
    "href": "posts/satellite-data-with-r-unveiling-earths-surface-using-the-icesat2r-package/index.html#about-isc-funded-projects",
    "title": "Satellite Data with R: Unveiling Earth’s Surface Using the ICESat2R Package",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nLearn more"
  },
  {
    "objectID": "posts/r4socialscience-empowering-social-science-research/index.html",
    "href": "posts/r4socialscience-empowering-social-science-research/index.html",
    "title": "R4SocialScience: Empowering Social Science Research with R in India",
    "section": "",
    "text": "Dr. Mohit Garg, organizer of the R4SocialScience group in Delhi, India recently talked to the R Consortium about his experience of starting an R user group. The R4SocialScience group aims to bridge the gap between social science research and data analysis, offering support and training to academics, researchers, and industry professionals. Dr. Garg shares his experiences, the growth of the R community in India, and his plans for expanding R’s reach.\nPlease share about your background and involvement with the RUGS group.\nI’m currently working as an assistant librarian at the Indian Institute of Technology, Delhi, one of the premier institutions in India.  My academic background includes a BTech in Information Technology from Guru Gobind Singh Indraprastha University followed by an MS in Librarian Information Science from the Indian Statistical Institute, an institution dedicated to statistics in India started by the late Professor P.C. Mahanobis. After that, I completed my PhD in Library and Information Science from IGNOU, New Delhi.\nMy interest in R began in 2013 when I started my MS at the Indian Statistical Institute.  Since then, I have taken various courses as part of my MS program and some online courses. I became interested in R due to its open source nature and the free availability of packages for all kinds of analysis. Then, I started promoting R in the academic community. However, in 2013, there was little interest in R because the prevalent approach in India was more focused on using commercial software for data analysis.  However, in the past few years, there has been an increasing interest in R, with many workshops and government-funded events dedicated to it.\nI have been providing R training to professors, teachers, and research scholars, and I have also worked on web-based development using Shiny packages. Furthermore, we have developed a web dashboard to visualize real-time research productivity data obtained from sources like Scopus through API. Recently, we completed a 12-week MOOC course on NPTEL SWAYAM platform with a focus solely on R. The course was quite popular, with 2584 learners from India joining, and 515 learners registering for the final examination. Although the course was free, participants had the option to pay for certification.\nCan you share what the R community is like in India?\nI have been involved in the academic profession since 2016 and have been giving lectures and providing resource points at various institutions. I believe that there is a need to build a community focused on social sciences, especially for those who may have a limited understanding of mathematics, and statistics. The idea is to create a specific community related to social science, not just in India, but also in collaboration with other institutions. The community will cater to three main groups: those who are proficient in coding and development of R packages, those who are familiar with basic R but need further guidance, and those who are completely new to R.\nThe community aims to provide support for those interested in social science and to make R more accessible by offering packages related to social science, basic R tutorials. One specific package gaining popularity in academia is “biblo shiny bibliometrics,” which facilitates scientific productivity mapping using R.\nWe want to emphasize that R is not just a programming language, but a software for data analysis, to encourage more people to explore its potential. While both R and Python are interpreted languages, we aim to dispel the fear of programming and demonstrate how these languages can be used effectively. Although Python appears to be more widely used in the industry, there is still a growing interest in R.\nWhat are your plans for the group going forward?\nI have been teaching R for more than 10 years, and I found that researchers are interested in using R. I have identified three potential co-organizers from different regions in India to make a team of four people. We have already received a grant, and we plan to conduct training sessions in different locations across India.\nI am focusing on a “train the trainer” model, where I aim to train individuals who can then carry out training sessions in their respective regions. India has over 50,000 colleges and around 1,200 universities, all involved in significant research and analysis activities. We also aim to have dedicated R trainers in all districts in India by 2026.\nOur approach involves dividing the country into five zones, followed by state-wise and district-wise planning. We are not heavily reliant on industry support, as our activities are primarily related to academia and research.\nWe plan to charge a nominal registration fee, which would cover expenses such as food and refreshment. We are hoping to minimize travel expenses, as they can be quite costly. But we will explore some way to fund the travel and accommodation expenses. We have hosted a one day workshop on “Doing Research using R” at Galgotias University.\nI am currently focusing on building a community and providing training sessions. I have noticed that online sessions may not be as effective as I had hoped, as participants seem to encounter many problems. Therefore, I am considering conducting more in-person workshops, which I believe will help popularize the training sessions. Additionally, I aim to develop specialized packages for social science and build a dedicated team. I am optimistic about these plans. During a recent workshop, I noticed that many participants preferred simple tools for data analysis. I intend to introduce such tools to make the training more accessible and user-friendly for participants. This is my vision for the community.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nWe have developed a platform utilizing the shiny and other text mining packages. This platform is still in the testing phase. The platform allows real-time data fetching from the Scopus API.\nFor example, if I search for a faculty member, it will display the publication data such as the number of publications, H-index, citations, types of publications, sources of publication, and annual publication distribution. We can also download this data.\nWe have also developed a word cloud based on the titles of the publications for each faculty member, processed using the TM package. This helps to infer the expertise of the professors. Furthermore, we have included a feature for identifying the H-classic, which is related to the H-index.  This platform is quite useful and efficient, especially for academic institutions. We now have the capability to download data from a specific date range as an Excel file. The data includes publication dates and the number of citations.\nWe’re in the process of creating a full dashboard for universities or institutions. We’ve also conducted a pilot study for other institutions. We are also considering publishing this work as a research paper to increase its visibility."
  },
  {
    "objectID": "posts/r4socialscience-empowering-social-science-research/index.html#how-do-i-join",
    "href": "posts/r4socialscience-empowering-social-science-research/index.html#how-do-i-join",
    "title": "R4SocialScience: Empowering Social Science Research with R in India",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/offa-r-users-group-empowering-data-driven-education-in-nigeria/index.html",
    "href": "posts/offa-r-users-group-empowering-data-driven-education-in-nigeria/index.html",
    "title": "Offa R Users Group: Empowering Data-Driven Education in Nigeria",
    "section": "",
    "text": "The R Consortium had a conversation with Anietie Edem Udokang, who is the founder and organizer of the Offa R Users Group (ORUG). He discussed the emerging local R community and the use of R for his research in time series analysis.\nThe Offa R Users Group has a Meetup coming up on March 26th, 2024, titled “Test for the Assumptions of Linear Regression Using R.” The group is also seeking individuals to serve as guest speakers for their online events.\nPlease share about your background and involvement with the RUGS group.\nMy name is Anietie Edem Udokang, and I am a chief lecturer at the Federal Polytechnic Offa. I hold a Master of Science degree in Statistics. It was during my postgraduate studies that my supervisor introduced me to R, which was around 2012. Since then, I’ve been using R and have discovered that it’s far superior to some of the other software programs I had previously used.\nI have found that interacting with others and utilizing specific features, such as the ability to download applications, has been incredibly beneficial to my analysis work. These special packages have helped me greatly, and I believe it is important to attach relevant packages when organizing data. This experience has made me passionate about using R for data analysis.\nEver since I began using R, I have had the privilege of engaging with a diverse group of individuals, including data scientists and software users. These interactions have led me to the realization that to continue growing and learning, it would be beneficial to establish a user group within our community. Initially, we called it the “Fedpofa R Users Group,” but later changed the name to “Offa R Users Group.” We have been organizing meetings, providing training, and engaging in other activities to keep the community vibrant.\nCan you share what the R community is like in Offa?\nR is not limited to academic use, but it is also used in industry. The reason for this is that polytechnics act as a bridge between the industry and academic institutions. If the students have a good grasp of how to use R, it means that industry will be directly or indirectly affected. Consultants often visit our ORUG and ask for some analysis, which we provide using R. Additionally, students also use R for their projects.\nI use R for many of my publications. R has gained a lot of popularity, not only within our institution but also among sister institutions in the area. Some departments have even made R the only software that students are required to use for analysis.\nWhat industry are you currently in? How do you use R in your work?\nI am in the education sector, and I use R for my work in time series analysis, which is my area of specialization. I rely on TSA, tseries and other related time series packages to carry out my work. For example, I used R for Modeling the Residuals of Financial Time Series with Missing Values for Risk Measures, which was my MSc project. I have also used R in the Application of the Seasonal Autoregressive Moving Average Model to Analyze and Forecast the Food Price Index (free registration required). Additionally, I used R in a paper titled “Volatility of Exchange Rates in Nigeria: An Investigation of Risk on Investment.” In another innovative project was Modelling Circular Time Series with Applications. These are just a few examples of the papers and research where I’ve personally used R.\nYou have a Meetup titled Test for the Assumptions of Linear Regression Using R, can you share more on the topic covered? Why this topic?\nSome authors use regression models without checking whether the assumptions hold or not. Instead of carrying out tests to confirm this, they assume that the model is valid if the assumptions are fulfilled. This topic aims to highlight the importance of carrying out such tests to ensure reliable and comprehensive results. Lack of adherence to the assumptions may lead to inaccurate conclusions. The focus will be on commonly used tests for normality, linearity, autocorrelation, heteroscedasticity/homoscedasticity, and multicollinearity, with illustrative examples using R.\nI appreciate the R Consortium for their valuable RUGs grant assistance in 2022. With this grant, I could open two other user groups: the Ilorin R Users Group and the Kwara Environmental Statistics R Group. I also want to express my gratitude to the R Consortium for sponsoring my Meetup subscription and covering other minor expenses in 2022. The subscription is still ongoing, and I hope that we can continue our partnership to promote the use of R in our community.\nI would like to request for speakers to present at our R User Group. We are currently seeking speakers for our upcoming events and would be delighted to welcome speakers from all over the world to share their R-related knowledge with us."
  },
  {
    "objectID": "posts/offa-r-users-group-empowering-data-driven-education-in-nigeria/index.html#how-do-i-join",
    "href": "posts/offa-r-users-group-empowering-data-driven-education-in-nigeria/index.html#how-do-i-join",
    "title": "Offa R Users Group: Empowering Data-Driven Education in Nigeria",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/empowering-data-science-in-mexico-r-ladies-queretaro-on-inclusivity-and-growth/index.html",
    "href": "posts/empowering-data-science-in-mexico-r-ladies-queretaro-on-inclusivity-and-growth/index.html",
    "title": "Empowering Data Science in Mexico: R-Ladies Querétaro on Inclusivity and Growth",
    "section": "",
    "text": "Driselda Sánchez-Aguirre, co-founder and organizer of R-Ladies Querétaro, recently spoke with the R Consortium about her journey in building a welcoming, diverse R community in Querétaro, Mexico. She shared insights on the chapter’s hybrid events, collaborative partnerships with other R-Ladies chapters, and upcoming workshops focused on accessible R training. Driselda highlighted the challenges and rewards of growing a supportive space for women in data science in Querétaro and beyond. Querétaro is located in central Mexico, about 4 hours north of Mexico City.\nPlease share your background and involvement with the RUGS group.\nI co-founded the R-Ladies Querétaro chapter as a PhD student in economics. It was fascinating to connect with women from various disciplines who shared an interest in creating the group together. One of the members was also a PhD student, but she specialized in genomics, while another was a postdoctoral researcher in psychology. We all shared a passion for using R, although I initially found it challenging because economics primarily focuses on business-related disciplines.\nWe have access to many software options for statistics that are easier to use but are often proprietary. Initially, I was just looking for a simple button to click to find results. However, I discovered that R offers much more, including beautiful graphs and visuals. Each time you use it for a new task, it presents a challenge, but it is incredibly rewarding to uncover the answers. Since 2019, we have organized sessions and workshops to continue developing this chapter.\nCan you share what the R community is like in Mexico?\n\nFrom my experience, R is primarily used in academia and the industry. Specifically, the R-Ladies Querétaro chapter is quite diverse, with a mix of professionals. For instance, I am an economist, Azalea works in psychology, Ana Betty and Karen study genomics, and Elizabeth is in neuroscience. One of our main focuses is inclusivity, ensuring that individuals from all backgrounds and skill levels feel welcome. All genders are welcome, but meetings and workshops are always organized and hosted by women.\n\nI remember our first meeting in 2019; it was a truly memorable occasion. We discovered that women from various industries attended the workshop, marking the inaugural chapter meeting in Querétaro. It was inspiring to see women working as programmers in the pharmaceutical industry and as engineers coming together. It was an incredible experience to have such a variety of backgrounds represented.\n\nWhen the pandemic began, managing the various profiles we maintained became challenging. Since then, the focus has shifted towards academic users, particularly women interested in workshops. While we still connect with women from industry through social networks and email, our primary target group is academia in Querétaro.\nSince last year, we have collaborated with R-Ladies Morelia, another chapter in Mexico. We discovered that a significant group of women use R for bioinformatics, a fascinating area of interest. I enjoy discussing social and economic topics, especially those related to tourism, political stories, and inclusivity. However, most discussions focus more on bioinformatics and similar subjects.\nPlease tell us about upcoming events from your group.\nDuring the COVID pandemic, we transitioned to online events, and since 2022, we have been working towards a hybrid format. Now, we’re excited to return to in-person gatherings.\nI would like to highlight a recent event from our group. On September 28th, we participated in the R-Ladies Mexico Annual Meeting, which brings together all R ladies’ chapters nationwide. The event is open to everyone who speaks Spanish, making it a fantastic opportunity to connect, share knowledge, and foster collaborative partnerships.\nAdditionally, thanks to a grant from the R Consortium, we plan to host four more workshops yearly. The first one was face-to-face on how to make maps with R, open to the general public but emphasizing students and researchers in earth sciences and geography. It was on November 21st, 2024, we had about 20 attendees, there was pizza and popcorn to share with each other.\nThe other three workshops will cover basic R concepts using ggplot and open science practices incorporating R. While we don’t have exact dates for all the workshops, we have already begun planning and are excited to offer these opportunities to our community.\nDo you recommend any techniques for planning for or during the event? (Github, Zoom, other.) Can these techniques be used to make your group more inclusive to people who cannot attend physical events in the future?\n\nWe use a variety of tools to ensure smooth planning for our events. GitHub is essential for sharing our resources. For example, when we’re hosting a workshop, it’s easier to share the GitHub link so that participants can access the materials we’ll be using.\nZoom also enables remote participation, making our events accessible to a wider audience. It includes reaction features that help gauge participant engagement. For instance, attendees can click a green button if they understand the task or a red button if they feel lost. This feedback allows us to tailor the learning experience to meet their needs better.\nWe use social media to promote our events, primarily X and Facebook. Additionally, we believe that collaborating with other R Ladies chapters enhances our outreach. We have partnered with chapters in Colombia and other locations in Mexico, which allows us to expand the topics we cover, as they also use their media channels to promote our events.\nWe have also found WhatsApp to be a useful communication tool. WhatsApp provides a real-time platform for organizers to communicate and coordinate. These tools help make the group more inclusive, accessible, and efficient, ensuring that tasks are completed on time.\nWhat challenges have you faced in organizing the R Ladies Querétaro Chapter? How have you overcome these challenges?\nI believe it’s crucial to emphasize the importance of collaboration and community support. As a nonprofit group, we often face challenges, especially when managing time due to other responsibilities, such as family obligations. To maintain consistent participation, we need to balance our personal and professional lives while continuing to advance our chapter.\nMaintaining the chapter is rewarding, but finding the time is also a constant challenge. We love what we do because we want to share all the good things it offers to different disciplines and areas of focus. However, this challenge to find time can be overwhelming. I believe we can overcome it through collaboration and community support. It’s important to emphasize the role of the community in helping us achieve our goals.\nHow do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 75,492 members in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/keith-karani-wachira-leading-the-dekut-r-community-in-kenya-and-innovating-with-r/index.html",
    "href": "posts/keith-karani-wachira-leading-the-dekut-r-community-in-kenya-and-innovating-with-r/index.html",
    "title": "Keith Karani Wachira: Leading the Dekut R Community in Kenya and Innovating with R",
    "section": "",
    "text": "Keith Karani Wachira, the Dekut R Communityorganizer based in Nyeri, Kenya, was recently interviewed by the R Consortium and shared his journey in the R community, which began in 2019 during his university years. Sparked by a tech meetup, Keith’s interest grew through the pandemic sessions. Now in academia, he uses R to address business automation challenges, attracting industry professionals to his practical sessions. Excited by trends like AI integration and tools like Quarto, Keith foresees increased automation and efficiency. Outside work, he enjoys baseball, graphic design, web development, and teaching R, finding great reward in his students’ success.\nPlease share about your background and your involvement in the R Community. What is your level of experience with the R language?\nI began my journey with R in early 2019 while studying at university. In May 2019, I learned about a tech community through a friend who posted in one of our school’s WhatsApp groups, inviting us to join a meetup. Curious, I decided to attend.\nI remember the meetup was on a Saturday, and it turned out to be the launch of a new club. My friend invited me and was part of the Microsoft Learn Students’ Ambassadors. His classmates used R for their engineering projects, which sparked my interest.\nDuring the first lesson, I found it challenging as there were about 30 students, most of whom were first-year students pursuing various degrees, including Business Information Technology, which I was majoring in, along with a minor in Communication. My first programming language that year was C, which I found interesting.\nOver time, I found the R language interesting, especially its syntax. What fascinated me the most was how data could be used to create visualizations. This curiosity led me to explore data from my local sewerage and water company, using R to create informative visualizations and derive insights that can be used in decision making.\nI continued attending the sessions in 2020 during the pandemic. Although we no longer had in-person classes, we adapted using Microsoft Teams for our meetings. Eric organized the meetups and arranged tech talks with speakers from Posit (formerly RStudio) and NairobiR. I remember attending these sessions and understanding how powerful R is.\nThroughout 2020, I attended regularly but still lacked confidence in the language. However, in 2022, I made significant progress. Under Eric’s leadership, we expanded the community to involve more people, especially students from the department of Actuarial Science, Telecommunication Engineering and electrical engineering. We set up a structured learning environment based on materials from Hadley Wickham’s books and resources from the R website and blogs.\nEric’s leadership greatly influenced me. He taught us how to write blogs using Markdown and publish on RPubs. This is a bit about my background. Today, we continue to teach R, following a structured approach to help others intermediate in using the language.\nWhat industry are you currently in? How do you use R in your work?\nI’m currently in academia, primarily focusing on various technical challenges. We hold sessions where we demonstrate the use of R in robotics for members in Electrical Engineering and Telecommunication Engineering. For those in Actuarial Science, we show how to create time series models using R.\nComing from a background in business and information technology, I focus on solving business challenges, particularly automating business processes and addressing issues in banking, logistics, retail using opensource datasets. Our efforts are not limited to academia; we concentrate on applying R across different disciplines within academia to tackle these challenges.\nWhy do industry professionals come to your user group? What is the benefit of attending?\nAn interesting scenario arose when I became interested in EMS (Engineering and Management Systems). We started organizing hybrid sessions after the COVID period and it caught interest of students from another university in Kenya ,Egerton University. Through, statistical analysis bureau of Egerton University they joined our sessions to learn how to leverage tidy models packages to create machine learning models and also collaborate with the community members.\nThey were very interested, and as future economists, we demonstrated how to build and appreciate these models. In previous meetups, we also introduced participants to Shiny apps, teaching them how to host their models and create interfaces to display their work.\nAnother valuable skill we taught was generating reports using R Markdown. This allows users to write code, format text, add videos, images, and emojis, and present their work in a professional and engaging manner. Attendees found this particularly useful as it enhanced their ability to write, structure, and report code effectively.\nParticipants learned to leverage the R ecosystem for coding, structuring their work, and reporting their findings by attending our sessions.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nA trend I’ve noticed is the widespread effort to include everyone in learning programming languages like R. This is evident in the emergence of specialized groups such as R for Medicine and R for Pharma. Two of our alumni even demonstrated how R can be used in robotics through a talk at Posit Conference 2022, demonstrating its applicability in specific industries. This specialization fascinates me, and I am eager to see how R will be used across various fields.\nAnother trend is using tools like Quarto, which facilitates the implementation of such specializations. Additionally, I am excited about the incorporation of AI in building R applications, such as using Gemini for Shiny apps. Although materials on this are currently limited, I see this as a growing trend.\nThe integration of AI will likely lead to the automation of many manual processes, further enhancing R’s utility and efficiency in various industries.\nWe would like to get to know you more personally. Can you please tell me about yourself? For example, your hobbies/interests or anything else you want to share.\nWhen not in front of my laptop, I enjoy playing baseball and softball, especially as a catcher. Catching allows me to see the entire game command the play, and I enjoy throwing the ball from home to second base and picking off a runner. It’s a challenging position that helps me focus and improve my aim.\nOn the side, I also do some graphic design using Canva which I use to create posters and newsletters for our community meetups. Additionally, I have web development skills using MERN stack.\nAnother passion of mine is teaching R to others. I love seeing people learn and apply the concepts and then go on to teach others. One of my students from his first year has now taken over as a lead in our community, which is incredibly encouraging. He even competed in hackathons and finished fourth, showing how much he has grown.\nTeaching and seeing others succeed is something I find very rewarding and motivating."
  },
  {
    "objectID": "posts/keith-karani-wachira-leading-the-dekut-r-community-in-kenya-and-innovating-with-r/index.html#how-do-i-join",
    "href": "posts/keith-karani-wachira-leading-the-dekut-r-community-in-kenya-and-innovating-with-r/index.html#how-do-i-join",
    "title": "Keith Karani Wachira: Leading the Dekut R Community in Kenya and Innovating with R",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more\n\n\n\ngd2md-html: xyzzy Mon Jul 29 2024"
  },
  {
    "objectID": "posts/empowering-girls-in-data-science-the-r-girls-school-network-initiative/index.html",
    "href": "posts/empowering-girls-in-data-science-the-r-girls-school-network-initiative/index.html",
    "title": "Empowering Girls in Data Science: The R-Girls-School Network Initiative",
    "section": "",
    "text": "The R Consortium recently interviewed Dr. Raiza Ghani, Professor Mohamed Amin, and R teacher Anisa Nawaz. Dr. Razia Ghani and her team at Green Oak Academy are leading a two-year project to establish the R-Girls-School (R-GS) network, addressing the underrepresentation of women, particularly from deprived and ethnically diverse backgrounds, in data science. The initiative aims to integrate data science into the UK national curriculum, which is used by schools globally. The project focuses on developing 10 R-based lesson plans in the first year, with the second year dedicated to networking and dissemination. This includes a dedicated website with extensive online resources. Supported by key figures and organizations in the R community, the project aims to provide sustainable, impactful education in data science for girls worldwide​. This project was funded by the R Consortium.\nR-Girls Website\nWhat inspired you to initiate the R-Girls-Schools (R-GS) Network project?\nDr. Ghani: Initially, we thought we would integrate programming into our school curriculum. Using programming to explain mathematical concepts would help the girls visualize and understand them better. Gradually, this idea expanded into a larger vision, where we aimed to create a network of schools using the lessons we developed. Part of the funding requirements was to open up our lessons beyond just our school.\nAdditionally, being an all-girls school made this initiative particularly appealing to us. We recognized that our students might not have had this exposure otherwise and wanted to provide them with this valuable opportunity. Professor Mohamed worked with us, making it an ideal situation. It was an opportunity that came our way, and we seized it enthusiastically.\nLogo design: Anisa Nawaz\nProfessor Mohamed: First, we observed that girls in our school generally didn’t take to computer science; they were often turned off by the subject. Second, Dr. Ghani, with a background in mathematics and statistics, understands the power of software in these fields, both in the classroom and in industry.\nI had the pleasure of helping set up the R community for the National Health Service (https://nhsrcommunity.com/) in the UK, which was a very positive experience. One summer, outside of school, Dr. Ghani and I discussed bringing the joy of R to the classroom. This idea seemed readily achievable because of Dr. Ghani’s background in mathematics and statistics. We then considered how to implement this and became aware of a funding opportunity from the R Consortium. As part of that process, we actively sought support from various individuals who replied positively.\nI should emphasize that our goal was not to teach computer programming. Dr. Ghani made it clear from the beginning that we see software as a tool to teach other subjects, not just programming. Our aim was to use R as an applied tool to help the girls in various subjects involving data collection, analysis, and visualization.\nIn summary, we wanted to see if teenage girls could experience the joy of using R. The support from the R consortium allowed us to pursue this idea.\nAnisa: My first experience with R was a request to design a logo. It was exciting to do and it’s great to see the logo has now been adopted. However when I started coding in R, I initially thought it would be very complicated, involving writing a lot of formulas and complex code. However, I’ve learned that coding is actually quite easy. Most resources can be found online, and often it’s just a matter of tweaking things, like replacing numbers or colors. The girls also noticed that while it seemed like a lot of text and difficult concepts at first, they began to understand what everything meant over time, making it much easier for them.\nOne challenge is that only a few girls are entering fields like data science because they need to understand how it works or what it looks like to work in that field. This lack of understanding makes it seem more complicated and intimidating. But now that they see how it works, I hope that in the future, more girls will be interested in these areas.\nCould you explain the significance of using R specifically, as opposed to other programming languages, in the context of this project?\nProfessor Mohamed: We were aware that computer science didn’t appeal to the girls, so we avoided using that label and the associated languages. Instead, we opted for R because of its strong worldwide community, numerous user groups, and abundant free resources. The R-Ladies group is also a significant part of that community, which helps build confidence for both staff and students in their journey with R.\nThis doesn’t mean we’re against other languages such as Python; we just chose to focus our energy on R. You can go far in your data science career with R, especially if your primary goal is to analyze existing data, look for insights, and create reports and graphics, rather than building data science products.\nDr. Ghani used SAS a long time ago when there were fewer choices, but SAS is not something we would consider bringing to the school. It’s a complex programming language that takes many years to master. These were some of the considerations we had when choosing R over other options. For us, it was a clear decision.\nDr. Ghani: From the school finance perspective, choosing R was a no-brainer. It’s freely available, which makes a huge difference compared to having to subscribe to something annually. We did have some annual subscriptions for other things, but R itself is free, and we were already using it in the school. We use R to produce graphs that show student progress and to print out timetables. This project was just a natural extension of what we were already doing.\nCan you elaborate on the specific challenges girls from disadvantaged, ethnically diverse backgrounds face in entering the field of data science?\nDr. Ghani: I think the key issue here is deprivation, particularly among ethnic minority backgrounds. The girls’ backgrounds likely play a significant role. Coming from a deprived family limits their exposure to fields like data science. For example, they might know about engineering but need to be made aware of the different types of engineers. Similarly, they might know about doctors but not the various specializations available.\nDeprivation makes it more difficult for them to access these opportunities. If you come from an influential family, you’re exposed to many different fields. In contrast, our community doesn’t offer the girls many readily available opportunities. This project was a chance for us to expose them to something they might not encounter until university.\nAnisa: It might sound more complicated, but we have girls in our class, ages 12-13 years, building websites by themselves. We encourage them and help fix mistakes. Many of these girls are learning on their own, despite lacking prior knowledge. Some don’t have computers at home or know how to use them well. I also teach ICT, and I’ve seen girls who struggle with basic computer skills, like typing quickly.\nI know some girls have a harder time because they come from backgrounds with limited financial resources and lack access to technology at home. They often need extra training in basic software like Word or PowerPoint. Without our support, it’s less likely they would be introduced to these topics. I think what we’re doing is very important and beneficial.\nProfessor Mohamed: Data science is not typically in the mindset of our students because they come from ethnically diverse and deprived backgrounds where traditional roles are more emphasized. Data science is not part of their vocabulary, and their parents wouldn’t know how to encourage them in this field even if they wanted to.\nOur school has been able to expand their horizons, showing them new interests and possibilities. They have found joy in R and data science, which was not initially within their bandwidth. We started with pre-made lessons, but with support, the girls’ horizons have expanded. They are now doing amazing projects with R, something we couldn’t have anticipated initially.\nIf someone had suggested on day one that 11 to 16-year-olds would be building their own websites using R, it would have seemed too ambitious. Yet, today, they are doing just that because they chose to pursue their interest without it being mandated. The girls asked to build websites - we had no such plans! The topics they choose for their websites are engaging and interesting, allowing them to do creative and intellectual work, organize, and debug code. These are sophisticated skills, and they are learning them in a fun way. None of this would have been available to them in the traditional curriculum."
  },
  {
    "objectID": "posts/empowering-girls-in-data-science-the-r-girls-school-network-initiative/index.html#about-isc-funded-projects",
    "href": "posts/empowering-girls-in-data-science-the-r-girls-school-network-initiative/index.html#about-isc-funded-projects",
    "title": "Empowering Girls in Data Science: The R-Girls-School Network Initiative",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nhttps://www.r-consortium.org/all-projects/call-for-proposals"
  },
  {
    "objectID": "posts/earl-early-bird-tickets-are-now-available/index.html",
    "href": "posts/earl-early-bird-tickets-are-now-available/index.html",
    "title": "EARL Early Bird Tickets Are Now Available!",
    "section": "",
    "text": "Contributed by Abbie Brookes, Senior Data Analyst at Datacove\n\nDatacove is pleased to announce the availability of tickets for the upcoming EARL (Enterprise Applications of the R Language) conference.\nThe EARL conference is a cross-sector event that will be held at the Grand Hotel in Brighton. This venue promises to provide attendees with a blend of Victorian elegance and modern conference facilities over three days, from the 3rd to the 5th of September 2024. The conference schedule includes high-quality workshops on the first day (3rd September) and two days of presentations and talks (4th – 5th September). An evening networking event is planned for the 4th of September at the British Airways i360 venue, offering attendees the opportunity to connect with peers and speakers in a relaxed setting.\nWe are offering tickets at a reduced early bird rate. Additionally, we provide discounts for government employees, NHS staff, charity workers, academics, and those making bulk purchases. For more detailed information on ticket pricing and discounts, contact Abbie Brookes at abbie.brookes@datacove.co.uk.\nThe EARL conference draws attendees from across the globe and from a variety of sectors. Previous participants have included notable organizations such as The Dogs Trust, BBC, Microsoft, Swiss RE, Posit, Sainsburys, and Bupa.\nThis year’s keynote speakers include:\n\nProfessor Andy Field, known for his contributions to statistics education\n\nChristel Swift, a senior data scientist at the BBC\n\nHadley Wickham, a key figure in the R community and author of the Tidyverse\nIn addition to the main conference, a selection of pre-conference workshops will be available, offering in-depth training opportunities. For more information on the conference venue, schedule, and registration, please visitour website. We invite you to join us for what promises to be an informative and engaging event for the R and Python communities"
  },
  {
    "objectID": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html",
    "href": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html",
    "title": "Join Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch",
    "section": "",
    "text": "Are you passionate about financial economics and eager to learn more about empirical research methods? Then our upcoming webinar is an unmissable opportunity for you!"
  },
  {
    "objectID": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#discover-tidy-finance-a-revolutionary-approach-in-financial-economics",
    "href": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#discover-tidy-finance-a-revolutionary-approach-in-financial-economics",
    "title": "Join Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch",
    "section": "Discover Tidy Finance: A Revolutionary Approach in Financial Economics",
    "text": "Discover Tidy Finance: A Revolutionary Approach in Financial Economics\nTidy Finance isn’t just a method; it’s a movement in financial economics. This webinar will introduce you to this innovative approach, which is grounded in the principles of transparency and reproducibility. With a focus on open source code in both R and Python, Tidy Finance is changing the game for students and instructors alike. You’ll learn about its applications in empirical research and how it’s reshaping the way we teach and learn in the financial domain."
  },
  {
    "objectID": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#what-youll-learn",
    "href": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#what-youll-learn",
    "title": "Join Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch",
    "section": "What You’ll Learn",
    "text": "What You’ll Learn\n\nIntroduction to Tidy Finance (10 mins): Get an overview of Tidy Finance principles and its significance in the field of financial economics.\nAccessing and Managing Financial Data (20 mins): Dive into the practical aspects of using R to import, organize, and manage various data sets.\nWRDS & Other Data Providers (10 mins): Explore different data providers, including open source and proprietary options.\nQ&A Session (15 mins): Have your queries addressed directly by Christoph in an interactive Q&A session."
  },
  {
    "objectID": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#who-should-attend",
    "href": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#who-should-attend",
    "title": "Join Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch",
    "section": "Who Should Attend?",
    "text": "Who Should Attend?\nThis webinar is tailored for students, professionals, and anyone with an interest in financial economics, data management, and empirical research. Whether you’re just starting or looking to deepen your understanding, this webinar will provide valuable insights and practical knowledge.\nRegister now to secure your spot in this enlightening session. Embrace the opportunity to learn from a leading expert and elevate your understanding of Tidy Finance and financial data management."
  },
  {
    "objectID": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#register-here",
    "href": "posts/join-our-upcoming-webinar-master-tidy-finance-access-financial-data-with-expert-christoph-scheuch/index.html#register-here",
    "title": "Join Our Upcoming Webinar: Master Tidy Finance & Access Financial Data with Expert Christoph Scheuch",
    "section": "Register here!",
    "text": "Register here!\nNOTE: This event has concluded. A recording is available here.\n📅 Mark your calendars and join us for this educational journey! 🚀"
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "",
    "text": "Blog contributed by Ning Leng, People and Product Leader, Roche-Genentech and Joel Laxamana, Principal Data Scientist, Roche-Genentech\nThe R Consortium is pleased to announce the successful completion of the Pilot 3 Submission which extended the work done in Pilots 1 and 2 by generating the ADaM datasets. The complete FDA response letter is available.\nThe objective of the R Consortium R Submission Pilot 3 Project is to test the concept that an R-language based submission package for ADaMs and TLFs can meet the needs and the expectations of the FDA reviewers, including assessing code review and analyzing reproducibility. All submission materials and communications from this pilot are publicly available, with the aim of providing a working example for future R-language based FDA submissions. This is an FDA-industry collaboration through the non-profit organization R Consortium.\nAll submission materials can be found at: submissions-pilot3-adam-to-fda. This is the first publicly available R-based FDA submission package including R scripts to generate Analysis Data Models (ADaM) and Tables, Listings & Figures (TLFs).\nOpen-Source Collaboration in standardizing Clinical Trial analyses and Submissions. Broadening ways to bring treatments to Patients."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-timeline",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-timeline",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Pilot 3 Timeline",
    "text": "Pilot 3 Timeline\nThe initial submission was submitted through the eCTD gateway on Aug 28, 2023. FDA verbal responses were received from Jan-July 2024 during R submission working group meetings. Documentation of this initial feedback and response can be found at response-FDA-IR-pilot3.pdf. The updated submission package addressed reported issues and was re-submitted on Apr 19, 2024. The final response letter from FDA was received on Aug 8, 2024."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-scope",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-scope",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Pilot 3 Scope",
    "text": "Pilot 3 Scope\nThe Pilot 3 test submission exemplifies an all-R submission package for ADaMs and TLFs, adhering to electronic Common Technical Document (eCTD) specifications. This comprehensive package not only includes ADaMs and TLGs, but it emulates a full study submission package including the source Study Data Tabulation Models (SDTMs) used to generate the Pilot 3 ADaMs. It also encompasses the installation and loading of the proprietary {pilot3utils} R package, various open-source R packages, R scripts for the Analysis Data Model (ADaM) datasets derived from Pilot 3, and Tables, Listings, and Figures (TLFs) from Pilot 1. In addition to other requisite eCTD components, the Pilot 3 package also includes the Analysis Data Reviewer’s Guide (ADRG) providing detailed steps leading to the execution of the analysis R scripts to re-produce the ADaMs and TLFs from a FDA reviewers perspective. These Pilot 3 submission materials are linked above.\nPilot 3 serves as a complement to Pilots 1 and 2, which demonstrated the feasibility of submitting TLF R scripts and R Shiny code, respectively. Furthermore, Pilot 3 successfully validated the submission of proprietary R packages in compressed file formats, serving as another alternative to {pkglite} or installation directly from github.\nIf you have any questions about this Pilot 3 submission, we would love to hear from you. Feel free to submit any questions you may have as a new issue in our Pilot 3 github repository or you may find any of the Pilot 3 team members in Pharmaverse slack."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#learnings-from-pilots-1-through-3",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#learnings-from-pilots-1-through-3",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Learnings from Pilots 1 through 3",
    "text": "Learnings from Pilots 1 through 3\nIn the three pilots, for various TLFs, the working group members intentionally created different tables in different formats using various open-source R packages. The FDA staff successfully accepted and reproduced the results generated from these different open-source packages. However, though not in scope of these Pilots, we want to share awareness that sponsors are responsible for selecting open-source packages that demonstrate sufficient reliability. Further information on this can be found in the R Validation Hub, formed in 2018 by the PSI AIMS Special Interest Group and supported by the R Consortium. It offers tools like {riskmetric} to quantify the “risk” of R packages and a user-friendly R Shiny app, {riskassessment}, to evaluate package reliability.\nThe majority of FDA staff feedback falls under the following themes :\n\nClear ADRG documentation on computing environment, package dependencies, and expected warnings\nClear documentation on data processing rules and statistical method implementation\nGood statistical practice in confirmatory trials, such as avoiding the possibility of “p-hacking” \n\nFor future submissions using open-source languages, it is recommended to give special attention to recommendation theme 1. Recommendation themes 2 and 3 are language-agnostic and should always be followed, regardless of the programming language used. All of these themes fall in line with the FDA’s Statistical Software Clarifying Statement."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#upcoming-pilots",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#upcoming-pilots",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Upcoming Pilots",
    "text": "Upcoming Pilots\nAs a next step, the R Consortium R Submission Working Group initiated submission pilot 4, to explore the use of novel technologies such as Linux containers and web assembly to bundle a Shiny application into a self-contained package, facilitating a smoother process of both transferring and executing the application."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#the-r-consortium-r-submission-working-group",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#the-r-consortium-r-submission-working-group",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "The R Consortium R Submission Working Group",
    "text": "The R Consortium R Submission Working Group\nThe R Consortium R Submissions Working Group is focused on improving practices for R-based clinical trial regulatory submissions.\nTo bring an experimental clinical product to market, electronic submission of data, computer programs, and relevant documentation is required by health authority agencies from different countries. In the past, submissions have been mainly based on the SAS language. \nIn recent years, the use of open source languages, especially the R language, has become very popular in the pharmaceutical industry and research institutions. Although the health authorities accept submissions based on open source programming languages, sponsors may be hesitant to conduct submissions using open source languages due to a lack of working examples.\nTherefore, the R Submissions Working Group aims at providing R-based submission examples and identifying potential gaps during submission of these example packages. All materials, including submission examples and communications, are publicly available on the R consortium Github page: https://github.com/RConsortium .\nThe R consortium R submission working group includes members from more than 10 pharmaceutical companies, as well as regulatory agencies. More details of the working group can be found at: https://rconsortium.github.io/submissions-wg/ .\nThe R consortium R submission working group is open to anyone who is interested in joining. If interested, please contact Joseph Rickert at director@r-consortium.org."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-fda-reviewers",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-fda-reviewers",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Pilot 3 FDA Reviewers",
    "text": "Pilot 3 FDA Reviewers\nFDA reviewers included  \nHye Soo Cho,  Paul Schuette, and Youn Kyeong Chang."
  },
  {
    "objectID": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-developers",
    "href": "posts/news-from-r-submissions-working-group-pilot-3/index.html#pilot-3-developers",
    "title": "News from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA",
    "section": "Pilot 3 Developers",
    "text": "Pilot 3 Developers\nThe Pilot 3 development team included Joel Laxamana (Project Lead, Roche), Robert Devine (J&J) , Benjamin Straub (GSK) , Kangjie Zhang (Bayer) , Thomas Neitmann (Roche), Phanikumar Tata (Syneos), Steven Haesendonckx (J&J), Yutong Liu (Moderna), Lei Zhao (Roche), Nicole Jones (Merck), Benjamin Wang (Merck), Dadong Zhang (Illumina), Declan Hodges (GSK)."
  },
  {
    "objectID": "posts/enhancing-r-the-vision-and-impact-of-jan-viteks-maintainr-initiative/index.html",
    "href": "posts/enhancing-r-the-vision-and-impact-of-jan-viteks-maintainr-initiative/index.html",
    "title": "Enhancing R: The Vision and Impact of Jan Vitek’s MaintainR Initiative",
    "section": "",
    "text": "The R Consortium recently interviewed Jan Vitek, a professor at Northeastern University’s Khoury College of Computer Sciences. He specializes in programming languages, compilers, and systems. Notably, he developed one of the first real-time Java virtual machines in collaboration with Boeing, which involved writing the navigation software of a ScanEagle UAV in Java and demonstrating that it out-performed the legacy version of the system written in C++. Vitek is actively involved in the programming language community and has held multiple leadership roles, including chairing SIGPLAN. In his spare time Vitek is a cinephile with a presence on Letterboxd and is the human of a dog named Olaf.\nVitek has been working on R for a decade. He is currently working on the MaintainR 2021 project, which aims to support and update the key components of the R ecosystem. The R Consortium is funding this project.\nCan you provide an overview of the MaintainR 2021 project and its main objectives?\n“When does a programming language die?” is the wrong question. Languages do not die, they slowly fade into irrelevance. A language fades away when no longer deemed useful enough for people to learn it and convince their colleagues to adopt it in their work and to maintain software projects written in it. Why does this happen? It comes about when newer languages that are better or appear cooler, start to emerge. The rise of Python has shifted many machine learning users from R to Python. The success of Julia has pushed performance-sensitive users to develop new mathematical libraries in this new language. Is R fading?\nThe programming landscape is evolving, and R, which has been around since 1995, isn’t the newest option available. To remain relevant any complex language depends on a large ecosystem of software elements that must be maintained and fixed regularly. R is certainly complex and it has many dependencies. It relies on a core group of developers who are allowed to make changes in the key parts of the language. These developers, while, on average, being significantly younger than Joe Biden, are not getting younger.\nMy work focuses on trying to modernize R. I’ve been examining R from a computer science perspective for about a decade, focusing on software components such as just-in-time compilers. My group is currently in the midst of writing our third attempt at writing a compiler for R. This effort led me to bring my collaborator, Tomas Kalibera, into the R community through our projects, which sparked his desire to assist the community. This was all part of a natural extension of our research. The goal of the MaintainR project is to maintain key parts of the R environment, which are challenging for volunteers to sustain. We have not found companies willing to contribute top-notch software engineers for this maintenance effort for their own reasons—perhaps they don’t have the resources, or they’re occupied with other tasks. Thus, our effort is focused on providing the necessary maintenance to prolong R’s usefulness.\nThe R ecosystem is dependent on the R interpreter, the core libraries, and CRAN. Which takes the most effort to maintain and why?\nEverything in this project is challenging because the components vary greatly in size and heterogeneity. The interpreter is the smallest part, which everyone relies on. Then, there’s the core library, which is about ten times larger than the interpreter and is a mix of R, C, and Fortran. Fortran isn’t as popular as it used to be, and we encounter issues when compiling it with modern compilers like LLVM. Ensuring Fortran compiles across all desired architectures and operating systems has been a persistent challenge.\nWe’ve also had difficulties integrating patches into LLVM and GCC for this purpose. Changes in these compilers can lead to breakages in our environment. The crown packages contain vast code—potentially 100 times more than the core library. This creates an inverted pyramid scenario where the amount of code increases as you move up the structure.\nMaintaining these packages is not our direct responsibility, but we can’t ignore them. Some are crucial for the users’ satisfaction. Some packages inevitably break as the language evolves and new versions are released. Tomas often has to approach maintainers to inform them of these issues. Sometimes, they respond and agree to implement fixes, but not always. Even when a technical fix might take just half a day, it can require a full week of negotiation with a developer to accept the patch.\nThis social aspect of software maintenance is significant and often the most challenging part. Developers have their own priorities, and a patch that doesn’t align with their goals can be seen as disruptive. Sometimes, the delay is simply because they are slow to respond. This complex interplay of technical and social challenges is a constant part of our efforts to keep the project moving forward.\nTomas Kalibera, a member of the core R team and supported as part of the MaintainR project, has implemented CheckR, a software tool for verification of the C code linked against the R interpreter. Can you explain how CheckR improves the R ecosystem and the overall quality of packages available to R users?\nMy team developed a tool called CheckR, which addresses issues arising from libraries written with a substantial amount of C code. The aim is to identify potentially misbehaving C that could cause unpredictable crashes, leading end users to mistakenly believe that R itself is faulty when, in fact, the issue may stem from a poorly written library or careless usage.\nCheckR processes the C code, transforms it, and an analyzer identifies points where things might go wrong. A common issue it detects involves what we call “Protect bugs.” This happens when the R code sends a value down to C, and C must “protect” this value to prevent it from being reclaimed by the garbage collector. Sometimes, developers handle this in a hasty and imprecise manner. If they make an error, the value given to C can be reclaimed and reused, leading to memory corruption—this could result in security flaws or crashes.\nCheckR is a static analyzer that flags potential issues but is not always definitive. It identifies possible problems, and we return to the developers to discuss whether these should be fixed. Often, developers are skeptical about the identified issues, which can lead to extended discussions. Sometimes, these issues might never occur, but often they do, and since CheckR is used daily across our entire codebase, it automatically generates reports that help us address these vulnerabilities. The next steps with this tool aren’t always clear-cut because we can’t predict all potential issues. For example, one persistent challenge has been how the Windows operating system encodes Unicode characters, requiring months of troubleshooting. Could we have foreseen this particular issue? Not really. It’s part of the unpredictable nature of software development, where new problems can emerge at any time.\nHave you been successful in extending the life of R by having CheckR run daily and helping with the interpreter, libraries, and CRAN?\nThousands of changes have been made to the R environment over time, and while I’d like to say that these changes have definitely improved things, as a scientist, I feel the need to provide concrete evidence, which I can’t always do. However, I can confidently say that each time we identify and fix a bug, the system has one less problem. The challenge, though, is that the potential for bugs can be virtually unlimited because new code is continually being added. It’s an ongoing process, and realistically, there might never be a point where we can declare it completely done.\nHow has it been working with the R Consortium? Would you recommend applying for an ISC grant to other R developers?\nIn our case, a lot of the work we do isn’t glamorous, and most volunteers are drawn to projects where they can attach their names to something flashy. Yet, there’s a continuous stream of necessary tasks that aren’t as appealing but are essential. Without a steady source of funding, sustaining efforts like ours would be impossible. The process we follow is streamlined, the community is welcoming, and your contributions can significantly impact a large user base.\nThe key message here is that funding is incredibly beneficial, especially for supporting those who contribute more gradually; the return on this investment is significant. For instance, in our project, without the funding, we couldn’t have supported the work of Tomas Kalibera, and nothing would have progressed. No company was willing to employ someone full-time for this, despite it being a crucial component of the ecosystem. Being able to provide funding allows us to engage someone who might otherwise have to spend their time on other activities and only contribute to this project in their spare time. Having someone fully dedicated for even a limited period is a tremendous advantage.\n\nAbout ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nLearn more"
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "",
    "text": "Guest Post contributed by Andrea Luciani, Bank of Italy, Directorate General for Economics, Statistics and Research, maintainer of the bimets package (Time Series and Econometric Modeling) in CRAN\nThe US Federal Reserve’s econometric model for the US economy (i.e., FRB/US) is publicly available at federalreserve.gov. The website states, “FRB/US is a large-scale estimated general equilibrium model of the US economy that was developed at the Federal Reserve Board, where it has been in use since 1996 for forecasting, analysis of policy options, and research projects.”\nFRB/US is a quarterly model with hundreds of equations and variables. The model definition and time series data are available for download on the Federal Reserve website, as is the source code, which allows users to perform several econometric exercises. However, the Federal Reserve publicly distributes source codes only for EViews™ and python.\nIn this post, we show how to load the FRB/US model, and perform in R the same econometric exercises provided by the Federal Reserve."
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html#the-frbus-model",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html#the-frbus-model",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "The FRB/US model",
    "text": "The FRB/US model\nThe Federal Reserve website also states, “Compared with DSGE models, however, FRB/US applies optimization theory more flexibly, which permits its equations to better capture patterns in historical data and facilitates modeling the economy in greater detail… A distinctive feature of FRB/US is its ability to switch between alternative assumptions about how economic agents form expectations. Under the VAR-based option, expectations are derived from the average historical dynamics of the economy as manifested in the predictions of estimated VAR models. Under model-consistent (MC), agents are assumed to form accurate expectations of future outcomes as generated by simulations of FRB/US itself.”\nFRB/US is a quarterly model, and counts 284 equations and 365 variables (Feb. 2024 version). The XML model definition is available for download on the Federal Reserve website, and contains, for each endogenous variable, the following information: the variable name, the variable definition with a short description, the economic sector the variable belongs to, the related equation in both EViews™ and python format, coefficients and exogenous variables involved in the equation.\n64 endogenous variables are marked as stochastic and, during the stochastic simulation exercise, will be transformed by applying sequences of shocks as drawn randomly from their historical residuals.\n14 endogenous variables belong to the MCE group (i.e., Model-Consistent Expectations) and have an alternative equation that contains forward-looking references.\nFinally, at the end of the XML model definition, users can find additional information on economic sectors and exogenous variables involved in the model definition."
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html#moving-towards-r",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html#moving-towards-r",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "Moving towards R",
    "text": "Moving towards R\nFRB/US model definition is available to R users in the FRB__MODEL dataset of the bimets package (bimets ver. 4.0.2, a software framework for time series analysis and econometric modeling):\n\n#load bimets\nlibrary(bimets)\n\n\n#load FRB/US MDL definition\ndata(FRB__MODEL)\n\n#print first 4 equations in model definition\ncat(substring(FRB__MODEL,1,1615))\n\nMODEL\n\n$DOWNLOADED FROM federalreserve.gov AND CONVERTED TO BIMETS MDL IN Feb, 2024\n\n$FRB/US is a large-scale estimated general equilibrium model of the U.S. economy \n$that was developed at the Federal Reserve Board, where it has been in use since 1996 \n$for forecasting, analysis of policy options, and research projects. \n\n$--------------------------------------------------------------------------\n\n$ ENDOGENOUS SECTION\n\n$-----------------------------------------------\n$Financial Sector\n$Monetary policy indicator for both thresholds\n$DMPTMAX equals one when either the unemployment threshold or\n$the inflation threshold is breached.\nIDENTITY&gt; dmptmax\nIF&gt; dmptlur&gt;=dmptpi\nEQ&gt; dmptmax=\ndmptlur\nIDENTITY&gt; dmptmax\nIF&gt; dmptlur&lt;dmptpi\nEQ&gt; dmptmax=\ndmptpi\n\n$-----------------------------------------------\n$Federal funds rate, first diff\nIDENTITY&gt; delrff\nEQ&gt; delrff=\nTSDELTA(rff)\n\n$-----------------------------------------------\n$Financial Sector\n$Monetary policy indicator for unemployment threshold\n$DMPTLUR equals zero when the unemployment rate is above its\n$threshold (LURTRSH) one when it is below. A logistic function\n$smoothes the transition, improving solution convergence properties.\nIDENTITY&gt; dmptlur\nEQ&gt; dmptlur=\n1/(1+EXP(25*(lur-lurtrsh)))\n\n$-----------------------------------------------\n$Financial Sector\n$Monetary policy indicator for inflation threshold\n$DMPTPI equals zero when expected inflation is below its threshold\n$and one when it is above. A logistic function smoothes the\n$transition, improving solution convergence properties.\nIDENTITY&gt; dmptpi\nEQ&gt; dmptpi=\n1/(1+EXP(-25*(zpic58-pitrsh)))"
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html#dynamic-simulation-in-a-monetary-policy-shock",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html#dynamic-simulation-in-a-monetary-policy-shock",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "Dynamic simulation in a monetary policy shock",
    "text": "Dynamic simulation in a monetary policy shock\nThe first econometric exercise proposed by the Federal Reserve is a dynamic simulation of the FRB/US model under a monetary policy shock. The simulation is operated from 2040-Q1 to 2045-Q4, after the rffintay time series, defined as “Value of eff. federal funds rate given by the inertial Taylor rule”, is shocked by 100 base points in 2040-Q1.\n\n# Load data\ndata(LONGBASE)\n\n# Load model\ndata(FRB__MODEL)\nmodel &lt;- LOAD_MODEL(modelText = FRB__MODEL)\n\nAnalyzing behaviorals...\nAnalyzing identities...\nOptimizing...\nLoaded model \"FRB__MODEL\":\n    0 behaviorals\n  284 identities\n    0 coefficients\n...LOAD MODEL OK\n\n# Load data into model\nmodel &lt;- LOAD_MODEL_DATA(model, LONGBASE, quietly=TRUE)\n\n# Specify dates\nstart &lt;- c(2040,1)\nend &lt;- normalizeYP(start+c(0,23),4)\n\n# Standard configuration, use surplus ratio targeting\nmodel$modelData$dfpdbt[[start,end]] &lt;- 0\nmodel$modelData$dfpsrp[[start,end]] &lt;- 1\n\n# Solve to baseline with adds\nmodel &lt;- SIMULATE(model,\n                  simType='RESCHECK',\n                  TSRANGE=c(start,end),\n                  ZeroErrorAC = TRUE,\n                  quietly=TRUE)\n\n# 100 bp monetary policy shock\ntrac &lt;- model$ConstantAdjustmentRESCHECK\ntrac$rffintay[[start]] &lt;- trac$rffintay[[start]]+1\n\n# Solve\nmodel &lt;- SIMULATE(model,\n                  simAlgo = 'NEWTON',\n                  TSRANGE = c(start,end),\n                  ConstantAdjustment = trac,\n                  BackFill = 12,\n                  quietly=TRUE)\n\nR code produces the following charts:\n\nOn the other hand, the python code provided by the US Federal Reserve produces very similar results:"
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html#stochastic-simulation",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html#stochastic-simulation",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "Stochastic simulation",
    "text": "Stochastic simulation\nAnother econometric exercise proposed by the Federal Reserve is a stochastic simulation of the FRB/US model. The stochsim procedure in the pyfrbus python package (available on the Federal Reserve web site) performs a stochastic simulation by applying sequences of shocks to 64 endogneous variables of the model, as drawn randomly from historical residuals. In a similar way in R, the STOCHSIMULATE procedure allows users to shock the same endogenous variables with randomly sampled historical residuals.\nR code, omitted for brevity, produces the following charts:\n\nOn the other hand, the python code provided by the US Federal Reserve produces very similar results, despite the random numbers generator being different between R and python:"
  },
  {
    "objectID": "posts/us-federal-reserve-quarterly-model-in-r/index.html#section",
    "href": "posts/us-federal-reserve-quarterly-model-in-r/index.html#section",
    "title": "The U.S. Federal Reserve quarterly model in R",
    "section": "________________",
    "text": "________________\nAdditional exercises, e.g., rational expectations, endogenous targeting, etc., and computational details are available in the package vignette The U.S. Federal Reserve quarterly model in R with bimets"
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "",
    "text": "Guest Post contributed by Joe Zhu, Leena Khatri, Emily de la Rua, Edoardo Mancini, Kangjie Zhang, Daphne Grasselly"
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#introduction",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#introduction",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Introduction",
    "text": "Introduction\nIn the dynamic world of clinical research, innovation and collaboration are key drivers of success. The NEST and admiral teams exemplify this through their groundbreaking partnership. By leveraging open-source tools and fostering a community-driven approach, they have significantly advanced data integration and reporting methodologies in the clinical research setting. This story celebrates their journey and achievements."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#the-nest-team",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#the-nest-team",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "The NEST Team",
    "text": "The NEST Team\nThe NEST team, an acronym for Next-Generation Exploratory and Standardized Tools, has pioneered a collection of open-sourced R packages designed to expedite insight generation under clinical research settings. Originating at Roche, NEST has attracted a diverse array of collaborators from academia, the pharmaceutical industry, and clinical research institutes, largely due to efforts like pharmaverse. Their mission is to accelerate clinical reporting and welcome contributions from the broader scientific community."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#the-admiral-team",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#the-admiral-team",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "The Admiral Team",
    "text": "The Admiral Team\nFocused on a complementary goal, the admiral team is dedicated to providing an open-source, modularized toolbox for creating ADaM datasets in R. Their approach is transparent and collaborative, empowering users to co-create and refine a harmonized methodology for ADaM development across the pharmaceutical industry. The admiral team designs their tools to be user-friendly and versatile, capable of addressing a wide range of data requirements."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#setting-the-stage-for-collaboration",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#setting-the-stage-for-collaboration",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Setting the Stage for Collaboration",
    "text": "Setting the Stage for Collaboration\nRecognizing the potential for synergies, the NEST and Admiral teams embarked on a collaborative journey to enhance their respective toolsets.\nTheir shared objectives included:\n\nDeveloping a robust toolbox of reusable functions and utilities for ADaM dataset creation and Tables/Listings/Graphs creation.\nEnsuring comprehensive documentation and testing of these functions.\nCreating detailed vignettes to guide users in generating and manipulating various datasets, and for subsequent tabulation.\nEncouraging contributions from the pharmaceutical community to foster a unified and robust development environment."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#overcoming-initial-challenges",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#overcoming-initial-challenges",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Overcoming Initial Challenges",
    "text": "Overcoming Initial Challenges\nInitially, the NEST team relied on simulated data for integration testing, which often lacked realism and failed to cover corner cases or expose software limitations. The opportunity arose to address these challenges by switching to using the more realistic test data offered by the {pharmaverseadam} package, whose original source is real SDTM data published through the CDISC Test Data pilot. This pivot allowed the NEST team to achieve more realistic and comprehensive testing, thus enhancing the robustness of their development work, and the {pharmaverseadam}/{admiral} team to improve the quality of their templates and test data through the constructive feedback that was received during the implementation phase."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#key-milestones-achieved",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#key-milestones-achieved",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Key Milestones Achieved:",
    "text": "Key Milestones Achieved:\nRealistic Data Integration: Transitioning from simulated to more realistic data provided the NEST team with more accurate and relevant testing conditions. This change was crucial in identifying and rectifying potential software limitations.\nScope and Dependency Management: Both teams agreed to avoid creating strong interdependencies that could extend release cycles. NEST packages maintained minimal data for documentation purposes, while admiral preserved extensive datasets separately.\nCI Integration and Automation: New CI integration tests ensured that template updates were automatically verified against stored pharmaverseadam datasets. This maintained consistency and allowed users to identify intended changes promptly.\nStrategic Pipelines: An automated pipeline was established to update pharmaverseadam ADaMs for each new release, reflecting any template changes Accurately."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#recent-developments",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#recent-developments",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Recent Developments",
    "text": "Recent Developments\nThe collaboration bore fruit as the teams uncovered critical insights and improvements:\nUsing pharmaverseadam data in the scda.test package helped the NEST team identify and correct issues in their table template development, specifically in calculating denominator values.\nThe realistic test data also revealed minor inconsistencies in the derivation of ECG data within the admiral framework, which were promptly addressed, enhancing data accuracy."
  },
  {
    "objectID": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#conclusion",
    "href": "posts/clinical-reporting-roches-nest-and-admiral-teams/index.html#conclusion",
    "title": "A Clinical Reporting Collaborative Triumph: Roche’s NEST and Admiral Teams",
    "section": "Conclusion",
    "text": "Conclusion\nThe collaboration between the NEST and admiral teams showcases the power of open-source initiatives and community-driven efforts such as the pharmaverse in advancing clinical research. By integrating realistic data and refining their testing processes, they have significantly enhanced the robustness and reliability of their tools. This partnership not only accelerates insight generation but also cultivates a culture of collaboration and innovation, benefiting the broader pharmaverse community.\nThe success of this collaboration highlights the profound impact of shared goals and collective innovation, paving the way for future advancements in clinical research methodologies and outcomes.\n\nAcknowledgement\nWe would like to thank Ben Straub, Jeff Dickinson, Stefan Bundfuss, Ross Farrugia, Zelos Zhu’s valuable contributions to this collaborative work."
  },
  {
    "objectID": "posts/ics-funded-grant-secure-tls-connections-in-{nanotext}-and-{mirai}-facilitating-high-performance-computing-in-the-life-sciences/index.html",
    "href": "posts/ics-funded-grant-secure-tls-connections-in-{nanotext}-and-{mirai}-facilitating-high-performance-computing-in-the-life-sciences/index.html",
    "title": "ISC-funded Grant: Secure TLS Connections in {nanonext} and {mirai} Facilitating High-Performance Computing in the Life Sciences",
    "section": "",
    "text": "Contributed by Charlie Gao, Director at Hibiki AI Limited\n\n\n\n{nanonext} is an R binding to the state of the art C messaging library NNG (Nanomsg Next Generation), created as a successor to ZeroMQ. It was originally developed as a fast and reliable messaging interface for use in machine learning pipelines. With implementations readily available in languages including C++, Go, Python, and Rust, it allowed individual modules to be written in the most appropriate language and for them to be piped together in a single workflow.\n{mirai} is a package that enables asynchronous evaluation in R, built on top of {nanonext}. It was initially created purely as a demonstration of the reliable RPC (remote procedure call) protocol from {nanonext}. However, open-sourcing this project greatly facilitated its discovery and dissemination, eventually leading to a long-term, cross-industry collaboration with Will Landau, a statistician in the life sciences industry, author of the {targets} package for reproducible pipelines. He ended up creating the {crew} package to extend {mirai} to handle the increasingly complex and demanding high-performance computing needs faced by his users.\nAs this work was progressing, security was still a missing piece of the puzzle. The NNG library supported integration with Mbed TLS (a SSL/TLS library developed under the Trusted Firmware Project), however secure connections were not yet a part of the R landscape.\nThe R Consortium, by way of an Infrastructure Steering Committee (ISC) grant, funded the work to implement this functionality from the underlying libraries and to also devise a means of configuring the required certificates in R. The stated intention was to provide a user-friendly interface for doing so. The end result somewhat exceeded these goals, with the default allowing for zero-configuration, single-use certificates to be generated on-the-fly. This affords an unparalleled level of usability, not requiring end users to have any knowledge of the intricacies of TLS.\nWill Landau talks about the impact TLS has had on his work:\n“I sought to extend {mirai} to a wide variety of computing environments through {crew}, from traditional clusters to Amazon Web Services. The integration of TLS into {nanonext} increases the confidence with which {mirai} can be deployed in these powerful environments, accelerating downstream applications and {targets} pipelines.”\nThe project to extend {mirai} to high-performance computing environments was featured in a workshop on simulation workflows in the life sciences, given at R/Pharma in October 2023 (video and materials accessible from https://github.com/wlandau/rpharma2023).\nWith the seed planted in {nanonext}, {mirai} and {crew} have grown to form an elegant and performant foundation for an emerging landscape of asynchronous and parallel programming tools. They already provide new back-ends for {parallel}, {promises}, {plumber}, {targets}, and Shiny, as well as high-level interfaces such as {crew.cluster} for traditional clusters and {crew.aws.batch} for the cloud.\n\n\n\nCharlie Gao, Director at Hibiki AI Limited"
  },
  {
    "objectID": "posts/transforming-academic-research-with-r-in-santa-rosa-argentina/index.html",
    "href": "posts/transforming-academic-research-with-r-in-santa-rosa-argentina/index.html",
    "title": "Transforming Academic Research with R in Santa Rosa, Argentina",
    "section": "",
    "text": "Marina Cock, co-organizer of R-Ladies Santa Rosa, recently spoke with the R Consortium about the growth of the R community in La Pampa and the transformative role of R in local academic research. Marina shared insights into the community’s activities, including introducing students to R, organizing meetups, and encouraging advanced statistical techniques like generalized linear mixed models. She also highlighted the challenges of promoting R in her university setting and her efforts to foster a supportive environment for learning and collaboration."
  },
  {
    "objectID": "posts/transforming-academic-research-with-r-in-santa-rosa-argentina/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/transforming-academic-research-with-r-in-santa-rosa-argentina/index.html#how-do-i-build-an-r-user-group",
    "title": "Transforming Academic Research with R in Santa Rosa, Argentina",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute\nhttps://r-consortium.org/all-projects/rugsprogram.htm"
  },
  {
    "objectID": "posts/webinar-r-databases-oracle-machine-learning-ml-massive-datasets/index.html",
    "href": "posts/webinar-r-databases-oracle-machine-learning-ml-massive-datasets/index.html",
    "title": "Webinar for R and Databases! How Oracle Machine Learning for R Helps with ML and Massive Datasets",
    "section": "",
    "text": "Are you seeking faster R data processing and enhanced machine learning capabilities for massive datasets in databases? Look no further. Full archive of the webinar is available to help you discover how Oracle Machine Learning for R (OML4R) can transform your data analysis and machine learning endeavors.\nWebinar Highlights:\nWe’ll also demonstrate real-world applications, including product bundling, demand forecasting, and customer churn prediction, showcasing OML4R’s potential to revolutionize your R workflows.\nDon’t Miss Out!\nElevate your data science skills and streamline your processes. The webinar recording is available to help you unlock the full potential of in-database analytics with OML4R. Take your R to the next level."
  },
  {
    "objectID": "posts/webinar-r-databases-oracle-machine-learning-ml-massive-datasets/index.html#full-webinar-available-here",
    "href": "posts/webinar-r-databases-oracle-machine-learning-ml-massive-datasets/index.html#full-webinar-available-here",
    "title": "Webinar for R and Databases! How Oracle Machine Learning for R Helps with ML and Massive Datasets",
    "section": "Full Webinar available here",
    "text": "Full Webinar available here\nGo to the webinar archive now and transform your approach to data analysis with Oracle Machine Learning for R."
  },
  {
    "objectID": "posts/improving-with-r-kylie-bemis-unveils-enhanced-signal-processing-with-matter-2-4-upgrade/index.html",
    "href": "posts/improving-with-r-kylie-bemis-unveils-enhanced-signal-processing-with-matter-2-4-upgrade/index.html",
    "title": "Improving with R: Kylie Bemis Unveils Enhanced Signal Processing with Matter 2.4 Upgrade",
    "section": "",
    "text": "The R Consortium recently connected with Kylie Bemis, assistant teaching professor at the Khoury College of Computer Sciences at Northeastern University. She has a keen interest in statistical computing frameworks and techniques for analyzing intricate data, particularly focusing on datasets with complex correlation patterns or those that amalgamate data from various origins.\nKylie created matter, an R package that offers adaptable data structures suitable for in-memory computing on both dense and sparse arrays, incorporating multiple features tailored for processing nonuniform signals, including mass spectra and various other types of spectral data. Recently, Kylie upgraded matter to version 2.4. Since our May 2023 discussion, Kylie has enhanced its signal processing capabilities, focusing on analytical tools like principal component analysis and dimension reduction algorithms, which are crucial for imaging and spectral data. A grant from the R Consortium supports this project.\nWe talked with you about matter in May 2023. You were providing support for matter and looking to improve the handling of larger data sets and sparse non-uniform signals. matter has been updated to version 2.4. What’s new?\nLast time we spoke, I had already rewritten most of the matter infrastructure in C++ for better maintainability. Since then, my focus has been on enhancing our signal processing capabilities. This summer, I’ve been adding essential signal processing functions and basic analytical tools, which are particularly useful in fields dealing with spectra or various types of signals.\nI’ve incorporated fundamental techniques like principal component analysis, non-negative matrix factorization, and partial least squares. I’ve also added several dimension reduction algorithms and a range of signal processing tools for both 1D and 2D signals. This includes smoothing algorithms for images and 1D signals and warping tools applicable to both.\nThese enhancements are crucial for working with imaging and spectral data and include features like distance calculation and nearest neighbor search.\nMy aim has been to augment matter with robust signal processing tools, particularly for sparse and non-uniform signals. This is inspired by my experience in augmented reality (AR) and my desire to integrate tools similar to MATLAB’s Signal Processing Toolbox or SciPy in Python. As someone primarily analyzing mass spectrometry imaging data, I found these tools initially in my Cardinal package. I wanted to transfer them to a more appropriate platform, not specific to mass imaging, and reduce Cardinal’s reliance on compiled native code for easier version updates.\nAdditionally, I’ve been building a more robust testing infrastructure for these tools and documenting them thoroughly, including citations for the algorithms I used for key picking and smoothing techniques. This documentation details the implementation of various algorithms, such as guided filtering and nonlinear diffusion smoothing, citing the sources of these algorithms.\nBy providing support for non-uniform signal data, matter provides a back end to mass spectrometry imaging data. But working with large files is applicable in a lot of domains. What are some examples?\nI deal with large files and data sets across various fields. Matter can be particularly impactful in areas dealing with signal, spectral, or imaging data. One field that comes to mind is remote sensing, where the imaging tools I’ve incorporated would be highly beneficial. That’s one key application area.\nAnother field is biomedical imaging, especially MRI data. For instance, a data format we often use for mass spectrometry imaging was originally developed for MRI – it’s called Analyze, and there’s a more recent variant known as NIfTI. This format is also supported in Cardinal for mass spec imaging data, but it’s primarily used in MRI and fMRI data analysis. While matter doesn’t directly offer plug-and-play functionality for MRI data, with some modifications, it could certainly be adapted for importing and processing MRI data stored in these formats.\nWe don’t have a specific function to read NIfTI files directly, but the structure of these files is quite similar to the mass imaging files we commonly work with. They consist of a binary file organized in a particular format, with a header that functions like a C or C++ struct, indicating where different image slices are stored. Understanding and interpreting this header, which is well-documented elsewhere, is key.\nSo, with some effort to read and attach the header file correctly, it’s entirely feasible to build a function for reading and importing MRI data. We’ve already done something similar with the Analyze format. Someone could definitely examine our approach and develop a method to handle MRI data effectively.\nPreviously, you indicated you wanted to improve R data frames and string support. You have a prototype data frame in the package already? What’s the schedule for improvements?\nI’m currently evaluating how far we’ll expand certain features in our project. One of these features is supporting strings, which is already implemented. Regarding data frames, I believe there might be better solutions out there, but it’s quite simple to integrate our data with them. For instance, taking a vector or an array, whether a matter matrix or a matter vector, and inserting it into a data frame column works well, particularly with Bioconductor data frames.\nI’m not entirely convinced that developing standalone, specialized data frame support in matter is necessary. It seems that other platforms, especially those like Bioconductor, are already making significant advancements in this area. For now, it seems sufficient that users can easily incorporate a matter vector or array into a data frame column. I’m hesitant to duplicate efforts or create overlapping functionalities with what’s already being done in this field.\nWhat’s the best way for someone to try matter? How should someone get started?\nLike any Bioconductor package, we offer a vignette on the Bioconductor website. This vignette provides a basic guide on how to start using our package, including creating matrices and arrays. It shows how these can serve as building blocks to construct larger matrices, arrays, and vectors. This is a straightforward way for users to begin.\nRegarding the applicability of our package, it really depends on the specific data needs of the user. For instance, our package provides out-of-memory matrices and arrays. If that’s the primary requirement, then our package is certainly suitable. However, there are other packages, both in Bioconductor, like HDF5 array support, and on CRAN, such as big memory and FF, that also offer similar functionalities.\nThe real advantage of our package becomes apparent when dealing with specific data types. If you’re working with data formats like MRI, where you have a binary file and a clear understanding of its format, our package can be very helpful. It simplifies attaching different parts of the file to an R data structure.\nMoreover, if your work involves signal data, particularly non-uniform signals like those in mass spectrometry or imaging data, our package becomes even more beneficial. Over the summer, I’ve added extensive support for preprocessing, dimension reduction, and other processes that are crucial for handling these types of data. So, in these scenarios, our package can be a valuable tool.\nAnything else you would like to share about matter 2.0?\nI’ve spent much of the summer working on improvements to the matter package, and it’s now in a good place, particularly regarding signal processing capabilities. These enhancements are largely aligned with the needs of mass spectrometry, an area I closely focus on. As new requirements emerge in mass spectrometry, I’ll look to add relevant features to matter, particularly in signal and image processing.\nHowever, my current priority is updating the Cardinal package to support all these recent changes in matter. Ensuring that Cardinal is fully compatible with the new functionalities in matter is my next major goal, and I’m eager to get started on this as soon as possible."
  },
  {
    "objectID": "posts/improving-with-r-kylie-bemis-unveils-enhanced-signal-processing-with-matter-2-4-upgrade/index.html#how-do-i-join",
    "href": "posts/improving-with-r-kylie-bemis-unveils-enhanced-signal-processing-with-matter-2-4-upgrade/index.html#how-do-i-join",
    "title": "Improving with R: Kylie Bemis Unveils Enhanced Signal Processing with Matter 2.4 Upgrade",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 65,000 members in 35 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/moffitt-cancer-center-bio-data-clubs-new-chapter-in-spatial-data-analysis/index.html",
    "href": "posts/moffitt-cancer-center-bio-data-clubs-new-chapter-in-spatial-data-analysis/index.html",
    "title": "Moffitt Cancer Center Bio-Data Club’s New Chapter in Spatial Data Analysis and Enhanced Hackathon Collaboration",
    "section": "",
    "text": "The R Consortium recently reconnected with Paul Stewart, founder of Moffitt Cancer Center Bio-Data Club in Tampa, Florida. Since the last update on January 6th, 2023, the Moffitt Cancer Center Bio-Data Club has hosted special guest Dr. Josh Starmer of StatQuest, and it has welcomed new co-organizers Rodrigo Carvajal, Nathan Van Bibber and Dr. Alex Soupir. The club has maintained its momentum with monthly meetings that have featured enriching discussions, educational talks, and practical tutorials.\nOne big change they have made this year is revamping their annual hackathon to broaden its scope and encourage greater participation from external academic institutions and industry partners. This expansion aims to enrich the event with diverse perspectives and innovative ideas, marking a significant step forward for the club and its contributions to bioinformatics and cancer research.\nWhat is new with Moffitt Cancer Center Bio-Data Club since last we spoke on Jan 6th, 2023?\nSomething new is that we hosted sessions on spatial data analysis. Our work at Moffitt often involves big molecular data, delving into patients’ tumor samples or blood to uncover insights about genes, proteins, and metabolites. This exploration aims to unravel the intricacies of cancer, paving the way for new treatments or early detection methods. Traditionally, we analyze patient tumors in bulk, meaning the entire sample is processed at once, and molecules of interest are extracted and profiled. However, the resulting data are just numbers in a matrix, and we lack the ability to define what part of the tumor the numbers are coming from. New spatial technologies have recently revolutionized our understanding of cancer and other diseases. We can now spatially resolve where genes, proteins, and metabolites come from in the tumor and neighboring cells. This advancement adds a crucial spatial dimension to our research, necessitating novel methods for data processing, quality control, and interpretation. Not to mention, these approaches generate some cool pictures. For example, here is an image from a spatial assay run at Moffitt for a project that I lead (funded by the Cancer Research Institute):\nI also want to touch on our hackathon. We’ve decided to broaden its scope this year, extending an open invitation to foster greater participation. Previously, attendance was mainly limited to the Bio-Data Club Meetup and our immediate connections at Moffitt. This year, we’re reaching out more actively to other academic institutions like the University of South Florida and industry partners. We are hoping to increase participation beyond last year’s 50 participants, and we are hoping to enrich the event with diverse perspectives and innovative ideas.\nPlease share about your background and your involvement in the R Community. What is your level of experience with the R language?\nI helped initiate the Bio-Data Club at Moffitt back in 2018. It began as an internal group but soon gained interest from beyond Moffitt, leading us to secure funding from the R Consortium. Since then, I’ve been dedicated to leading the club. In addition to this, I mentor trainees at Moffitt, including Moffitt research staff and students from the University of South Florida.\nI’m actively engaged in the local data science community; I’ve delivered lectures at the Tampa Bay R Users Group, the Tampa Bay Data Science Meetup, and, notably, at the 2023 D4CON Data Science Conference in Tampa, organized by Lander Analytics. (Editor’s note: Lander Analytics is an R Consortium member.) While my talks aren’t exclusively about the R programming language, they are intended to cater to the Tampa data science community.\nMy experience with R spans over a decade. As a Moffitt Cancer Center faculty member, I extensively leverage R in my research. I’d classify my proficiency as advanced, though I wouldn’t label myself an expert because I still learn new things about this great language daily.\nWhy do industry professionals come to your user group? What is the benefit of attending?\nBeing a part of Moffitt, located on the University of South Florida campus, our focus naturally gravitates toward biomedical academic research, and showcasing how data science operates within an academic research setting is beneficial. It offers a unique perspective and exposes attendees to cutting-edge techniques, like spatial omics analyses, which might not be part of the typical workload in a standard 9-to-5 job. However, our meetings must cater to a broad audience. Our meeting topics are applicable across many interests, one of which comes to mind was a presentation and demo by ComplexHeatmap author Dr. Zuguang Gu. We’re committed to broadening our discussions and introducing various topics and libraries relevant to R users and the broader data science community. My aim is to ensure that our meetings are inclusive, informative, and beneficial for everyone involved, irrespective of their field of work.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nThe realm of spatial omics and spatial data analysis, especially in the context of big biological data like genomics, proteomics, and metabolomics, is rapidly evolving. It’s fascinating to see the development of numerous packages, including spatialGE and scSpatialSIM, which are pioneered right here at Moffitt. These tools are a game-changer because they allow individuals who aren’t necessarily experts in imaging or spatial data analysis to engage in and benefit from this research.\nAs a bioinformatics or biological data science researcher, my research focuses on mass spectrometry data, which involves comprehensive profiling of proteins, metabolites, and lipids in tumors or blood. This is a fairly specialized field, yet even here, there’s the Cardinal R package tailored for spatial analyses. This progress is exciting and indicative of a significant trend in our field. This trajectory is not just a fleeting moment but a substantial shift that will persist and evolve, shaping the future of bioinformatics.\nPlease share any additional details you would like included in the blog.\nIf you have a neat package or tool you would like to showcase, and please feel free to reach out at paul.stewart@moffitt.org. This is a great way for trainees or junior data scientists to get a presentation on their CV.\nMoffitt is consistently looking for talent on the academic research side and the operational side. For anyone who is interested, I’d recommend visiting the Moffitt website.\nI’m also excited to share that I’ll be presenting again at this year’s D4 conference in Tampa, scheduled for June 5th and 6th and hosted by Lander Analytics. Additionally, I want to shout out to the Tampa Bay Data Science Meetup and the Tampa Bay Data Engineering Meetup.\nOur annual hackathon is set for December 12th and 13th, 2024. Details about the hackathon are forthcoming, but for those eager to stay informed, the best approach is to join our Bio-Data Club Meetup. We consistently post all the relevant updates there, ensuring you’re well-informed and prepared for the event. Mark your calendars for December 12th and 13th – it’s shaping to be an enriching and exciting experience!"
  },
  {
    "objectID": "posts/moffitt-cancer-center-bio-data-clubs-new-chapter-in-spatial-data-analysis/index.html#how-do-i-join",
    "href": "posts/moffitt-cancer-center-bio-data-clubs-new-chapter-in-spatial-data-analysis/index.html#how-do-i-join",
    "title": "Moffitt Cancer Center Bio-Data Club’s New Chapter in Spatial Data Analysis and Enhanced Hackathon Collaboration",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/r-en-buenos-aires-new-generations-working-to-strengthen-the-community/index.html",
    "href": "posts/r-en-buenos-aires-new-generations-working-to-strengthen-the-community/index.html",
    "title": "R en Buenos Aires: New Generations Working to Strengthen the Community",
    "section": "",
    "text": "R en Buenos Aires: New Generations Working to Strengthen the Community\n \n\n\n\n\n\n\nThe R Consortium recently interviewed Andrea Gomez Vargas to find out about the R in Buenos Aires User Group. Andrea has a degree in sociology. Currently, she works as an analyst of population statistics at the National Institute of Statistics and Census - INDEC Argentina. She also teaches at universities in social science and data science.\nAndrea has been an active member of the R community in Argentina and Latin America since 2018. She has been part of R-Ladies Buenos Aires and is currently part of the R-Ladies global team and the LatinR organizing committee.\n\n\nAndrea was part of the 2023-2024 cohort of the rOpenSci champions program, and in 2024 she decided to take over the leadership of R en Buenos Aires.\n\nWhy did you decide to take the lead of the chapter?\n\n\n I decided to take on the leadership of the chapter to actively contribute to the local impact of the R user community. Most of my knowledge has come from these communities - the trust and selfless support I’ve received has helped me grow as a professional and inspired me to take on projects I never thought I could. For this reason, I believe it is essential to reengage in activities to invite new generations to participate, explore new tools and opportunities, and collaborate in a space that welcomes all levels of experience and diverse professional backgrounds.\n\n\n\n\n\n\nWhat motivates you to continue promoting R learning?\nCommunities are essential spaces for breaking down barriers to access information and knowledge, especially when it comes to free and open-source software. When these resources are paid or only reach a small percentage of people, it creates inequities. As a public university teacher, I am driven by the belief that everyone, regardless of background, should have the opportunity to learn and grow in a collaborative, open environment. That’s what keeps me motivated to continue spreading R knowledge and ensuring it remains accessible for all.\n Participants from the December 20th, 2024, meetup\n\n\nWhat are your main objectives for the R chapter in Buenos Aires, and what challenges do you anticipate in achieving them?\nThe main objectives at this moment for the R chapter in Buenos Aires are to have more events to disseminate relevant topics in the community, such as the use of Quarto, Shiny, R packages, Git, and GitHub. A key challenge is ensuring that volunteer work doesn’t overwhelm us or lead to burnout, as organizing these events requires a lot of behind-the-scenes work. Currently, in addition to myself, Emanuel and Ariana are part of the local team coordinating activities—and although teamwork is essential, we must find a balance between collective effort and the well-being of the chapter members.\n\n\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\n\n\n  I’m working on the development of the arcenso package, a package with census data from Argentina, now in its first version on Github, but we are looking to reach CRAN.\narcenso is a project supported by the rOpenSci Champions Program cohort 2023-2024, with me as lead developer, Emanuel Ciardullo as co-developer and Luis D. Verde as mentor. It is a very important project because it makes census data accessible and homogenized in a way that any user can work with it in R.\n\n  \n\n\nDetails from the arcenso page:\narcenso is a package under development that will allow access to the official data of the national population censuses in Argentina from the National Institute of Statistics and Census - INDEC. Currently, the results of the historical censuses of 1970, 1980, 1991, 2001, 2010 and 2022 are available in different formats through physical books, PDFs, Excel files or in REDATAM, without having a unified system or format that allows working with the data of these six census periods as a database. In addition, the presentation of the data is not homogeneous between the periods, making it difficult to make historical or serial comparisons of the available information.\nThis package aims to make census data available, homogenized and ready to use. It will include the census data from 1970 to 2022. Having a package of census information will allow the public and private sectors, citizens and other actors in society to access current and historical information on Argentina’s population, households and housing in a more accessible way.\n\nFor more information, see soyandrea.github.io/arcenso\n\n\n\nWhat R resources/techniques do/did you use? (Posit (RStudio), Github, Tidyverse, etc.)\nI use R on a daily basis to teach, work and collaborate in the community. Part of my work requires processing and combining various data sources (censuses, surveys and administrative records) to produce socio-demographic indicators for the country. I also design and develop digital statistical products, such as a Shiny app or dashboards. For all this I rely on several R packages for ETL and visualisation (gt, tidyverse, expss, plotly, quarto, and many more). And this is what I try to teach my students or the people who attend the workshops.\n Photo of Betsy, Ariana, and Andrea, organizers of the October 29, 2024, meetup, from left to right\n\n\nYou had a Meetup on October 29th, 2024. Can you share more about the topic covered?\n[Editor’s note: There were two more events held by R en Buenos Aires at the end of 2024. Please see the meetup page for more information (in Spanish).]\nThe topic of the workshop was socio-demographic analysis in R using data from the Argentine Labour Force Survey. We learned about the R packages needed to calculate the indicators and how to present the results in graphs and tables.\n\nThe workshop was aimed at university students who are taking their first steps in R and who would like to do real-life practice guided by people from the community with experience in the field.\nAfter the workshop a specific website r-unlam.netlify.app was created. We believe it is a good practice for people who cannot attend physically to have access to all the materials and to have the activities documented.\n Participants from the October 29th, 2024, meetup\n\n\nYou can reach out to R in Buenos Aires through the following:\n\nLinkedin: https://www.linkedin.com/company/r-en-buenos-aires/\nGithub: https://github.com/renbaires\nX: https://x.com/renbaires\n\nInstagram: https://www.instagram.com/renbuenosaires\n\n\n\nHow do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/unlocking-the-power-of-r-for-insurance-and-actuarial/index.html",
    "href": "posts/unlocking-the-power-of-r-for-insurance-and-actuarial/index.html",
    "title": "Unlocking the Power of R for Insurance and Actuarial Science: Webinar Series Recap",
    "section": "",
    "text": "The R Consortium recently hosted a webinar series tailored specifically for insurance and actuarial science professionals. This series, called the R/Insurance webinar series, led by experts Georgios Bakoloukas and Benedikt Schamberger, was crafted to guide attendees from transitioning from Excel to R to implementing R in production environments, fostering a performance culture with R, and mastering high-performance programming techniques. \nWhether new to R or looking to deepen your expertise, these webinars offer valuable insights into leveraging R’s capabilities in your field. All sessions are now accessible on YouTube, providing a fantastic resource for ongoing learning and development. \nFor further details and to watch the webinars, visit the R Consortium’s website."
  },
  {
    "objectID": "posts/the-evolution-of-melbournes-business-analytics-and-r-business-user-group/index.html",
    "href": "posts/the-evolution-of-melbournes-business-analytics-and-r-business-user-group/index.html",
    "title": "The Evolution of Melbourne’s Business Analytics and R Business User Group",
    "section": "",
    "text": "Maria Prokofieva, organizer of the Business Analytics and R Business User Group, spoke to the R Consortium last year about the Adoption of R by the Actuaries Community in Melbourne. Recently, Maria updated the R Consortium on the group’s focus, which has shifted towards business consultancy. The group provides a platform for graduate students to gain valuable industry experience and mentorship through various projects. The group is committed to ethical data governance and inclusive community building and prioritizes these values in all its initiatives.\nPlease share about your background and your involvement in the R Community.\nMy name is Maria Prokofieva. I work as a Leading ML Engineer at Mitchell Institute at Victoria University. I lead a stack of projects that use data to inform strategy and policy development. I am also an academic at the university, conducting research and teaching courses on ML/AI and data analysis. Through my work, I have the privilege of collaborating with various organizations, governments, and scholars to assist them in utilizing data to make decisions that impact the lives of many. I love open source, and what we see today is amazing – the world is changing. I have been a member of R and Python communities for many years, and seeing us grow is great.\nHow has your R User Group been doing since the last time we spoke?\nThe group has been performing well. As we grow, we focus on projects and become extremely busy with them. We already have a small community of people involved in different projects who also work together and communicate regularly. Once a month, we organize meetups where we present master classes—we moved to an in-person space but occasionally do online events. Our group has two main directions: business consultancy and business knowledge exchange.\nWe have been quite successful in building connections with bigger and smaller businesses interested in doing more data analysis. Some smaller businesses have staff who can perform their duties, and this is where community members have been fantastic.\nThe backbone of my community comprises my current and former Master’s students, who completed a course on business analytics. They are passionate about using R in everyday tasks and already possess some knowledge and experience, which they are happy to share. They are also interested in building connections and networking for their future jobs. This platform provides a mutually beneficial relationship for new students who get valuable industry experience through unpaid volunteering. These students receive mentorship from business leaders and senior software developers who share their programming knowledge and their knowledge of business negotiations and working with clients through the entire project life cycle.\nWe have been successful in working with cloud services such as AWS. We are actively exploring ways to automate data science on AWS and have several upcoming workshops where we will dive deeper into this topic. One workshop will focus on AWS Bedrock, where we will introduce non-technical business community members to employing large language models to perform their tasks. Our workshops focus on addressing specific problem-solving tasks rather than just the environment. We look into the business problems and how they can be solved.\nIt’s better to identify a problem and brainstorm solutions than to focus on tools. It’s fascinating to see how the community comes up with unique solutions to the problem. This approach is exactly what we need today, where no single preferred tool exists. Even if we use R Studio, we can easily integrate Python and other environments to accomplish the task. The focus should always be on the task guiding the process rather than the tools themselves.\nAny recent project you have worked on using R?\nOur recent project is based on utilising AWS Bedrock and GPT-4 to implement a Retrieval-Augmented Generation (RAG) system for a business. This system streamlines customer email communication using internal documents and company FAQs to auto-generate tailored responses. With some components there, we successfully integrated data analysis in R with Python implementation. We also have a few projects using open source models and integrating transformer models from Hugging Face. R is a star for any data-wrangling tasks and data visualizations!\nWhat are your plans for the upcoming months?\nOne area of interest that we plan to focus on is the use of responsible AI and responsible practices. This is crucial not only for AI but also for any data management that we undertake. Responsible modeling and responsible data science are important concepts that need more attention. We have seen instances where people intentionally or accidentally manipulate statistics, and this needs to change. We must focus on being data governors and ensure our analysis is responsible. This includes managing the data and the application size, as well as ensuring continuity of work. Many packages are available, but maintaining and updating them is challenging. Our future work is to contribute to the community by ensuring the continuity of our packages so developers can rely on them.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nMany people talk about large language models, but the focus is often on their applicability and use cases. While many amazing models are available, businesses need to see how they can be practically applied to their needs. It’s not just about text generation – image generation and other areas are also important. When we share the use cases with the businesses, the possibilities they haven’t considered often amaze them. Therefore, there is a growing demand for case studies demonstrating these models’ practical applications rather than just tutorials.\nWe focus on the practical applications of tools. Our approach is to identify a problem and explore various solutions. I’m not interested in specific software packages but in finding efficient solutions to problems. If there’s a new tool that can help me solve a problem more effectively, I’m open to learning about it and sharing my experience with others.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nThe most important technique is interaction, networking, and keeping the connection alive among the group members. This is especially crucial when you have a larger proportion of new users in the group. It’s important to ensure that once they learn the skills, they understand that we are all busy and have business obligations to attend to. Therefore, it’s necessary to make sure that we keep the group relevant to all members, without getting carried away by our busy lives.\nThis is more about sitting together and engaging in problem-solving exercises, such as preparing for AWS certification. The group can help with other tasks, too, creating additional value beyond just learning. This is where the benefits of membership come in. Members are also motivated to give back to the community, as they can use their skills in real life, not just for learning purposes.\nFor instance, we have an AWS data practitioner interested in learning R. However, this is an opportunity for that person to share their expertise and contribute to the group. Similarly, we have a cybersecurity professional who is also interested in learning R. But this is an opportunity for them to present a use case on how machine learning can automate some of their tasks. They are also willing to share their knowledge, which may not have been considered. Therefore, it’s important to create a diverse experience for all members and engage with them in all possible ways. While it can be difficult to involve every group member, it’s crucial to understand their general interests and what’s important for them and focus on their professional development.\nTake a moment to analyze where your members come from and their future plans and steps. Discuss their next career moves. It will be beneficial to provide networking opportunities where members can get referrals for job searches and advice for their next career move. These opportunities are quite important. Therefore, promotions should always be the end goal. You cannot become complacent or content with where you are because life is about growth and evolution."
  },
  {
    "objectID": "posts/the-evolution-of-melbournes-business-analytics-and-r-business-user-group/index.html#how-do-i-join",
    "href": "posts/the-evolution-of-melbournes-business-analytics-and-r-business-user-group/index.html#how-do-i-join",
    "title": "The Evolution of Melbourne’s Business Analytics and R Business User Group",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "",
    "text": "Dive into the world of validation at the first R Validation Hub community meeting of the year! What defines a validated R package? Is it ensuring reproducibility across systems? Prioritizing bug-free and well-maintained packages? We want to hear YOUR take!"
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html#join-the-community-call-microsoft-teams-meeting",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html#join-the-community-call-microsoft-teams-meeting",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "Join the community call! (Microsoft Teams meeting) ",
    "text": "Join the community call! (Microsoft Teams meeting)"
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html#meeting-details",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html#meeting-details",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "Meeting Details",
    "text": "Meeting Details\n\nWhen: February 20, 12:00 EST\nWhere: Virtual meeting"
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html#why-attend",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html#why-attend",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "Why Attend?",
    "text": "Why Attend?\nThis is your chance to share your perspective, learn from diverse viewpoints, and help shape the future of validation in the R ecosystem. Whether you’re a developer, user, or enthusiast, your insights are valuable."
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html#lets-discuss",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html#lets-discuss",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "Let’s Discuss",
    "text": "Let’s Discuss\nWhat does validation mean in the R world to you? Join us to debate, learn, and network. Mark your calendars and prepare to contribute to shaping the standards of R package validation."
  },
  {
    "objectID": "posts/unraveling-the-term-validation-join-the-discussion/index.html#join-the-call-here",
    "href": "posts/unraveling-the-term-validation-join-the-discussion/index.html#join-the-call-here",
    "title": "Unraveling the term “Validation”: Join the Discussion at the R Validation Hub Community Meeting on February 20, 2024",
    "section": "Join the call here!",
    "text": "Join the call here!"
  },
  {
    "objectID": "posts/the-2024-isc-grant-program-will-begin/index.html",
    "href": "posts/the-2024-isc-grant-program-will-begin/index.html",
    "title": "The 2024 ISC Grant Program will begin Accepting Applications Soon!",
    "section": "",
    "text": "The R Consortium is excited to announce the second cycle of the 2024 Infrastructure Steering Committee (ISC) Grants Program. The Call for Proposals will open soon. This initiative aims to support projects that strengthen the R ecosystem’s technical and social infrastructure. \nHere is a list of projects that received grants from the R Consortium in the First Cycle in 2024. \nFrom the Call for Proposals page:\nThe ISC is interested in projects that:\n\nAre likely to have a broad impact on the R community.\nHave a focused scope (a good example is the Simple Features for R project). If you have a larger project, consider breaking it up into smaller chunks (a good example of this done is with the DBI/DBItest project submission, where multiple proposals came in over time to address the various needs).\nHave a low-to-medium risk with a low-to-medium reward. The ISC tends not fund high-risk, high-reward projects.\n\nWhether you’re working on groundbreaking tools or organizing community-driven events, this is your chance to secure funding and make a significant impact on the R community!\nKey Dates:\n\nSeptember 1, 2024: Grant Application Period Opens\nOctober 1, 2024: Grant Application Period Closes\nNovember 1, 2024: Notification of Accepted Grantees\nDecember 1:  Deadline for acceptance of grant and contract. Public notification of grantees occurs shortly thereafter.\n\nSubmit your proposal by October 1, 2024, and contribute to the ongoing growth of the R ecosystem. Visit the R Consortium website for detailed guidelines and submission instructions. Don’t miss this opportunity to bring your innovative ideas to life!"
  },
  {
    "objectID": "posts/kolkata-r-user-group-a-rich-history-with-statistics/index.html",
    "href": "posts/kolkata-r-user-group-a-rich-history-with-statistics/index.html",
    "title": "Kolkata R User Group: A Rich History with Statistics",
    "section": "",
    "text": "The R Consortium recently spoke with Samrit Pramanik of the Kolkata R User Group about his experience starting a new R User Group in India. Samrit highlighted Kolkata’s rich history with statistics and talked about the diverse local R community.\nThe Kolkata R User group is organizing its second online event titled “A New Approach for Teaching Data Analytics with R” on July 13th. R users from around the world are invited to join this event.\nPlease share your background and involvement with the RUGS group.\nMy name is Samrit Pramanik. I work as a data scientist at a US-based private firm and have a post-graduate degree in statistics from the University of Calcutta. I have been using R since my post-graduate days in 2018 and used it extensively in various projects during my studies. Since 2022, I have also been an R instructor for a non-profit organization. Additionally, I have been involved in several short projects working with R. Since April 2024, I have managed the Kolkata R User group.\nThis is the third city-based R user group in India that is affiliated with the R Consortium. I plan to arrange virtual meetups monthly and in-person meetups annually. I enjoy helping and teaching people from diverse backgrounds, not only in statistics, mathematics, and data science but also in other areas. I want to teach them to use R language to add value to their professional and personal projects.\nCan you share what the R community is like in Kolkata?\nThe Kolkata User Group has been formed with a broader perspective that I would like to share with you. Kolkata is known for its reputation in statistical research and education. The city is recognized as the birthplace of modern statistics in India, with the establishment of the Indian Statistical Institute (ISI) in 1931 by a prominent figure in statistics. The University of Calcutta, where I graduated, was the first in Asia to offer a post-graduate degree in statistics in 1941. This rich history made the formation of the Kolkata R User Group inevitable. Our community consists of academics and professionals from diverse fields such as life sciences, healthcare, the public sector, physics, astrophysics, and other industries. This diverse background facilitates robust exchanges of ideas and techniques related to R and data, making our R community in Kolkata truly unique.\nPlease tell us about your recent and upcoming events?\nI would like to highlight a recent event. Last month, in June, we had our inaugural session where we introduced Quarto, a recently released reporting tool by Posit. Our goal was to make the participants aware of this tool and its outstanding features, such as website building, ebook writing, creating thesis papers, manuscripts, and blogging sites. We aimed to show participants, including early graduate students, professionals in the industry, and researchers from academia, that they can use Quarto in their projects and studies for reporting. This was our first organized session.\nThe upcoming session is scheduled for July 13th. It will focus on a new approach to teaching R to students with non-technical backgrounds such as business students. Dr. Abhimanyu Gupta from Saint Louis University will be the speaker at this event.\nWe have received very positive feedback and responses from the participants who are showing interest in the upcoming events. They want us to organize such events frequently. People are very much aware of these events and this community. They are very responsive, and we have received positive responses. Two esteemed Economics professors have expressed interest in joining our organizing team and working with us.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nCurrently, I am working on two projects. The first project involves cricket analytics, where I extensively use R for cleaning up messy raw data and conducting exploratory data analysis at both the team and individual player levels and published a shiny dashboard on performance analysis of T20I players. I’m also building a statistical model to predict the total score of an innings, the winner of the match, and the tournament. Lastly, I aim to compile all the findings into an ebook format.\nCricket Performance Analysis Shiny Dashboard\nThe second project revolves around converting the functions and features of AstroPy, an open source software package for astronomy and astrophysics, into R. Our goal is to enhance its popularity among researchers and scientists in the astronomy, astrophysics, and cosmology domains. I am collaborating with another individual from a physics background on this open source project, and we plan to publish it on GitHub soon for public access."
  },
  {
    "objectID": "posts/kolkata-r-user-group-a-rich-history-with-statistics/index.html#how-do-i-join",
    "href": "posts/kolkata-r-user-group-a-rich-history-with-statistics/index.html#how-do-i-join",
    "title": "Kolkata R User Group: A Rich History with Statistics",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/enhancing-clinical-trial-data-sharing-with-r-consortiums-r-submissions-working-group/index.html",
    "href": "posts/enhancing-clinical-trial-data-sharing-with-r-consortiums-r-submissions-working-group/index.html",
    "title": "Enhancing Clinical Trial Data Sharing with R Consortium’s R Submissions Working Group",
    "section": "",
    "text": "The R Consortium’s working group R Submissions Working Group is spearheading an innovative approach to clinical trial data sharing, according to a feature in Nature. This initiative, led by Eric Nantz, a statistician at Eli Lilly in Indianapolis, Indiana, involves a pilot project with the US Food and Drug Administration (FDA). Sharing clinical trial data traditionally requires each scientist to install custom computational dashboards, a cumbersome and error-prone process.\nNantz elaborates on the benefits of using webR and WebAssembly in this context: “Using WebAssembly, [it] will minimize, from the reviewer’s perspective, many of the steps that they had to take to get the application running on their machines.” This technology not only simplifies the data sharing process but also has the potential to accelerate drug approval timelines and enhance collaborative research across various fields.\nFor more details, read the full article on Nature’s website:Read the full article here (Paid subscription required).\nTo further explore Eric Nantz’s insights on using R and Shiny in regulatory submissions, you can also check out the R/Adoption Series: R and Shiny in Regulatory Submissions with Eric Nantz."
  },
  {
    "objectID": "posts/the-cleveland-r-user-groups-journey-through-pandemic-adaptations-and-baseball-analytics-r-consortium/index.html",
    "href": "posts/the-cleveland-r-user-groups-journey-through-pandemic-adaptations-and-baseball-analytics-r-consortium/index.html",
    "title": "The Cleveland R User Group’s Journey Through Pandemic Adaptations and Baseball Analytics",
    "section": "",
    "text": "Last year, R Consortium talked to John Blischak and Tim Hoolihan of the Cleveland R User Group about their regular structured and casual virtual meetups during the pandemic. Recently, Alec Wong, another co-organizer of the Cleveland R User Group, updated the R Consortium about how the group provides a networking platform for a small but vibrant local R community. Alec shared details of a recent event from the group regarding the use of R for analyzing baseball data. He also discussed some tools for keeping the group inclusive and improving communication among group members.\n\n\n\nPlease share about your background and involvement with the RUGS group.\nI completed my Bachelor of Science degree in Fisheries and Wildlife from the University of Nebraska-Lincoln in 2013, and my Master of Science degree in Statistical Ecology from Cornell University in late 2018. During my graduate program, I gained extensive experience using R, which is the de facto language of the ecological sciences. I discovered a passion for the language, as it is extremely intuitive and pleasant to work with.\nAfter completing my program in 2018, I moved to Cleveland and immediately began attending the Cleveland R User Group in 2019, and have been a consistent member ever since. I eagerly look forward to each of our events.\nAfter completing my graduate program, I started working at Progressive Insurance. Working for a large organization like Progressive provides me with many diverse opportunities to make use of my extensive experience with R. I was happy to find a vibrant R community within the company, which allowed me to connect with other R users, share knowledge, and I enthusiastically offer one-on-one assistance to analysts from all over Progressive.\nStarting in 2022, I accepted the role of co-organizer of the Cleveland R User Group. As a co-organizer, I help with various tasks related to organizing events, such as the one we held last September. I am passionate about fostering the growth of these communities and helping to attract more individuals who enjoy using R.\nOur group events are currently being held in a hybrid format. When we manage to find space, we will meet in person, such as when we met to view the 2023 posit::conf in October–several members visited in person and watched and discussed videos from the conference. Most of our meetups continue to be virtual, including our Saturday morning coffee meetups, but we are actively searching for a more permanent physical space to accommodate our regular meetups.\nI am only one of several co-organizers of the Cleveland R user group. The other co-organizers include Tim Hoolihan from Centric Consulting, John Blischak who operates his consulting firm JDB Software Consulting, LLC, and Jim Hester, currently a Senior Software Engineer atNetflix. Their contributions are invaluable and the community benefits tremendously from their efforts.\nCan you share what the R community is like in Cleveland? \nI believe interest in R has been fairly steady over time in Cleveland since 2019. We have a handful of members who attend regularly, and typically each meeting one or two new attendees will introduce themselves.\nI would venture to say that R continues to be used frequently in academic settings in Cleveland, though I am ‌unfamiliar with the standards at local universities. At least two of our members belong to local universities and they use R in their curricula.\nAs for industry usage, many local companies, including Progressive use R. At Progressive, we have a small, but solid R community; although it is not as large as the Python community, I believe that the R community is more vibrant. This seems characteristic of R communities in varying contexts, as far as I’ve seen. Another Cleveland company, the Cleveland Guardians baseball team, makes use of R for data science. In September 2023 we were fortunate to invite one of their principal data scientists to speak to us about their methods and analyses. (More details below.)\nTypically, our attendance is local to the greater Cleveland area, but with virtual meetups, we’ve been able to host speakers and attendees from across the country; this was a silver lining of the pandemic. We also hold regular Saturday morning coffee and informal chat sessions, and it’s great to see fresh faces from outside Cleveland joining in.\nYou had a Meetup titled “How Major League Teams Use R to Analyze Baseball Data”, can you share more on the topic covered? Why this topic?\nOn September 27th, 2023, we invited Keith Woolner, principal data scientist at the Cleveland Guardians baseball team, to give a presentation to our group. This was our first in-person meetup after the pandemic, and Progressive generously sponsored our event, affording us a large presentation space, food, and A/V support. We entertained a mixed audience from the public as well as Progressive employees.\nKeith spoke to us about “How Major League Baseball Teams Use R to Analyze Baseball Data.” In an engaging session, he showcased several statistical methods used in sports analytics, the code used to produce these analyses, and visualizations of the data and statistical methods. Of particular interest to me was his analysis using a generalized additive model (GAM) to evaluate the relative performance of catchers’ ability to “frame” a catch; in other words, their ability to convince the umpire a strike occurred. The presentation held some relevance for everyone, whether they were interested in Cleveland baseball, statistics, or R, making it a terrific option for our first in-person presentation since January 2020. His presentation drove a lot of engagement both during and after the session.\n\n\n\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future? \nOne of our co-organizers, John Blischak, has created a slick website using GitHub Pages to showcase our group and used GitHub issue templates to create a process for speakers to submit talks. Additionally, the Cleveland R User group has posted recordings of our meetups to YouTube since 2017, increasing our visibility and accessibility. Many people at Progressive could not attend our September meetup and asked for the recording of our September 2023 meetup as soon as it was available.\nRecently, we have also created a Discord server, a platform similar to Slack. This was suggested by one of our members, Ken Wong, and it has been a great addition to our community. We have been growing the server organically since October of last year by marketing it to attendees who visit our events, particularly on the Saturday morning meetups. This has opened up an additional space for us to collaborate and share content asynchronously. Ken has done an excellent job of organizing the server and has added some automated processes that post from R blogs, journal articles, and tweets from high-profile R users. Overall, we are pleased with our progress and look forward to continuing to improve our initiatives.\n\nHow do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/announcing-health-technology-assessment-HTA-working-group/index.html",
    "href": "posts/announcing-health-technology-assessment-HTA-working-group/index.html",
    "title": "Announcing the Health Technology Assessment (HTA) Working Group",
    "section": "",
    "text": "The R Consortium is pleased to announce a new Working Group (WG) focused on Health Technology Assessment (HTA). The HTA WG has a mission of promoting the use of R in all aspects of HTA analytics, including both clinical assessment and economic evaluation. It aims to build on the success of other R Consortium working groups in bringing together and promoting dialogue between the broadest range of stakeholders from the HTA ecosystem (industry, HTA bodies, academics and others) to identify needs and address challenges through practical tools and pilot exercises. Health Technology Assessment (HTA) helps decision-makers determine which medical technologies and treatments are effective and worth paying for. It can help ensure that the right treatments reach the right patients at the right time by assessing clinical evidence and economic evaluations to inform policy-making about reimbursement and market access.\nRecent policy changes, such as the EU HTA Regulation, require pharmaceutical companies to face stricter standards and shorter deadlines for submitting evidence. At the same time, HTA authorities must review an increasing number of complex analyses under the pressure for timely evidence-based decisions. Lastly, there is pressure on academia to provide easy-to-use HTA software and tools.\nInitially, the WG will focus on the following objectives.\n\nFoster Collaboration and Knowledge Sharing:\n\nUnderstanding the needs of all stakeholders for HTA analytics, and where the use of R may best fit.\nPromote the common goal of delivering HTA analytics work that meets those needs and efficiently utilizes R.\nBecome a central hub for connecting existing and new R initiatives in the HTA space, ensuring efficient and unified efforts.\n\nDevelop and Document Best Practices:\n\nDevelop and disseminate best practices for using R in HTA analytics work for clinical and economic evaluation.\nPromote transparency and reproducibility in HTA analytics work.\n\nExplore Pilot Studies with HTA authorities\n\nExplore pilot studies to test and refine open source R-based tools and frameworks for clinical and economic evaluation.\nPursue collaborative efforts with HTA authorities to validate these tools, demonstrating their value in real-world HTA scenarios.\n\n\nIf you think any of this is exciting and would like to become involved, please leave your name and email in issue number 1 at the HTA GitHub repository."
  },
  {
    "objectID": "posts/empowering-the-R-Community-Insights-from-Myles-Mitchell-of-the-Leeds-Data-Science-Group/index.html",
    "href": "posts/empowering-the-R-Community-Insights-from-Myles-Mitchell-of-the-Leeds-Data-Science-Group/index.html",
    "title": "Empowering the R Community: Insights from Myles Mitchell of the Leeds Data Science Group",
    "section": "",
    "text": "The R Consortium recently interviewed Myles Mitchell, co-organizer of the Leeds Data Science group, to discuss the local R community and the group’s recent activities. Myles highlighted the group’s efforts to create an inclusive and welcoming environment for all participants. The group is dedicated to creating networking opportunities for students interested in pursuing a career in data science and sharing job openings.\nThe Leeds Data Science group is hosting an in-person event titled “Improving the Fidelity and Stability of Large Language Models” on the 23rd of July.\nPlease share about your background and involvement with the RUGS group.\nI am a data scientist at Jumping Rivers, a data science consultancy. We collaborate with various companies on data-related projects, such as data storage, modeling, developing data visualization dashboards, and offering data science training. Initially, I had a background in Python, but I learned R while working at Jumping Rivers, where many of our staff are proficient in R, and much of our infrastructure is written in R.\nAt Jumping Rivers, we receive funding from the R Consortium. We organize the Leeds Data Science Meetups every two months and the North East Data Science Meetups every three months. Additionally, we hold annual conferences, such as Shiny in Production (October) and SatRdays London (April), which run once a year. I organize the North East and Leeds Data Science Meetups for Jumping Rivers.\nCan you share what the local R Community is like?\nI am located in Newcastle, in the northeast of England, where a large community is keenly interested in data science. Our community includes Newcastle University and Northumbria University students, many of whom are studying data science or statistics. There are also professionals from various industries looking for data science jobs. Our meetups are attended by prospective data scientists and students eager to network and learn more about the field.\nBoth universities teach R, and many industries in the area employ data science techniques, including Northumbrian Water and Nissan. These companies use data science to solve everyday problems, such as detecting water leaks and optimizing manufacturing processes.\nData science is relevant across almost all industries, and R, along with Python and other languages, is a crucial tool in solving data science problems. In the Northeast, consultancies like Jumping Rivers specialize in data science. In summary, we have a large community of students and industry professionals in the Northeast, and it’s a similar story in Leeds.\nYou have a Meetup on “Improving the Fidelity and Stability of Large Language Models”, can you share more on the topic covered? Why this topic?\nDuring our Meetup on “Improving the Fidelity and Stability of Large Language Models,” we will explore how to enhance software solutions with AI capabilities, focusing on improving the accuracy and reliability of these models. Drawing from real-world experiences, we will discuss successful strategies for development, tackle the challenge of model ‘hallucinations,’ and address other significant obstacles. This topic is essential as the AI sector continues to grow rapidly, and integrating AI effectively is crucial for developers to achieve robust performance and innovative functionality in their projects. The session is designed for developers of all skill levels interested in incorporating AI into their work, ensuring they can implement practical and effective methodologies for positive outcomes.\nRyan Mangan will be presenting this meetup. Ryan is a seasoned technologist with over 18 years of experience in cloud computing, AI, and virtualization. He founded Efficient Ether Ltd, a Microsoft startup specializing in AI, cloud optimization, and sustainability. Ryan is a recognized Microsoft MVP, VMware vExpert, and Chartered Fellow of the British Computer Society. He has authored several e-books and publications, including “Mastering Azure Virtual Desktop,” and is active in public speaking and blogging within the tech community.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nRegarding techniques, I’m currently reviewing how we organize our meetups. Our meetups are free to attend for all participants, and we aim to create a welcoming and accessible environment for everyone to network and meet like-minded individuals in the area. The meetups are held every two to three months on weekdays in the evenings, providing attendees with time to travel from their place of work to the venue. We offer refreshments at the start, including pizza and soft drinks, and we ensure that vegan, gluten-free, and halal options are included to cater to a wide range of dietary preferences.\nWe often run interactive workshops at the North East Data Science Meetups, including a recent meetup on the Apache Arrow interface for R, led by Nic Crane on July 18th. To make our workshops as inclusive as possible, we provide attendees with all necessary materials and dependencies via a cloud environment created using Posit Workbench. It allows participants without prior installation of RStudio IDE to contribute and interact with the workshop materials. Our goal is to make our workshops accessible to a broad audience, including those from non-R backgrounds. In general, we aim to create an event where attendees can participate without the burden of installing multiple packages or downloading data.\nMost attendees attend our meetups to network and meet industry professionals, especially students exploring post-graduation career opportunities. With this in mind, we always reserve a part of the meetup for advertising similar meetups and conferences in the area and job opportunities in data science. Many attendees regard these meetups as a regular source of news, so we try to provide a central hub of information and a place to enjoy high-quality live talks and workshops.\nThese are in-person meetups. We could attract more people if we recorded and live-streamed it on Zoom. However, managing a Zoom call and recording would create more work for the organizers, and an in-person event provides better networking opportunities than online. In saying that, we will continue to look at ways to make these accessible and appeal to a wide range of backgrounds, and we will always take feedback from the community seriously.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nIn the northeast and Leeds data science meetups, there is a significant interest in machine learning, training and deploying machine learning models, and productionizing these models (ML Ops). Attendees often expect talks on these topics and are particularly interested in chatGPT, generative AI, and other related issues. However, data science encompasses a broader range of areas, including visualizing data and creating dashboards, and we try to cover all of these areas in our talks and workshops. Despite our efforts, there is a clear trend toward machine learning-focused discussions, with many talk submissions focusing on ML Ops and deploying models on the cloud."
  },
  {
    "objectID": "posts/empowering-the-R-Community-Insights-from-Myles-Mitchell-of-the-Leeds-Data-Science-Group/index.html#how-do-i-join",
    "href": "posts/empowering-the-R-Community-Insights-from-Myles-Mitchell-of-the-Leeds-Data-Science-Group/index.html#how-do-i-join",
    "title": "Empowering the R Community: Insights from Myles Mitchell of the Leeds Data Science Group",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/building-bridges-in-haifa-israel/index.html",
    "href": "posts/building-bridges-in-haifa-israel/index.html",
    "title": "Building Bridges in Haifa, Israel: How the New R User Group in Haifa is Establishing a Diverse R Community",
    "section": "",
    "text": "The R Consortium recently interviewed Eli Eydlin, a dedicated member of the R community who has been instrumental in establishing an R User Group in Haifa, Israel. With a background in physics and a recent shift into the biotech industry, Eli was motivated to create the group after noticing the absence of a local R community in his new city. Despite Haifa’s relatively small size, it boasts a diverse R community, including professionals from high-tech companies, academia, and startups. Eli shared his experience organizing their first Meetup, which featured speakers from vastly different backgrounds, and his plans to make future events more inclusive. His story highlights the importance of community building and the impact of taking the initiative, offering inspiration for others looking to contribute to their local R communities.\nPlease share about your background and involvement with the RUGS group.\nI’ve been working in a biotech startup for nearly two years. My background is more on the pharma side, but I decided to dive into this new field. When I moved, I noticed that there wasn’t an R User Group in the area, even though I knew of other groups in different cities and countries that were doing great things. I didn’t like the idea of not having one here, so I decided to start one myself. We just had our first event, and I’m really excited to be a part of this initiative.\nCan you share what the R community is like in Haifa?\nOne of the reasons I started this was to meet new people who are also R programmers or users. I already know that the community is really diverse. My city isn’t huge—around 300,000 people—but has much to offer. There are big high-tech companies like Microsoft and Amazon here that support their R&D departments, and I’m certain that some of our members are involved. Like in many places in Israel, there are hundreds of small startups. What I find interesting is that people come from all sorts of backgrounds—mostly from academia, as usual, but now also from government, traditional companies, and small businesses. I’m excited to see where this leads.\nYou had a Meetup on August 6th, 2024. Can you share more about the topic covered? Why this topic?\nWe have two completely different topics and two amazing speakers. Sofia Nazarova is a marine biologist at Israel Oceanographic & Limnological, who also organizes private guided tours. She teaches people about plants and animals, so she’s not a programmer. However, she co-authored the first-ever R textbook published in Russian, which makes her experience unique. Typically, I work with people who are programmers or data scientists, but she’s out there in the field, literally working with marine life.\nOur second speaker was Adi Sarid, the CEO of Sarid Institute LTD, a data science company focusing on production and consumption. He’s also writing a book on R, this time in Hebrew. It’s a completely different experience—he’s a business leader working with governments and large firms, and he showcased some fantastic examples of practical applications in his talk.\nI deliberately chose speakers with very different backgrounds because that interests me. While organizing the group, I thought about what I wanted to learn and the connections I wanted to make.\nWho was the target audience for attending this event?\nTo be honest, there wasn’t a specific target audience for this event because I didn’t know anyone. I just tried to reach out to whoever might be interested in participating. After the first event, I noticed a big jump in interest, but only one woman attended. So, for the next event, I want to specifically target women and try to figure out what went wrong. It seems like many women are using R, but for some reason, they didn’t show up. We’ll address that and improve things moving forward.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nWe didn’t use anything for the first event, which we may do with the future in mind. We wanted to stay connected, especially since we’re in Israel, and it’s important to support each other under pressure. The event went well, but after it was over, I started receiving messages from people saying they couldn’t attend because they needed to spend time with their kids or were afraid of potential security issues.\nI realize how important it is to offer in-person meetings, but I now acknowledge that it’s not feasible for everyone. So, for the next event, we’ll make it easier for people to join remotely, perhaps through Zoom or a similar platform. We’ll also hold events in more secure locations. It’s clear that while in-person events are valuable, they aren’t always possible or suitable for everyone.\nWe would like to get to know you more personally. Can you please tell me about yourself? For example, hobbies/interests or anything you want to share about yourself.\nFirst of all, I have a physics background and a master’s degree in it. I recently transitioned into the pharma and biotech industry, which has been a new and exciting challenge for me. My interests have always been diverse, and I’m particularly fascinated by this field, as well as by the natural beauty of Israel, especially its trees. On a different note, I’m also a harmonica player, which is another passion of mine.\nPlease share any additional details you would like included in the blog.\nI want to take the initiative with the R Consortium and contribute to its efforts. I see how cool and relatively easy it is to organize such a group. Focusing on developing countries is important, but it’s also relevant here in Israel, even though we’re relatively wealthy. What motivated me was seeing others take action, and I realized that I needed to step up and organize a group as well. The tools and support provided by the R Consortium are incredibly helpful for bringing people together. So, I just wanted to say thank you for that."
  },
  {
    "objectID": "posts/building-bridges-in-haifa-israel/index.html#how-do-i-join",
    "href": "posts/building-bridges-in-haifa-israel/index.html#how-do-i-join",
    "title": "Building Bridges in Haifa, Israel: How the New R User Group in Haifa is Establishing a Diverse R Community",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/introducing-r-to-malawi-a-community-in-the-making/index.html",
    "href": "posts/introducing-r-to-malawi-a-community-in-the-making/index.html",
    "title": "Introducing R to Malawi: A Community in the Making",
    "section": "",
    "text": "David Mwale, the R Users Malawi group organizer, recently spoke with the R Consortium about his efforts to establish and grow the R community in Malawi. David shared insights into the group’s inaugural meeting, the excitement surrounding R among researchers and students, and his plans to engage academic institutions through online and in-person events. He also discussed the challenges of introducing R in a region where other tools like Stata and SPSS dominate and his vision for fostering a vibrant and supportive R ecosystem in Malawi.\nPlease share your background and involvement with the RUGS group.\nI hold a bachelor’s degree in agricultural economics and a diploma in monitoring and evaluation. I have experience working with various data software, including Stata and SPSS. Last year (2023), I enrolled in a master’s program in data science at the University of Edinburgh, where I was introduced to the R programming language. I’ve used R a few times at work for school assessments and participated in several training sessions on LinkedIn Learning.\nRecently, I discovered user groups for R in neighboring countries, such as Botswana. I contacted the R user group in Johannesburg and learned about another community group on LinkedIn. I inquired about how they established their groups so we could create our own R user group. Following the steps they provided and the information I found on the R Consortium website, I applied to set up our group. I’m happy to report that we had our first meeting just last month.\nCan you share what the R community is like in Malawi?\nThe use of R in Malawi is still in its infancy and is not widely adopted. For instance, at one academic institution, master’s students are still being taught Stata and SPSS. While these tools are not wrong, R is a programming language growing in popularity. It has a large community and significant support.\nOne issue may be that academic institution lecturers themselves still need to become familiar with R. They tend to teach what they already know, which might limit students’ exposure to more modern tools. A colleague of mine, pursuing his studies at an institution in Malawi, mentioned that they still use Stata for their master’s dissertation. Again, while this is acceptable, R offers more advantages.\nHow was the response to your first event? How did you promote the event?\nI created a LinkedIn account and designed a poster for the event. I posted the poster on LinkedIn, X (formerly Twitter), and my WhatsApp status. Many people registered for the event; however, since this was our first event, I needed to figure out how to manage the registration link. We encountered an issue with the registration link for which platform to use.\nI switched from Zoom to Google Meet because Zoom has associated costs. Although many people registered for the meeting, the turnout was significantly lower than expected. There might have been confusion regarding the links I shared. We used one link on the advertising poster, but I sent a different link closer to the meeting time through the R user group. Some people did not notice the latest email I sent.\nWhat are your plans for the group going forward? Do you plan on hosting online or in-person events?\nI have two plans. I intend to continue hosting meetings online and in person, particularly at universities, where I can engage with fellow students.\nIn summary, I aim to organize a meeting around January or February in 2025. I would like to connect with either a student leader or a department head, such as a lecturer interested in data science so that we can hold an R user session for the students on their campus.\nRegarding the group’s organization, I am currently looking for co-organizers. I reached out to one person, but they are too busy. I also contacted another individual currently in Germany but originally from Malawi, and he is interested in participating as an organizer.\nWhen I advertised the R User Group, there was a positive response because R is not widely used here in Malawi. Despite its limited usage, there was significant excitement among people working in research, data monitoring, evaluation, and academic students. Although the turnout at our first meeting was lower than expected, the enthusiasm will grow as we continue. Many people are eager to learn how to use R.\nSince this is just the beginning, it can be challenging to get started and engage people, but over time, we will likely attract more members and find co-organizers to assist with event planning. We are optimistic about promoting the use of R in Malawi."
  },
  {
    "objectID": "posts/introducing-r-to-malawi-a-community-in-the-making/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/introducing-r-to-malawi-a-community-in-the-making/index.html#how-do-i-build-an-r-user-group",
    "title": "Introducing R to Malawi: A Community in the Making",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/building-data-highways-kirill-mullers-journey-in-enhancing-rs-database/index.html",
    "href": "posts/building-data-highways-kirill-mullers-journey-in-enhancing-rs-database/index.html",
    "title": "Building Data Highways: Kirill Müller’s Journey in Enhancing R’s Database",
    "section": "",
    "text": "Kirill Müller is the author of the {DBI} package, which helps to connect R and database management systems (DBMS). The connection to a DBMS is achieved through database-specific backend packages that implement this interface, such as RPostgres, RMariaDB, and RSQLite. There’s more information here. Most users who want to access a database do not need to install DBI directly. It will be installed automatically when one of the database backends is installed. If you are new to DBI, the introductory tutorial is an excellent starting point for familiarizing yourself with essential concepts.\n{DBI} supports about 30 DBMS, including:\nYour latest work with the R Consortium was focused on the maintenance and support for {DBI}, the {DBItest} test suite, and the 3 backends to open source databases ({RSQLite}, {RMariaDB} and {RPostgres}). You stated that “Keeping compatibility with the evolving ecosystem (OS, databases, R itself, other packages) is vital for the long-term success of the project.” What’s the current status?\nDBI and the other projects are available for use. Please try them!\nI always strive for a healthy, “green” build, prioritizing clean and efficient outcomes. However, given the complexity of the projects, with their many moving parts and the continuous influx of new developments, achieving perfection at all times can be challenging. My goal is to ensure that everything we build meets a standard of functionality, even if there are moments when the builds don’t meet every expectation.\nFortunately, the generous funding provided by the R Consortium empowers us to address and rectify any issues as they emerge. This financial support is crucial, as it allows for the immediate tackling of problems, ensuring that our projects remain on the cutting edge and continue to serve the community effectively. Despite the occasional imperfections, my commitment is to promptly and efficiently solve these problems, maintaining the high quality and reliability of our builds.\nMore information available here.\nIs performance an issue with big data sets? Does R have performance advantages or disadvantages compared to other languages?\nR has unique strengths as a powerful interface language. R treats data frames as first-class data structures. Functions and expressions are first-class objects, enabling easy parsing, computing, and emitting code, fostering robust programming practices. Moreover, R’s “pass by value” semantics (to be more accurate, “pass by reference and copy on write) ensure that functions do not inadvertently alter your data. This eliminates concerns over state management and makes data manipulation both predictable and secure.\nDespite performance considerations, R is adept at efficiently handling bulk data operations. For example, working with columnar data frames that contain anywhere from 100,000 to 3 million rows is smooth due to R’s vectorized approach, allowing for efficient column-wise addition or multiplication. However, the performance can decline if large data frames are processed cell by cell.\nAnd here’s the true power of R: As an interface language, R enables the use of external, high-speed engines—be it DuckDB, Arrow, traditional databases, or data processing tools like data.table and collapse—for computation, while R itself is used to compose the commands for these engines. This integration showcases R’s versatility and efficiency by leveraging the strengths of these specialized engines for heavy lifting, thereby bypassing its performance limitations in certain areas.\nTherefore, the focus should not be just on performance in isolation but rather on what can be achieved through R’s integration with other systems. This flexibility allows R to extend its utility well beyond mere data processing, making it a potent tool not only for technical users but also accessible to those with less technical expertise. The intuitive syntax of R, especially with domain-specific languages like dplyr, makes it exceptionally user-friendly, resembling plain English and facilitating a smoother workflow for a wide range of tasks.\nWho uses databases and R most? Are they already using R and need to connect to different types of DBMS?\nAs an interface language, R is remarkably versatile. It is designed to facilitate connections with a broad spectrum of tools and systems. This versatility positions R as a central hub for orchestrating a wide range of tasks, enabling users to maintain their workflow within the platform without wrestling with complex interfaces. Command-line interfaces are acceptable, offering a decent level of control and flexibility. File-based interfaces, on the other hand, can be cumbersome and inefficient, making them far from ideal for dynamic data management tasks.\nThe spectrum of interfaces available for database interaction varies. The most effective solution is an R package that includes bindings to a library. This setup provides a direct conduit to the necessary functionality, streamlining the interaction process. Examples are DBI backends for PostgreSQL, SQLite, MySQL, and ODBC, or the new ADBC (Arrow Database Connectivity) standard (more on that later). These backends facilitate direct, low-friction access to databases from within R.\nFocusing on native solutions, I want to emphasize the potential of the dm package, which I see as offering substantial benefits beyond what the DBI backends might provide. The dm package closely integrates database concepts with R. It enables sophisticated operations, such as the management of data models with primary and foreign keys, execution of complex joins, and the transformation of data frames into a fully operational data warehouse within R. These capabilities extend and enhance the functionalities provided by dplyr, dbplyr, and DBI, offering a comprehensive toolkit for database management directly through R.\nRMySQL is being phased out in favor of the new RMariaDB package. Why?\nWhen I first got involved with the DBI Library, it was after being awarded my first contract, which focused on connecting R to SQLite, PostgreSQL, and MariaDB. It’s important to note that MariaDB and MySQL are essentially related; MariaDB is a fork of MySQL. Despite their independent evolution, they remain largely interchangeable, allowing connections to either MariaDB or MySQL databases without much trouble. This similarity can sometimes cause confusion.\nIn terms of technical specifics, our MySQL package utilizes C to create bindings to its underlying library, while our DBI package prefers C++, which I find more user-friendly for these tasks. When I took charge of the project, these packages were already separate, and I didn’t challenge that decision. Starting anew offers the benefit of not needing to maintain backward compatibility with existing our MySQL users, which has posed significant challenges, especially with the RSQLite package. That package’s widespread use across several hundred other packages meant we had to conduct reverse dependency checks, running tests from those packages against modifications in ours to ensure compatibility. This process, essentially an enhanced test suite, required considerable effort.\nReflecting on it now, I would have preferred to initiate a project like RSQLite, to begin with a clean slate. Starting fresh allows for quicker progress without the constraints of backward compatibility or the expectation of maintaining behaviors that may no longer be relevant or supported. However, you also want to avoid alienating your user base. So, transitioning to C++ and starting from scratch was a strategic choice, and it was one that the maintainer of our MySQL and I agreed upon.\nI should mention the odbc package, which isn’t included in the scope of R Consortium projects but is essential to our work. We use the odbc package extensively to connect with a variety of commercial databases and specialized database systems, some of which might not offer a straightforward method for direct interaction. In our setup, the odbc package acts as a crucial database interface, bridging the gap between the database itself and DBI.\nThere’s been a significant new development in this space, known as ADBC, accompanied by an R package named adbi. This initiative, spearheaded by Voltron Data, represents a modern reimagining of ODBC, specifically designed to enhance analytical workflows. While traditional databases have been geared towards both reading and writing data, ADBC focuses on optimizing data reading and analysis, recognizing that data science and data analysis workflows predominantly require efficient data reading capabilities. This focus addresses a gap left by ODBC, which wasn’t originally designed with high-speed data analysis in mind.\nThese developments are exciting, and I’m keen to see what the future holds for us in this evolving landscape.\nWhat’s the difference between DBI and dbplyr?\nI could describe it as a relationship between DBI and dbplyr, where dbplyr acts as a user of DBI. DBI supplies the essential functionality that enables dbplyr to operate effectively. This setup allows dbplyr to concentrate on constructing SQL queries, while other packages handle the responsibility of connecting to the individual databases.\nWhat are the biggest issues with using R and databases moving forward?\nThe current DBI project faces challenges that are tough to solve within its existing scope. These challenges could significantly impact many dependent components, which is why this repository has little code and serves mainly as a placeholder for ideas we think DBI is missing. However, these ideas have the potential to become significant enhancements.\nOne major technical challenge I’ve faced is with query cancellation. If a query runs too long, the only option is to terminate the process, which stops our entire session. This issue is closely related to the concept of asynchronous processing, where a query is sent off, and other tasks are done in parallel until the query results are ready. This would be especially useful in applications like Shiny, allowing it to handle multiple user sessions simultaneously within the same R process. Finding a solution to this problem is crucial due to the current lack of effective alternatives in our infrastructure.\nWhile not every issue signifies a major problem, there are certainly areas that DBI does not address, some of which may be beyond its intended scope. Still, there are notable gaps that require attention.\nAs for our original plan, we’re taking a different direction thanks to the introduction of the ADBC via the adbi package. ADBC offers a stronger foundation for achieving our goals. With ADBC, all data is funneled through the Arrow data format, which means we no longer need individual backends to translate data into R data frames separately, and at the same time other ecosystems can be integrated easier. In addition, a substantial part of the known challenges for DBI, including query cancellation and asynchronous processing, are already solved by ADBC. Using ADBC as a bridge between databases and ecosystems reduces the complexity from a many-to-many (n × m) problem to a more manageable one-to-one (n + m) problem. This reduces duplication of effort and makes it easy to support new databases or new ecosystems. More information here.\nHow has it been working with the R Consortium? Would you recommend applying for an ISC grant to other R developers?\nThis is an excellent opportunity for young professionals to secure funding for their ideas or explore areas that haven’t been fully addressed yet. R is a fantastic tool, but it constantly evolves with new technologies being introduced. I’m particularly impressed by how the consortium supports various projects, including R-Ladies and SatRdays, which promote inclusivity within the community. I was approached with the idea of applying for a project, something I might not have considered alone. This makes me curious whether there’s a list of challenges similar to what the Google Summer of Code offers, where potential mentors submit project ideas for students to work on under their guidance. I haven’t looked into this possibility for the consortium in detail yet, but the thought of it excites me. I thoroughly enjoy being part of this process and am eager to see what long-term collaborations might emerge from it."
  },
  {
    "objectID": "posts/building-data-highways-kirill-mullers-journey-in-enhancing-rs-database/index.html#about-isc-funded-projects",
    "href": "posts/building-data-highways-kirill-mullers-journey-in-enhancing-rs-database/index.html#about-isc-funded-projects",
    "title": "Building Data Highways: Kirill Müller’s Journey in Enhancing R’s Database",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure."
  },
  {
    "objectID": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html",
    "href": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html",
    "title": "Tackling Hurdles: Embracing Open Source Packages in Pharmaceutical Research",
    "section": "",
    "text": "The R Validation Hub next meeting is May 21st, 12:00 PM EST."
  },
  {
    "objectID": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html#join-the-call-here",
    "href": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html#join-the-call-here",
    "title": "Tackling Hurdles: Embracing Open Source Packages in Pharmaceutical Research",
    "section": "Join the call here! ",
    "text": "Join the call here! \nIn the dynamic field of pharmaceutical research, open source R packages offer incredible potential to innovate and enhance efficiency. The R Validation Hub is guiding the community building riskmetric and the riskassessment app. riskmetric is a framework to quantify an R package’s “risk of use” by assessing a number of meaningful metrics designed to evaluate package development best practices, code documentation, community engagement, and development sustainability. Together, the riskassessment app and the riskmetric package aim to provide some context for validation within regulated industries. \nThe benefits of utilizing open source tools in pharmaceutical projects are compelling. To address these issues and maximize their potential, join us at the R Validation Hub community meeting on May 21st at 12:00 PM EST. This gathering will focus on sharing best practices, troubleshooting common problems, and exploring innovative solutions together.\nEmbrace the opportunity to transform pharmaceutical research with us. Let’s innovate, collaborate, and overcome these hurdles together."
  },
  {
    "objectID": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html#join-the-call-here-1",
    "href": "posts/Tackling-Hurdles-Embracing-Open-Source-Packages-in-Pharmaceutical-Research/index.html#join-the-call-here-1",
    "title": "Tackling Hurdles: Embracing Open Source Packages in Pharmaceutical Research",
    "section": "Join the call here!",
    "text": "Join the call here!"
  },
  {
    "objectID": "posts/r4hr-in-buenos-aires-leveraging-r-for-dynamic-hr-solution/index.html",
    "href": "posts/r4hr-in-buenos-aires-leveraging-r-for-dynamic-hr-solution/index.html",
    "title": "R4HR in Buenos Aires: Leveraging R for Dynamic HR Solutions",
    "section": "",
    "text": "Marcela Victoria Soto, co-organizer of the R4HR -Club de R para RRHH, Buenos Aires, Argentina, recently updated the R Consortium about the group’s recent activities. Last year, Sergio García Mora, the group’s founder, discussed the adoption and expansion of R in human resources in Argentina. Marcela emphasized the importance of data analysis for informed and agile decision-making for companies in Argentina. She also shared details of some of her budgeting, accounting, and annual income tax projects.\nR4HR is holding an online event called “Data Visualization in HR” on June 1, 2024, for Spanish-speaking R users. The meetup will be conducted via Google Meet.\nPlease share your background and involvement with the RUGS group.\nI earned a bachelor’s degree in labor relations and received training as a labor relations teacher at the University of Buenos Aires (UBA). Additionally, I completed a postgraduate course in Human Resources Management from the Pontifical Catholic University of Argentina (UCA) and a Diploma in Computational Social Sciences from the National University of General San Martín (UNSAM). I also attended the Argentina Program at the University of Salta, completing all three program modules.\nWhat industry are you currently in? How do you use R in your work?\nI currently work in the textile industry as the Head of Human Resources. At Yagmour, I use R to present reports on employee turnover, salary reports, accounting entries, etc. Additionally, I use R to consolidate the annual Human Resources budget according to the company’s accounts.\nCan you share what the R community is like in Buenos Aires?\nThe R4HR community is a collaborative space comprising individuals interested in data and human resources. We hold various meetups within the community where projects, R packages, etc., are shared. It is a Spanish-speaking community. The R Club is a meeting space for professionals in the field, where we can share tools, new ways of addressing issues, and novel approaches to similar problems. People who attend and are familiar with R sometimes need to be made aware of everything this programming language offers for simple and complex issues—the benefit of attending lies in sharing and creating spaces for knowledge exchange.\nYou have a Meetup on “Data Visualization in HR” on June 1st, 2024. Can you share more about the topic covered? Why this topic?\nIn June, we will hold a meetup to address Data Visualization in HR using the ggplot2 package, adding interactivity and context with plotly. This topic is not just interesting but also highly practical. Visualization is a great way to interpret data and graphically identify behavior patterns, which can also prompt questions about the presented information. The plotly package can add insights that are not apparent in the graphs. Additionally, plotly allows for creating interactive visualizations, enabling users to explore and manipulate the charts directly within the visualization. It can include zooming, data selection, and more, providing a richer and more dynamic user experience.\nThis meetup’s target audience is individuals interested in understanding the benefits of working with R‌ and people in the human resources field who are interested in the topic.\nFor this event, we conducted the invitation through Meetup and provided a Google Meet link. After the event, we will upload it to YouTube and communicate to the community through social media.\nWould you like to tell us about an interesting recent Meetup from the group?\nI recently presented at a group event titled Annual Income Tax with R to showcase the various problems one can address using R beyond data visualization or analysis. In Argentina, to carry out this development, one must consider the guidelines provided by the Federal Administration of Public Revenues (AFIP), which, at the national level, determines the parameters to be used for presentations; payroll software interprets these parameters. Those who do not have a payroll system can use the development done in R to carry out this presentation.\nIn Argentina, the frequent changes and calculation methods have made everything related to this tax quite complex. They impose this tax on salaries that are considered high-value. It is a tax withheld by the company, and due to inflation and various modifications, the analysis and handling of this tax end up being one of the most complex issues for employees in the country. I made this process easier in this meetup by using R.\n.png\nWhat trends do you currently see in R language and your industry? Are there any trends you see developing in the near future?\nTrends in R are about its growing popularity and its transformative impact. It allows more people to join and enhances its application to various problems. There is also ongoing work on clustering applied to Human Resources to understand how each group functions, their relationships, common characteristics, etc. In Argentina, due to the current economic situation, data analysis not only at the salary level but also at the soft skills level is an urgent necessity for companies aiming to use data for agile decision-making. Business data is vital for analyzing the rest of the decisions that need to be made by Human Resources and the entire company. To use data for agile decision-making, companies must consider salary levels, understand which soft skills are needed and what the context requires, and make decisions accordingly.\nA trend that will continue to develop in the future relates to Artificial Intelligence and how it complements everyday tasks or serves as a support tool.\nPlease share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting related to your industry?\nI have worked on several projects in R, starting with the basics related to data visualization of absenteeism, turnover, and salary analysis.\nSomething different that I worked on with R was creating the annual Income Tax presentation. The objective was to consolidate the yearly information of each employee covered by the regulations according to the parameters provided by the Federal Administration of Public Revenues. It required interpreting each requirement at the programming level. This file had to be submitted in TXT format, which meant working with rare extensions in Human Resources areas.\nAnother different project in R was creating accounting entries. It allows for systematizing a large amount of information and grouping it according to the accounts.\nI have also used R to prepare information presented to the Ministry of Labor, which required extensive cross-referencing. For example, it involved cross-referencing gender with absences, working hours, days, leaves, and paid leaves, among other variables. The complexity of this was the relationship between the data, where any incorrect data would ultimately lead to inconsistencies in the information.\nLastly, before applying R, the Budgeting process in our company involved transferring information across different Excel sheets, using pivot tables, and copying and pasting it into a summarized form. It took a significant amount of time, and whenever a variable needed to be changed, the entire process had to be redone, which implied errors due to the large amount of information transfer. Today, people work on this process dynamically in Excel and then process it in a script that consolidates all the information in minutes, sometimes less. It allows for the creation of multiple scenarios dynamically in a time of significant volatility and limited time. This process using R has achieved a substantial reduction in time, in addition to ensuring data consistency."
  },
  {
    "objectID": "posts/r4hr-in-buenos-aires-leveraging-r-for-dynamic-hr-solution/index.html#how-do-i-join",
    "href": "posts/r4hr-in-buenos-aires-leveraging-r-for-dynamic-hr-solution/index.html#how-do-i-join",
    "title": "R4HR in Buenos Aires: Leveraging R for Dynamic HR Solutions",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/empowering-dengue-research-through-the-dengue-data-hub/index.html",
    "href": "posts/empowering-dengue-research-through-the-dengue-data-hub/index.html",
    "title": "Empowering Dengue Research Through the Dengue Data Hub: R Consortium Funded Initiative",
    "section": "",
    "text": "The Dengue Data Hub, an ambitious initiative funded by the R Consortium ISC, transforms how researchers access and utilize dengue-related data. At its core, the Dengue Data Hub aims to provide a centralized repository for dengue incidence, mortality, and risk-related data, streamlining the research process and empowering scientific inquiry into this global health issue. The platform offers easy access through the denguedatahub R package, a Shiny app, and an informative website, making data analysis more efficient and accessible.\nPlease note: denguedatahub version 2.1.1 was published on CRAN on Sep 22, 2024.\nDr. Thiyanga Talagala, a Senior Lecturer at the University of Sri Jayewardenepura in Sri Lanka, spearheads this initiative. With a PhD from Monash University, where she honed her skills in R programming and data science, Dr. Talagala is deeply passionate about leveraging her expertise to address Sri Lanka’s public health challenges, particularly dengue. Together with her sister, Dr. Priyanga Talagala, she co-founded the R-Ladies Colombo group and has been instrumental in bringing innovative solutions to the scientific community. Dr. Talagala’s commitment to enhancing dengue research through accessible data resources is central to her ongoing work, making the Dengue Data Hub a vital tool for researchers worldwide.\nTell us about your background and how it connects to the Dengue Data Hub project\nCurrently, I am working as a Senior Lecturer, Department of Statistics, Faculty of Applied Sciences, University of Sri Jayewardenepura, Sri Lanka. I earned my PhD from Monash University, Australia. During my time at Monash University in Australia, I was part of the NUMBAT research group, where I developed a deep interest in the R programming language and discovered its incredible potential for data analysis and research. I also had the opportunity to meet and collaborate with leading experts in the field, which further fueled my passion for R and data science. I also got to know about the R Ladies community, and I attended events organized by R-Ladies Melbourne.\nOnce I returned to Sri Lanka after completing my PhD, I felt a strong desire to contribute to my country using the knowledge I had gained. I, along with my Sister, Dr Priyanga Dilini Talagala (we both did our PhDs together at Monash University), established the R Ladies Colombo meetup group.\nDengue is a major public health issue in Sri Lanka. As a data scientist, I can contribute to its mitigation by establishing a centralized repository for dengue data for data analysis and modeling, which empowers dengue research. This project was funded by R Consortium ISC 2022 - 1 Grant and I have been working on it since 2022.\nWhat is the Dengue Data Hub?\nThe Dengue Data Hub is a centralized repository that provides access to a variety of data sets related to dengue incidence and other relevant factors. This includes data on dengue deaths, reported cases, indigenous cases, local cases, dengue serotypes, breeding sites, and country-wise levels of risk. I have data related to annual dengue incidence for 195 countries around the world.\nWhy is this project important for the research community?\nDengue researchers often spend their valuable time searching for datasets, web scraping and cleaning data. The publication of data in a centralized repository helps to prevent duplicate efforts. The dengue data hub enables the community to focus on analysis and modeling rather than data collection and cleaning. Additionally, it enhances research sustainability by allowing researchers to utilize data for their studies while preserving it for future researchers.\nHow do researchers use the Dengue Data Hub?\nThere are three straightforward ways for anyone to participate. Use the denguedatahub R software package, use the Dengue Data Hub Shiny app (for non-programmers), or use our website which provides tutorials and examples.\nThe denguedatahub R package allows researchers to download dengue-related data easily. For Sri Lanka, it includes web scraping functions that directly retrieve weekly epidemiological reports published by the Epidemiology Unit, Ministry of Health, Sri Lanka. This functionality also cleans the data into a tidy format. Additionally, the package offers various data manipulation functions tailored for dengue data visualization and modeling. You can find the package on GitHub at https://github.com/thiyangt/denguedatahub.\nThe Shiny app provides an interface for non-programmers to access dengue data. It is available at: https://denguedatahub.shinyapps.io/denguedatahub/\nThis website is the home for the projects. It provides tutorials and examples. The site was developed using Quarto.\nWhat impact do you hope the Dengue Data Hub will have?\nMy hope is that the Dengue Data Hub will become a go-to resource for dengue researchers globally. I believe the hub will accelerate dengue research and discoveries which will help in developing effective strategies to combat dengue. The dengue data hub also serves as a\nteaching tool for data science and statistics, as it includes comprehensive data sets.\nDo you have any final thoughts or messages you’d like to share with the research community?\nI invite dengue researchers worldwide to collaborate on this project. I do not have access to clinical trial data, so contributions in that area would be especially valuable. We are looking to expand the datasets available, as comprehensive data sharing is essential for advancing our collective understanding of dengue epidemiology. Additionally, we welcome contributions of data, analytical tools, and insights that can help strengthen the hub’s capacity to serve as a central resource for researchers globally.\nYou can learn more about how to collaborate here. We can build a stronger network to enhance dengue research and response efforts worldwide."
  },
  {
    "objectID": "posts/empowering-dengue-research-through-the-dengue-data-hub/index.html#about-isc-funded-projects",
    "href": "posts/empowering-dengue-research-through-the-dengue-data-hub/index.html#about-isc-funded-projects",
    "title": "Empowering Dengue Research Through the Dengue Data Hub: R Consortium Funded Initiative",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nhttps://r-consortium.org/all-projects/callforproposals.html"
  },
  {
    "objectID": "posts/new-r-user-group-in-thailand-is-building-awareness-of-r/index.html",
    "href": "posts/new-r-user-group-in-thailand-is-building-awareness-of-r/index.html",
    "title": "New R User Group in Thailand is Building Awareness of R",
    "section": "",
    "text": "Dr. Nathakhun Wiroonsri is an academic at the Department of Mathematics, Faculty of Science, King Mongkut’s University of Technology Thonburi in Thailand. With a strong foundation in applied mathematics, Dr. Wiroonsri’s expertise lies in theoretical probability, machine learning, and statistical analysis. His research aims to bridge these areas to develop innovative methodologies for solving real-world problems, particularly in clustering and healthcare applications.\nBeyond his academic pursuits, Dr. Wiroonsri is deeply involved in promoting the use of R in Thailand. He founded R x TH, Thailand’s R user group supported by the R Consortium, to foster collaboration and build a vibrant community for R enthusiasts. His efforts include organizing workshops for beginners, experienced users, and professionals, aiming to make R more accessible and appealing across industries, especially among the younger generation."
  },
  {
    "objectID": "posts/new-r-user-group-in-thailand-is-building-awareness-of-r/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/new-r-user-group-in-thailand-is-building-awareness-of-r/index.html#how-do-i-build-an-r-user-group",
    "title": "New R User Group in Thailand is Building Awareness of R",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/unlocking-chemical-volatility-how-the-volcalc-r-package-is-streamlining-scientific-research/index.html",
    "href": "posts/unlocking-chemical-volatility-how-the-volcalc-r-package-is-streamlining-scientific-research/index.html",
    "title": "Unlocking Chemical Volatility: How the volcalc R Package is Streamlining Scientific Research",
    "section": "",
    "text": "The R Consortium recently interviewed Kristina Riemer, director of the CCT Data Science Team at the University of Arizona, and Eric Scott, Scientific Programmer and Educator in the CCT Data Science Team, the developers behind the volcalc package, to discuss the motivation and development of this innovative tool designed to automate the calculation of chemical compound volatilities. volcalc streamlines the process by allowing users to input a compound and quickly receive its volatility information, eliminating the need for time-consuming manual calculations. Initially created to assist Dr. Laura Meredith in managing a large database of volatile compounds, volcalc has since grown into a more versatile tool under Eric’s leadership, now supporting a wider range of researchers.\nKristina and Eric share insights into the challenges they faced, including managing dependencies, integrating with CRAN and Bioconductor, and refining complex molecular identification methods. They also discuss future enhancements, such as incorporating temperature-specific volatility calculations and expanding the package’s functionality to estimate other compound characteristics. This project was funded by the R Consortium.\nCould you share what motivated the development of the volcalc package and how it aligns with the broader goals of the R ecosystem, particularly in scientific computing?\nKristina: I was heavily involved in the initial development of volcalc, and later on, Eric took over the project. We developed volcalc because we began collaborating with Dr. Laura Meredith, who was compiling a database of volatile chemical compounds. At the time, she had around 300 compounds, and her students manually gathered details for each one by examining their representations and calculating various associated values. This process was tedious and prone to errors, so we thought there must be a more efficient and automated way to handle it.\nThat’s when we came up with the idea of creating a pipeline where someone could input a compound and quickly receive its volatility information, eliminating the need for all the manual labor. The purpose of volcalc was to transform the process from taking months to gather details for 300 compounds to obtaining information for thousands in a much shorter time.\nEric: volcalc was initially developed specifically for a project where the researchers were mainly interested in chemical compounds from the KEGG database (Kyoto Encyclopedia of Genes and Genomes). When I joined the team and learned about the project, I was thrilled because, as a chemical ecologist, I saw its potential. However, I also recognized a limitation: the tool only worked with the KEGG database. This was a drawback because many researchers, including food scientists and others who work with similar compounds, might not find their compounds in that specific database.\nThis realization inspired me to apply for the R Consortium grant. We saw a significant opportunity to expand volcalc, making it more flexible and applicable to a wider range of researchers. We also wanted to improve its integration within the R ecosystem by adding features like returning the file path of a molecule representation after downloading it, so it could be easily piped into subsequent steps. These enhancements aimed to make the tool more versatile and user-friendly for a broader audience.\nWhat were the most significant challenges you faced during the development of the initial version of volcalc, and how did you overcome them?\nKristina: One of the most challenging aspects of developing volcalc, which continues to be an issue, is managing dependencies. Specifically, we rely heavily on a command-line program to handle much of the processing. Early on, we struggled with how to enable users to run volcalc without needing to install this program on their own computers, as many of our users aren’t familiar with that kind of setup. I spent a lot of time trying to create a reproducible environment using Binder, but I was never able to get it fully working. Even today, there are still issues related to managing these dependencies, which Eric can elaborate on further.\nIt was incredibly important to have Eric on this project because I don’t have a strong background in chemistry. His ability to come in and figure out some of the intricate details that would have taken me much longer to grasp was a huge advantage. The more we can collaborate with domain experts, the better our results will be.\nEric: One thing that has helped with the dependency challenges is that we’ve started building volcalc on R-Universe, which means binaries are available there. While it’s not on CRAN yet, having these binaries on R-Universe makes installation a bit easier. However, we’ve faced some challenges with dependencies, particularly because two of them are from Bioconductor. We didn’t originally aim to develop this package for Bioconductor, which uses S4 objects and has different standards than CRAN. Our goal was to get it on CRAN, but our first submission was rejected because the license field for the Bioconductor package wasn’t formatted to CRAN’s liking. These differences between Bioconductor and CRAN have created barriers, even though the authors of the Bioconductor package have been very responsive. Their package works fine on Bioconductor, but it doesn’t meet CRAN’s criteria, which has been a frustrating challenge.\nAnother major challenge in developing volcalc relates to the method we use for estimating volatility. This method involves counting the numbers of different functional groups on molecules—such as hydroxyl groups or sulfur atoms—and assigning coefficients to them. To do this programmatically, we use something called SMARTS, which is essentially like regular expressions but for molecular structures. Regular expressions for text are already challenging, but SMARTS is even more complex because it deals with three-dimensional molecules.\nBefore I joined the group, the first version of volcalc had most of these functional groups figured out, but not all. I spent a significant amount of time trying to develop SMARTS strings to match additional molecules. Moving forward, I hope that if we implement new versions, we can get help from the community to refine these SMARTS strings, as there are likely people out there who are more skilled at it than I am.\nThe original project proposal mentions expanding volcalc to work with any chemical compound with a known structure. What are the key technical challenges you anticipate in achieving this goal?\nEric: This task turned out to be less difficult than I initially expected, but let me explain. In the original version of volcalc, before we received the R Consortium funding, the main function started with a KEGG ID—an identifier specific to the KEGG database. The function would download a MOL file, which is a text representation of a molecule corresponding to that ID. It would then identify and count the functional groups in the molecule, and finally, calculate the volatility based on those counts.\nThe major change we needed to implement to make volcalc more versatile was to decouple these steps. In the current version of volcalc, the functionality to download a MOL file from KEGG is still available, but it’s now separate from the main function that calculates volatility. This means that the inputs for calculating volatility can now be any MOL file, not just ones from KEGG. The file can come from any database, be exported from other software, or even be downloaded manually. Additionally, the tool now supports SMILES, which is another, simpler text-based representation of molecules.\nThere are various ways to represent chemicals in text, including another format called InChI. The Bioconductor packages we use, ChemmineR and ChemmineOB, have the ability to translate from InChI and other types of chemical representations. However, that feature isn’t available on Windows. So, I decided to keep volcalc focused on SMILES and MOL files. I believe that chemists and other researchers should be able to obtain data in one of these two formats, or use another tool to translate their data into these formats. I didn’t want to overload volcalc with the responsibility of being a chemical representation translator, as that didn’t seem like its primary purpose.\nCan you walk us through the process of implementing the SIMPOL algorithm within the volcalcc package?\nKristina: The algorithm itself is fairly simple; it’s just basic math. You need to input some constants, the mass of the compound, and the counts of the functional groups we discussed earlier. Writing the code for this was straightforward and not particularly challenging.\nEric: Each functional group has a coefficient associated with it, which is multiplied by the number of times that group appears in the molecule. These values are then summed up, and the mass of the molecule is factored in as well. The challenging part wasn’t the algorithm itself, which is straightforward—just multiplying by coefficients and adding them up. The real difficulty was interpreting what the authors of the algorithm meant by each of the functional groups. Some were oddly specific, like how the hydroxyl group that is part of a nitrophenol group isn’t supposed to count toward the total number of hydroxyl groups. I spent a lot of time poring over the paper, particularly one table, to fully understand how they defined each group. That interpretation was the hardest part.\nWhat future functionalities or expansions do you see as crucial for volcalc, especially in the context of evolving research needs in chemoinformatics?\nEric: Right now, we’re working on allowing users to specify different temperatures. The paper that describes the SIMPOL.1 method includes equations for how the coefficients of each functional group change with temperature. These changes aren’t always linear, and the contributions of functional groups can shift in importance as the temperature varies. This is an important feature to include because the version of volcalc we currently have uses coefficients calculated at 20°C, based on a table from the original paper. To accommodate other temperatures, we need to integrate another table that provides equations for calculating these coefficients based on temperature, and that’s what we’re working on.\nAnother key feature we want to leave room for in the future is the ability to add other methods for estimating volatility. SIMPOL.1 is just one type of group contribution method, but there are other approaches described in various papers that use different functional groups, equations, and coefficients. The basic idea remains the same: count the functional groups in a molecule, apply an equation, and estimate volatility. We’re trying to structure the code in a way that makes it easy to incorporate additional methods later, even if we don’t add them right away. I think these are the most important features we’re focusing on right now.\nKristina: We’re focused on the features I mentioned in the near future, but looking further ahead, I could see volcalc expanding to estimate other characteristics of compounds beyond just volatility. While I’m not a chemistry expert or a chemical ecologist, I imagine that those interested in volatility might also be interested in other compound characteristics that currently lack automated tools for estimation. So, it’s possible the package could evolve to include those features.\nThat said, one of the things I appreciate about the R package ecosystem is that it allows for specialized tools. Since anyone can build what they need, we don’t end up with massive, overly complex packages that try to do everything and become difficult to maintain. It might be better to keep volcalc focused and leave room for separate packages to handle additional functionality. This way, the tools remain manageable and easier to maintain in the long run.\nHow has it been working with the R Consortium? Would you recommend applying for an ISC grant to other R developers?\nKristina: The application process was straightforward, and I found the grant format to be very practical. It was focused on milestones and product development, which is refreshing compared to many academic research grants that tend to avoid specific deliverables. I highly recommend considering this grant. I believe people often overlook smaller funding sources, but even small amounts can make a big impact on the work you’re doing.\nEric: The first time I applied for an R Consortium grant was as a grad student, and I strongly encourage trainees to apply as well. It was a great experience for me because I could do it independently—my advisor wasn’t involved as one of the authors, and it wasn’t a complex process like applying for an NSF grant. It was straightforward and really rewarding. The only tricky part was figuring out the payment process, but that’s something people can work out.\nI’ve noticed there seem to be fewer projects in recent years, and I don’t think it’s due to a lack of funding. It seems like fewer people are applying, which is why I especially encourage others to give it a shot. From what I’ve seen, there’s a very good chance of getting funded if you apply right now.\nPeople should be creative and think broadly about how their project can benefit the broader R community. This doesn’t mean you need to develop the next big thing like R-Universe or CRAN. It can be something smaller, like a package that other R users will find helpful. For example, with our project, volcalc, our main goal was to encourage chemists—who usually use point-and-click software—to start using R. That was enough of a contribution to the R community to get funded. So, I really encourage people to think creatively about what “benefiting the R community” can mean."
  },
  {
    "objectID": "posts/unlocking-chemical-volatility-how-the-volcalc-r-package-is-streamlining-scientific-research/index.html#about-isc-funded-projects",
    "href": "posts/unlocking-chemical-volatility-how-the-volcalc-r-package-is-streamlining-scientific-research/index.html#about-isc-funded-projects",
    "title": "Unlocking Chemical Volatility: How the volcalc R Package is Streamlining Scientific Research",
    "section": "About ISC Funded Projects",
    "text": "About ISC Funded Projects\nA major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nLearn More!"
  },
  {
    "objectID": "posts/r-universe-named-r-consortiums-newest-top-level-project/index.html",
    "href": "posts/r-universe-named-r-consortiums-newest-top-level-project/index.html",
    "title": "R-Universe Named R Consortium’s Newest Top Level Project",
    "section": "",
    "text": "The R Consortium is proud to announce our newest top level project, R-Universe. R-universe is a platform for improving publication and discovery of research software in R, developed by rOpenSci.\nCritical R community projects that need support over a longer time period are evaluated by the Infrastructure Steering Committee (ISC) for long-term status. Being designated Top Level gives a project guaranteed funding for 3 years, along with a voting seat on the ISC.\n“The ability to find and evaluate high quality R packages is important to the R community, and the R Consortium is pleased to support the R-Universe project with a long-term commitment to help strengthen the foundation of the R package ecosystem,” said Terry Christiani, R Consortium executive director. “We are pleased to be working more closely together with rOpenSci on this effort.”\nR-Universe will be joining R Consortium’s three current Top Level Projects:\n\nDBI - R’s interface to databases\nR-Ladies - Promoting diversity in the R community with 200+ groups worldwide\nR User Group Support Program (RUGS) - facilitating person-to-person exchange of knowledge in small group settings on a global scale\n\n“R-universe provides a searchable catalog for R software, articles, datasets, anywhere in the ecosystem, and it is an open platform for running CRAN-like package repositories ranging from personal to lab to industry-scale production to make your work visible and accessible to a big audience, with or without CRAN,” said Noam Ross, rOpenSci executive director. “We are very excited to continue to strengthen R infrastructure and work closely with the R Consortium.”\nR-universe allows users and developers of R packages to:\n\nDiscover: R-universe provides a searchable catalog for R software, articles, datasets, anywhere in the ecosystem. It is indexed and ranked using R specific features.\nLearn: R-universe serves rendered material and extensive background information to learn about a package and get started using it.\nPublish: R-universe is an open platform for running personal CRAN-like package repositories to make work public and accessible to a big audience, with or without CRAN.\nDevelop: R-universe provides a zero-config development environment for continuous integration (identify upcoming breakage before release), experimental R features, new platforms such as WebAssembly, and more.\n\nFor more information about the R Consortium’s Top Level Projects, please visit: https://r-consortium.org/all-projects/"
  },
  {
    "objectID": "posts/r-ladies-cotonou-a-community/index.html",
    "href": "posts/r-ladies-cotonou-a-community/index.html",
    "title": "R-Ladies Cotonou – A Community that Makes R Accessible for French-Speaking African Women",
    "section": "",
    "text": "Nadejda Sero, the founder of the R Ladies Cotonou chapter, shared with the R Consortium her experiences learning R, the challenges of running an R community in a developing country, and her plans for 2024. She also emphasized the importance of considering the realities of the local R community when organizing an R User Group (RUG).\nPlease share about your background and involvement with the RUGS group.\nMy name is Nadejda Sero, and I am a plant population and theoretical ecologist. I have a Bachelor of Science in Forestry and Natural Resources Management and a Master of Science in Biostatistics from the University of Abomey-Calavi (Benin, West Africa). I discovered R during my Master’s studies in 2015. From the first coding class, I found R exciting and fun. However, as assignments became more challenging, I grew somewhat frustrated due to my lack of prior experience with a programming language.\nSo, I jumped on Twitter (current X). I tweeted, “The most exciting thing I ever did is learning how to code in R!” The tweet caught the attention of members of the R Ladies global team. They asked if I was interested in spreading #rstats love with the women’s community in Benin. I was thrilled by the opportunity and thus began my journey with R-Ladies Global.\nThe early days were challenging due to the novelty of the experience. I did not know much about community building and social events organization. I started learning about the R-Ladies community and available resources. The most significant work was adjusting the resources/tools used by other chapters to fit my realities in Benin. My country, a small French-speaking developing African country, had poor internet access and few organizations focused on gender minorities. (We are doing slightly better now.) On top of that, I often needed to translate some materials into French for the chapter.\nAs I struggled to make headway, the R-Ladies team launched a mentoring program for organizers. I was fortunate enough to participate in the pilot mentorship. The program helped me understand how to identify, adjust, and use the most effective tools for R-Ladies Cotonou. I also gained confidence as an organizer and with community work. With my fantastic mentor’s help, I revived the local chapter of R-Ladies in Cotonou, Benin. I later joined her in the R-Ladies Global team to manage the mentoring program. You can read more about my mentoring experience on the R-Ladies Global blog.\nHappy members of R-Ladies Cotonou sharing some pastries after the presentation. At our first official meetup, the attendees discovered and learned everything about R-Ladies Global and R-Ladies Cotonou.\nI am grateful for the opportunity to have been a part of the R-Ladies community these last six years. I also discovered other fantastic groups like AfricaR. I am particularly proud of the journey with R-Ladies Cotonou. I am also thankful to the people who support us and contribute to keeping R-Ladies Cotonou alive.\nCan you share what the R community is like in Benin?\nR has been commonly used in academia and more moderately in the professional world over the past 2-3 years. For example, I worked with people from different areas of science. I worked in a laboratory where people came to us needing data analysts or biostatisticians. We always used R for such tasks, and many registered in R training sessions. The participants of these sessions also came from the professional world and public health. I have been out of the country for a while now, but the R community is booming. More people are interested in learning and using R in different settings and fields. I recently heard that people are fascinated with R for machine learning and artificial intelligence. It is exciting to see that people are integrating R into various fields. There are also a few more training opportunities for R enthusiasts.\nCan you tell us about your plans for the R Ladies Cotonou for the new year?\nMore meetups from our Beninese community, other R-Ladies chapters, and allies.\nWe are planning a series of meetups that feature students from the training “Science des Données au Féminin en Afrique,” a data science with R program for francophone women organized by the Benin chapter of OWSD (Organization for Women in Science for the Developing World). We have three initial speakers for the series: the student who won the excellence prize and the two grantees from R-Ladies Cotonou. The program is an online training requiring good internet, which is unfortunately expensive and unreliable. If you want good internet, you must pay the price.\nR-Ladies Cotonou supported two students (from Benin and Burkina Faso) by creating a small “internet access” grant using the R Consortium grant received in 2020.\nThe meetup speaker is taking us through a review of the most practical methods of importing and exporting datasets in R. The attendees are listening and taking notes.\nThis next series of meetups will focus on R tutorials with a bonus. The speakers will additionally share their stories embracing R through the training. The first speaker, Jospine Doris Abadassi, will discuss dashboard creation with Shiny and its potential applications to public health. I hope more folks from the training join the series to share their favorite R tools.\nI believe these meetups will assist in expanding not only the R-Ladies but the entire R community. I particularly enjoy it when local people share what they have learned. It further motivates the participants to be bold with R.\nAbout “Science des Données au Féminin en Afrique“, it is the first time I know that a data science training is free for specifically African women from French-speaking areas. Initiated by Dr. Bernice Bancole and Prof. Thierry Warin, the program trains 100 African francophone women in data science using R, emphasizing projects focused on societal problem resolution. The training concluded its first batch and is now recruiting for the second round. So, the community has expanded, and a few more people are using R. I appreciate that the training focuses on helping people develop projects that address societal issues. I believe that it enriches the community.\nAs I said in my last interview with the R consortium, “In some parts of the world, before expecting to find R users or a vivid R community, you first need to create favorable conditions for their birth – teach people what R is and its usefulness in professional, academic, and even artistic life.” It is especially true in Benin, whose official language is French. English is at least a third language for the average multilingual Beninese. Many people are uncomfortable or restrained in using R since most R materials are in English. I hope this OWSD Benin training receives all the contributions to keep running long-term. You can reach the leading team at owsd.benin@gmail.com.\nOur other plan is to collaborate with other R-Ladies chapters and RUGS who speak French. If you speak French and want to teach us something, please email cotonou@rladies.org.\nOtherwise, I will be working on welcoming and assisting new organizers for our chapter. So, for anyone interested, please email cotonou@rladies.org.\nAre you guys currently hosting your events online or in-person? And what are your plans for hosting events in 2024?\nWe used to hold in-person events when we started. Then, the COVID-19 pandemic hit, and we had to decide whether to hold events online. Organizing online events became challenging due to Cotonou’s lack of reliable internet access or expensive packages. As a result, we only held one online event with poor attendance. We took a long break from our activities.\nGoing forward, our events will be hybrid, a mix of in-person and online events. In-person events will allow attendees to use the existing infrastructure of computers and internet access of our allies. It also offers an opportunity to interact with participants. Therefore, I am working with people in Cotonou to identify locations with consistent internet access where attendees can go to attend the meetups. Online events will be necessary to accommodate speakers from outside of the country. It will be open to attendees unable to make it in person.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nThe techniques and tools should depend on the realities of the community. What language is comfortable for attendees? What meeting modality, online or in person, works best for participants?\nAs mentioned earlier, I was inexperienced, and organizing a chapter was daunting. My mentoring experience shifted my perspective. I realized that I needed to adjust many available resources/tools. Organizing meetups became easier as I integrated all these factors.\nFor example, our chapter prioritizes other communication and advertisement tools like regular emails and WhatsApp. The group is mildly active on social media, where the R community is alive (X/Twitter, Mastodon). It is easier to have a WhatsApp group to share information due to its popularity within our community. We recently created an Instagram account and will get LinkedIn and Facebook pages (with more co-organizers). I would love a website to centralize everything related to R-Ladies Cotonou. Using emails is an adjustment to Meetup, which is unpopular in Benin. Getting sponsors or partners and providing a few small grants for good internet would help tremendously our future online events.\nAdjusting helps us to reach people where they are. It is imperative to consider the community, its realities, and its needs. I often asked our meetup participants their expectations, “What do you anticipate from us?” “What would you like to see in the future?” Then, I take notes. Also, we have Google Forms to collect comments, suggestions, potential speakers, contributors, and preferred meeting times. It is crucial to encourage people to participate, especially gender minorities less accustomed to such gatherings.\nI have also attempted to make the meetups more welcoming and friendly in recent years. I always had some food/snacks and drinks available (thanks to friends and allies). It helps make people feel at ease and focus better. I hope the tradition continues for in-person meetups. It is valuable to make the meetups welcoming and friendly. How people feel is essential. If they come and feel like it is a regular lecture or course, they may decide to skip it. But, if they come to the meetup and learn while having fun, or at the very least, enjoy it a little, it benefits everyone.\nThese are some of the key aspects to consider when organizing a meetup. It is critical to consider the people since you are doing it for them. Also, make sure you have support and many co-organizers if possible.\nAll materials live on our GitHub page for people who can’t attend physical events. Another solution would be recording and uploading the session on the R-Ladies Global YouTube or our channel.\nWhat industry are you currently in? How do you use R in your work?\nI am now a Ph.D. student in Ecology and Evolutionary Biology at the University of Tennessee in Knoxville.\nR has no longer been my first programming language since I started graduate school. I still use R for data tidying data analysis but less extensively. I worked a lot with R as a master’s student and Biostatistician. It was constant learning and growth as a programmer. I had a lot of fun writing my first local package. However, I now work more with mathematical software like Maple and Mathematica. I wish R were as smooth and intuitive as this software for mathematical modeling. I like translating Maple code to R code, especially when I need to make visualizations.\nI am addicted to ggplot2 for graphs. I love learning new programming languages but am really attached to R (it’s a 9-year-old relationship now). I developed many skills while programming in R. R helped me become intuitive, a fast learner, and sharp with other programming languages.\nMy most recent project that utilized R, from beginning to end, was a project in my current lab on the evolutionary strategies of plants in stochastic environments. We used R for demographic data tidying and wrangling. Data analysis was a mix of statistical and mathematical models. It was a good occasion to practice writing functions and use new packages. I enjoy writing functions for any task to automate repetitive tasks, which reduces the need for copying and pasting code. I also learned more subtleties in analyzing demographic data from my advisor and colleagues who have used R longer."
  },
  {
    "objectID": "posts/r-ladies-cotonou-a-community/index.html#how-do-i-join",
    "href": "posts/r-ladies-cotonou-a-community/index.html#how-do-i-join",
    "title": "R-Ladies Cotonou – A Community that Makes R Accessible for French-Speaking African Women",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "media-partners.html",
    "href": "media-partners.html",
    "title": "Media Partners",
    "section": "",
    "text": "Media Partners\nThe R Consortium is proud to partner with the following media and associations to amplify information about R community activities around the globe. If you are interested in becoming a media partner, please contact us at info@r-consortium.org.\n\nR news and tutorials contributed by hundreds of R bloggers"
  },
  {
    "objectID": "about/join.html",
    "href": "about/join.html",
    "title": "Why Join the R Consortium?",
    "section": "",
    "text": "The R Consortium is the mechanism for corporate entities and other organizations to support  and engage with the R Community. Membership in the R Consortium signals community leadership, a long term viewpoint, and an appreciation for the efforts of R’s open source contributors. Membership shows commitment and a desire to contribute to the community, strengthening it for the benefit of all.\n\n\n\nHelps fund key R infrastructure such as the R-Hub build system, database interfaces, distributed computing architecture, regional conferences, local R user groups and more.\nProvides a way for companies to generate industry-wide support for projects that they see as valuable.\n\nThe bulk of the R Consortium budget goes directly to funding key community projects.\n\nThrough participation in the R Consortium Infrastructure Steering Committee (ISC), members have a voice in the process of selecting projects and the opportunity to guide their development.\nGives companies direct access to the R Foundation:\n\nBoard members interact with the R Foundation’s representative on the R Consortium Board of Directors.\nISC members:\n\nWork side-by-side with R Foundation members engaged in technical projects,\nParticipate in regular meetings with R Foundation members.\n\n\nProvides insight and access to accurate and up-to-date knowledge about important developments in the the R Community and the extended R ecosystem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenefits by member class\nPlatinum\nSilver\n\n\n\n\nOne seat on the Board of Directors with full voting rights\n\n\n\nCheck\n\n\n\n\n\n\n\nXmark\n\n\n\n\n\n\nOne seat on the ISC with full voting rights\n\n\n\nCheck\n\n\n\n\n\n\n\nXmark\n\n\n\n\n\n\nElect Silver representatives to the Board and ISC (1 Board seat per 3 Silver members, 1 ISC seat for all Silver members)\n\n\n\nXmark\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nCompany logo on R Consortium website and collateral\n\n\n\nCheck\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nR Consortium logo on company website\n\n\n\nCheck\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nMembership dues (annually)\nUS$100,000\n100+ FTE US $25,000 &lt;100 FTE / non-profits, universities US $10,000\n\n\n\n\n\n\n\n\n\n\nReview the Membership Documents.\n\n\nR Consortium Membership Datasheet (PDF)\nR Consortium Bylaws (PDF)\nR Consortium Membership Agreement (PDF)\nR Consortium – Certificate of Incorporation (PDF)\n\n\nFill out our online membership application form.\nRemit the annual dues payment that is applicable for your membership level.\nBegin participating in Events, Discussions, Projects and working Groups.\n\nIf you have questions about membership or joining the R Consortium, please contact our member support desk and you will be contacted as soon as possible. Thank you."
  },
  {
    "objectID": "about/join.html#membership-in-the-r-consortium",
    "href": "about/join.html#membership-in-the-r-consortium",
    "title": "Why Join the R Consortium?",
    "section": "",
    "text": "Helps fund key R infrastructure such as the R-Hub build system, database interfaces, distributed computing architecture, regional conferences, local R user groups and more.\nProvides a way for companies to generate industry-wide support for projects that they see as valuable.\n\nThe bulk of the R Consortium budget goes directly to funding key community projects.\n\nThrough participation in the R Consortium Infrastructure Steering Committee (ISC), members have a voice in the process of selecting projects and the opportunity to guide their development.\nGives companies direct access to the R Foundation:\n\nBoard members interact with the R Foundation’s representative on the R Consortium Board of Directors.\nISC members:\n\nWork side-by-side with R Foundation members engaged in technical projects,\nParticipate in regular meetings with R Foundation members.\n\n\nProvides insight and access to accurate and up-to-date knowledge about important developments in the the R Community and the extended R ecosystem."
  },
  {
    "objectID": "about/join.html#how-r-consortium-membership-helps-support-the-r-community",
    "href": "about/join.html#how-r-consortium-membership-helps-support-the-r-community",
    "title": "Why Join the R Consortium?",
    "section": "",
    "text": "Benefits by member class\nPlatinum\nSilver\n\n\n\n\nOne seat on the Board of Directors with full voting rights\n\n\n\nCheck\n\n\n\n\n\n\n\nXmark\n\n\n\n\n\n\nOne seat on the ISC with full voting rights\n\n\n\nCheck\n\n\n\n\n\n\n\nXmark\n\n\n\n\n\n\nElect Silver representatives to the Board and ISC (1 Board seat per 3 Silver members, 1 ISC seat for all Silver members)\n\n\n\nXmark\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nCompany logo on R Consortium website and collateral\n\n\n\nCheck\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nR Consortium logo on company website\n\n\n\nCheck\n\n\n\n\n\n\n\nCheck\n\n\n\n\n\n\nMembership dues (annually)\nUS$100,000\n100+ FTE US $25,000 &lt;100 FTE / non-profits, universities US $10,000\n\n\n\n\n\n\n\n\n\n\nReview the Membership Documents.\n\n\nR Consortium Membership Datasheet (PDF)\nR Consortium Bylaws (PDF)\nR Consortium Membership Agreement (PDF)\nR Consortium – Certificate of Incorporation (PDF)\n\n\nFill out our online membership application form.\nRemit the annual dues payment that is applicable for your membership level.\nBegin participating in Events, Discussions, Projects and working Groups.\n\nIf you have questions about membership or joining the R Consortium, please contact our member support desk and you will be contacted as soon as possible. Thank you."
  },
  {
    "objectID": "about/governance.html",
    "href": "about/governance.html",
    "title": "Governance",
    "section": "",
    "text": "The primary mission of the R Consortium is to develop and implement infrastructure projects to support the R community. As a Linux Foundation Project, the R Community embraces principles of openness and collaboration as defined in the Code of Conduct."
  },
  {
    "objectID": "about/governance.html#board-of-directors",
    "href": "about/governance.html#board-of-directors",
    "title": "Governance",
    "section": "Board of Directors",
    "text": "Board of Directors\nThe business of the foundation is managed by its Board of Directors, composed of appointed Platinum members of the R Consortium, annually elected Silver members of the R Consortium, and the ISC appointed director as defined in the ByLaws (PDF).\n\n\n\n\nMehar Singh\n\n\nPROCOGIA (SILVER MEMBER REPRESENTATIVE)(R CONSORTIUM CHAIR)\n\n\nMehar founded ProCogia a decade ago to offer more value and better service to clients than traditional consulting firms. Mehar has a background in Electrical Engineering and has worked primarily in consulting, technology and telecom sectors. He has held board positions at R Consortium, University of Washington, Society of Punjabi Engineers & Technologists to name a few. He is passionate about open-source technology, developing innovative products, skydiving and sea fishing.\n\n\n\n\n\n\n\n\nDavid Smith\n\n\nMICROSOFT (PLATINUM MEMBER)(R CONSORTIUM TREASURER)\n\n\nDavid Smith is a developer advocate at Microsoft, with a focus on data science and the R community. With a background in Statistics, he writes regularly about applications of R at the Revolutions blog (blog.revolutionanalytics.com), and is a co-author of “Introduction to R”, the R manual. Follow David on Twitter as @revodavid\n\n\n\n\n\n\nKieran Martin\n\n\nKieran works in the Data Sciences Department in Product Development at Roche. There he has been heavily involved in the creation of OCEAN, the new data science platform which is enabling the use of R in clinical reporting. He led R Enablement from 2020-2024, helping spearhead the transition to using R in this context. In 2024 he co-chaired the program committe for UseR!\n\n\nROCHE (PLATINUM MEMBER)\n\n  \n\n\n\n\nMichael Lawrence\n\n\nR FOUNDATION (R FOUNDATION REPRESENTATIVE)\n\n\nMichael is a scientist in the Bioinformatics and Computational Biology department at Genentech Research and Early Development (gRED), based in South San Francisco, CA. There he leads the development of tools, applications and environments for analyzing genomic data using R and Bioconductor. His research interests are in visualization, software interfacing, and genomic data manipulation. Michael is a member of the Bioconductor Technical Advisory Board, the R Core team, and the R Foundation Board.\n\n \n\n\n\n\nHenrik Bengtsson\n\n\nR FOUNDATION (R FOUNDATION REPRESENTATIVE) (ISC DIRECTOR)\n\n\nHenrik Bengtsson is an Associated Professor at University of California, San Francisco, a member of the R Foundation, with a background in Computer Science and Mathematical Statistics. He has used R since 2000 for applied research in statistics and bioinformatics. He develops statistical methods, scientific computational software, and programming tools. His work includes R packages for science (e.g. matrixStats, and PSCBS, aroma.affymetrix) and software development (e.g. future, profmem, startup, and R.rsp).\n\n   \n\n\n\n\nHadley Wickham\n\n\nPOSIT (PLATINUM MEMBER)\n\n\nHadley is Chief Scientist at RStudio, a member of the R Foundation, and Adjunct Professor at Stanford University and the University of Auckland. He builds tools (both computational and cognitive) to make data science easier, faster, and more fun. His work includes packages for data science (the tidyverse: including ggplot2, dplyr, tidyr, purrr, and readr) and principled software development (roxygen2, testthat, devtools). He is also a writer, educator, and speaker promoting the use of R for data science. Learn more on his website, http://hadley.nz.\n\n       \n\n\n\n\nJared Lander\n\n\nLANDER ANALYTICS (SILVER MEMBER REPRESENTATIVE)\n\n\nJared P. Lander is Chief Data Scientist of Lander Analytics, the Organizer of the New York Open Statistical Programming Meetup and the New York R Conference and R in Government Conference, an Adjunct Professor at Columbia Business School, and a Visiting Lecturer at Princeton University. He is the author of R for Everyone (now in its second edition), a book about R Programming geared toward Data Scientists and Non-Statisticians alike. Jared is a frequent speaker at conferences, universities and meetups around the world.\n\n\n\n\n\nBenjamin Arancibia\n\n\nGSK (SILVER MEMBER REPRESENTATIVE)\n\n\nBenjamin Arancibia, Director of Data Science, focuses on enabling the use of R in GSK Biostatistics. He builds tools to make data science fun, reproducible, and helps advocate for the use of R in the department. Ben is passionate about making sure that teams have the right support when using R in production analyses and helping teams learn while delivering. He is an advocate of R and open source technologies internally at GSK and externally speaking about lived experiences at various conferences.\n\n \n\n\n\n\nMike K Smith\n\n\nPFIZER (SILVER MEMBER REPRESENTATIVE)\n\n\nMike K Smith, Lead, R Centre of Excellence and Senior Director Statistics at Pfizer. Mike is a professional geek, helping colleagues from the business lines understand the power of reproducibility, automation and writing good code and helping the IT department understand the needs of the business lines. He is passionate about driving business outcomes through primary research, data and alternative data solutions as well as statistical analysis.\n\n \n\n\n\n\nUday Preetham Palukuru\n\n\nMERCK (SILVER MEMBER REPRESENTATIVE)\n\n\nUday Preetham Palukuru is a Standards lead at Merck &Co., providing leadership to develop and maintain global standards for ADaM implementation, R package development, Open Source package qualification, Computing Platform enhancements and compliance management tools. He has contributed to various internal and external R packages and is a member of the R Validation Hub Executive committee. He actively promotes the use of open source software in clinical trial data analysis via forums and paper publications. He has a PhD in Bioengineering from Temple University.\n\n\n\n\nPhilip Brown\n\n\nBIOGEN (PLATINUM MEMBER)"
  },
  {
    "objectID": "about/governance.html#infrastructure-steering-committee",
    "href": "about/governance.html#infrastructure-steering-committee",
    "title": "Governance",
    "section": "Infrastructure Steering Committee",
    "text": "Infrastructure Steering Committee\n\nAn Infrastructure Steering Committee (ISC) is responsible for the identification, selection, and oversight of infrastructure projects, as well as directing best practices and community leadership within the R community. Voting representatives are appointed by the Platinum and Silver members of the R Consortium, as well as an elected member from the Silver membership class and the project leads for all Top Level Projects as directed in the ISC Charter (PDF)."
  },
  {
    "objectID": "about/governance.html#leadership",
    "href": "about/governance.html#leadership",
    "title": "Governance",
    "section": "Leadership",
    "text": "Leadership\nAs a project operating within the Linux Foundation, the project staff from the Linux Foundation focuses on project growth and health, ensuring a vendor-neutral environment for collaboration.\n\n\n\n\nTerry Christiani\n\n\nEXECUTIVE DIRECTOR\n\n\n30 years of building content strategies to help companies acquire and support customers. Successfully rebranded and created content programs to help build and sell 4 different companies. Built programs to identify and remedy content management issues affecting content performance. Managed outreach programs to open source communities through digital, hybrid, and IRL events.\n\n\n&lt;a target=“_blank” class=“tmm_sociallink” https://www.linkedin.com/in/davehurst/” title=““&gt;   \n\n\n\n\n\nCrystal Mierly\n\n\nPROJECT COORDINATOR\n\n\nCrystal is the project coordinator for R Consortium. She has been supporting technical projects for the last 5 years in a rapidly changing and adapting industry.\n\n\n \n\n\n\n\n\nDr. Amanda Martin\n\n\nDIRECTOR OF PROGRAM MANAGEMENT\n\n\nDr. Amanda Martin is a Director of Program Management for the R Consortium. Amanda has taught and managed technical projects since 2005 with the single desire to improve the entire world."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "R Consortium Mission Statement",
    "section": "",
    "text": "R Consortium Mission Statement\nThe R Consortium promotes the growth and development of the R language and its ecosystem by supporting technical and social infrastructure, fostering community engagement, and driving industry adoption.\nWe work to ensure a thriving, diverse global R community by providing resources, facilitating collaboration, and advocating for the use of R in multiple industry sectors.\nWe provide funding for technical infrastructure through grants and working groups.\nWe provide funding for social infrastructure through grants for R user groups and events around the world.\nWe provide a neutral space where industry, academia, and government can collaborate on mission critical processes and standards."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Consortium",
    "section": "",
    "text": "R User Group Program and Small Conference Funding Program now accepting applications Partner with us to support your meetup or local event.\n\n\nLEARN MORE\n\n\n\n\nFind your local R user group Network with fellow statisticians and learn from your peers.\n\n\nFIND A USER GROUP\n\n\n\n\nR Consortium: Supporting the R community, the R Foundation and organizations developing, maintaining and distributing R software.\n\n\n\n\nFind your local R user group Network with fellow statisticians and learn from your peers.\n\n\nLEARN MORE\n\n\n\n\nR/Medicine Webinar: Visualizing Survival Data with the {ggsurvfit} R Package\n\n\nWebinar Recording\n\n\n\n\nTidy Finance Webinar Series\n\n\nWebinar Information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWHAT IS THE R CONSORTIUM\n\n\nThe central mission of the R Consortium is to work with and provide support to the R Foundation and to the key organizations developing, maintaining, distributing and using R software through the identification, development and implementation of infrastructure projects.\n\n\nThe R language is an open source environment for statistical computing and graphics, and runs on a wide variety of computing platforms. The R language has enjoyed significant growth, and now supports over 2 million users. A broad range of industries have adopted the R language, including biotech, finance, research and high technology industries. The R language is often integrated into third party analysis, visualization and reporting applications.\n\n\n\n   \n\n\n\nGOVERNANCE\n\n\nREAD OUR ANNUAL REPORT 2023\n\n\n\n\nJoining R Consortium\n\n\nIndustry-leading organizations have joined the R Consortium to support an open source governance and foundation model to provide support to the R community, the R Foundation and groups and individuals, using, maintaining and distributing R software.\n\n\nLEARN MORE ABOUT MEMBERSHIP\n\n\n\n\nNeed Help?\n\n\nIf you need help such as with billing, mailing lists or other wise then please use this service desk for support.\n\n\nGET HELP\n\n\n\n\nBLOG\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA new year and the same, unwavering commitment\n\n\nAs we open our first round for Infrastructure Steering Committee call for proposals and R User Groups’ submissions, we want to take a moment to reiterate our mission as the…\n\n\n\nTerry Christiani\n\n\nMar 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPromoting R in Nigeria: How Unilorin R User Group is Making an Impact\n\n\nDr. M.K. Garba and Ezekiel Ogundepo, organizers of the University of Ilorin, shortened to Unilorin R User Group, recently spoke with the R Consortium about their efforts to…\n\n\n\nR Consortium\n\n\nMar 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Submissions Working Group: Pilot 5 Launch and more!\n\n\nThe R Consortium Submission Working Group is excited to announce a new Pilot 5 that aims to deliver an R-based Submission to the FDA using Dataset-JSON. This post also…\n\n\n\nR Consortium\n\n\nFeb 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeville R Users Group: R’s Role in Optimization Research and Stroke Prevention\n\n\nAlberto Torrejon Valenzuela, organizer of the Seville R Users Group, recently spoke with the R Consortium about the dynamic growth of the R community in Seville and the…\n\n\n\nR Consortium\n\n\nFeb 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building\n\n\nJeffrey Stevens, organizer of the Nebraska R User Group, recently spoke with the R Consortium about his efforts to establish a vibrant R community across Nebraska.\n\n\n\nR Consortium\n\n\nFeb 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew R User Group in Thailand is Building Awareness of R\n\n\nDr. Nathakhun Wiroonsri and the RxTH User Group are aiming to make R more accessible and appealing across industries, especially among the younger generation.\n\n\n\nR Consortium\n\n\nJan 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about/thank-you.html",
    "href": "about/thank-you.html",
    "title": "Contributors to this Website",
    "section": "",
    "text": "The R language is open source and is supported worldwide by people who are enthusiastic to learn and improve. The R Consortium supports R infrastructure technology projects, events, webinars, R user groups, and much more. We support the R community and we benefit from it, too.\n\n\nSimisani Ndaba, R-Ladies Gaborone chapter founder and organizer\nIsabella Velásquez, Sr. Product Marketing Manager, Posit\nErik Rodriguez, San Jose State University, Information Science & Data Analytics major\nPhat Ca, University of Hawaii, Computer Science major\nPriyanka Gagneja, R-Ladies Gaborone member\nDaniel D. Sjoberg (he/him) is a Software Engineer at Genentech, contributed R plot to main homepage. Webinar talk here: https://www.r-consortium.org/r-medicine-webinar-visualizing-survival-data-with-the-ggsurvfit-r-package\nChristoph Scheuch is the Head of Artificial Intelligence at the social trading platform wikifolio Financial Technologies AG, contributed R plot to main homepage. Previous webinar here: https://www.r-consortium.org/new-webinar-tidy-finance-and-accessing-financial-data Upcoming webinar series here: https://www.r-consortium.org/tidy-finance-webinar-series"
  },
  {
    "objectID": "about/thank-you.html#the-following-people-have-helped-contribute-to-this-r-consortium-quarto-based-website",
    "href": "about/thank-you.html#the-following-people-have-helped-contribute-to-this-r-consortium-quarto-based-website",
    "title": "Contributors to this Website",
    "section": "",
    "text": "Simisani Ndaba, R-Ladies Gaborone chapter founder and organizer\nIsabella Velásquez, Sr. Product Marketing Manager, Posit\nErik Rodriguez, San Jose State University, Information Science & Data Analytics major\nPhat Ca, University of Hawaii, Computer Science major\nPriyanka Gagneja, R-Ladies Gaborone member\nDaniel D. Sjoberg (he/him) is a Software Engineer at Genentech, contributed R plot to main homepage. Webinar talk here: https://www.r-consortium.org/r-medicine-webinar-visualizing-survival-data-with-the-ggsurvfit-r-package\nChristoph Scheuch is the Head of Artificial Intelligence at the social trading platform wikifolio Financial Technologies AG, contributed R plot to main homepage. Previous webinar here: https://www.r-consortium.org/new-webinar-tidy-finance-and-accessing-financial-data Upcoming webinar series here: https://www.r-consortium.org/tidy-finance-webinar-series"
  },
  {
    "objectID": "about/faq.html",
    "href": "about/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "FAQ\n\nIs the R Consortium committed to R as an open-source project?\nDo I have to be an employee of a member of the R Consortium to contribute to infrastructure projects?\nWas the R community consulted about the projects considered by the R Consortium?\nWhat kinds of projects will the R Consortium undertake?\nHow are R Consortium projects selected and managed?\nAre the leaders of the R Consortium R users?\nCan I review the governance documents for the R Consortium?\nHow is the R Consortium governed?\nAre membership dues tax-deductible?\nCan an individual become a member of the R Consortium?\nWhy the focus on organizations rather than individuals?\nWhat is the relationship between the R Consortium and the Linux Foundation?\nWhat is the relationship between the R Consortium and the R Foundation?\nWho are the members of the R Consortium?\nWhy an R Consortium?\nDo I have to be an employee of a member of the R Consortium to contribute to infrastructure projects?\nCan I review the governance documents for the R Consortium?\nWhat wouldn’t the R Consortium do?\nWhat kinds of projects will the R Consortium undertake?\nWho will be involved?\n\n\n\nIs the R Consortium committed to R as an open-source project?\nDefinitely! The R Consortium’s explicit mission is to “advance the worldwide promotion of and support for the R open source language”, and all of its activities are in support of the Open Source R Project. It will support and promote the use of Open Source R in all contents, including in commercial and business settings.\nAs defined in its charter, the projects of the Infrastructure Steering Committee will focus on support of the user base, support of developers, and general advancement of Open Source R. In particular, a commercial fork of R isn’t compatible with that mission, and won’t be a project of the R Consortium.\n\n\n\nDo I have to be an employee of a member of the R Consortium to contribute to infrastructure projects?\nNo. The R Consortium welcomes contributions of time, effort and ideas for all passionate users and developers of the R language.\n\n\n\nWas the R community consulted about the projects considered by the R Consortium?\nYes. R Consortium projects are proposed by the community to the Infrastructure Steering Committee.\n\n\n\nWhat kinds of projects will the R Consortium undertake?\nThe R Consortium will coordinate and support projects that directly benefit stakeholders within the R user community. Here are some examples of the types of projects the R Consortium might undertake\n\nImproving documentation and tools.\nSponsoring and helping execute conferences and events.\nHelping to scale and build out R infrastructure.\nMaintaining an enhanced website focused on the R user community.\n\nThis is not an exhaustive list. Anyone may propose a project to the Infrastructure Steering Committee, which selects and executes projects.\n\n\n\nHow are R Consortium projects selected and managed?\nThe technical projects undertaken by the R Consortium in support of the R Project and the R Community are overseen by the Infrastructure Steering Committee. The charter of the Infrastructure Steering Committee (ISC) describes its mission, which is to advance the worldwide promotion of and support for R, and to develop projects, technical and infrastructure collaboration initiatives, support specific initiatives related to R. The membership of the ISC is drawn from the Platinum Members, Silver Members and the R Foundation. As the ISC appoints top-level projects, it is expected that those project leads will join the ISC as voting members.\n\n\n\nAre the leaders of the R Consortium R users?\nThe Board Members (including the Chairperson) are appointed or elected by members (depending on the membership class). There is always one board member representing the R Foundation, to provide guidance to the R Consortium in its mission to support the R Project. The remaining Board members are drawn from the membership, and represent the organizations that have joined the R Consortium. All of the current board members have extensive R experience.\nThe members of the Infrastructure Steering Committee are appointed by the Platinum Members, Silver Members, and the R Foundation member, and includes representatives with significant technical experience, including R package developers, community leaders, and the individuals from the R Core Group.\n\n\n\nCan I review the governance documents for the R Consortium?\nYes! You can review the by-laws for the R Consortium (PDF)and the charter for the Infrastructure Steering Committee.\n\n\n\nHow is the R Consortium governed?\nThe R Consortium is governed by the R Consortium Board of Directors, which is made up of representatives determined by its members. (Members of the board are elected or appointed depending on membership levels; for details please see the by-laws.) The Board meets regularly to manage the business of the Consortium. Meetings are led by the Chairperson of the R Consortium, a rotating position held by a board member elected by the Board as a whole.\nThe technical projects undertaken by the R Consortium in support of the R Project and the R Community are overseen by the Infrastructure Steering Committee.\n\n\n\nAre membership dues tax-deductible?\nThe R Consortium is a US-based 501(c)6 non-profit organization. Dues are not tax-deductible as charitable donations by individuals, but under US IRS rules (PDF) may be deductible as trade or business expenses.\n\n\n\nCan an individual become a member of the R Consortium?\nYes, individuals may support the R Consortium by joining as a non-voting associate member. You can also support the R project by contributing to the R Foundation directly.\n\n\n\nWhy the focus on organizations rather than individuals?\nHundreds of companies around the world have invested heavily in R, by building systems on the R platform and by hiring thousands of R developers. The R Consortium provides a means for those companies to invest in the R Project directly, to collaborate on projects of mutual interest to support the R Community as a whole, and to support the ongoing success of the R Project.\n\n\n\nWhat is the relationship between the R Consortium and the Linux Foundation?\nThe R Consortium is an independent organization, but as Collaborative Project of the Linux Foundation, the Linux Foundation provides operational support and guidance.\n\n\n\nWhat is the relationship between the R Consortium and the R Foundation?\nThe R Foundation is the leader of the R Project and the custodian of the R source code and copyright. The R Foundation determines the definition and evolution of the R language.\nThe R Consortium, as an independent entity, exists to support the R Community and the R Project as a whole — and that includes providing support to the R Foundation. That’s why the R Foundation has a guaranteed seat on the Board and the Infrastructure Steering Committee, to represent the interests of the R Foundation and to propose projects to support R itself.\n\n\n\nWho are the members of the R Consortium?\nMembers of the R Consortium include the following types of organizations (PDF): any association, partnership, organization, governmental agency, company, corporation, academic entity, or non-profit entity with an interest in supporting R. (Individuals may also join as associate members.) In addition, the R Foundation is automatically a member and always has a seat on the Board and the Infrastructure Steering Committee. You can see a current list of members here.\n\n\n\nWhy an R Consortium?\nThe R user community has experienced tremendous growth. With growth there is a greater need for cooperation and communication among R users and R stakeholders. R will continually benefit from improvements to its technical tools and resources. The mission of the R Consortium is to help with support and coordination of the important activities of the R Community, via projects selected and executed its Infrastructure Steering Committee.\n\n\n\nDo I have to be an employee of a member of the R Consortium to contribute to infrastructure projects?\nNo! The R Consortium welcomes contributions of time, effort and ideas for all passionate users and developers of the R language. After formal meetings of the Infrastructure Steering Committee have begun (which we anticipate will occur soon), we will distribute information on how project ideas can be submitted to the Infrastructure Steering Committee.\n\n\n\nCan I review the governance documents for the R Consortium?\nYes! You can find copies of the by-laws (PDF) for the R Consortium, Inc. and the charter for the infrastructure steering committee.\n\n\n\nWhat wouldn’t the R Consortium do?\nInterfere with the R language itself and its development.\n\n\n\nWhat kinds of projects will the R Consortium undertake?\nThe R Consortium will coordinate and support projects that directly benefit stakeholders within the R user community, for example:\n\nImproving documentation and tools.\nSponsoring and helping execute conferences and events.\nHelping to scale and build out R infrastructure.\nMaintaining an enhanced website focused on the R user community.\n\n\n\n\nWho is involved?\nR users and stakeholders as members of the consortium in addition to representatives from the R Foundation with operational support provided by The Linux Foundation."
  },
  {
    "objectID": "about/privacy.html",
    "href": "about/privacy.html",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "Effective Date: September 20, 2018\nThe R Consortium, Inc. (“R Consortium”) is a group organized under an open source governance and foundation model to support the worldwide community of users, maintainers and developers of R software. This Privacy Policy describes our policies and procedures about the collection, use, disclosure and sharing of your personal information or personal data when you use our websites and participate in or use our Project sites (collectively, the “Sites”).\nCapitalized terms that are not defined in this Privacy Policy have the meaning given them in our Terms of Use. In this Privacy Policy, “personal information” or “personal data” means information relating to an identified or identifiable natural person. Your use of our Sites, and any dispute over privacy, is subject to this Policy and our Terms of Use, including its applicable limitations on damages and the resolution of disputes. The R Consortium Terms of Use are incorporated by reference into this Policy.\n\n\nWe collect information directly from individuals, from third parties, and automatically through the Sites. You do not have to provide us your personal information. However, if you choose not to disclose certain information, we will not be able to provide you with access to certain services or features, including participation in certain aspects of our open source projects.\nYour Contributions to Open Source Projects.\nAttribution,Provenance and Integrity. When you contribute source code, documentation or other content to one of our Projects (whether on your own behalf or through contributions made as part of your employment services to your employer), we collect and store the information and content that you contribute. This includes the contents of those contributions, as well as data required to confirm the provenance of intellectual property contained in those contributions, and personal information that you make publicly available in the record of the contribution pursuant to sign-offs under the Developer Certificate of Origin (https://developercertificate.org/). Some Projects require additional agreements or information pursuant to their intellectual property policies; in such cases we collect and store information related to your acceptance of those agreements. We may also collect information relating to your participation in technical, governance or other Project-related meetings.\nOther Project-related Content. The content you provide in relation to Projects also includes materials that you make publicly available in connection with Project development, collaboration and communication, such as on mailing lists, blogs, Project wiki pages and issue trackers, and related services.\nYour Content. We collect and store the information and content that you post to the Sites, including your questions, answers, comments, forum postings, and responses to surveys. Please see the section on Publicly Available Information for how the information you post will be viewed on our Sites.\nCommunications. When you communicate with us (via email, phone, through the Sites or otherwise), we may maintain a record of your communication.\nAutomatically Collected Data. In addition, R Consortium may automatically collect the following information about Users’ use of the sites or services through cookies, web beacons, and other technologies: your domain name; your browser type and operating system; web pages you view; links you click; your IP address; the length of time you visit our Sites and or use our services; and the referring URL, or the webpage that led you to our Sites. We may combine this information with other information that we have collected about you, including, where applicable, your user name, name, and other personal information. Please see our cookie policy at https://www.linuxfoundation.org/cookies/ for more information about our use of cookies.\nDe-identified Data. We may de-identify and aggregate certain data we collect such that the data no longer identifies or can be linked to a particular User or an individual data subject (“De-identified Data”), subject to the terms of any applicable User agreements. We may use this data to improve our Services, analyze trends, publish market research, and for other marketing, research or statistical purposes, and may disclose such data to third parties for these specific purposes.\n\n\n\nR Consortium uses the information we collect for our legitimate business interests, which include the following purposes:\nProviding our Sites and Services. To provide the Services and our Sites (including Project Sites), to communicate with you about your use of our Sites and Services, to respond to your inquiries, provide troubleshooting of the Sites and for other purposes to support Users and the community.\nOperating our Open Source Projects. To enable communication between and among open source developers in the community; to facilitate and document Project governance and technical decision making; to maintain, and make publicly available on a perpetual basis, records regarding intellectual property provenance and license compliance for Project contributions; and for related activities to further R Consortium’s purposes, including fostering an ecosystem that supports the collaborative and public development of free and open source software projects. See the “Attribution, Provenance and Integrity” section above for more information.\nPersonalization. To tailor the content and information that we may send or display to you on our Sites and in our Services, to offer location customization and personalized help and instructions and to otherwise personalize your experiences.\nAdvertising. For targeting advertising to you on our Sites and third-party sites and measuring the effectiveness and reach of ads and services (through third-party ad networks and services).\nAnalytics. To gather metrics to better understand how Users access and use our Sites and Services and participate in our Projects; to evaluate and improve the Sites, including personalization, to develop new services; and to understand metrics regarding the community health of our Projects.\nCompliance. To comply with legal obligations and requests. For example, to comply with laws that compel us to disclose information to public authorities, courts, law enforcement or regulators, maintain records for a certain period, or maintain records demonstrating enforcement and sublicensing of our trademarks and those of our Projects.\nBusiness and Legal Operations. As part of our general business and legal operations (e.g., accounting, record keeping, and for other business administration purposes), and as necessary to establish, exercise and defend (actual and potential) legal claims.\nPrevent Misuse. Where we believe necessary to investigate, prevent or take action regarding illegal activities, suspected fraud, situations involving potential threats to the safety of any person or violations of our Terms of Use or this Privacy Policy.\n\n\n\n\n\n\n\n\nPurposes of Processing\nLegal Bases of Processing (EU Users)\n\n\n\n\n\nProviding our Sites and Services\n- Our Legitimate Business Interests- Necessary to the Performance of a Contract with You (upon your request, or as necessary to make the Services available)- Compliance with Law\n\n\n\nOperating our Open Source Projects\n- Our Legitimate Business Interests- Where Necessary to the Performance of a Contract with You (upon your request, or as necessary to enable your participation in the Projects or to make the Services available)- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nPersonalization\n- Our Legitimate Business Interests\n\n\n\nAdvertising\n- Our Legitimate Business Interests- With Your Consent\n\n\n\nAnalytics\n- Our Legitimate Business Interests\n\n\n\nCompliance\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nBusiness and Legal Operations\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nPrevent Misuse\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\n\n\n\n\nWe disclose information as set forth below, and where individuals have otherwise consented:\nPublicly Available Information, including Your Contributions to Open Source Projects. User names, other user ids, email addresses and other attribution information related to the information and contributions that a User posts in conjunction with or subject to an Open Source license are publicly available in the relevant Project source code repositories. Your contributions to Open Source Projects, and certain of your other Content such as comments and messages posted to public forums, are available to other participants and users of our Projects and of our Services, and may be viewed publicly. In some cases you may be able to provide Project or contribution- related information directly to third-party sites and services; these third parties are independent data controllers and their use of your personal information is subject to their own policies.\nService Providers. We may share your information with third party service providers who use this information to perform services for us, such as payment processors, hosting providers, auditors, advisors, contractors and consultants. In addition, The Linux Foundation performs services for R Consortium as a managed services provider with regards to Projects. In such cases, R Consortium may share with The Linux Foundation the same types of data as described above, doing so in the furtherance of performing services for those Projects. The Linux Foundation’s privacy policy is available at https://www.linuxfoundation.org/privacy/.\nAffiliates.The information collected about you may be accessed by or shared with related companies and affiliates of R Consortium, whose use and disclosure of your personal information is subject to this Privacy Policy, unless an affiliate has its own separate privacy policy.\nOranizational Events. We may disclose or transfer information, including personal information, as part of any merger, sale, and transfer of our assets, or restructuring of all or part of our business operations, bankruptcy, or similar event.\nLeally Required. We may disclose your information if we are required to do so by law (including to law enforcement in the U.S. and other jurisdictions).\nProtection of Rights. We may disclose information where we believe it necessary to respond to claims asserted against us or, comply with legal process (e.g., subpoenas or warrants), enforce or administer our agreements and terms, for fraud prevention, risk assessment, investigation, and protect the rights, property or safety of R Consortium, its Users, participants in its Projects, or others.\nAnonmized and Aggreated Data. We may share aggregate or de-identified information with third parties for research, marketing, analytics and other purposes, provided such information does not identify a particular individual.\n\n\n\nWe and our third-party providers use cookies, clear GIFs/pixel tags, JavaScript, local storage, log files, and other mechanisms to automatically collect and record information about your usage and browsing activities on our Site and across third party sites or online services. We may combine this information with other information we collect about Users. Below, we provide a brief summary these activities. For more detailed information about these mechanisms and how we collect activity information, see our Cookie Policy.\nCookies These are small files with a unique identifier that are transferred to your browser through our websites. They allow us to remember Users who are logged in, to understand how Users navigate through and use the Sites, and to display personalized content and targeted ads (including on third party sites and applications).\nPixels, web beacons, clear GIFs These are tiny graphics with a unique identifier, similar in function to cookies, which we track browsing activities. We use these as part of our Training Affiliate Program. We also use these in our emails to let us know when they have been opened or forwarded, so we can gauge the effectiveness of our communications.\nAnalytics Tools We may use internal and third-party analytics tools, including Google Analytics. The third-party analytics companies we work with may combine the information collected with other information they have independently collected from other websites and/or other online products and services. Their collection and use of information is subject to their own privacy policies.\nPlease note that R Consortium does not respond to “do not track” signals or other similar mechanisms intended to allow California residents to opt-out of Internet tracking under California Online Privacy Protection Action (“CalOPPA”).\nTargeted Ads As discussed in our Cookie Policy, we may work with third party advertisers to display more relevant ads on our website and on third party sites; these third parties may display ads to you based on your visit to our Sites and other third party sites. For more information about this and how you can opt out of such ads, please see our Cookie Policy.\n\n\n\nWe have implemented commercially reasonable precautions to protect the information we collect from loss, misuse, and unauthorized access, disclosure, alteration, and destruction. Please be aware that despite our best efforts, no data security measures can guarantee 100% security.\nYou should take steps to protect against unauthorized access to your passwords, phone, and computer by, among other things, signing off after using a shared computer, choosing robust passwords that nobody else knows or can easily guess, not using a password for more than one site or service, and keeping your log-ins and passwords private. We are not responsible for any lost, stolen, or compromised passwords or for any activity on your account via unauthorized password activity. You must promptly notify us if you become aware that any information provided by or submitted to our Sites or through our Services is lost, stolen, or used without permission at privacy@linuxfoundation.org.\n\n\n\nYou may opt out or revoke your consent to receive marketing emails from us by using unsubscribe or opt out mechanisms included in our marketing emails or by emailing privacy@linuxfoundation.org. You may unsubscribe from mailing lists via the applicable mailing list’s subscription website or, in some cases, by using the unsubscribe mechanisms included in such emails.\n\n\n\nWe apply a general rule of keeping personal data only for as long as required to fulfill the purposes for which it was collected. However, in some circumstances, we may retain personal data for other periods of time, for instance where we are required to do so in accordance with legal, tax and accounting requirements, or if required to do so by a legal process, legal authority, or other governmental entity having authority to make the request, for so long as required. In specific circumstances, we may also retain your personal data for longer periods of time corresponding to a statute of limitation, so that we have an accurate record of your dealings with us in the event of any complaints or challenges.\n\n\n\nIf you are located within the European Union (EU) or European Economic Area, you should note that your information will be transferred to the United States where R Consortium is located. The U.S. is deemed by the European Union to have inadequate data protection. However, we have put in place European Commission approved Standard Contractual Clauses which protect personal data transferred between R Consortium and affiliated entities as well as The Linux Foundation, its managed service provider. In addition, if personal data is transferred to third party service providers located outside the European Union, we will take steps to ensure that your personal data receives the same level of protection as if it remained within the EU, including by entering into data transfer agreements, or using the European Commission approved Standard Contractual Clauses. You have a right to obtain details of the mechanism under which your personal data is transferred outside of the EU by contacting privacy@linuxfoundation.org.\n\n\n\nExcept as specifically indicated within a Site, we do not knowingly collect or solicit personal information from anyone under the age of 16, or knowingly allow such persons to register. If we become aware that we have collected personal information from a child under the relevant age without parental consent, we take steps to delete that information.\n\n\n\nThe Sites may contain links to third party sites or online services. We are not responsible for the practices of such third parties, whose information practices are subject to their own policies and procedures, not to this Privacy Policy.\n\n\n\nAccess and Amendment. You may contact our privacy coordinator, as set forth below, to access or amend your personal information.\nAdditional Rights. Individuals in the European Economic Area (and other jurisdictions where applicable) have additional rights under applicable law:\n\nto obtain a copy of your personal data together with information about how and on what basis that personal data is processed;\nto rectify inaccurate personal data (including to have incomplete personal data completed);\nto erase your personal data (in limited circumstances, such as where it is no longer necessary in relation to the purposes for which it was collected or processed);\nto restrict processing of your personal data under certain circumstances;\nto export certain personal data in machine-readable format to a third party (or to you) when we justify our processing on the basis of your consent or the performance of a contract with you;\nto withdraw your consent to our processing of your personal data (where that processing is based on your consent);\nto obtain, or see a copy of the appropriate safeguards under which your personal data is transferred to a third country or international organization; and\nto object to our use and processing of your personal information that is conducted on the basis of a legitimate interest or to perform a contract with you. You also have the right to object at any time to any processing of your personal data for direct marketing purposes, including profiling for marketing purposes.\n\nLodging a Complaint. You also have the right to lodge a complaint with your local supervisory authority for data protection, or privacy regulator.\nSubmitting a Request. To exercise the above rights or contact us with questions or complaints regarding our treatment of your personal data, contact us at privacy@linuxfoundation.org. Please note that we may request proof of identity, and we reserve the right to charge a fee where permitted by law, especially if your request is manifestly unfounded or excessive. We will endeavor to respond to your request within all applicable timeframes.\n\n\n\nCalifornia law permits users who are California residents to request and obtain from us once a year, free of charge, a list of the third parties to whom we have disclosed their personal information (if any) for their direct marketing purposes in the prior calendar year, as well as the types of personal information disclosed to those parties. If you are a California resident and would like to request this information, please submit your request in an email to privacy@linuxfoundation.org.\n\n\n\nIf you have any questions about our practices or this Privacy Policy, please contact us at privacy@linuxfoundation.org, or write to us at: R Consortium, 1 Letterman Drive, Building D, Suite D4700, San Francisco, CA 94129.\n\n\n\nThis Policy is current as of the effective date set forth above. If we change our privacy policies and procedures, we will post those changes on this page and/or continue to provide access to a copy of the prior version. If we make any changes to this Privacy Policy that materially change how we treat your personal information, we will endeavor to provide you with reasonable notice of such changes, such as via prominent notice on our Sites or to your email address of record, and where required by law, we will obtain your consent or give you the opportunity to opt out of such changes."
  },
  {
    "objectID": "about/privacy.html#personal-data-that-r-consortium-collects",
    "href": "about/privacy.html#personal-data-that-r-consortium-collects",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "We collect information directly from individuals, from third parties, and automatically through the Sites. You do not have to provide us your personal information. However, if you choose not to disclose certain information, we will not be able to provide you with access to certain services or features, including participation in certain aspects of our open source projects.\nYour Contributions to Open Source Projects.\nAttribution,Provenance and Integrity. When you contribute source code, documentation or other content to one of our Projects (whether on your own behalf or through contributions made as part of your employment services to your employer), we collect and store the information and content that you contribute. This includes the contents of those contributions, as well as data required to confirm the provenance of intellectual property contained in those contributions, and personal information that you make publicly available in the record of the contribution pursuant to sign-offs under the Developer Certificate of Origin (https://developercertificate.org/). Some Projects require additional agreements or information pursuant to their intellectual property policies; in such cases we collect and store information related to your acceptance of those agreements. We may also collect information relating to your participation in technical, governance or other Project-related meetings.\nOther Project-related Content. The content you provide in relation to Projects also includes materials that you make publicly available in connection with Project development, collaboration and communication, such as on mailing lists, blogs, Project wiki pages and issue trackers, and related services.\nYour Content. We collect and store the information and content that you post to the Sites, including your questions, answers, comments, forum postings, and responses to surveys. Please see the section on Publicly Available Information for how the information you post will be viewed on our Sites.\nCommunications. When you communicate with us (via email, phone, through the Sites or otherwise), we may maintain a record of your communication.\nAutomatically Collected Data. In addition, R Consortium may automatically collect the following information about Users’ use of the sites or services through cookies, web beacons, and other technologies: your domain name; your browser type and operating system; web pages you view; links you click; your IP address; the length of time you visit our Sites and or use our services; and the referring URL, or the webpage that led you to our Sites. We may combine this information with other information that we have collected about you, including, where applicable, your user name, name, and other personal information. Please see our cookie policy at https://www.linuxfoundation.org/cookies/ for more information about our use of cookies.\nDe-identified Data. We may de-identify and aggregate certain data we collect such that the data no longer identifies or can be linked to a particular User or an individual data subject (“De-identified Data”), subject to the terms of any applicable User agreements. We may use this data to improve our Services, analyze trends, publish market research, and for other marketing, research or statistical purposes, and may disclose such data to third parties for these specific purposes."
  },
  {
    "objectID": "about/privacy.html#purposes-and-legal-bases-for-our-using-of-your-information-purposes-and-legitimate-interests",
    "href": "about/privacy.html#purposes-and-legal-bases-for-our-using-of-your-information-purposes-and-legitimate-interests",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "R Consortium uses the information we collect for our legitimate business interests, which include the following purposes:\nProviding our Sites and Services. To provide the Services and our Sites (including Project Sites), to communicate with you about your use of our Sites and Services, to respond to your inquiries, provide troubleshooting of the Sites and for other purposes to support Users and the community.\nOperating our Open Source Projects. To enable communication between and among open source developers in the community; to facilitate and document Project governance and technical decision making; to maintain, and make publicly available on a perpetual basis, records regarding intellectual property provenance and license compliance for Project contributions; and for related activities to further R Consortium’s purposes, including fostering an ecosystem that supports the collaborative and public development of free and open source software projects. See the “Attribution, Provenance and Integrity” section above for more information.\nPersonalization. To tailor the content and information that we may send or display to you on our Sites and in our Services, to offer location customization and personalized help and instructions and to otherwise personalize your experiences.\nAdvertising. For targeting advertising to you on our Sites and third-party sites and measuring the effectiveness and reach of ads and services (through third-party ad networks and services).\nAnalytics. To gather metrics to better understand how Users access and use our Sites and Services and participate in our Projects; to evaluate and improve the Sites, including personalization, to develop new services; and to understand metrics regarding the community health of our Projects.\nCompliance. To comply with legal obligations and requests. For example, to comply with laws that compel us to disclose information to public authorities, courts, law enforcement or regulators, maintain records for a certain period, or maintain records demonstrating enforcement and sublicensing of our trademarks and those of our Projects.\nBusiness and Legal Operations. As part of our general business and legal operations (e.g., accounting, record keeping, and for other business administration purposes), and as necessary to establish, exercise and defend (actual and potential) legal claims.\nPrevent Misuse. Where we believe necessary to investigate, prevent or take action regarding illegal activities, suspected fraud, situations involving potential threats to the safety of any person or violations of our Terms of Use or this Privacy Policy.\n\n\n\n\n\n\n\n\nPurposes of Processing\nLegal Bases of Processing (EU Users)\n\n\n\n\n\nProviding our Sites and Services\n- Our Legitimate Business Interests- Necessary to the Performance of a Contract with You (upon your request, or as necessary to make the Services available)- Compliance with Law\n\n\n\nOperating our Open Source Projects\n- Our Legitimate Business Interests- Where Necessary to the Performance of a Contract with You (upon your request, or as necessary to enable your participation in the Projects or to make the Services available)- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nPersonalization\n- Our Legitimate Business Interests\n\n\n\nAdvertising\n- Our Legitimate Business Interests- With Your Consent\n\n\n\nAnalytics\n- Our Legitimate Business Interests\n\n\n\nCompliance\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nBusiness and Legal Operations\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims\n\n\n\nPrevent Misuse\n- Our Legitimate Business Interests- Compliance with Law- As necessary to establish, exercise and defend legal claims"
  },
  {
    "objectID": "about/privacy.html#sharing-of-information",
    "href": "about/privacy.html#sharing-of-information",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "We disclose information as set forth below, and where individuals have otherwise consented:\nPublicly Available Information, including Your Contributions to Open Source Projects. User names, other user ids, email addresses and other attribution information related to the information and contributions that a User posts in conjunction with or subject to an Open Source license are publicly available in the relevant Project source code repositories. Your contributions to Open Source Projects, and certain of your other Content such as comments and messages posted to public forums, are available to other participants and users of our Projects and of our Services, and may be viewed publicly. In some cases you may be able to provide Project or contribution- related information directly to third-party sites and services; these third parties are independent data controllers and their use of your personal information is subject to their own policies.\nService Providers. We may share your information with third party service providers who use this information to perform services for us, such as payment processors, hosting providers, auditors, advisors, contractors and consultants. In addition, The Linux Foundation performs services for R Consortium as a managed services provider with regards to Projects. In such cases, R Consortium may share with The Linux Foundation the same types of data as described above, doing so in the furtherance of performing services for those Projects. The Linux Foundation’s privacy policy is available at https://www.linuxfoundation.org/privacy/.\nAffiliates.The information collected about you may be accessed by or shared with related companies and affiliates of R Consortium, whose use and disclosure of your personal information is subject to this Privacy Policy, unless an affiliate has its own separate privacy policy.\nOranizational Events. We may disclose or transfer information, including personal information, as part of any merger, sale, and transfer of our assets, or restructuring of all or part of our business operations, bankruptcy, or similar event.\nLeally Required. We may disclose your information if we are required to do so by law (including to law enforcement in the U.S. and other jurisdictions).\nProtection of Rights. We may disclose information where we believe it necessary to respond to claims asserted against us or, comply with legal process (e.g., subpoenas or warrants), enforce or administer our agreements and terms, for fraud prevention, risk assessment, investigation, and protect the rights, property or safety of R Consortium, its Users, participants in its Projects, or others.\nAnonmized and Aggreated Data. We may share aggregate or de-identified information with third parties for research, marketing, analytics and other purposes, provided such information does not identify a particular individual."
  },
  {
    "objectID": "about/privacy.html#cookies-tracking-and-interest-based-ads",
    "href": "about/privacy.html#cookies-tracking-and-interest-based-ads",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "We and our third-party providers use cookies, clear GIFs/pixel tags, JavaScript, local storage, log files, and other mechanisms to automatically collect and record information about your usage and browsing activities on our Site and across third party sites or online services. We may combine this information with other information we collect about Users. Below, we provide a brief summary these activities. For more detailed information about these mechanisms and how we collect activity information, see our Cookie Policy.\nCookies These are small files with a unique identifier that are transferred to your browser through our websites. They allow us to remember Users who are logged in, to understand how Users navigate through and use the Sites, and to display personalized content and targeted ads (including on third party sites and applications).\nPixels, web beacons, clear GIFs These are tiny graphics with a unique identifier, similar in function to cookies, which we track browsing activities. We use these as part of our Training Affiliate Program. We also use these in our emails to let us know when they have been opened or forwarded, so we can gauge the effectiveness of our communications.\nAnalytics Tools We may use internal and third-party analytics tools, including Google Analytics. The third-party analytics companies we work with may combine the information collected with other information they have independently collected from other websites and/or other online products and services. Their collection and use of information is subject to their own privacy policies.\nPlease note that R Consortium does not respond to “do not track” signals or other similar mechanisms intended to allow California residents to opt-out of Internet tracking under California Online Privacy Protection Action (“CalOPPA”).\nTargeted Ads As discussed in our Cookie Policy, we may work with third party advertisers to display more relevant ads on our website and on third party sites; these third parties may display ads to you based on your visit to our Sites and other third party sites. For more information about this and how you can opt out of such ads, please see our Cookie Policy."
  },
  {
    "objectID": "about/privacy.html#data-security",
    "href": "about/privacy.html#data-security",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "We have implemented commercially reasonable precautions to protect the information we collect from loss, misuse, and unauthorized access, disclosure, alteration, and destruction. Please be aware that despite our best efforts, no data security measures can guarantee 100% security.\nYou should take steps to protect against unauthorized access to your passwords, phone, and computer by, among other things, signing off after using a shared computer, choosing robust passwords that nobody else knows or can easily guess, not using a password for more than one site or service, and keeping your log-ins and passwords private. We are not responsible for any lost, stolen, or compromised passwords or for any activity on your account via unauthorized password activity. You must promptly notify us if you become aware that any information provided by or submitted to our Sites or through our Services is lost, stolen, or used without permission at privacy@linuxfoundation.org."
  },
  {
    "objectID": "about/privacy.html#marketing-choices",
    "href": "about/privacy.html#marketing-choices",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "You may opt out or revoke your consent to receive marketing emails from us by using unsubscribe or opt out mechanisms included in our marketing emails or by emailing privacy@linuxfoundation.org. You may unsubscribe from mailing lists via the applicable mailing list’s subscription website or, in some cases, by using the unsubscribe mechanisms included in such emails."
  },
  {
    "objectID": "about/privacy.html#retention-of-your-personal-data",
    "href": "about/privacy.html#retention-of-your-personal-data",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "We apply a general rule of keeping personal data only for as long as required to fulfill the purposes for which it was collected. However, in some circumstances, we may retain personal data for other periods of time, for instance where we are required to do so in accordance with legal, tax and accounting requirements, or if required to do so by a legal process, legal authority, or other governmental entity having authority to make the request, for so long as required. In specific circumstances, we may also retain your personal data for longer periods of time corresponding to a statute of limitation, so that we have an accurate record of your dealings with us in the event of any complaints or challenges."
  },
  {
    "objectID": "about/privacy.html#international-transfers",
    "href": "about/privacy.html#international-transfers",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "If you are located within the European Union (EU) or European Economic Area, you should note that your information will be transferred to the United States where R Consortium is located. The U.S. is deemed by the European Union to have inadequate data protection. However, we have put in place European Commission approved Standard Contractual Clauses which protect personal data transferred between R Consortium and affiliated entities as well as The Linux Foundation, its managed service provider. In addition, if personal data is transferred to third party service providers located outside the European Union, we will take steps to ensure that your personal data receives the same level of protection as if it remained within the EU, including by entering into data transfer agreements, or using the European Commission approved Standard Contractual Clauses. You have a right to obtain details of the mechanism under which your personal data is transferred outside of the EU by contacting privacy@linuxfoundation.org."
  },
  {
    "objectID": "about/privacy.html#childrens-privacy",
    "href": "about/privacy.html#childrens-privacy",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "Except as specifically indicated within a Site, we do not knowingly collect or solicit personal information from anyone under the age of 16, or knowingly allow such persons to register. If we become aware that we have collected personal information from a child under the relevant age without parental consent, we take steps to delete that information."
  },
  {
    "objectID": "about/privacy.html#links-to-third-party-sites-and-services",
    "href": "about/privacy.html#links-to-third-party-sites-and-services",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "The Sites may contain links to third party sites or online services. We are not responsible for the practices of such third parties, whose information practices are subject to their own policies and procedures, not to this Privacy Policy."
  },
  {
    "objectID": "about/privacy.html#your-rights",
    "href": "about/privacy.html#your-rights",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "Access and Amendment. You may contact our privacy coordinator, as set forth below, to access or amend your personal information.\nAdditional Rights. Individuals in the European Economic Area (and other jurisdictions where applicable) have additional rights under applicable law:\n\nto obtain a copy of your personal data together with information about how and on what basis that personal data is processed;\nto rectify inaccurate personal data (including to have incomplete personal data completed);\nto erase your personal data (in limited circumstances, such as where it is no longer necessary in relation to the purposes for which it was collected or processed);\nto restrict processing of your personal data under certain circumstances;\nto export certain personal data in machine-readable format to a third party (or to you) when we justify our processing on the basis of your consent or the performance of a contract with you;\nto withdraw your consent to our processing of your personal data (where that processing is based on your consent);\nto obtain, or see a copy of the appropriate safeguards under which your personal data is transferred to a third country or international organization; and\nto object to our use and processing of your personal information that is conducted on the basis of a legitimate interest or to perform a contract with you. You also have the right to object at any time to any processing of your personal data for direct marketing purposes, including profiling for marketing purposes.\n\nLodging a Complaint. You also have the right to lodge a complaint with your local supervisory authority for data protection, or privacy regulator.\nSubmitting a Request. To exercise the above rights or contact us with questions or complaints regarding our treatment of your personal data, contact us at privacy@linuxfoundation.org. Please note that we may request proof of identity, and we reserve the right to charge a fee where permitted by law, especially if your request is manifestly unfounded or excessive. We will endeavor to respond to your request within all applicable timeframes."
  },
  {
    "objectID": "about/privacy.html#california-privacy-rights",
    "href": "about/privacy.html#california-privacy-rights",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "California law permits users who are California residents to request and obtain from us once a year, free of charge, a list of the third parties to whom we have disclosed their personal information (if any) for their direct marketing purposes in the prior calendar year, as well as the types of personal information disclosed to those parties. If you are a California resident and would like to request this information, please submit your request in an email to privacy@linuxfoundation.org."
  },
  {
    "objectID": "about/privacy.html#contact-us",
    "href": "about/privacy.html#contact-us",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "If you have any questions about our practices or this Privacy Policy, please contact us at privacy@linuxfoundation.org, or write to us at: R Consortium, 1 Letterman Drive, Building D, Suite D4700, San Francisco, CA 94129."
  },
  {
    "objectID": "about/privacy.html#changes-to-the-privacy-policy",
    "href": "about/privacy.html#changes-to-the-privacy-policy",
    "title": "Privacy Policy of R Consortium, Inc.",
    "section": "",
    "text": "This Policy is current as of the effective date set forth above. If we change our privacy policies and procedures, we will post those changes on this page and/or continue to provide access to a copy of the prior version. If we make any changes to this Privacy Policy that materially change how we treat your personal information, we will endeavor to provide you with reasonable notice of such changes, such as via prominent notice on our Sites or to your email address of record, and where required by law, we will obtain your consent or give you the opportunity to opt out of such changes."
  },
  {
    "objectID": "about/contact.html",
    "href": "about/contact.html",
    "title": "Contact Us",
    "section": "",
    "text": "Contact Us\nFor general inquiries, membership inquiries, or requests for access to collaborative infrastructure, please feel free to visit our service desk.\nYou can also send us email directly at info@r-consortium.org\nIf you would like information on becoming a member of the R Consortium, please visit the Join page."
  },
  {
    "objectID": "governance/isc-charter.html",
    "href": "governance/isc-charter.html",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "The mission and goals of the Infrastructure Steering Committee include the following activities:\n\nadvance the worldwide promotion of and support for the R open source language and environment as the preferred language for statistical computing and graphics (the “Environment”);\ncreate, organize, establish, maintain and develop infrastructure projects, technical and infrastructure collaboration initiatives, support specific initiatives related to the Environment and within the budget approved, and as provided by, the Board, and such other initiatives (collectively, “Projects”) as the Infrastructure Steering Committee deems appropriate to support, enable and promote the Environment;\nencourage and increase user adoption, involvement with, and contribution to, the Environment;\nfacilitate communication and collaboration among users and developers of the Environment, the R Consortium and the R Foundation;\nserve as the primary point of contact among the R Consortium and its user and developer base and act as a liaison to open source communities;\noperate within budgets approved by the Board;\nsupport and maintain policies set by the Board; and\nundertake such other activities as may from time to time be appropriate to further the purposes and achieve the goals set forth above.\n\n\n\n\nThe voting membership of the Infrastructure Steering Committee shall consist of:\n\none appointed representative from each Platinum Member;\none appointed representative from the R Foundation Member;\na number of elected representatives, selected by the Silver Members as a class that is equal to the number in the R Consortium Board of Directors elected Silver Representative; and\nthe project lead from each top-level project, subject to section 3.g. below.\n\n\n\n\n\nThe Infrastructure Steering Committee shall elect a Chair and an ISC Director (as defined in Section 4.3(d) of the R Consortium By-laws).\nThe Chair and ISC Director may be (but are not required to be) the same person.\nThe Infrastructure Steering Committee shall be under the leadership of the Chair, with the advice and consent of the Board, who shall serve at the pleasure of the Infrastructure Steering Committee and the Board.\nEach of the Infrastructure Steering Committee Chair and ISC Director shall be elected annually with no term limits.\nAny collaborator, user or developer of the Environment (collectively a “Collaborator”), can suggest, submit or otherwise propose a Project for consideration by the Infrastructure Steering Committee. The Infrastructure Steering Committee may implement such rules concerning format and minimum proposal requirements as it reasonably sees fit (“Proposal Requirements”).\nThe Infrastructure Steering Committee may approve a process for the creation of and organization of Projects and the appointment of top-level projects as the Infrastructure Steering Committee deems necessary.\nThe Infrastructure Steering Committee may from time to time designate particular Projects as top-level projects and specify an individual as the project lead for the top-level project (who will then become a voting member of the Infrastructure Steering Committee if the project lead’s employer is not otherwise represented on the Infrastructure Steering Committee, until such time as they are replaced as project lead or the Project ceases by Infrastructure Steering Committee action to be a top-level project).\nAny Project can be concluded, archived or otherwise terminated, and any top-level project can lose its status as a top-level project, by action of the Infrastructure Steering Committee.\nAny Project that involves code dependencies with the R language will require collaboration with the R Foundation or other maintainer of R code and permission from the relevant team.\n\n\n\n\n\nActions of the Infrastructure Steering Committee can be taken by meeting at which a quorum of voting representatives is present or by written action. Meetings can be held in person or via any electronic, telecommunication or other medium through which the meeting participants can clearly speak and hear each other. In the case of action by meeting, a quorum shall consist of a majority of the voting representatives of the Infrastructure Steering Committee.\nWhile it is the goal of the R Consortium to operate as a consensus based community, if any decision requires a vote to move forward, votes shall be based on a majority vote of the Infrastructure Steering Committee voting representatives then in attendance, or, in the case of written action, a vote of the majority of the voting members. In the event of a tied vote, the Chair shall be entitled to submit a tie-breaking vote.\n\n\n\n\nThe Infrastructure Steering Committee will, to the best of its ability, adhere to the policies set forth below. In cases where the Infrastructure Steering Committee makes a judgment that the goals of R Consortium are better served by making exceptions to these policies, it is expected that the Infrastructure Steering Committee will communicate these exceptions and indicate their reasons to the Board at the next Board meeting.\n\nThe scope of projects chosen by the Infrastructure Steering Committee will focus on outreach, development and support of the user base, support of developers, support of the R Foundation, and general advancement of the Environment as defined in the R Consortium By-laws. R Consortium will support projects focused on the following:\n\nThe advancement of user adoption, involvement with, and contribution to, the Environment;\nIncreasing communication and collaboration among users and developers of the Environment, the R Consortium and the R Foundation;\nServing as the primary point of contact among the R Consortium and its user and developer base;\nCollaboration with external and industry projects;\nFunding of specific initiatives related to the Environment, within the parameters and budget set by the Board; and\nOther projects that the Infrastructure Steering Committee determines will improve the Environment.\n\nTo the extent possible, there should be no overlap between the significant functions of top-level projects, and top-level projects should not interfere with their respective operations, purpose or goals.\nThe following relate to the operation of the Infrastructure Steering Committee.\n\nCommunication: All communication between and within the Infrastructure Steering Committee and projects will be in a fair, open and consistent fashion.\nOpenness: The Infrastructure Steering Committee should ensure that all decisions are made in an open and transparent fashion.\nResponsive to Collaborators, Users and Developers: The Infrastructure Steering Committee should ensure issues and needs of Collaborators are being addressed in a timely fashion and that Collaborators can submit input and suggestions to the Infrastructure Steering Committee.\n\n\n\n\n\n\nThis charter may be amended by action of the Board of Directors of the R Consortium.\n\n\n\n\n\nIn the case of all Projects involving the deriving or generation of code or documentation, the commitment and contribution of such code or documentation shall comply with, and be under, any applicable licensing requirements (outbound and inbound), and where no such licensing requirements exist, the commitment and contribution of such code or documentation shall be done under a license and pursuant to such other requirements, such as the submission of a developer’s certificate of origin, as may be approved by the Infrastructure Steering Committee. As part of the approval process of any license by the Infrastructure Steering Committee pursuant to this Section 7, the Infrastructure Steering Committee shall notify the Board of its intended license selection and provide the Board with an opportunity to comment on such license selection."
  },
  {
    "objectID": "governance/isc-charter.html#mission-of-the-infrastructure-steering-committee",
    "href": "governance/isc-charter.html#mission-of-the-infrastructure-steering-committee",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "The mission and goals of the Infrastructure Steering Committee include the following activities:\n\nadvance the worldwide promotion of and support for the R open source language and environment as the preferred language for statistical computing and graphics (the “Environment”);\ncreate, organize, establish, maintain and develop infrastructure projects, technical and infrastructure collaboration initiatives, support specific initiatives related to the Environment and within the budget approved, and as provided by, the Board, and such other initiatives (collectively, “Projects”) as the Infrastructure Steering Committee deems appropriate to support, enable and promote the Environment;\nencourage and increase user adoption, involvement with, and contribution to, the Environment;\nfacilitate communication and collaboration among users and developers of the Environment, the R Consortium and the R Foundation;\nserve as the primary point of contact among the R Consortium and its user and developer base and act as a liaison to open source communities;\noperate within budgets approved by the Board;\nsupport and maintain policies set by the Board; and\nundertake such other activities as may from time to time be appropriate to further the purposes and achieve the goals set forth above."
  },
  {
    "objectID": "governance/isc-charter.html#membership-on-the-infrastructure-steering-committee",
    "href": "governance/isc-charter.html#membership-on-the-infrastructure-steering-committee",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "The voting membership of the Infrastructure Steering Committee shall consist of:\n\none appointed representative from each Platinum Member;\none appointed representative from the R Foundation Member;\na number of elected representatives, selected by the Silver Members as a class that is equal to the number in the R Consortium Board of Directors elected Silver Representative; and\nthe project lead from each top-level project, subject to section 3.g. below."
  },
  {
    "objectID": "governance/isc-charter.html#operation-of-the-infrastructure-steering-committee",
    "href": "governance/isc-charter.html#operation-of-the-infrastructure-steering-committee",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "The Infrastructure Steering Committee shall elect a Chair and an ISC Director (as defined in Section 4.3(d) of the R Consortium By-laws).\nThe Chair and ISC Director may be (but are not required to be) the same person.\nThe Infrastructure Steering Committee shall be under the leadership of the Chair, with the advice and consent of the Board, who shall serve at the pleasure of the Infrastructure Steering Committee and the Board.\nEach of the Infrastructure Steering Committee Chair and ISC Director shall be elected annually with no term limits.\nAny collaborator, user or developer of the Environment (collectively a “Collaborator”), can suggest, submit or otherwise propose a Project for consideration by the Infrastructure Steering Committee. The Infrastructure Steering Committee may implement such rules concerning format and minimum proposal requirements as it reasonably sees fit (“Proposal Requirements”).\nThe Infrastructure Steering Committee may approve a process for the creation of and organization of Projects and the appointment of top-level projects as the Infrastructure Steering Committee deems necessary.\nThe Infrastructure Steering Committee may from time to time designate particular Projects as top-level projects and specify an individual as the project lead for the top-level project (who will then become a voting member of the Infrastructure Steering Committee if the project lead’s employer is not otherwise represented on the Infrastructure Steering Committee, until such time as they are replaced as project lead or the Project ceases by Infrastructure Steering Committee action to be a top-level project).\nAny Project can be concluded, archived or otherwise terminated, and any top-level project can lose its status as a top-level project, by action of the Infrastructure Steering Committee.\nAny Project that involves code dependencies with the R language will require collaboration with the R Foundation or other maintainer of R code and permission from the relevant team."
  },
  {
    "objectID": "governance/isc-charter.html#voting",
    "href": "governance/isc-charter.html#voting",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "Actions of the Infrastructure Steering Committee can be taken by meeting at which a quorum of voting representatives is present or by written action. Meetings can be held in person or via any electronic, telecommunication or other medium through which the meeting participants can clearly speak and hear each other. In the case of action by meeting, a quorum shall consist of a majority of the voting representatives of the Infrastructure Steering Committee.\nWhile it is the goal of the R Consortium to operate as a consensus based community, if any decision requires a vote to move forward, votes shall be based on a majority vote of the Infrastructure Steering Committee voting representatives then in attendance, or, in the case of written action, a vote of the majority of the voting members. In the event of a tied vote, the Chair shall be entitled to submit a tie-breaking vote."
  },
  {
    "objectID": "governance/isc-charter.html#policy",
    "href": "governance/isc-charter.html#policy",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "The Infrastructure Steering Committee will, to the best of its ability, adhere to the policies set forth below. In cases where the Infrastructure Steering Committee makes a judgment that the goals of R Consortium are better served by making exceptions to these policies, it is expected that the Infrastructure Steering Committee will communicate these exceptions and indicate their reasons to the Board at the next Board meeting.\n\nThe scope of projects chosen by the Infrastructure Steering Committee will focus on outreach, development and support of the user base, support of developers, support of the R Foundation, and general advancement of the Environment as defined in the R Consortium By-laws. R Consortium will support projects focused on the following:\n\nThe advancement of user adoption, involvement with, and contribution to, the Environment;\nIncreasing communication and collaboration among users and developers of the Environment, the R Consortium and the R Foundation;\nServing as the primary point of contact among the R Consortium and its user and developer base;\nCollaboration with external and industry projects;\nFunding of specific initiatives related to the Environment, within the parameters and budget set by the Board; and\nOther projects that the Infrastructure Steering Committee determines will improve the Environment.\n\nTo the extent possible, there should be no overlap between the significant functions of top-level projects, and top-level projects should not interfere with their respective operations, purpose or goals.\nThe following relate to the operation of the Infrastructure Steering Committee.\n\nCommunication: All communication between and within the Infrastructure Steering Committee and projects will be in a fair, open and consistent fashion.\nOpenness: The Infrastructure Steering Committee should ensure that all decisions are made in an open and transparent fashion.\nResponsive to Collaborators, Users and Developers: The Infrastructure Steering Committee should ensure issues and needs of Collaborators are being addressed in a timely fashion and that Collaborators can submit input and suggestions to the Infrastructure Steering Committee."
  },
  {
    "objectID": "governance/isc-charter.html#amendments",
    "href": "governance/isc-charter.html#amendments",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "This charter may be amended by action of the Board of Directors of the R Consortium."
  },
  {
    "objectID": "governance/isc-charter.html#intellectual-property-policy",
    "href": "governance/isc-charter.html#intellectual-property-policy",
    "title": "R Consortium Infrastructure Steering Committee Charter",
    "section": "",
    "text": "In the case of all Projects involving the deriving or generation of code or documentation, the commitment and contribution of such code or documentation shall comply with, and be under, any applicable licensing requirements (outbound and inbound), and where no such licensing requirements exist, the commitment and contribution of such code or documentation shall be done under a license and pursuant to such other requirements, such as the submission of a developer’s certificate of origin, as may be approved by the Infrastructure Steering Committee. As part of the approval process of any license by the Infrastructure Steering Committee pursuant to this Section 7, the Infrastructure Steering Committee shall notify the Board of its intended license selection and provide the Board with an opportunity to comment on such license selection."
  },
  {
    "objectID": "posts/apply-now-r-consortium-infrastructure-steering-committee/index.html",
    "href": "posts/apply-now-r-consortium-infrastructure-steering-committee/index.html",
    "title": "Apply Now! R Consortium Infrastructure Steering Committee (ISC) Grant Program Open for Proposals!",
    "section": "",
    "text": "a Help build R infrastructure! We’re opening the call for proposals for the 2024 Infrastructure Steering Committee (ISC) Grant Program. The R Consortium is dedicated to enriching the R Ecosystem, directly supporting projects that strengthen both its technical and social infrastructures."
  },
  {
    "objectID": "posts/apply-now-r-consortium-infrastructure-steering-committee/index.html#what-we-fund",
    "href": "posts/apply-now-r-consortium-infrastructure-steering-committee/index.html#what-we-fund",
    "title": "Apply Now! R Consortium Infrastructure Steering Committee (ISC) Grant Program Open for Proposals!",
    "section": "What We Fund:",
    "text": "What We Fund:\nOur grants target projects that make a difference in the R community, focusing on:\nTechnical Infrastructure: Enhancements in key R packages, development tools like R-hub, and improvements for R on various operating systems.\nSocial Infrastructure: Projects like SatRDays that promote local engagement and initiatives for better tracking of R Consortium activities.\nWe’re eager to see your innovative ideas and how they can propel the R ecosystem forward. This is a call to action for all who wish to contribute to the growth and enhancement of R. Let’s build a stronger R community together!\nSubmit your proposal now and be a part of shaping the future of the R Ecosystem. Learn more about how to apply here.\nWe look forward to your submissions and furthering the R community’s advancement together!\n\nApply now!"
  },
  {
    "objectID": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html",
    "href": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html",
    "title": "R/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced",
    "section": "",
    "text": "The R/Medicine conference provides a forum for sharing R based tools and approaches used to analyze and gain insights from health data. Conference workshops provide a way to learn and develop your R skills. Midweek demos allow you to try out new R packages and tools, and our hackathon provides an opportunity to learn how to develop new R tools. The conference talks share new packages, and successes in analyzing health, laboratory, and clinical data with R and Shiny with a vigorous ongoing discussion with speakers (with pre-recorded talks) in the chat."
  },
  {
    "objectID": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#keynote-addresses",
    "href": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#keynote-addresses",
    "title": "R/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced",
    "section": "Keynote Addresses",
    "text": "Keynote Addresses"
  },
  {
    "objectID": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#call-for-abstracts",
    "href": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#call-for-abstracts",
    "title": "R/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced",
    "section": "Call for Abstracts",
    "text": "Call for Abstracts\nR/Medicine is seeking abstracts for:\n\nLightning talks (10 min, Thursday, June 13, or Friday, June 14) Can pre-record so that you can be live on chat to answer questions\nRegular talks (20 min, Thursday, June 13, or Friday, June 14) Can pre-record so that you can be live on chat to answer questions\nDemos (1 hour demo of an approach or a package, Wednesday, June 12) Done live, preferably interactive\nWorkshops (2-3 hours per topic, Monday, June 10, or Tuesday June 11, usually with a website and a repo, participants can choose to code along. Usual 5-10 min breaks each hour.\nPosters for poster session on Wednesday, June 12. Can include live demos of an app or a package."
  },
  {
    "objectID": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#confirmed-workshops-monday-june-10-and-tues-june-11",
    "href": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#confirmed-workshops-monday-june-10-and-tues-june-11",
    "title": "R/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced",
    "section": "Confirmed Workshops (Monday, June 10, and Tues, June 11)",
    "text": "Confirmed Workshops (Monday, June 10, and Tues, June 11)\nNote: Final dates and times TBD. More workshops being added. Check the R/Medicine website for updates.\n\nCausal Inference with R – Lucy D’Agostino and Malcolm Barrett\nTidying your REDCap data with REDCap Tidier – Stephan Kadauke and Will Beasley\nNext Generation Shiny apps with bslib – Garrick Aden-Buie"
  },
  {
    "objectID": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#register-here",
    "href": "posts/r-medicine-coming-june-10-14-2024-call-for-abstracts-open-keynotes-announced/index.html#register-here",
    "title": "R/Medicine Coming June 10-14, 2024 – Call for Abstracts Open – Keynotes Announced",
    "section": "Register here!",
    "text": "Register here!\nThe R/Medicine website is being updated as we receive the latest information. Please check in again soon!"
  },
  {
    "objectID": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html",
    "href": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html",
    "title": "Using R to Submit Research to the FDA: Pilot 4 Successfully Submitted to FDA Center for Drug Evaluation and Research",
    "section": "",
    "text": "The R Consortium is excited to announce that, on September 20, 2024, the R Submissions Working Group successfully submitted its latest test submission package—featuring a WebAssembly component—through the FDA’s Electronic Common Technical Document (eCTD) gateway! This marks a significant milestone as the FDA Center for Drug Evaluation and Research (CDER) staff has officially received the submission package.\nStatistician Eric Nantz at pharmaceuticals company Eli Lilly in Indianapolis, Indiana, says that using WebAssembly “will minimize, from the reviewer’s perspective, many of the steps that they had to take to get the application running on their machines.”\nThe complete set of submission materials is available publicly on GitHub: R Consortium Submissions Pilot 4."
  },
  {
    "objectID": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#about-the-pilot-4-project",
    "href": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#about-the-pilot-4-project",
    "title": "Using R to Submit Research to the FDA: Pilot 4 Successfully Submitted to FDA Center for Drug Evaluation and Research",
    "section": "About the Pilot 4 Project",
    "text": "About the Pilot 4 Project\nThe objective of the R Consortium R submission Pilot 4 Project is to explore the use of novel technologies such as Linux containers and WebAssembly to bundle a Shiny application into a self-contained package, facilitating a smoother process of both transferring and executing the application. The application was built using the source data sets and analyses contained in the R submission Pilot 1-3. To our knowledge, this is the first publicly available submission package that includes a WebAssembly component. We hope this submission package and what we have learned can serve as a good reference for future regulatory submission efforts. The WebAssembly technology compiles applications into a portable, consistent environment driven by a web browser, allowing agency reviewers to easily run and evaluate software without complex setups. The second half of the Pilot 4 Project (leveraging container technology to package a Shiny application) will be submitted as an additional package later this year. Additional agency feedback will be shared in future communications."
  },
  {
    "objectID": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#about-the-r-submissions-working-group",
    "href": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#about-the-r-submissions-working-group",
    "title": "Using R to Submit Research to the FDA: Pilot 4 Successfully Submitted to FDA Center for Drug Evaluation and Research",
    "section": "About the R Submissions Working Group",
    "text": "About the R Submissions Working Group\nThe R Consortium R Submissions Working Group is focused on improving practices for R-based clinical trial regulatory submissions.\nHealth authority agencies from different countries require electronic submission of data, computer programs, and relevant documentation to bring an experimental clinical product to market. In the past, submissions have mainly been based on the SAS language.\nIn recent years, the use of open source languages, especially the R language, has become very popular in the pharmaceutical industry and research institutions. Although the health authorities accept submissions based on open source programming languages, sponsors may be hesitant to conduct submissions using open source languages due to a lack of working examples.\nTherefore, the R Submissions Working Group aims to provide R-based submission examples and identify potential gaps while submitting these example packages. All materials, including submission examples and communications, are publicly available on the R consortium GitHub page."
  },
  {
    "objectID": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#join-the-r-submissions-working-group",
    "href": "posts/using-r-to-submit-research-to-the-fda-pilot-4-successfully-submitted/index.html#join-the-r-submissions-working-group",
    "title": "Using R to Submit Research to the FDA: Pilot 4 Successfully Submitted to FDA Center for Drug Evaluation and Research",
    "section": "Join the R Submissions Working Group",
    "text": "Join the R Submissions Working Group\nThe R Submissions Working Group comprises members from over 10 pharmaceutical companies, as well as regulatory agencies. We are a collaborative community open to anyone interested in contributing to this important work. For more information, or to get involved, visitour website or contact us directly at director@r-consortium.org."
  },
  {
    "objectID": "posts/R-Medicine-is-coming-June-10-14-2024-See-Top-Five-R-Medicine-Talks-from-Previous-Years/index.html",
    "href": "posts/R-Medicine-is-coming-June-10-14-2024-See-Top-Five-R-Medicine-Talks-from-Previous-Years/index.html",
    "title": "R/Medicine is coming June 10-14, 2024 – See Top Five R Medicine Talks from Previous Years",
    "section": "",
    "text": "What to get a feel for the kind of content will be available at R/Medicine 2024? We’re spotlighting the most engaging and educational sessions from past R Medicine Virtual Conferences. Whether you’re a healthcare professional, a data scientist, or simply curious about the intersection of healthcare and technology, these selected talks offer a wealth of knowledge and innovation using the R programming language. Dive into these sessions to enhance your understanding and skills in medical data science.\n\n🔗 Register for the R Medicine 2024 Virtual Conference here!\n\n\n1. GitHub Copilot in Rstudio, It’s Finally Here! – R Medicine Virtual Conference 2023\nThis session introduces GitHub Copilot for RStudio, a highly anticipated tool that enhances coding efficiency and innovation in medical research. Watch as experts demonstrate its capabilities and potential impact on healthcare data analysis.\n\n\n\n\n2. Analyzing Geospatial Data in R (Sherrie Xie) – R/Medicine 2022 Virtual Conference\nFeaturing Sherrie Xie, this presentation explores the applications of geospatial data analysis within the healthcare sector using R. Gain insights into the importance of spatial data in understanding health trends and outcomes.\n\n\n\n\n3. R/Medicine 101: Intro to R for Clinical Data (Stephan Kadauke, Joe Rudolf, Patrick Mathias) – R/Medicine 2022\nThis introductory session is perfect for those new to using R in a clinical setting. The speakers guide you through the basics and demonstrate how R can revolutionize medical research and patient care.\n\n\n\n\n4. Introduction to R for Medical DataTidy Spreadsheets in Medical Research – R/Medicine 2021\nUMich Prof and {medicaldata} author Peter Higgins will cover best practices for using medical data in spreadsheets like Excel and Google Sheets.\n\n\n\n\n5. Multistate Data Using the {survival} Package – R/Medicine 2021\nExplore the use of the {survival} package in R for analyzing multistate data. Discover the methods and models that are shaping the future of survival analysis in medical research.\n\n\nEngage and Learn More!\nEach of these sessions provides unique insights and practical tools for harnessing the power of R in medical research and healthcare analytics. Whether you are watching these for the first time or revisiting them, each video promises a deep dive into the capabilities of R that are driving advancements in the field.\n📢 Mark Your Calendars! The R Medicine Conference for this year is scheduled for June 10-14. Register now to secure your spot and connect with a community of like-minded professionals!\n\n\n🔗 Register for the R Medicine 2024 Virtual Conference here!\nRemember to subscribe to the R Medicine channel for more updates and upcoming conference information. Enhance your skills in medical data science today!"
  },
  {
    "objectID": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html",
    "href": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html",
    "title": "Join our R/Medicine Webinar: Quarto for Reproducible Medical Manuscripts",
    "section": "",
    "text": "Join the R Consortium for an enlightening webinar on March 20th, 2024, at 4:00 PM ET, featuring Mine Cetinkaya-Rundel, Professor of the Practice of Statistical Science at Duke University. Discover the innovative Quarto tool to streamline the creation of reproducible, publication-ready manuscripts."
  },
  {
    "objectID": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html#key-highlights",
    "href": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html#key-highlights",
    "title": "Join our R/Medicine Webinar: Quarto for Reproducible Medical Manuscripts",
    "section": "Key Highlights:",
    "text": "Key Highlights:\n\nQuarto Manuscripts Introduction: Learn how to easily integrate reproducibility into your research with Quarto’s user-friendly features, creating comprehensive bundled outputs ready for journal submission.\nInteractive Demo: Witness a live demonstration of Quarto in action, showcasing how to enhance your current manuscript preparation process and address common challenges.\nExpert Guidance: Gain insights from Mine Cetinkaya-Rundel’s extensive experience in statistical science and reproducible research, offering valuable tips for improving your workflow."
  },
  {
    "objectID": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html#event-details",
    "href": "posts/join-our-r-medicine-webinar-quarto-for-reproducible-medical-manuscripts/index.html#event-details",
    "title": "Join our R/Medicine Webinar: Quarto for Reproducible Medical Manuscripts",
    "section": "Event Details:",
    "text": "Event Details:\nWhen: March 20th, 2024, at 4:00 PM ET\nDon’t miss this opportunity to refine your manuscript preparation process with the latest advancements in reproducibility technology.\n\nRegister now!"
  },
  {
    "objectID": "posts/empowering-data-science-how-r-is-transforming-research-in-cameroon/index.html",
    "href": "posts/empowering-data-science-how-r-is-transforming-research-in-cameroon/index.html",
    "title": "Empowering Data Science: How R is Transforming Research in Cameroon",
    "section": "",
    "text": "NyAvo RATOVO-ANDRIANARISOA, the co-founder of the R Community Cameroon, recently spoke with the R Consortium about the rapid growth of the R community in Cameroon and the impact of R on local research and data analysis. NyAvo provided insights into the community’s activities, such as developing an R community website using Shiny and implementing innovative projects like a custom search application. He also discussed the challenges and strategies in building a robust R ecosystem in Central Africa.\nPlease share your background and involvement with the RUGS group.\nI am a statistical engineer from the Institute of Statistics of Central Africa in Cameroon, originally from Madagascar. Currently, I serve in a monitoring and evaluation role with the United Nations. My journey with R began about five years ago as a student. I started learning R during my studies and expanded my expertise by freelancing as a Shiny developer. Over time, I’ve also gained experience with OCR technology, working with Tesseract and utilizing Google Cloud Colab’s API Amazon Web services for R and artificial intelligence models.\nWith a solid statistical background, I specialize in data mining. In 2020, before learning about the R Consortium campaign, I had already envisioned creating an R community in Cameroon. After discussing the idea with some colleagues and discovering the potential support, it became the perfect opportunity to bring this vision to life. My colleagues and I officially launched the R Community Cameroon at the beginning of this year.\nI would like to mention my colleagues who have co-founded the group with me: Romain TCHAKOUTE, Idrissa DABO, Saidou BOUREIMA, Mianala MANAMBIRAVAKA, and Ronald DJEUMEN.\nCan you share what the R community is like in Cameroon?\nCameroon is home to one of Central Africa’s largest science schools. I am part of a vibrant academic community of 30 members from several nationalities. This environment brings together some of the brightest minds, and R is an integral part of our curriculum. However, our use of R goes beyond basic statistics and plotting; we focus on more sophisticated applications, such as Monte Carlo estimation, model development, and advanced R programming.\nSeveral professors in our school possess strong statistical backgrounds and rely on R for their research. Additionally, our alums who have transitioned into the industry continue to leverage R for data analysis. While Cameroon has a limited amount of data, we conduct numerous surveys. The initial step most of us take is data cleaning, predominantly using R. Once the data is clean, we employ Quarto to generate automatic reports, allowing us to summarize survey results quickly. Some of my colleagues also explore other functionalities of R, like creating applications with R Shiny.\nAnother significant group is comprised of economics students or those working on their theses. They often seek our assistance to learn R for tasks such as descriptive statistics and building logistic models.\nDo you recommend any techniques for planning for or during the event? (Github, Zoom, other.) Can these techniques be used to make your group more inclusive to people unable to attend physical events in the future?\nCurrently, we rely on PowerPoint to create posters for our events and Google Meet for online meetings before having the Meetup Pro account provided by R Consortium. Many of us, the co-founders of the community, are technicians, so we also use Word for various tasks. However, leadership skills have been crucial in convincing people to join our vision. To engage others, we often organize dinner or lunchtime meetings. We’ve invested significant effort into these initiatives, and through them, we’ve successfully negotiated several partnerships. Initially, I contacted colleagues at the National Institute of Statistics to rally support for our cause.\nOur community now includes students and academics, and some PhD doctors are still in the learning phase. I discussed creating a community in Cameroon, asking what value we could offer to encourage their participation. I proposed that they become co-founders of the community, a role they could highlight on their resumes. Seven people have already stepped up as leaders within our group.\nWe’re active both online and in person. It’s important to note that we organize two types of meetings. The first is an internal meeting with our community leaders, typically attended by around seven people. We use a WhatsApp group for communication and usually meet monthly for lunch at a restaurant for these meetings. The second activity involves larger groups. For these, we first coordinate with the administration, such as the school mentioned earlier, who then communicate with the students. We also document and share these activities online to inform others, though most of our communication is direct and specific.\nFor example, after explaining our vision to a university contact, they were interested and agreed to offer a course at their institution. We then coordinated with the student body leader, planned a session, and shared the event online. We even hired a professional photographer to capture the event, sharing the photos with the school for further distribution. However, we haven’t yet posted about this activity on LinkedIn.\nLooking ahead, we’re planning a session with another school—the statistical school where I studied. We’re currently in discussions with their management. Once we’ve had our conversation, possibly next week, we’ll talk with the student leaders. After the session, we plan to share our activities online, including photos, to highlight what we’re accomplishing in Cameroon.\nDo you have any upcoming events planned for the group?\nWe have an upcoming event that I consider one of the most important we’ve planned. It is our group’s quarterly meeting. The main objective of this meeting is to develop our R community website using Shiny. It will be a workshop where we’ll gather in one place and form small groups comprising beginners and experienced members. During the workshop, we’ll collaborate to code and discuss ideas, and ideally, by the end of the session, we will have the code for our community website ready for deployment.\nWe’re currently facing some logistical challenges to organize this event. In Cameroon, when we organize events, we strive for perfection, ensuring everything from photography to visibility is top-notch. We’re searching for a suitable hotel venue to host our event.\nWhat trends do you currently see in R language and your industry?\nIn Cameroon, Quarto is one of the most popular packages we promote during our R community sessions. Another widely used package is R Markdown. While I primarily use R Markdown to produce outputs for my job, I am also working on becoming more proficient with Quarto, as it is the future of reporting and documentation.\nI frequently use the tidyverse, tidyr, labelled, and haven suite of packages for data cleaning and reporting. A significant part of my job involves data cleaning, and I rely on tidyverse in conjunction with Quarto for these tasks.\nWe also utilize R for machine learning, though there is still potential for improvement in this area. We are focused on leveraging Shiny, Quarto, and tidyverse for our work.\nPlease share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting, primarily related to your industry?\nWe are currently working on an exciting project that is still in progress. The aim is to develop an application inspired by the functionality seen in the movie Fast and Furious, where users can search for information on the Internet. We are utilizing the httr package to collect data from online sources.\nThe application will enable users to input a search term, such as “lion in Cameroon,” and receive a dataset with all relevant information. Our goal is to provide high-quality data for researchers and other users, which involves considerable effort to ensure the accuracy and usefulness of the data."
  },
  {
    "objectID": "posts/empowering-data-science-how-r-is-transforming-research-in-cameroon/index.html#how-do-i-join",
    "href": "posts/empowering-data-science-how-r-is-transforming-research-in-cameroon/index.html#how-do-i-join",
    "title": "Empowering Data Science: How R is Transforming Research in Cameroon",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/seville-r-users-group-rs-role-in-optimization-research-and-stroke-prevention/index.html",
    "href": "posts/seville-r-users-group-rs-role-in-optimization-research-and-stroke-prevention/index.html",
    "title": "Seville R Users Group: R’s Role in Optimization Research and Stroke Prevention",
    "section": "",
    "text": "Alberto Torrejon Valenzuela, organizer of the Seville R Users Group, recently spoke with the R Consortium about the dynamic growth of the R community in Seville and the group’s role in fostering collaboration across academia and industry. Alberto shared highlights from hosting the Third Spanish R Conference, which brought together local and international participants. He discussed the group’s initiatives, including monthly workshops and online outreach through platforms like YouTube. He also reflected on his research in optimization and a collaborative project analyzing stroke prevention, showcasing how R drives innovation in scientific research and community development.\nPlease share your background and involvement with the RUGS group.\nMy name is Alberto Torrejon Valenzuela. I am from Los Barrios, a town in Cádiz, southern Spain. I have moved to Seville, which is a bit further north, where I studied for a double degree in Mathematics and Statistics. During my studies, one of my professors introduced me to R. Although I was learning several programming languages, I realized that I could accomplish everything I needed with just R. Since then, I have continued to use it throughout my studies.\nI also joined the R group in Sevilla, which I discovered through Meetup. It was another motivation to enhance my R skills. The Sevilla R Users Group meets at the University of Sevilla’s facilities every one to two months. During these meetings, we discuss our work and share our experiences. Our group includes many users from academia and industry, making our discussions very diverse. We enjoy discussing our various implementation packages and applications; hearing from both perspectives is always interesting.\nYour Group recently hosted the Third Spanish R Conference. Please share some details about the event.\nThe Third Spanish R Conference took place from November 6 to 8 in Seville, co-organized by the Institute of Mathematics at the University of Seville and Sevilla R group, with support from the R Consortium and several other organizations.\nWe used a catchy slogan for the conference: “R tiene un color especial” (R has a special color). This is a modification of the lyrics of a famous song about Seville that everyone in Spain knows. It became a hit!\nThe conference featured a wide range of activities from both scientific and social perspectives. We had four plenary speakers: Jakub Nowosad, from University of Münster, and Hannah Frick from POSIT, along with national speakers Rosana Ferrero, who is very active in social networking, and Javier Tejedor Aguilera from Endesa, who represents the industry.\nAdditionally, it’s important to mention that the group recognized the contributions of two founding members, Francisco Rodriguez-Sanchez and Jerónimo Carranza, during the conference. We honored them with a gift to acknowledge their hard work.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nOrganizing a conference, like the one in Spain, is quite a significant undertaking. In addition to the conference, the group hosts monthly meetings called “TalleR”, the Spanish word for workshop. We typically emphasize the “R” at the end of the word. We exchange knowledge about our packages and various other topics during these meetings.\nWe primarily use social networks to connect with the local community, including the former Twitter (now known as X), BlueSky, and LinkedIn. We rely on our Meetup page to organise the event, where we post details about our seminars or talleres. People can indicate whether they will attend in person or online, making this a helpful tool. Additionally, since some members are researchers and professors in the University of Seville, we have support from Microsoft Teams to stream and record these meetings, as many participants come from South American and Spanish-speaking countries. For example, in our last meeting, we had attendees from Panama and Colombia.\nAfter the meeting, we usually post our recordings on our YouTube channel. Every session is recorded there. We also have a website and a Telegram group where we engage in more active discussions. This is mainly for our meetings.\nHowever, as you mentioned, organizing a large conference like the Spanish R Conference requires additional support. We received this support from the Institute of Mathematics at the University of Seville, which provided significant assistance regarding the location and logistics of our conference. Since our successful collaboration with the Institute of Mathematics, our local group has been keen to maintain and expand this partnership to enhance our meetings held at the Institute.\nAdditionally, a significant portion of our support came from the Spanish Association known as R-Hispano. They provided valuable tools and assistance when co-organizing our events, which has been incredibly helpful. We’re also thankful for financial support from the R Consortium.\nHow do you use R for your work?\nI use both R and Python for my research. I have two distinct lives: a professional and a personal one. In my free time, I enjoy programming, and I also need to program in my professional life. My research focuses on optimization.\nOptimization models aim to find the best solution to a given problem. I work in a lab run by Justo Puerto, a full professor in the Department of Statistics and Operations. One of the primary areas I’m involved in is ordered optimization, which involves sorting procedures to identify the best solutions to various combinatorial and decision optimization problems.\nWe study numerous problems, ranging from logistics issues, such as resource or facility location problems, to statistical issues like linear regression or efficient statistics computation. The framework of ordered optimization allows us to generalize these problems to include abstract concepts such as equity or minimizing envy among clients. For instance, we can optimize the location of a supermarket, hospital, voting center, or bus and train lines, ensuring equitable access so that no one feels envious of their neighbors.\nAdditionally, we apply these algorithms to statistical problems to improve the computation or estimators. The optimization community is familiar with Python algorithms and packages, but the R community is catching up. I use several R packages, including ROI and OMPR, allowing comprehensive data analysis.\nPlease share about a project you are working on or have worked on using the R language. Goal/reason, result, anything interesting, primarily related to your industry?\nI am discussing a topic that highlights one of R’s best uses in boosting and supporting community initiatives. Since I work at the Institute of Mathematics, a research team from Hospital Universitario Virgen Macarena contacted us for statistical support. I was the first to volunteer, and we signed a collaboration contract to begin our work.\nThe project I’m currently involved in focuses onstudying and preventing strokes through analyzing large databases. Stroke is one of the worst medical conditions from the point of view of rapid care for the affected person because when it occurs, there is usually a very short period of time until brain death is reached. Timely care is essential for improving outcomes.\nThis research is crucial for the team led by Joan Montaner, which is focused on finding the best combination of drugs for stroke prevention. They aim to provide effective medications to individuals diagnosed with a stroke to improve their chances of survival, especially within the critical first 24 hours.\nThe team has access to a historical dataset of more than 100,000 patients, and I am analyzing this data using our software tools. We are uncovering some interesting insights, and we hope this information will assist them in testing these drug combinations. Ultimately, we aim to help develop more extensive protocols for administering these medications to patients."
  },
  {
    "objectID": "posts/seville-r-users-group-rs-role-in-optimization-research-and-stroke-prevention/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/seville-r-users-group-rs-role-in-optimization-research-and-stroke-prevention/index.html#how-do-i-build-an-r-user-group",
    "title": "Seville R Users Group: R’s Role in Optimization Research and Stroke Prevention",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute\nhttps://r-consortium.org/all-projects/rugsprogram.htm"
  },
  {
    "objectID": "posts/thank-you-joseph-rickert-a-legacy-of-leadership/index.html",
    "href": "posts/thank-you-joseph-rickert-a-legacy-of-leadership/index.html",
    "title": "Thank You, Joseph Rickert: A Legacy of Leadership and Innovation in the R Community",
    "section": "",
    "text": "As we announce the end of Joseph (Joe) Rickert’s tenure as the Executive Director of the R Consortium, we reflect on his remarkable contributions that have significantly contributed to the R community. Joe’s leadership has been instrumental in fostering growth, innovation, and collaboration within the R ecosystem.\nFounding the R Consortium\nJoe has been with the R Consortium since its inception in 2014. He was initially appointed to be Microsoft’s representative to the Infrastructure Steering Committee (ISC) and was soon tasked with creating the R User Groups (RUGS) grants program. Joe also pioneered the formation of ISC working groups to foster industry-wide collaborative projects. In 2016, Joe was appointed to be RStudio’s representative to the Board of Directors. In 2018, he took on the role of Secretary, and by 2019, he was elected Chair of the Board. In 2023, Joe took on the role of Executive Director. Under his guidance, the R Consortium has grown into an inclusive organization supporting the R programming language and its community. Our new executive director, Terry Christiani, was affirmed by the board of directors in our August 2024 board meeting after a selection committee interviewed candidates and made recommendations.\nAdvancing User Groups\nOne of Joe’s notable achievements is his unwavering support for R user groups worldwide. He recognized the importance of grassroots movements in spreading the use of R and provided essential resources and funding to these groups. He was instrumental in funding the R-Ladies as a top-level ISC project that operates worldwide to provide safe places for women to come together and learn from each other in an otherwise male-dominated space. Joe was also directly involved with the Bay Area useR Group (BARUG), organizing events, speaking, or contributing to discussions around the R programming language, especially in the context of data science and statistical computing. This support has enabled countless R enthusiasts to connect, share knowledge, and collaborate on projects, thereby strengthening the global R community.\nIndustry Collaboration and Working Groups\nJoe actively reached out to industry leaders to create unique working groups aimed at solving industry-wide problems. These collaborations have led to the development of working groups focused on R programming solutions that benefit not only the community but also industries that rely on data science and statistical computing.\nA Legacy of Innovation\nThroughout his tenure, Joe has been a driving force behind numerous initiatives that have propelled the R community forward. His efforts have ensured that the R Consortium remains a dynamic and inclusive organization, fostering a spirit of collaboration and innovation. His leadership has left an indelible mark on the R community, and his legacy will continue to inspire future generations of R users and developers.\nAs we welcome new leadership, we extend our heartfelt gratitude to Joe Rickert for his dedication, vision, and tireless efforts in advancing the R community. Thank you, Joe, for your invaluable contributions and for paving the way for a brighter future for the R ecosystem."
  },
  {
    "objectID": "posts/the-crucial-role-of-release-control-in-r-for-healthcare-organizations/index.html",
    "href": "posts/the-crucial-role-of-release-control-in-r-for-healthcare-organizations/index.html",
    "title": "The Crucial Role of Release Control in R for Healthcare Organizations",
    "section": "",
    "text": "Guest blog contributed by Ning Leng, People and Product Leader, Roche-Genentech; Eric Nantz, Director, Eli Lilly and Company; Ben Straub, Principal Programmer, GSK; Sam Parmar, Statistical Data Scientist, Pfizer\nSupporting the science of drug development requires computational tools with careful implementations of core statistical functions and data structures. The R programming language, a general purpose language developed by statisticians that grows dynamically through the contributions of a worldwide community of developers, is a common choice for serious statistical work. However, managing new versions of the core R language and the hundreds of specialized libraries (called packages in R) necessary to support multiple development groups in a way that ensures the consistency, reproducibility, and reliability of results poses many practical challenges\nThe FDA, for example, requires that the software and tools supporting a clinical trial submission are capable of producing reproducible results for an extended period of time. This means submitting code based on a version of R that is sufficiently tested and stable yet new enough to support the critical R packages over the required FDA time horizon.\nSo, how is the R environment release managed across different healthcare organizations? We interviewed individuals from different pharma companies to learn their internal approaches to keep their R environment up-to-date and secure.\n\nRoche’s Scientific Computing Environment is container based, with clinical reporting done from managed qualified images being released twice per year – roughly timed to capture the last update to an R major version (April release) and a 6 month later update (September release). For each image, R packages undergo a mostly automated risk assessment to document package quality. Automated indicators of package quality include test coverage, thoroughness of documentation, test coverage of exported objects (using covtracer), and may be supplemented with package adoption measured using download counts, author reputation or other peripheral knowledge of the package’s history. Prior to internal publication, a representative sample of reverse dependencies are re-evaluated to safeguard against breaking changes. If the package meets our quality criteria it is published to a continuously updated repository of validated packages corresponding to the image’s R minor version (e.g. x.x). This allows flexibility for teams to roll forward to newer releases of packages within a managed release by moving their renv snapshot to a later date, easing the transition between bi-annual image releases. A generalized version of Roche’s automated process has been open sourced as ’theValidator’, and more details on the Roche process was shared within the R Validation case studies series.\nEli Lilly currently updates its qualified R environment only after a new major release of R is available and the corresponding release of Bioconductor (utilizing that version of R) is also available. In a new release, all packages currently installed from the CRAN and Bioconductor repositories are refreshed to their latest versions at the time of the release. Once the new R version is deployed, all packages are frozen for that particular release to ensure stability and reproducibility. Lilly maintains multiple R versions for backward compatibility. Only packages available on CRAN or Bioconductor are permitted for installation in the central package library. Lilly uses a hybrid approach of automation and risk-based assessment when a new package is requested for installation. In the event that a new version of a package is necessary for a project (such as a new Shiny application), the users are encouraged to leverage the renv package created by Posit to create a project-based environment which will not impact the central package library. As technology evolves and the R language becomes more prominent in clinical data analysis, Lilly continues to assess the current and future possibilities of a robust clinical computing environment primed for innovation while adhering to the foundational principles of reproducibility and transparency.\nGSK releases “frozen R environments” for clinical reporting work on a 6-12 month cycle. The choice of R version is the latest stable release with at least one patch release of R, e.g. 4.3.1 rather than 4.3.0. As R itself is stable with decades of use, we prefer to focus on package assessment for building of our “frozen R environments.” Packages for this environment can be from external sources (CRAN, Bioconductor) or internally built at GSK, regardless of origin we assess the same way. We pay close attention to author qualification and institutional backing, types and breadth of testing, documentation and examples, and the practice of software development life cycle practices. Once a package is approved in this process it will be included in the frozen environment. Packages change over time, if substantial changes are implemented in the packages, then we re-assess with a focus on those changes for allowing up-versioning of the package in the frozen environment. These frozen environments ensure that clinical reporting can be easily reproduced if needed as all packages versions and the version of R used during the analysis are contained in the frozen environment.\nPfizer releases one new R version every year. We typically target R-x.y.1 releases to pick up patches – so we might consider this a “stable” release. The process of testing, documenting, and deploying R into validated containers is performed every 6 months, with a new release of R once per year, e.g. R-4.3.1, and an update to package set and package versions 6 months later (for the same R version). We take a snapshot date of CRAN to form the basis of our package set for the container build. We try to balance competing priorities of getting latest versions of packages and newest package releases, while maintaining a snapshot and version-controlled release to ensure reproducibility and stability.\n\nHere is what we have: four companies and four somewhat complex bespoke solutions. It seems likely that if we interviewed a hundred representatives from a hundred different companies we would get at least a hundred different solutions. It is also not difficult to imagine that multiple protocols for managing R and package versions imposed a fairly complex project management solution on the FDA as it simultaneously deals with submissions from multiple sponsors.\nIn the R Consortium’s R Submissions Work Group meeting we have been discussing whether there might be a simple solution for at least dealing with the R versioning problem that might serve as a de facto standard for the industry. One suggestion that has gained some traction is that sponsors use the previous minor and latest patched R version for a submission. For example, if R version 4.4.0 is currently available then it is suggested that a sponsor uses the latest patch version (4.3.z). If R version 4.5.0 becomes available, then it is suggested that a sponsor uses the latest patch version (4.4.z). This ensures that the minor version is stable and most likely available to all stakeholders. Of course, if a version change eliminates a security problem, that might be preferred. (Note that R versions are organized R x.y.z where, x is the major version, y is the minor version, and z is the patch version.)\nWe would love to hear what you think. Please, go to Issue number 117 on the GitHub repository of our working group and leave a comment."
  },
  {
    "objectID": "posts/endophytes-oaks-and-r-how-r-ladies-morelia-is-cultivating-science-and-community-in-morelia-mexico/index.html",
    "href": "posts/endophytes-oaks-and-r-how-r-ladies-morelia-is-cultivating-science-and-community-in-morelia-mexico/index.html",
    "title": "Endophytes, Oaks, and R: How R-Ladies Morelia is Cultivating Science and Community in Morelia, Mexico",
    "section": "",
    "text": "Goretty Mendoza, the organizer of the R-Ladies Morelia, recently spoke to the R Consortium about her experience with the group and her work using R in molecular biology. Under her guidance, the group has grown into a supportive space for women from diverse fields, focusing on building R skills, sharing knowledge, and fostering collaboration. Goretty is committed to empowering the local R community through online and physical events that encourage learning and networking.\nPlease share about your background and involvement with the RUGS group.\nI am a PhD student specializing in molecular biology, focusing on endophytic fungi. My work involves high-throughput sequencing, particularly amplicon sequencing, to study microbiomes.\nI started using R during my PhD. Initially, I practiced independently through online courses, but then I discovered an R-Ladies community. The group was just starting in my city, so I took the opportunity to join. Attending the meetings helped me overcome my fear of working with R and allowed me to improve my skills. Gradually, I became more involved, and a few months ago, we had the opportunity to hold a face-to-face meeting with some members of our R-Ladies community who live in other cities, thanks to the R Consortium’s grant. I’m sure we returned home more motivated, knowing we all aim to improve our R skills.\nCan you share what the local R community is like?\nOur local R community is a group of enthusiastic women from various fields. Most of us come from science, mainly mathematics or biology, but we also have members from areas like finance or economics interested in learning R. At the start of each semester, we meet to share our interests and goals for the upcoming months. During our face-to-face meetings, we enjoy coffee and cookies, which create a welcoming atmosphere. A key focus of our group is ensuring that those with more experience in R share their knowledge with new members who are just starting. It creates an environment where everyone can learn and grow together. Our R-community is a great opportunity to get involved, collaborate with other women, and make new friends as we learn.\nPlease share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting related to your industry?\nI’m pursuing my PhD, and R is a tool I use almost daily. For example, I use R for a project involving the study of endophytic associations in different temperate oak species of Mexico. To this end, we initially explored the functional leaf traits of these oak species, and I had to learn different R packages for this project, such as data manipulation and visualization (e.g., dplyr and ggplot2). Additionally, I used specialized packages like ‘TPD’ to calculate metrics related to functional diversity studies and ‘hypervolume’ to calculate climatic niches.\nOur study aimed to determine if a functional niche partitioning between two evolutionary groups of oaks allowed them to coexist. We conducted a functional niche analysis and graphical visualization using R and the packages above. An interesting finding was that the analysis suggested differences in functional similarity among the groups, indicating evidence of functional niche partitioning and resource gradients.\nThese studies are crucial for conservation efforts and guide the development of management practices supporting temperate forests’ long-term health and resilience.\nWhat resources/techniques do/did you use? (Posit (RStudio), Github, Tidyverse, etc.)\nIs this an ongoing project? Please share any details or CTA for who should get involved!\nAmong the various R packages I used, some are for data manipulation and visualization, such as dplyr and ggplot2, and others more specialized, like TPD for calculating metrics used in functional diversity studies, hypervolume for constructing functional niches, and ecospat to calculate climatic niche overlap indices.\nWe extensively utilized GitHub repositories, ensuring that all the scripts were well-documented to allow others to reproduce the analyses easily. Our ongoing project on endophytic fungi associated with oaks is crucial as a first approximation for understanding the complex interactions between fungi and their host plants.\nThe concept of hidden diversity is a novel and intriguing area that we are just beginning to explore. For those interested in diving deeper into this field, there are several ways to get involved. You can join professional networks in microbial ecology or engage with the field of computational biology through organizations and online communities. Additionally, participating in conferences, workshops, and collaborations with researchers and professionals in the field offers valuable opportunities to contribute to current research.\nWhat trends do you currently see in R language and your industry? Are there any trends you see developing in the near future?\nIn metagenomics, one of the key trends is the development of massive datasets generated by next-generation sequencing (NGS). It has enabled a deeper and more detailed analysis of microbial communities and their diversity and functions. In this context, R remains an essential tool for statistical analysis and data visualization with specialized libraries like phyloseq and vegan.\nHowever, given the complexity of metagenomic data, other programming languages like Python and Bash are becoming indispensable. In the near future, the use of interdisciplinary workflows that combine R, Python and Bash will continue to grow, along with the development of more integrated tools to manage large datasets. Additionally, we can expect an increased use of artificial intelligence and machine learning to analyze these data."
  },
  {
    "objectID": "posts/endophytes-oaks-and-r-how-r-ladies-morelia-is-cultivating-science-and-community-in-morelia-mexico/index.html#how-do-i-join",
    "href": "posts/endophytes-oaks-and-r-how-r-ladies-morelia-is-cultivating-science-and-community-in-morelia-mexico/index.html#how-do-i-join",
    "title": "Endophytes, Oaks, and R: How R-Ladies Morelia is Cultivating Science and Community in Morelia, Mexico",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/navigating-r-impact-in-vienna-insights-from-the-finance-and-pharmaceutical-sectors/index.html",
    "href": "posts/navigating-r-impact-in-vienna-insights-from-the-finance-and-pharmaceutical-sectors/index.html",
    "title": "Navigating R’s Impact in Vienna: Insights from the Finance and Pharmaceutical Sectors",
    "section": "",
    "text": "The R Consortium recently spoke with Mario Annau, co-organizer of the Vienna R User Group. During the conversation, he discussed the use of R in the finance and pharmaceutical industries in Vienna. He also shared insights into the latest and upcoming trends in using R in these sectors and tips for organizing successful hybrid meetups with minimal overhead.\nIn September 2022, Mario Annau talked to the R Consortium about the role of the local financial industry in the Robust Vienna R Community. Recently, the R Consortium reached out to Mario for a detailed discussion about the use of R in the finance and pharmaceutical industries in Vienna. Mario shared his insights regarding the latest and upcoming trends in using R in these sectors and tips for organizing successful hybrid meetups with minimal overhead.\nPlease share about your background and involvement with the RUGS group.\nI became interested in R during my university studies in computer science. I earned a bachelor’s degree in software engineering and a master’s in intelligent systems or computational intelligence. During my master’s studies, I began using R. I also found out that Kurt Hornik, was at a different university in Vienna and was also using R. Together with other R core developers, he created R with its package repository and many features. Although I am not a trained statistician, I became more involved in statistics and machine learning, which are closely related. I did my master’s thesis with Kurt Hornik.\nDuring my second thesis, I became increasingly involved with R, which led me to explore text mining and sentiment analysis with this language. This interest ultimately kick-started my career. I am proud to say that I am one of the few people who have truly benefited from using R in my professional life. Back then, using open source software in companies was uncommon, and many people preferred Matlab and other professional tools. People would often ask me who supported R and why it was free. However, I found that having this skill set was very beneficial.\nThe experience of using open source languages and technologies has been really helpful for me. Over the years, I have switched jobs and worked for different employers, but the knowledge I gained has always been useful in other settings and companies. Unlike bigger corporations, I never had to worry about buying licenses or running into budget issues. For example, Matlab is expensive, so it’s always a concern for some companies. But since I’ve had experience with open source technologies, I never had to deal with those issues.\nI learned about open source technologies during my university studies and discovered that they are free to use even in my professional career. This has been very helpful to me, and I am amazed at how far I have been able to go with it. Although R is not as widely used in the professional field as other languages, it has served me very well, and I am happy to be able to use it in my career. The Vienna R User Group allows me to bring it to the local R community.\nCan you share what the R community is like in Vienna?\nIt’s evident that the industry has started accepting open source, including R. I work primarily in the financial sector and pharma, which are industries where R is widely used. R is also a strong contender, alongside Python, in these fields.\nThe acceptance of using R in production environments is increasing, but some companies still view it as just a tool for creating graphs and nothing else. Despite this perception, I still use R a lot in production, and it works well. However, some wrong assumptions about using R in production are still present, which makes it challenging to deploy. Since R is a dynamic language and not compiled, some issues need to be addressed. Python also faces similar issues but is seen as easier to use. Although it is possible to use R in production, it depends on the department, as IT departments tend to be less accepting of R compared to the statistics or math departments.\nThere are always discussions regarding the best programming language to use in various industries. However, with the emergence of cloud technology and containerization, it is possible to package everything up into a nice container, making it work well. R is an industry-standard, and many risk departments in the financial industry use it to develop core models. Although people may complain and want to learn other languages like Python, R is still widely used.\nWhat industry are you currently in? How do you use R in your work?\nWe apply our expertise to various industries, including finance and pharmaceuticals. As external consultants, we assist clients in setting up proper procedures and creating useful dashboards and applications. We often work with existing R codes or other resources to improve their functionality and create helpful add-ons. Our focus is on maximizing existing knowledge and leveraging the existing code base. Our services often involve package creation, documentation, containerization, and dashboard framework development. We tailor our approach to suit the unique needs of each project.\nNowadays, we are developing more and more frameworks to set up departments in the industry with the right infrastructure. This includes developing R packages and connecting everything with the rest of the organization. Initially, we started by creating small models and calculations, but it gradually became more significant, and now we are mostly helping entire departments set themselves up in the right way and make the most of R and their people.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nThe trend of containerization has been around for some time now, where you package your app or REST API dashboard in a Docker container and deploy it in an environment such as the cloud. This trend is prevalent in both R and Python. As for upcoming trends, I am excited about the web assembly initiative, which makes it possible to run a Shiny app within a browser without a server. This initiative has great potential and can bring R to people who are unaware of its existence. It is exciting to see R bring data and statistics to life in various applications. I hope that this initiative can go further and reach more people.\nRegarding the deployment of our Shiny projects, it is always surprising to see how complicated it can be depending on the environment. This tool aims to make the deployment process easier and accessible to a broader audience. Currently, the loading times are still too long, but these issues can be optimized with some improvements.\nI have noticed another trend in certain industries, which is the increasing demand for regulatory compliance. For example, the FDA regulates the pharmaceutical industry, while finance has its own regulatory authorities. This trend encompasses ensuring that packages and codes are properly regulated and reviewed. I am seeing this trend in both the finance and pharmaceutical industries.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nWe have a GitHub page and a Meetup page, which is our setup. We tried to ensure that everything we present is also available, such as code and slides on GitHub, so that it’s easy for everyone to access. However, finding speakers and rooms is always a challenge. The good news is that finding rooms is getting easier than finding speakers. Some companies are always willing to host an hour-long meetup and have some online meetings. We are a group of smart people who like to talk about interesting things.\nThe most challenging aspect is locating speakers, particularly female speakers. I am pleased that initiatives like R Ladies provide a dedicated space for women in this field. Generally, finding speakers is a difficult task for us, and we rely heavily on referrals from friends and acquaintances. However, as a community, we always work to overcome this obstacle.\nIt’s important to always have a stream of topics and speakers available for events, but this can be difficult, especially when finding female speakers. Creating a welcoming and safe community where everyone feels comfortable sharing their knowledge is essential. Organizing these events is worth the effort, as you get to meet many like-minded people in your industry, and it can help you professionally. You’ll learn a lot and get to know people in your field, which is always an advantage. So, if you’re thinking of organizing meetups, just do it, and you’ll see how far it can take you.\nBefore COVID, our meetings were always in person. We tried recording them, but it didn’t work out. During COVID, we had to switch to online meetings only, and afterward, we started having hybrid meetings. I don’t find online meetups very satisfying because you miss out on the networking and socializing aspects. Going out to a bar or a pub and talking with people is an important part of the experience for me. That’s why I still prefer in-person meetups. However, thanks to COVID, things have changed, and I think we can now find more ways to combine the benefits of in-person and online meetings.\nYou are creating a lot of content that some people miss due to various reasons. There may be people who wanted to attend but couldn’t due to certain difficulties. To address this issue, we have now set up hybrid meetings, which require more equipment, like microphones and cameras. Most of the time, I have to carry this equipment. However, it makes sense to have this kind of content and share it with your community. Sometimes, speakers may not be happy about it, but it’s rare. Most of the time, it makes sense to do it hybrid.\nAs for the hybrid, I can say that recording can be difficult, and it rarely works out perfectly the first time around. However, I would recommend setting up a system that reduces your overhead for platforms like YouTube Live. Strive for minimal overhead to make your life easier. Don’t make the mistake we did once when Hadley Wickham was in town and we had to do a lot of editing and cutting because the recording wasn’t perfect. Instead, aim for a setup that works seamlessly and consider doing live streams instead.\nThe most practical way to share content with YouTube is to stream it live. This automatically uploads the content online, eliminating the need for further actions. As a result, when users visit the platform, the content is readily available for viewing.\nI have realized that delaying uploading our content to perform tasks such as editing and rearrangement is a time-consuming process that‌ does not offer significant benefits. Therefore, we are working towards improving our setup by acquiring high-quality microphones and mobile cameras to make the process more efficient and provide our viewers with a seamless experience.\nI am often amazed by the gratitude expressed by individuals around the world who get the opportunity to participate. Without the necessary infrastructure, achieving this would be impossible. However, some members of my community believe that it requires an excessive amount of work.\nIn light of the current global situation, people are less likely to travel or move to different cities for work or other purposes. Therefore, hybrid events are the most suitable way to improve accessibility and encourage community participation. Event organizers should consider using hybrid formats to provide a more inclusive and efficient experience for all participants."
  },
  {
    "objectID": "posts/navigating-r-impact-in-vienna-insights-from-the-finance-and-pharmaceutical-sectors/index.html#how-do-i-join",
    "href": "posts/navigating-r-impact-in-vienna-insights-from-the-finance-and-pharmaceutical-sectors/index.html#how-do-i-join",
    "title": "Navigating R’s Impact in Vienna: Insights from the Finance and Pharmaceutical Sectors",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/gergely-daroczis-journey-empowering-r-users-in-hungary/index.html",
    "href": "posts/gergely-daroczis-journey-empowering-r-users-in-hungary/index.html",
    "title": "Gergely Daróczi’s Journey: Empowering R Users in Hungary",
    "section": "",
    "text": "Gergely Daróczi, the founder and organizer of the Budapest Users of R Network, updated the R Consortium about the group’s recent activities. Last year, Gergely discussed the group’s inception, and the challenges faced by the group during the pandemic. The group has now resumed in-person meetings, followed by networking sessions. The recent events organized by the group have focused on bioinformatics, large language models, and mathematical modeling.\nPlease share about your background and involvement with the RUGS group.\nI have a background in social sciences, and it was during one of my university classes 20 years ago that I was introduced to the R language. We had to use R to run simulations related to the chaotic behavior of the Hungarian potato market. I found R more enjoyable and versatile than other GUI tools like IBM’s SPSS and started using it for other projects as well. Later, I even developed some additional packages for R.\nI have been working with R for almost 20 years now. Despite my academic background in social sciences, I have worked in various industries, such as ad tech, fintech, and health tech, for the past 10 years.\nIn 2013, I attended my first useR! conference in Albacete, Spain, and it was a great experience to meet fellow R users from around the world. At the conference, I met Szilard Pafka, a Hungarian living in LA and organizer of the Los Angeles R User group. He suggested that I start an R User group in Hungary. After returning home, I decided to give it a shot, and we held our first meeting at the end of the summer of 2013. In a university room, it felt like there were only a dozen R users from academia. However, a lot has changed since then, as we now have almost 2,000 members in the local R User group, which exceeded my original expectations for such a small country like Hungary. It has been an interesting and great experience.\nIn Hungary, the community’s growth began slowly, with only 20 to 30 members in the first few years. However, it gradually increased over time. The community also hosted some famous personalities such as Romain Francois, Matt Dowle, and Hadley Wickham, which further accelerated its growth. Additionally, the community organized the first satRday and second ERUM conference, which provided a platform for networking and knowledge sharing, further strengthening the community.\nHow has the group been doing since our last conversation?\nAfter COVID, restarting the meetups was very challenging. We didn’t organize any virtual events because the main benefit of meetups was meeting in person, having face-to-face conversations, and getting to know each other. Therefore, we waited until the quarantine was over and it was safe to meet in person. We started slowly, organizing only two events per year with around 30 to 70 attendees, which was much lower than before COVID-19. However, it has been great to reconnect with old friends and make new ones.\nRecently, we have been focusing on bioinformatics and I was introduced to a local company that offered help with reaching out to speakers. Speakers drive these community meetings by bringing in a topic for discussion and talk, which we continue to discuss later on. Our past few events have focused on life sciences and have followed a lightning talk format, where we had around five 15-minute talks at each event. The topics were diverse, covering life sciences, some with LLMs involved, others focused on highly advanced math for modeling. We also had shiny applications that showed the biodiversity of forests in Hungary and some open-source tools besides R.\nAny techniques you recommend using for planning for or during the event?\nI can only offer subjective experiences on the matter, but I have witnessed the success of both virtual and in-person communities. However, our focus is on providing an exceptional in-person experience. To achieve this, we search for a central venue that is easily accessible for most of our members. This can be challenging, even in Hungary, a small country, as it can be difficult for members from other cities to travel to the capital for meetups. Nevertheless, we do our best to find a central venue, such as a university or an industry partner who can offer a space for talks and a networking opportunity afterward.\nIt is important to have a room with plenty of chairs and a larger area for people to gather after the talks. We can provide soft drinks, beer, or wine along with some pizzas and have a chat for an hour or two after the talk. The venue is a crucial factor. It’s also important to have speakers who are interested in the community so that they will come to learn as well. It’s great to have speakers with interesting topics, but the most important thing for me is networking. After the talks, coming together and getting to know others, learning about their struggles, and maybe sharing some tips in person with each other, becoming friends, or learning about opportunities in other industries. Networking and facilitating connections are crucial tasks for R user group organizers.\nWhat trends do you currently see in R language?\nFive years ago, machine learning models were a hot topic, and everyone discussed different implementations of GBM. However, things have changed, and nowadays, large language models (LLM) rule over all the topics. LLMs are often implemented in languages other than R, making it difficult to train them from R. Despite this, there are still many use cases for LLMs, even in life sciences and health tech. However, caution must be taken when using AI and LLMs in these fields. Recently, at two bioinformatics events, some nice use cases of LLMs were shared with the audience. This has attracted new members interested in learning how to use AI or LLMs, which can be as simple as doing some API integrations in R, such as calling the chatGPT API to generate text or images.\nI’m excited that COVID restrictions are easing up and meetups are returning to normal. I can’t wait for the first in-person useR! conference in Salzburg in a few months. I highly recommend that anyone who can travel to Salzburg in July join us. The city has excellent train connections to European cities, so I hope many people from Europe can make it. I’m looking forward to attending an in-person useR! conference again.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nCurrently, I’m focusing on the ETL pipeline of the Spare Cores project, collecting information on cloud compute resources, which will soon have the R bindings as well. In the past, I’ve been working on R packages related to reporting (e.g. “pander”) and using R in production (e.g. “logger,” “dbr” or “boto3”). Recently, I enjoyed integrating APIs and frameworks from other programming languages, such as Python (kudos to the reticulate team!), in R."
  },
  {
    "objectID": "posts/gergely-daroczis-journey-empowering-r-users-in-hungary/index.html#how-do-i-join",
    "href": "posts/gergely-daroczis-journey-empowering-r-users-in-hungary/index.html#how-do-i-join",
    "title": "Gergely Daróczi’s Journey: Empowering R Users in Hungary",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/collaborative-growth-the-botswana-r-user-group-and-regional-partnerships/index.html",
    "href": "posts/collaborative-growth-the-botswana-r-user-group-and-regional-partnerships/index.html",
    "title": "Collaborative Growth: The Botswana R User Group and Regional Partnerships",
    "section": "",
    "text": "In 2022, Edson Kambeu, founder and organizer of the Botswana R User Group, shared his plans with the R Consortium how the “New R Community in Botswana Wants to Implement Data Into Local Businesses. In this new interview, Edson updated the R Consortium about the group’s growth and recent activities. The Botswana R User Group has attracted a global audience through its online events and actively collaborates with R User Groups in the region.\nThe Botswana R User Group is seeking speakers for their upcoming online events. If you are an R expert interested in sharing your experience with R users in Botswana, please contact Edson at botswanarusers@gmail.com\nPlease share about your background and involvement with the RUGS group.\nMy educational background is in finance. I pursued finance and investments for my master’s degree but also studied economics during my undergraduate years. Mathematics has been my strongest subject since primary school, and I’m passionate about it. This passion led me to develop an interest in Statistics and statistical software.\nIn the past, I mainly used SPSS, Stata, and EViews for my statistical analysis projects. Then, someone introduced me to data science. During my research on data science, I discovered that two popular programming languages are used for it. I installed Python for the first time, but I could not use it as I didn’t have a computer science background. So, I switched to R and started watching a few YouTube videos. From there, I continued to learn and improve my skills in R.\nR was my first language of choice for Data Science. Currently, I use both R and Python for my work.\nI am pursuing a Master’s in Computer Science with Data Science from the University of Sunderland. Our different modules use R and Python, and knowing both languages is helping me in my studies.\nAs I was learning R around 2019 and beginning to follow several R Users on Twitter, I discovered that small R communities gathered together to learn and share knowledge about it. R Ladies Johannesburg in South Africa inspired me the most, as they held events more frequently during that time. I then became interested in starting an R User community in Botswana.\nIn February 2020, I reached out to Heather Turner, who was scheduled to visit Botswana and other Southern African countries to conduct Introduction to R workshops. During our conversation, Heather provided me with all the information needed to start a community. As a result, in March 2020, Botswana R Users was established during Heather Turner’s Introduction to R workshop.\nHow has your group been doing since we last talked?\nOur meetup group had about 100 members when we last talked to you. We now have almost 400 members. However, I have observed that people from different countries are joining us. We are now a global meetup group rather than a Botswana User group. This is because we mostly hold online meetups, which allow people from other countries to join.\nParticipants attending an online meetup hosted by Botswana R users in collaboration with Estwatini R Users and Bulawayo R\nWe are, however, still committed to growing the local community. We want to see more local participation in our meetup group. Last year, we collaborated with R Ladies Gaborone to organize an introduction to R workshop to increase our local membership. We are pleased to announce that this year, we plan to hold another workshop as a pre-conference event in the upcoming Botswana Deep Learning Indaba conference in July 2024. This workshop will help us to increase our local membership further and create more awareness about our group.\nParticipant at the Introduction to R Workshop held in collaboration between Botswana R users and R Ladies Gaborone\nWe value collaborations with our partner R User meetup groups in Southern Africa. In recent years, we have had regular meetups involving collaborative efforts with the Bulawayo R User Group from Zimbabwe, the Eswatini R User Group from Swaziland, and the Namibia R User Group from Namibia. We have established a routine of holding joint meetups almost every two months, depending on the availability of speakers. The idea is to grow our communities by increasing the frequency of activities.\nVebash Naidoo of RLadies Jozi presenting in an online meetup for Botswana R Users\nYou have a Meetup titled “GIS and Creating Dashboards in R. A case study of conflicts events in Kenya,” can you share more on the topic covered? Why this topic?\nI had an opportunity to attend a series of workshops and webinars organized by the United Nations for their Datathon. I realized the importance of GIS in advancing sustainable development. In January 2024, I invited Godwin Murithi, a GIS specialist, to present a topic on GIS. The topic was “GIS and Creating Dashboards in R. A case study of conflict events in Kenya.” We wanted to expose our members to the rising field of GIS and show them how the R language and various packages can help solve GIS problems. It was a fascinating topic for our participants, and they loved it.\nHow has the use of R evolved in the industry since we last talked?\nWe are observing an increasing acceptance of the R programming language, particularly in universities. Some universities have adopted R as their primary language for statistics and quantitative programs. This trend indicates academic institutions’ growing preference for open source programming languages.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nOrganizing is one of the most challenging tasks. To get speakers, I have primarily used Twitter (now called X) and LinkedIn to communicate with people who might want to speak at our meetup groups. Lately, there has been a problem with sending direct messages on Twitter. The reason is that Twitter has changed its messaging system. Now, to send a direct message, you need to be verified. I have been affected by the fact that my usual way of talking to people has been disrupted. Therefore, I have resorted to using LinkedIn to search for people interested in R and reach out to them. Sometimes, they are too busy or cancel, which can be challenging. However, I have been successful in finding potential speakers through these platforms.\nOccasionally, we use different video conferencing tools like Zoom and Google Meet. We usually rely on these two platforms. However, sometimes a speaker may prefer using Google Meet over Zoom, so we try to be flexible and accommodate their preferences.\nWe also use GitHub. We have our account, and if the speaker has their material on GitHub, they can share the link with us. Alternatively, they can provide us with the material directly, and we will upload it onto our own GitHub account for the community to access. Ultimately, it all depends on the speaker’s preference.\nPlease share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting, especially related to the industry you work in?\nOne of my recent school projects was to create a dashboard about UK imports and exports, which I completed towards the end of last year. I developed this project using Shiny and R packages such as Shiny Dashboard, ggplot2, and dplyr.\nI’m currently working on another project that is still in its early stages. The goal of this project is to identify areas in Botswana that require greater financial inclusion. I am currently gathering data and plan to utilize R and Python to apply geospatial techniques.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nI have observed that people find Quarto and GIS techniques interesting. The community is gaining increasing interest in these areas, and I foresee the increasing use of R in GIS applications."
  },
  {
    "objectID": "posts/collaborative-growth-the-botswana-r-user-group-and-regional-partnerships/index.html#how-do-i-join",
    "href": "posts/collaborative-growth-the-botswana-r-user-group-and-regional-partnerships/index.html#how-do-i-join",
    "title": "Collaborative Growth: The Botswana R User Group and Regional Partnerships",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "",
    "text": "It has been a momentous year for the R Consortium, and we are very grateful for the engagement and support we have received from our member sponsors and all the members of the R community."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#members-91-r-user-groups-39-countries-6-continents",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#members-91-r-user-groups-39-countries-6-continents",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "76,048 members, 91 R User Groups, 39 countries, 6 continents",
    "text": "76,048 members, 91 R User Groups, 39 countries, 6 continents\n\nOur R User Groups program is better than ever! We helped to support a lot of you out there learning and sharing the R language. It is exciting to see this type of activity and we hope that in 2025, these groups will continue to grow and that we can sponsor new groups, too. We are always looking for more and better ways to support the community. We hope that you will let us know your suggestions for helping to grow the R community in your area."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#working-groups-and-top-level-projects-delivering-progress-and-access",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#working-groups-and-top-level-projects-delivering-progress-and-access",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "Working Groups and Top-Level Projects delivering progress and access",
    "text": "Working Groups and Top-Level Projects delivering progress and access\nMany of our working groups and projects had solid wins this year in pushing forward on their projects.\n\nOur Submissions working group achieved its fourth successful submission with the FDA – the first to feature WebAssembly to bundle a Shiny application into a self-contained package.\nWe kicked off our Health Technology Assessment (HTA) working group with two workstreams (1. Stakeholder and landscape mapping and opportunity assessment & 2. R Tools for HTA – Identification, Curation, and Education) addressing issues in health technology evaluation and building a well-documented resource for robust R tools in HTA.\nMultilingual R Documentation has published its first package rhelpi18n adding multilingual documentation support. This effort is a co-sponsored project with rOpenSci and the Chan-Zuckerberg Initiative’s Open Science Program,\nWe have added R-universe as a new Top-Level Project. R-universe provides a searchable catalog for R software, articles, datasets, anywhere in the ecosystem, and it is an open platform for running CRAN-like package repositories. We are thrilled to be working with rOpenSci on this important infrastructure project for the R community."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#quarto-powered-website",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#quarto-powered-website",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "Quarto powered website",
    "text": "Quarto powered website\nWe must brag about our beautiful new Quarto-based website that we launched this year. Performance was increased by 65% faster overall, with homepage load times going from 2.3 seconds to 0.8 seconds on average in testing. The team did a wonderful job, and we invite the community to join us in contributing to the site. This is a great opportunity for first time contributors and for others to get a chance to work with a Quarto site."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#expanding-support-for-the-r-language-and-infrastructure",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#expanding-support-for-the-r-language-and-infrastructure",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "Expanding support for the R language and infrastructure",
    "text": "Expanding support for the R language and infrastructure\nThe Infrastructure Steering Committee (ISC) funds two grant cycles per year for projects that support the development of the R language and the maintenance of its infrastructure. We funded 13 new projects in 2024. We have dispersed technical grants totaling almost $1.5 million since our founding. Our next grant cycle will re-open March 1, 2025, and now is a great time to contact the ISC to start the process."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#events-irl-and-digital-were-huge-wins-for-all-of-us",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#events-irl-and-digital-were-huge-wins-for-all-of-us",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "Events IRL and digital were huge wins for all of us!",
    "text": "Events IRL and digital were huge wins for all of us!\nLive events are a great way to share new developments and raise awareness of what our community needs or wants. The R Consortium sponsored 12 events this year, and we are looking forward to seeing a lot of you next year at R/Medicine June 10-13 and useR! August 8-10. To access all the digital events and webinar content we produce, please subscribe to our YouTube channel so you are sure to get new videos as we post them."
  },
  {
    "objectID": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#new-year-new-opportunities-and-challenges",
    "href": "posts/moving-forward-to-meet-new-challenges-in-2025/index.html#new-year-new-opportunities-and-challenges",
    "title": "Moving forward to meet new challenges in 2025",
    "section": "New year, new opportunities and challenges",
    "text": "New year, new opportunities and challenges\nI encourage you to register for R/Medicine June 10-13 and SAVE THE DATE for useR! at Duke University August 8-10. We are looking forward to all the great programming in 2025 and would love to hear from the community any requests/ideas for content you would like to see.\nFinally, our mission in support of the R language and its community is at the core of everything we do. This means we need to answer new challenges that face both. The recently passed Cyber Resilience Act will require CRAN and all community repositories to make changes to meet its requirements for distribution of packages in the EU. We are asking now for financial support to ensure that we, in coordination with the Linux Foundation, can assist all our repository maintainers to plan and work toward compliance by October of 2027.\nTo our current members, we thank you for your support and ask you to consider renewing your support at the next level.\nIf you're considering becoming a member-sponsor of the R Consortium, feel free to reach out to me (director at r-consortium dot org) or view the materials on our website."
  },
  {
    "objectID": "posts/r-consortiums-submission-working-group-advancing-r-for-regulatory-success-at-pharmasug-2024/index.html",
    "href": "posts/r-consortiums-submission-working-group-advancing-r-for-regulatory-success-at-pharmasug-2024/index.html",
    "title": "R Consortium’s Submission Working Group: Advancing R for Regulatory Success at PharmaSUG 2024",
    "section": "",
    "text": "PSUg 2024\n\n\nThe R Submission Working Group is making significant strides in promoting the use of R for regulatory submissions in the pharmaceutical industry. At PharmaSUG 2024, held from May 19-22 in Baltimore, MD, the group’s impact was evident through various insightful presentations and discussions.\nOne highlight was Ben Straub’s presentation, “Piloting into the Future: Publicly available R-based Submissions to the FDA,” which showcased the growing adoption of R in both industry and regulatory settings. Straub emphasized the vibrant R community and its diverse packages that enhance statistical analysis and data visualization, highlighting R’s role in facilitating efficient and transparent FDA submissions.\nAdditionally, André Veríssimo and Ismael Rodriguez’s presentation, “Automating SDTM Using R: A Practical Guide,” demonstrated the advantages of using R for automating the creation of Study Data Tabulation Model (SDTM) datasets. They provided a detailed guide on implementing automation techniques and sharing best practices and real-world applications to improve data management workflows with R.\nThese presentations underscored the R Submission Working Group’s contributions to advancing the use of R in regulatory processes promoting greater efficiency, reproducibility, and transparency in pharmaceutical data management."
  },
  {
    "objectID": "posts/empowering-r-enthusiasts-satrdays-london-2024-unveiled/index.html",
    "href": "posts/empowering-r-enthusiasts-satrdays-london-2024-unveiled/index.html",
    "title": "Empowering R Enthusiasts: SatRDays London 2024 Unveiled",
    "section": "",
    "text": "SatRDays London 2024 is set to ignite the data science community with a vibrant lineup of speakers and a rich array of topics ranging from survival analysis to geospatial data. This inclusive event, designed for R enthusiasts at all levels, emphasizes networking and collaboration amidst the backdrop of King’s College London’s iconic Bush House. Keynote speakers like Andrie de Vries, Nicola Rennie, and Matt Thomas bring unparalleled expertise, offering attendees a unique opportunity to deepen their knowledge and connect with peers. As a hub of innovation and learning, SatRDays London promises to be a cornerstone event for anyone passionate about R and its applications in the real world.\n\nRegister Now!\nHow does this year’s satRDays in London compare to last year’s event? What’s new and different?\nAfter a successful SatRdays London in 2023, we are keeping the format the same, but with a whole new lineup of speakers! This year we’re excited to welcome:\n\nAndrie de Vrie – Posit\nHannah Frick – Posit\nCharlie Gao – Hibiki AI Limited\nMichael Hogers – NPL Markets Ltd\nMatthew Lam & Matthew Law – Mott MacDonald\nMyles Mitchell – Jumping Rivers\nNicola Rennie – Lancaster University\nMatt Thomas – British Red Cross\n\nTalk topics for the day include survival analysis, geospatial data, styling PDFs with Quarto and using R to teach R, as well as a range of other exciting themes! The talks can reach a varied audience from aspiring data scientists right to the experienced audiences.\nTake a look at the full list on the conference website for more information.\nWho should attend? And what types of networking and collaboration opportunities should attendees expect?\nAnyone and everyone with an interest in R! The SatRdays conferences are designed to be low cost, to allow as many to attend as possible, and they’re on a SatRday, so you don’t have to worry about getting time off work if your job isn’t necessarily R focussed.\nNetworking is the main focus of the event. We have multiple coffee breaks to give attendees the opportunity to interact with fellow R enthusiasts. If you’re brand new to this kind of event, and are not sure where to start, don’t worry! Find one of the attendees from JR, and we’ll be happy to help you make introductions!\nCan you share some insights into the keynote speakers, their areas of expertise, and how they will contribute to the overall experience at SatRDays?\nAt this year’s event, we have talks from three invited speakers – Andrie de Vries of Posit, Nicola Rennie from the University of Lancaster and Matt Thomas of the British Red Cross.\nAndrie is Director of Product Strategy at Posit (formerly RStudio) where he works on the Posit commercial products. He started using R in 2009 for market research statistics, and later joined Revolution Analytics and then Microsoft, where he helped customers implement advanced analytics and machine learning workflows.\nNicola is a lecturer in health data science based at the Centre for Health Informatics, Computing, and Statistics at Lancaster University. She is particularly interested in creating interactive, reproducible teaching materials and communicating data through effective visualisation. Nicola also collaborates with the NHS on analytical and software engineering projects, maintains several R packages, and organises R-Ladies Lancaster.\nMatt is Head of Strategic Insight & Foresight at the British Red Cross. His team conducts research and analysis to understand where, how and who might be vulnerable to various emergencies and crises within the UK.\nCould you elaborate on the types of sessions and workshops available and how they cater to different interests and skill levels within the R community?\nThe day will consist of eight 25-ish minute talks, plus Q&A, from a variety of speakers across various sectors.\nThe talks are on a wide range of topics. For example, last year we had speakers talking about everything from using R for mapping air quality, to EDI and sustainability in the R project, and why R is good for data journalism. If you want to take a look at what you can expect, we have a playlist of last year’s talk recordings available on our YouTube channel.\nWith the event being hosted at King’s College London, how does the venue enhance the experience for attendees, both in terms of facilities and location?\nWe’re very excited to be partnering with CUSP London again this year, who provide the amazing Bush House venue at King’s College London. The venue is a beautiful listed building, right in the heart of London, only a few minutes walk from Covent Garden.\nBeing in the center of London means easy access to multiple public transport links, both for national and international attendees!\nThe venue facilities and supporting technology provides a great space for sharing insights and networking.\n\n\nDon’t miss out, register today!"
  },
  {
    "objectID": "posts/one-more-step-forward-the-r-consortium-submission-working-group-presentation-to-swissmedic-on-regulator-submission-using-r-and-shiny/index.html",
    "href": "posts/one-more-step-forward-the-r-consortium-submission-working-group-presentation-to-swissmedic-on-regulator-submission-using-r-and-shiny/index.html",
    "title": "One More Step Forward: The R Consortium Submission Working Group’s Presentation to Swissmedic on Regulatory Submission using R and Shiny",
    "section": "",
    "text": "This post was authored by Gregory Chen, Biostatistics and Research Decision Sciences (BARDS), MSD, Switzerland, and Ning Leng, Product Development Data Sciences (PDD), F. Hoffmann-La Roche, USA\n\nOn January 30, 2024, the R Consortium Submission Working Group made a presentation to Swissmedic in Bern, Switzerland, with 10 attendees in person and 50 online. It started with a motivation as to why to consider using open source and specifically R for regulatory submissions. The group then proceeded to show cases of the pilot 1 and 2 submission to FDA.\nThe conclusion was an insightful discussion for about 20 minutes with the participants on the lessons learned, key factors to sort in line for broader adoption of R and Shiny for regulatory submissions, and what would be most added value for a regulatory shiny app, namely\n\nHow to deploy the submitted R package and Shiny App to guarantee the clinical outcomes can be smoothly reproduced on the regulatory side\nWhat would be the ultimate purpose of a regulatory shiny app, and what are value-added features? Should the app only focus on offering interactivities to facilitate the review of tables, figures, and listings in CSR, or should it also include designed features to enable exploratory, descriptive analysis (e.g., for subgroups) to certain degrees, which may greatly shorten back-and-forth inquiry between regulator and drug developer?\nValidation and version traceability of dependent open source R packages used in the submission package\nHow to leverage existing and emerging cross-industrial initiatives (e.g. R consortium) in the open source space to support and ease the potential technical issue during the adoption of R for submission\n\nAccompanying this post, the full presentation slide deck is made publicly available here, inviting further exploration and discussion.\nThe R Consortium’s presentation at Swissmedic represents a hopeful step toward more interactive, efficient, and transparent regulatory submissions. As the conversation between the R Consortium and regulatory bodies continues, our future collection of pilot projects hopefully will offer richer examples and templates to our growing R community within the pharmaceutical sector, spanning both regulatory and drug developer sides.\nTo find out more about the R Consortium Submission Working Group, please see: https://rconsortium.github.io/submissions-wg/"
  },
  {
    "objectID": "posts/Full-time-Korea-R-User-Group-Founder-Victor-Lee-Sees-AI-Future-for-R-and-Quarto-Textbooks-R-Consortium/index.html",
    "href": "posts/Full-time-Korea-R-User-Group-Founder-Victor-Lee-Sees-AI-Future-for-R-and-Quarto-Textbooks-R-Consortium/index.html",
    "title": "Full-time Korea R User Group Founder Victor Lee Sees AI Future for R and Quarto Textbooks",
    "section": "",
    "text": "The R Consortium recently interviewed Victor Lee, organizer of the Korea R User Group, about his role establishing and expanding the Korean R community. Victor shared his journey, beginning with an introduction to R and open source programming languages while working at the Hyundai Motor Company, and later, his efforts in establishing the tidyverse community in Korea. He highlighted his extensive experience with R, including writing blog posts, publishing Quarto books, and building websites for the Korea R User Group. Victor will be a Software Carpentry instructor at the Software Carpentry Workshops at Sejong University.\nPlease share about your background and your involvement in the R Community.\nMy first introduction to our community was about 10 years ago, and it wasn’t a good experience. I used to work at the Hyundai Motor Company at that time and was intrigued by the software carpentry led by Greg Wilson. I also delved into statistics and open-source programming languages, particularly S and R programming. I was heavily involved in posting about tidyverse, which was my entry point into the community environment. In Korea, I sought out the Korean community, which mainly focused on the basics. This made me realize the need for a community in Korea based on tidyverse principles, and that’s why I started the tidyverse community in Korea 10 years ago.\nI was first introduced to S-PLUS during my undergraduate years as a statistics major, and I was fascinated by its superior graphics compared to SAS/SPSS. After majoring in computer engineering and working at Hyundai Motor Company for 10 years, I obtained a Software Carpentry Instructor certification and translated “Python for Informatics” into a Korean book. I became captivated by the Hadleyverse, and Since 2016, I have been co-organizing the Seoul R Meetup, sponsored by Kyobo DPLANEX (a continuous sponsor and is currently the largest sponsor of the Seoul R Meetup, representing one of South Korea’s leading insurance companies) alongside Choonghyun Ryu, the founder of the Korea R User Group. In 2021, we hosted the Korea R Conference, and in 2021, we established the Korea R User Group as a non-profit organization, transitioning from a community to an official organization.\nWhat is your level of experience with the R language?\nWith the support of the R community, ChatGPT, and Copilot AI, I now confidently tackle any data science problem using R. For about 10 years, I’ve consistently written blog posts using R Markdown and now Quarto. Upgrading my e-books with Bookdown led to the publication of five Quarto books on data science. Using the Quarto framework, I also built the Korea R User Group and R Conference websites. As a civic data journalist, I’ve written around 100 articles utilizing R’s visualization capabilities. Reflecting on my journey, I see how effectively I’ve applied the R language in various fields.\nWhat industry are you currently in? How do you use R in your work?\nI originally set up the Korean R community 10 years ago and am a founding member of the nonprofit Korea R User Group, established three years ago. I left KPMG to dedicate my time to running the Korea R User Group. This year, I have been fully involved in managing the organization and leading several projects, including two major abandoned projects, focusing on them for the past few months.\nCurrently, I am focusing on publishing and developing open statistical packages at a non-profit public interest corporation. In 2020, with good intentions, I started the “Open Statistical Package” project to independently develop statistical packages like SAS, SPSS, and Minitab. However, some Shiny developers without a strong background in statistics took the project in their direction, causing it to lose steam. It felt as though they had hijacked the project and the hard work the Korea R User Group put in, leaving us frustrated and disappointed.\nTo prevent this kind of thing from happening again, we’re beefing up our license policy, including trademark registration for BitStat[1]. We’re also switching up our development engines to webr and shinylive and are in the process of creating BitStat2[2].\n[1]: https://github.com/bit2r/BitStat [2]: https://github.com/bit2r/BitStat2\nWe also established a publishing company named “BitStat” as the Korea R User Group promoted Quarto digital writing as a new open source project. Recently, we have published and released five data science books, expanding the base of R users. While writing the sixth book on probability and statistics, I restarted the development of open statistical packages using Web-R and Shinylive.\nR has evolved from a simple data analysis and statistical language to a tool that can replace office software. I now use Quarto to create almost all documents, and R is the first language I use in developing the open statistical package that I am currently working on.\nWhy do industry professionals come to your user group? What is the benefit for attending?\nIn Korea, about 20 to 30 years ago, R was the number one programming language for data science and statistics, particularly in areas like machine learning. However, with the rise of Python, many R users transitioned to Python due to its increasing popularity. Despite this shift, R remains significant in Korea, with many people continuing to use both R and Python.\nFor my day-to-day work, I find R quite convenient and easy to use, especially for therapeutic data and open-source case studies. This year, I’ve noticed that users who join the Korea R User Group come from diverse backgrounds, including drug discovery, regulatory agency, and real estate.\nOver the past decade, many users joined the group to determine whether Python or R was better suited for their work. However, the recent trend clearly leans towards artificial intelligence development, such as LLM (Large Language Model) development. Participants from various industries with an interest in quantitative analysis are now attending the user group.\nTheir motivation for attending, apart from AI fields represented by LLM, is to acquire the latest technology in other data science areas and to gain knowledge from diverse, in-depth analysis experiences and model development. Additionally, many people come to obtain information about Quarto, ggplot, gt, and shiny, seeking business opportunities related to these tools.\nWhat trends do you currently see in R language and your industry? Any trends you see developing in the near future?\nThis year, our community in Korea is focusing on Quarto due to upcoming government policy changes. Analog methods are expected to disappear within five years, so the government is funding the development of AI digital textbooks. I believe Quarto technology, the next generation of R Markdown, is perfect for this purpose.\nAs generative artificial intelligence (AI) has gained significant attention in Korea, there is growing interest in using R and Python together with generative AI to solve data science problems and increase productivity, rather than focusing on the languages themselves. When using generative AI with languages such as R, Python, and SQL, it becomes necessary to find tools that can automate and store the outputs, inevitably leading to increased interest in Quarto.\nThis perspective has been reinforced by my experience using Quarto in various ways, starting from R Markdown. I have come to realize that Quarto is truly well-suited for generative AI and data science. If other countries are developing AI texts using Quarto or R Markdown, we could introduce this technology to the Korean market and the Korean government.\nHaving written five books – plus a sixth on probability and statistics – I’ve experimented with various features of Quarto books. I’ve realized we no longer need older statistical packages like SAS and SPSS. My current project involves implementing statistical software using WebAssembly (WASM) technology.\nWe would like to get to know you more personally. Can you please tell me about yourself? For example, your hobbies/interests or anything else you want to share.\nInitially, I wasn’t sure if I would succeed, but I became involved in election campaigns and grew passionate about analyzing political and election data. My interest lies in using data to uncover trends and insights from various social datasets.\nNext month, we will have a data journalism meetup, and I have friends who will join because of the articles I wrote. They will showcase some of their analyses on TV, including summaries of data related to election campaigns.\nI first developed a connection with data while majoring in statistics and then pursued computer engineering in graduate school. Although this combination of backgrounds is common now, it was unusual in Korea at the time, giving me a unique career path. My passion for open-source software and faith in the community have driven me to where I am today.\nI enjoy analyzing data, and whenever I come across interesting datasets, I analyze them and document my experiences on my blog. This hobby, along with the copyright-free nature of data, led me to develop an interest in predicting election winners using data from annual elections in South Korea. Since 2016, I have experienced three general elections, presidential elections, and local elections. Although there won’t be an election next year, I am very much looking forward to the next one."
  },
  {
    "objectID": "posts/Full-time-Korea-R-User-Group-Founder-Victor-Lee-Sees-AI-Future-for-R-and-Quarto-Textbooks-R-Consortium/index.html#how-do-i-join",
    "href": "posts/Full-time-Korea-R-User-Group-Founder-Victor-Lee-Sees-AI-Future-for-R-and-Quarto-Textbooks-R-Consortium/index.html#how-do-i-join",
    "title": "Full-time Korea R User Group Founder Victor Lee Sees AI Future for R and Quarto Textbooks",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/rconsortium-grants-comittee-announces-new-chair/index.html",
    "href": "posts/rconsortium-grants-comittee-announces-new-chair/index.html",
    "title": "R Consortium Grants Committee Announces New Chair",
    "section": "",
    "text": "The R Consortium is pleased to announce that Katherine Jeschke has been appointed Chair of the Grants Committee.\nShe will oversee day-to-day grant processes for both pre- and post-awards, ensuring grants meet the R Consortium’s strategic objectives. Katherine will report to the Executive Director and work closely with the Infrastructure Steering Committee and the RUGS program to track grants and help improve the effectiveness of R Consortium grants in supporting the R Community.\nKatherine’s non-profit grants and administration skills were honed over more than 25 years of experience in marketing communications, and staff, budget, development, and grants management for non-profits and trade organizations, as well as corporate and public sector consulting organizations.\nShe holds an MA degree in American History and Museum Administration from George Washington University and a BA degree in Fine Arts and Art History from the University of Maryland.\n“Getting acquainted with our various grants and procedures while evaluating the strategic effectiveness of R Consortium grants is a big undertaking, but her background and years of experience should ease her way,” said Joseph Rickert, Executive Director of the R Consortium.\nShe may be reached at kj.jeschke@posit.co"
  },
  {
    "objectID": "posts/r-ladies-goiania-promoting-diversity-and-inconclusion-in-local-r-community/index.html",
    "href": "posts/r-ladies-goiania-promoting-diversity-and-inconclusion-in-local-r-community/index.html",
    "title": "R-Ladies Goiânia: Promoting Diversity and Inclusion in Local R Community",
    "section": "",
    "text": "Fernanda Kelly, founder and organizer of the R-Ladies Goiânia, recently talked to the R Consortium about the group’s efforts to provide a learning and networking platform to gender and ethnic minorities in the local R community. She discussed the group’s successful transition to virtual events, which has helped increase its visibility and reach.\n\n\n\nPlease share about your experience and involvement with the RUGS group.\nMy name is Fernanda Kelly, and I’m 28 years old. I graduated from the Federal University of Goiás with a degree in statistics. During my studies, I became familiar with the R programming language. However, it wasn’t until 2019 that I realized how underrepresented women and black people are in this field. This led me to establish a new R-Ladies chapter that same year to promote diversity and inclusion in the industry.\nI worked as a statistician for 4 years at Hospital Moinhos de Vento, where I was involved in the Pfizer Project that analyzed the effectiveness of the COVID-19 vaccine in Brazil. After that, I worked as a Data Scientist at Accenture Brasil. I hold a degree in Machine Learning and an MBA from the University of São Paulo. Recently, I completed a specialization in project management, and I am currently pursuing a master’s degree in Intelligent Systems and their applications in the Healthcare sector.\nI have incorporated the R language extensively in my work and studies. Its versatility in interacting with other languages and its diverse range of tools for creating reports, such as R Markdown and Quarto, provide users with multiple ways to develop high-quality models and reports. I have used R for various tasks, such as modeling, data processing, manipulation, and writing with blogdown and R Markdown. R’s constant updates and information dissemination about its features have increased my usage of the language even more.\nI haven’t been involved with the RUGS community lately, but I found out about the initiative on LinkedIn and thought, ‘Why not apply?’ Sometimes we hold ourselves back and don’t even consider applying for opportunities, but I applied this time and succeeded.\nOur group is a chapter of the global R-Ladies community that strives to promote awareness of R programming language among individuals belonging to minority genders. We cover a broad range of topics helping facilitate individuals entering the job market. Some topics we cover include public speaking, mentoring on how to fill out LinkedIn, and occasionally Excel. We believe R programming goes beyond just coding and that is why we emphasize the development of soft skills as well. We view the community as a trainer of future professionals. To date, we have held over 40 meetings, and this year we plan to offer over 20 workshops. These workshops will cover an array of diverse topics, but our primary goal is to showcase the functionalities of the R programming language in comparison to other programming languages like Python.\nI want to emphasize that the work I have accomplished for the R community since 2019 with R-Ladies Goiânia was not a solo endeavor. I have great admiration for the exceptional women I have walked alongside, and currently, I am fortunate to have Jennifer Lopes (a remarkable black woman) by my side since 2023, who has been helping me with R-Ladies Goiânia.\nCan you share what the R community is like in Goiânia?\n\n\n\nWhen I talk about community, I also refer to the city of Goiânia, located in the heart of Brazil, where the population is a mix of different ethnicities. The R community in Goiânia is huge, especially within the university. Many degree programs use R as their primary programming language. I fell in love with the power of the R during my undergraduate studies in statistics. However, during my master’s degree, I realized that there was a lack of representation for minority genders and ethnic groups. This led me to search for communities that catered to this audience. As a result, I discovered the R-Ladies community and founded the R-Ladies Goiânia chapter in mid-May 2019. Since then, the chapter has grown and reached out to many women, black people, and members of the LGBT community.\nR language is widely used in Brazil across various sectors, including health, agriculture, and financial institutions. The primary reason for its popularity is the vast range of packages it offers and the structured control offered by CRAN, which enhances the language’s credibility and security.\n\nDo you have an upcoming event planned? Can you share more about the topic covered? Why this topic?\nWe have an upcoming event planned which will be presented by Julia Helen, who lives in Rio de Janeiro. She is a statistician by profession and works as a data scientist at a large television station in Brazil. The meetup will cover the connection between R and Python. This event will take place on March 16th, and everyone is invited to attend. The primary focus of the meeting will be to teach R programmers how to use Python within RStudio effectively. By leveraging both languages, programmers will take advantage of their combined functionalities. The choice of this topic is because of the high demand among R programmers to learn about the use of Python and how to make both languages work seamlessly within RStudio.\nAny techniques you recommend using when planning or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive for people who may not be able to attend financial events in the future?\nR-Ladies Goiânia is present on diverse networks, but we recommend using GitHub to access our course material. We have complete control over the material available on GitHub, and it helps participants gain knowledge on the platform, which is often required by companies in Brazil. We are currently using Zoom through the Sympla platform, which is free and offers many control options over the event. The platform allows us to manage registration, accept the code of conduct, and send certificates to attendees.\nWe have hosted our meetings online since 2020, and it has worked well for our group. In our meetings we have people from various states in Brazil and, sometimes, we have people from other countries participating. This is incredible and this way we can reach more people, making the chapter decentralized. We have already reached 100 people watching the Introduction to R meetup. All of our events are recorded, and this gives people who could not attend the live event and people in career transition the opportunity to access the content. Currently, our YouTube channel has more than twenty videos.\nFor the future, we are planning more accessibility, but we know how poorly developed the accessibility of broadcasting platforms is. R-Ladies Goiânia aims to achieve real diversity in its meetings and has been working towards this with campaigns on Instagram, LinkedIn and Twitter. We are seeking innovation and managed to open a mentoring program, which is a big step for the chapter and we are extremely happy.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nAs I mentioned before, my most recent project involved using the R programming language to analyze the effectiveness of the Pfizer vaccine in Brazil. The project was conducted in collaboration with Pfizer, a large pharmaceutical company, and the results have been published in an article titled “BNT162b2 mRNA COVID-19 against symptomatic Omicron infection following a mass vaccination campaign in southern Brazil: A prospective test-negative design study“. The code used for this project is available on my GitHub.\nWhat resources/techniques do/did you use? (Posit (RStudio), Github, Tidyverse, etc.)\nIn this project, we utilized a range of techniques. R Markdown was the most frequently used tool for generating reports in both HTML and PDF formats. Apart from the tidyverse package, we also employed a variety of packages for analyzing PDF data (such as pdftools), data analysis (including lme4 and sampling), and data tabulation (such as reactable, DT, and qwraps2). We utilized GitHub solely to host the codes for the published article.\n\nHow do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "",
    "text": "Jeffrey Stevens, organizer of the Nebraska R User Group, recently spoke with the R Consortium about his efforts to establish a vibrant R community across Nebraska. Jeffrey shared insights into the group’s activities, including fostering connections between academics, industry professionals, and nonprofits, and creating a hybrid model to engage participants from across the state. He also discussed his passion for package development, open science initiatives like the Many Dogs Project, and the challenges of building an inclusive R ecosystem in a geographically dispersed region."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-share-your-background-and-involvement-with-the-rugs-group.",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-share-your-background-and-involvement-with-the-rugs-group.",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "Please share your background and involvement with the RUGS group.",
    "text": "Please share your background and involvement with the RUGS group.\nI am a professor of psychology at the University of Nebraska-Lincoln, where I lead the Canine Cognition and Human Interaction Lab. My research focuses on animals, comparative psychology, and animal cognition, a field I have been involved in since the mid-1990s.\nI have been using R for over 15 years, but I initially worked with S-Plus during my graduate studies in the late 1990s. For the past 15 years, R has been my primary tool for data analysis.\nIn the last three years, I have also ventured into package development. To date, I have published three packages on CRAN. One package excluder is designed for data wrangling specifically tailored for survey data that psychologists often encounter. Another package flashr creates flashcard slide decks to assist learners in mastering R; it includes R functions and descriptions, allowing students to familiarize themselves with terms and functionalities. My most recent package cocoon takes statistical objects. It generates R Markdown or LaTeX text that can be easily inserted into documents, making extracting and presenting the statistics you need simpler.\nI teach R to diverse learners, including undergraduates, graduate students, postdocs, lab managers, and some faculty members. Additionally, I serve as a data science mentor for Posit, guiding corporate individuals through data science training programs. In this role, I lead cohorts of employees seeking to enhance their R and data science skills. I have participated in several of these mentoring sessions, and my extensive experience with R has made it an essential part of my daily work."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#what-was-your-motivation-behind-starting-this-r-user-group",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#what-was-your-motivation-behind-starting-this-r-user-group",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "What was your motivation behind starting this R User group?",
    "text": "What was your motivation behind starting this R User group?\nI know a few people at my university who use R, but there are just a handful here and there—not many. Most of them were using it for their projects. Then, about two years ago, I discovered that there was a faculty member in the Statistics Department named Susan VanderPlas. She had joined the department a bit earlier, but that was when I first learned about her. I found out that she shared my passion for R; she is also an R user and an educator enthusiastic about building websites and engaging with the community. She was the first person at my university with whom I connected over our shared interest in R.\nI proposed starting an R user group, but she initially suggested we take a different approach. Last year, instead of forming a formal user group, we contacted everyone on campus who used R. The goal was to gather and have informal monthly chats about R-related topics. During our meetings, we discussed various subjects. The first gathering occurred right after Posit::Conf, where we shared our experiences from that conference.\nAs we continued meeting, I realised that my original vision was establishing a dedicated user group for R enthusiasts. Susan and I started a user group after talking with others on board with the idea. I took the initiative to move forward with it, and the R consortium grant was the primary motivation that pushed us to get serious about this project. Preparing the grant proposal was what got things started. Without that grant, I’m not sure we would have progressed as far as we have.\nWhile I’m leading this initiative, Susan is also helping out. It’s important to me that we extend our reach beyond the university. While most of my connections are within the university, I want to engage with other universities, government, and industry groups. That’s why we aim to connect with the broader community in Nebraska.\nI learned there was a group in Omaha, about an hour from my location in Lincoln, Nebraska, but it has become inactive. We invited anyone from Omaha, Lincoln, and surrounding areas to join us.\nNebraska is not a very populous state. Most of the population is concentrated in Lincoln and Omaha, leaving many smaller towns with fewer residents. However, we wanted to ensure that people from these smaller areas also had the opportunity to participate, so we decided to make our initiative statewide rather than city-specific.\nTraditionally, many of our user groups have focused on urban areas. Still, given Nebraska’s vast land area, creating a welcoming environment for those outside the major cities was important. Several hundred miles separate some of the smaller towns, and we want to ensure everyone feels included.\nOur goal is to make as many of our meetings hybrid as possible. This way, we can include individuals in western Nebraska and other towns beyond Lincoln and Omaha. We want them to feel connected and engaged. Our first kickoff meeting was in person, but after that, we have implemented the hybrid model so that participants from all around Nebraska can join our discussions as well. It’s important to us to involve those outside the main urban centres."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#can-you-share-what-the-r-community-is-like-in-nebraska",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#can-you-share-what-the-r-community-is-like-in-nebraska",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "Can you share what the R community is like in Nebraska?",
    "text": "Can you share what the R community is like in Nebraska?\nAlthough I have little experience with industry connections, I want to involve more industry professionals in our group. I have sent out an email summarising our discussions. I encouraged industry professionals to reach out, as one of our kickoff meeting discussions focused on the topics people want to hear about in future talks.\nAll attendees at the kickoff meeting were from academia or involved in nonprofit or government roles, such as parks and recreation or public media. However, no one from a corporate background was present. A graduate student expressed a strong interest in moving from academia to industry and asked how a graduate student with academic skills can transition into an industry job.\nI highlighted this topic in my email, emphasizing the desire for industry partners to participate and share their insights. The academic participants are significantly interested in how to transition to industry positions, an area I feel more comfortable discussing.\n Nebraska R User Group Kickoff Meeting: Collin Berke"
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-provide-details-about-the-kick-off-meeting-for-your-group.-what-topics-were-discussed-and-how-did-participants-respond",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-provide-details-about-the-kick-off-meeting-for-your-group.-what-topics-were-discussed-and-how-did-participants-respond",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "Please provide details about the kick-off meeting for your group. What topics were discussed, and how did participants respond?",
    "text": "Please provide details about the kick-off meeting for your group. What topics were discussed, and how did participants respond?\nThe kickoff meeting was fantastic. As I mentioned last year, the original group consisted of about five or six people from the university. Typically, only four of us met each month, which was relatively small. However, we had 20 people in attendance for the kickoff meeting, which was great! It was mostly folks from Lincoln; unfortunately, no one from Omaha could make it since the meeting was in person.\n Nebraska R User Group Kickoff Meeting: Rachel Rogers\nI was excited about the turnout, mainly because most attendees were academics I already knew. Still, I also met a few new people from the university. Additionally, we had representatives from Nebraska Public Media and Nebraska Game and Parks, which was exciting because it included some nonprofit and governmental groups.\nWe did not have a specific topic to discuss, as the main goal was to spend most of the time networking. I wanted everyone to talk, make connections, and meet new people.\nMy main goal for the kickoff meeting was facilitating communication among the attendees. We dedicated a significant portion of time to this at the beginning and end of the meeting to ensure everyone had ample opportunity to chat. I also made introductory announcements and introduced myself, outlining what we hoped to achieve with the group.\nWe included a couple of lightning talks in the agenda. These were short, five-minute presentations showcasing the various projects participants had been working on. The aim was to help everyone build connections and gain insight into their peers’ work.\n Nebraska R User Group Kickoff Meeting: Participants\nOne graduate student discussed a package they developed based on their research, while a faculty member presented an R course they created along with its accompanying website. A representative from Nebraska Public Media shared how they utilize R in their daily operations. Lastly, I provided a brief overview of my flashcard package.\nThe goal was to provide a brief insight into what various people are doing from different perspectives. The event was very successful. The attendees enjoyed it; they were excited to learn about what others were doing and to get involved. Overall, I was pleased with how the kickoff meeting turned out."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#do-you-have-a-plan-for-this-year-what-is-the-frequency-of-the-events-you-plan-to-host-and-what-topics-will-you-cover",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#do-you-have-a-plan-for-this-year-what-is-the-frequency-of-the-events-you-plan-to-host-and-what-topics-will-you-cover",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "Do you have a plan for this year? What is the frequency of the events you plan to host, and what topics will you cover?",
    "text": "Do you have a plan for this year? What is the frequency of the events you plan to host, and what topics will you cover?\nI’m still working on that piece. I plan to hold these events roughly once a month during the academic year. So, starting in February, I envision having sessions in February, March, April, and May. Over the summer, we could get creative and consider doing something different instead of just talking. An in-person event could be a good option.\nAs mentioned, I want to involve some industry professionals. They would like to discuss the role of R in the industry and explore how people learning R can leverage their skills to seek job opportunities.\nI recently attended our second meeting, which was our initial discussion. I asked the group if they wanted to share topics, ideas, or presentations. One suggestion was to have a “beginner’s night” for those with little exposure to the subject. This would help newcomers by introducing them to the basics.\nUser groups often contain members with varying experience levels, and it is essential to have a sense of how to cater to everyone. Our last meeting featured an advanced talk on extensions to ggplot2, specifically building geoms, which is quite complex. We want to ensure that we also engage those new to R. It’s essential that they feel included, have the opportunity to ask questions, and learn something valuable by attending the group.\nI don’t have a fully developed plan yet, but I have two initial ideas I’m still working on. I aim to be as inclusive as possible, engaging participants from various experience levels and backgrounds—from the industry, academia, government, or non-profits. I want to involve everyone and see what we can achieve together."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-share-about-a-project-you-are-working-on-or-have-worked-on-using-the-r-language.-what-is-the-goalreason-result-or-anything-interesting-primarily-related-to-your-industry",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#please-share-about-a-project-you-are-working-on-or-have-worked-on-using-the-r-language.-what-is-the-goalreason-result-or-anything-interesting-primarily-related-to-your-industry",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "Please share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting, primarily related to your industry?",
    "text": "Please share about a project you are working on or have worked on using the R language. What is the goal/reason, result, or anything interesting, primarily related to your industry?\nMy work involves running the Canine Cognition and Human Interaction Lab with two main focuses. One focus is studying dog cognition. We invite pet dog owners to bring their dogs to our lab on campus, where we play games involving treats. We hide food in specific locations or provide choices, measuring the dogs’ decisions. These activities aim to understand how dogs think and process information.\nOne project I’m particularly excited about is called the Many Dogs Project. This initiative is a consortium of dog labs from around the world. Several labs participate in a collaborative study, each conducting the same experiment in their respective locations. Ultimately, we aggregate all the data, allowing us to analyze a large sample size. For our first study, 20 labs tested 700 dogs, which provided us with a remarkable dataset for our behavioral research. I’m looking forward to the insights we can gain from these projects!\nIt’s a fantastic project because it brings together a diverse group. It’s collaborative and collegial, strongly emphasising open source and open science. We use R for our analyses; everything we do is made public, allowing everyone access to the data and scripts. I’m excited to be a part of this project. In fact, after my initial involvement, I ran to become the co-director of the Many Dogs Project, which I am now. I truly enjoy contributing to such initiatives.\nI recently had the chance to work with Shiny for the first time. I developed my first Shiny app, which allows users to explore some of the data collected from the Many Dogs Project. We gathered substantial information about the dogs, including their aggression, fearfulness, and training history. This app allows users to examine correlations, such as the relationship between a dog’s aggression and trainability.\nI haven’t publicized the app yet because I want to get feedback from my colleagues in the Many Dogs Project before making it fully available. It’s been a fun experience. Initially, I hadn’t worked much with Shiny because it seemed different from R, and I was unsure if I could manage it. However, I attended a workshop on Shiny designed for data science mentors, and I decided to use it to build the Many Dogs Project app as my project for that workshop."
  },
  {
    "objectID": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/connecting-nebraska-through-r-jeffrey-stevens-journey-of-community-building/index.html#how-do-i-build-an-r-user-group",
    "title": "Connecting Nebraska Through R: Jeffrey Stevens’ Journey of Community Building",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html",
    "href": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html",
    "title": "R/Pharma 2024, Virtual, October 29-November 1, Includes New Dedicated Asia-Pacific (APAC) Track",
    "section": "",
    "text": "R/Pharma 2024 is coming up Oct 29-Nov 1, 2024. This is a free event, fully virtual. R users in Pharma around the world are encouraged to attend, ask questions, and contribute their opinions!"
  },
  {
    "objectID": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html#register-now-for-free",
    "href": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html#register-now-for-free",
    "title": "R/Pharma 2024, Virtual, October 29-November 1, Includes New Dedicated Asia-Pacific (APAC) Track",
    "section": "Register now for free!",
    "text": "Register now for free!\nFor the first time, R/Pharma will be including a dedicated Asia-Pacific (APAC) track which better aligns with Asian time zones and includes 2 pre-conference workshops, 3 keynotes that will be recorded from the global track and then streamed with live discussion sessions thereafter, and 2 live panels, one focusing on Japan, and one on China. In addition, there are 20 contributed talks.\n\n\nThe R Consortium talked with Daniel Sabanés Bové, R/Pharma organizer, co-chair of openstatsware.org, co-founder of RCONIS, a biostatistics consulting and software engineering firm, (co-)author of multiple R packages published on CRAN and Bioconductor, and author of the book “Likelihood and Bayesian Inference: With Applications in Biology and Medicine.” Daniel is giving a 3-hour workshop on October 27 with Joe Zhu (Roche) on “Good Software Engineering Practice for R Packages,” and introducing openstatsware in a talk on 31 October.\nWe talked to Daniel to find out more about the new APAC track.\n\n\nWhy is R/Pharma adding an APAC track now?\nLast year, I was on an extended business trip for Roche for 6 weeks in Shanghai. I was fortunate to attend the first China Pharma R User Group (RUG) Meeting in March 2023, so I have seen how active the community is. I also found out how tough it can be to be based in Asia - you just don’t get enough sleep working with colleagues in Europe and North America!\nSo when the R/Pharma program committee reported that they have been approached by colleagues in Asia about organizing events in their time zone or region, I used the opportunity of my upcoming move to Taipei mid 2024 to propose organizing a dedicated track in the Asia-Pacific timezones.\nThe R/Pharma APAC track is designed specifically to help avoid time zone burnout, as well as to foster the APAC regional community.\n\n\nHow does adoption of R in Pharma in APAC differ from other parts of the world?\nThis is not based on robust data, but from a personal perspective I have noticed one key feature is that biotech and Pharma companies in Asia are concentrated in a few hubs, there is Shanghai, Tokyo, and not too many more. Having said that, I have noticed the rise of Contract Research Organizations (CROs) e.g. in India that are starting to use R - the CROs are catching up. Compare that to Europe and the United States, with a wide range of Pharma companies and organizations spread around many different locations. This also influences the adoption of R and open source technologies in general.\n\n\nWhat are some of the key topics being covered in the APAC track?\nI was pleasantly surprised at the amount and variety of proposals submitted. We have organized the APAC track’s topics into 6 types of sessions:\n\nChange management (moving from proprietary software to R)\nSessional clinical reporting (producing tables and reports)\nShiny\nBest practices\nAI/ML\nHigh dimensional data\n\nWe have quite an exciting APAC Track program that includes:\n\n2 pre conference workshops\n3 keynote streams, which are recorded keynotes that are slightly delayed to stream during convenient APAC times, plus we have added some discussion after\n2 live panel discussion (China, Japan)\n20 contributed talks in total\n\n\n\nFull Agenda\nA full list of workshops, keynotes, talks and panels is available here.\nIf you use the filter button you can get just the APAC Track information."
  },
  {
    "objectID": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html#register-now-for-free-1",
    "href": "posts/rpharma-2024-virtual-oct29-nov1-apac-track/index.html#register-now-for-free-1",
    "title": "R/Pharma 2024, Virtual, October 29-November 1, Includes New Dedicated Asia-Pacific (APAC) Track",
    "section": "Register now for free!",
    "text": "Register now for free!\nIf you, or your organization, would like to support R/Pharma you can do so following this link. Be sure to follow the R/Pharma blog, LinkedIn and Twitter/X."
  },
  {
    "objectID": "posts/the-r-consortium-2023-a-year-of-growth-and-innovation/index.html",
    "href": "posts/the-r-consortium-2023-a-year-of-growth-and-innovation/index.html",
    "title": "The R Consortium 2023: A Year of Growth and Innovation",
    "section": "",
    "text": "Excerpted from the Annual Report\n\nAccess the annual report here!\nLetter from the Chair — Mehar Pratap Singh, Chairman\nWelcome to the 2023 Annual Report of the R Consortium. This document reflects a year of significant growth, innovation, and community engagement within and beyond the R ecosystem. As we present the accomplishments and milestones of the past year, we also set our sights forward, laying out the path for an even more collaborative and impactful future.  \nThe R Consortium serves as a central hub for the R community, bringing together industry leaders, academic institutions, and individual contributors to foster the development and proliferation of the R language. Our mission is to support the R community through funding, infrastructure improvement, community initiatives, and global outreach.  \nIn 2023, the R Consortium played a pivotal role in shaping the development of the R ecosystem. Through monetary grants, nearly $200,000 dollars to develop R packages and other technical infrastructure, through fostering industry wide collaborative working groups, and by supporting R-Ladies, R user groups, and several important industry conferences, including Latin-R, New York R, and Bioconductor conferences. This report highlights some of these achievements, showcasing the collective effort of our members and the broader community.  \nRecognizing the dynamic nature of data science technologies and the evolving needs of industry, we also recognize the responsibility of the R Consortium to help set a vision for the evolution of the R ecosystem. As you read through this report, we hope you’ll appreciate the strides we’ve made together and feel inspired by the potential of what we can achieve in the future. The R Consortium is more than just an organization: it’s a vibrant community of innovators, problem-solvers, and thought leaders. Together, we are shaping a future where the power of R is accessible to all and continues to drive progress across industries worldwide.   \nThank you for your continued support and dedication to the R Consortium and the wider R community. \n\n\nAccess the annual report here!"
  },
  {
    "objectID": "posts/submissions-wg-pilot5-pilot6-and-more/index.html#progress-reports-and-future-plans",
    "href": "posts/submissions-wg-pilot5-pilot6-and-more/index.html#progress-reports-and-future-plans",
    "title": "R Submissions Working Group: Pilot 5 Launch and more!",
    "section": "Progress Reports and Future Plans",
    "text": "Progress Reports and Future Plans\nUpdates on Pilot 4\nThe objective of the R Consortium R submission Pilot 4 Project is to explore the use of novel technologies such as Linux containers and WebAssembly to bundle a Shiny application into a self-contained package, facilitating a smoother process of both transferring and executing the application. The application was built using the source data sets and analyses contained in the R submission Pilot 1-3. To our knowledge, this is the first publicly available submission package that includes a WebAssembly component. We hope this submission package and what we have learned can serve as a good reference for future regulatory submission efforts. The WebAssembly technology compiles applications into a portable, consistent environment driven by a web browser, allowing agency reviewers to easily run and evaluate software without complex setups. The second half of the Pilot 4 Project (leveraging container technology to package a Shiny application) will be submitted as an additional package later this year. Additional agency feedback will be shared in future communications.\nThe R Consortium is excited to announce that, on September 20, 2024, the R Submissions Working Group successfully submitted its test submission package—featuring a WebAssembly component—through the FDA’s Electronic Common Technical Document (eCTD) gateway! This marks a significant milestone as the FDA Center for Drug Evaluation and Research (CDER) staff has officially received the submission package.\nStatistician Eric Nantz at pharmaceuticals company Eli Lilly in Indianapolis, Indiana, says that using WebAssembly “will minimize, from the reviewer’s perspective, many of the steps that they had to take to get the application running on their machines.”\nPotential Pilot 6\nThe Pilots have been making use of the original CDISC Pilot data from around 2008-2010 that were used as PoC for the FDA for CDISC standards. This data has been reused for many other projects across the industry as there is a severe lack of publicly available CDISC data. You can read about my quest to find some more data here. The submissions working group would like to create new simulated data from raw, SDTM and ADaMs that could be used to test new techniques, ways of working, etc all brought up to modern standards. If interested get in touch!\nA Re-Envisioned ADRG\nThe Analysis Data Reviewer’s Guide (ADRG) has been focused on the proprietary language SAS for delivering submissions over many years. As open-source languages such as R are accepted as valid mechanisms to deliver a submission the ADRG needs to “re-envisioned” to accommodate these languages. The pilots have had questions on how to document certain technical aspects in the ADRG of the R-based submission package, e.g. packages used and versions, R versions and layouts of the file folders.\nWell we are in luck. Former Pilot members are working with the PHUSE Version Metadata for Open-Source Languages to support ADRG enhancements for open-source submissions and are sharing their recommendations to the Pilots. You can find out more at the below links:\n\nCommunication of Version Metadata for Open-Source Languages\nWelcome to the PHUSE Open-Source Metadata Documentation Working Group Site\nProblem Statement\n\nMore about the R Submissions Working Group\nThe R Consortium R Submissions Working Group is focused on improving practices for R-based clinical trial regulatory submissions.\nHealth authority agencies from different countries require electronic submission of data, computer programs, and relevant documentation to bring an experimental clinical product to market. In the past, submissions have mainly been based on the SAS language.\nIn recent years, the use of open source languages, especially the R language, has become very popular in the pharmaceutical industry and research institutions. Although the health authorities accept submissions based on open source programming languages, sponsors may be hesitant to conduct submissions using open source languages due to a lack of working examples.\nTherefore, the R Submissions Working Group aims to provide R-based submission examples and identify potential gaps while submitting these example packages. All materials, including submission examples and communications, are publicly available on the R consortium GitHub page.\nJoin the R Submissions Working Group\nThe R Submissions Working Group comprises members from over 10 pharmaceutical companies, as well as regulatory agencies. We are a collaborative community open to anyone interested in contributing to this important work. For more information, or to get involved, visit our website or contact us directly at director@r-consortium.org."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "",
    "text": "Are you ready to delve into the world of finance through the lens of R? Look no further than the R Finance Conference (May 18, 2024, University of Illinois Chicago) – your gateway to cutting-edge insights, advanced methodologies, and unparalleled networking opportunities. As an enthusiast of data-driven finance or an R programming aficionado, this single-track, one-day event promises to be an enlightening experience. R Finance is the must-attend event in the realm of financial technology."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#a-glimpse-into-history",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#a-glimpse-into-history",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "A Glimpse into History",
    "text": "A Glimpse into History\nFounded in 2009, the R Finance Conference quickly evolved into the premier event in the financial technology landscape. Originating from the shared enthusiasm of R users in the Chicago financial center, a group of loosely connected enthusiasts was seeking to improve financial analysis. From its humble beginnings to its current stature, it remains committed to fostering knowledge exchange and driving advancements in R-based finance."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#why-choose-a-single-track-event",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#why-choose-a-single-track-event",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "Why Choose a Single-Track Event?",
    "text": "Why Choose a Single-Track Event?\nOne distinctive feature of the R Finance Conference is its single-track format. Unlike multi-track conferences, where attendees must choose between concurrent sessions, a single-track event offers a shared group experience. Single track offers:\n\nFocused Learning:\nAttendees can fully immerse themselves in each session without the distraction of conflicting schedules. This focused approach enhances learning and ensures that participants extract maximum value from every presentation.\n\n\nEnhanced Networking:\nThe single-track format encourages interaction among attendees as everyone gathers in the same sessions. This facilitates meaningful discussions, idea exchange, and networking opportunities with like-minded professionals, fostering a sense of community and collaboration.\n\n\nComprehensive Coverage:\nBy following a single track, attendees gain exposure to a diverse range of topics and perspectives within the realm of R-based finance. From quantitative modeling and algorithmic trading to risk management and data visualization, each session contributes to a holistic understanding of the subject matter."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#key-highlights-of-r-finance-conference",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#key-highlights-of-r-finance-conference",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "Key Highlights of R Finance Conference",
    "text": "Key Highlights of R Finance Conference\n\nExpert Speakers: Renowned experts and thought leaders in finance and data science share their insights, best practices, and real-world experiences. In 2022, speakers included Matthew Dixon, Associate Professor, Department of Applied Math and Affiliate Professor, Stuart School of Business, Illinois Tech; Veronika Rockova, Professor of Econometrics and Statistics, University of Chicago, Booth School of Business and James S. Kemper Foundation Faculty Scholar; and Thomas P. Harte, Head of Fixed Income & Liquidity Strats at Morgan StanleyInteractive Workshops: Hands-on workshops provide attendees with practical skills and techniques to implement R-based solutions in their professional endeavors.\nNetworking Opportunities: Engage with industry peers, establish valuable connections, and exchange ideas during networking breaks, social events, and interactive sessions.\nExhibition Showcase: Explore cutting-edge technologies, tools, and services offered by exhibitors and sponsors, offering valuable insights into the latest innovations in financial technology."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#join-us-at-r-finance-2024",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#join-us-at-r-finance-2024",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "Join Us at R Finance 2024",
    "text": "Join Us at R Finance 2024\nDon’t miss out on the opportunity to elevate your finance skills and network with industry leaders at the R Finance Conference 2024. Reserve your spot today and embark on a transformative journey in R-based finance.\nFor more information and registration, visit R Finance Conference."
  },
  {
    "objectID": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#register-now",
    "href": "posts/unlocking-financial-insights-join-us-at-the-r-finance-conference/index.html#register-now",
    "title": "Unlocking Financial Insights: Join Us at the R Finance Conference",
    "section": "Register now!",
    "text": "Register now!"
  },
  {
    "objectID": "posts/r-addicts-paris-promoting-diversity-in-r/index.html",
    "href": "posts/r-addicts-paris-promoting-diversity-in-r/index.html",
    "title": "R Addicts Paris: Promoting Diversity in R",
    "section": "",
    "text": "Vincent Guyader, organizer of the R Addicts Paris and president of ThinkR, recently updated the R Consortium on the group’s activities. Last year, Vincent discussed the application of R in developing solutions for industrial problems. He emphasized the importance of helping people become fluent in R and leveraging the language to add value to their work. ThinkR is dedicated to enhancing R proficiency in various industries. The R Addicts Paris, one of France’s oldest and largest R user groups with 1,800 members, continues to foster a strong R community under Vincent’s leadership.\nPlease share your background and involvement with the RUGS group.\nMy name is Vincent, and I have been using R since my student days. During my studies, I took on freelance R projects for various companies. Currently, I head a company called ThinkR, where we have a team of over 10 experts specializing in everything related to R. Our services include training, consulting, developing Shiny applications, creating R packages, and more. We also collaborate with Posit and handle hardware installations for clients, primarily in France but also in Switzerland, Belgium, and other parts of Europe.\nSince 2018, I have been managing the R user group in Paris, known as the R Addicts Paris. It’s one of the oldest and possibly the largest R user groups, with 1,800 members. I aimed to organize meetups every three months, but the next one has been delayed due to internal organizational issues. I genuinely enjoy helping people become fluent in R and use the language to add value to their work.\nWhat challenges do you face in organizing the R Addict Paris group and how do you overcome those challenges?\nOne of the main challenges is that our users are not professional programmers or developers; they are specialists in fields like biology and finance. They have to shift their mindset to use programming languages. My daily job involves helping these individuals embrace software development. Coming from a genetics and biochemistry background, I understand how challenging this can be for non-developers. However, I love doing this, and I have a dedicated, competent team to assist.\nBased on your work with ThinkR, which industries in France do you see using R?\nWe have clients in various fields across France, including finance, retail, and research. The health sector is particularly prominent. For instance, a company that used SAS a few years ago now uses R & Python. About half of our clients currently use Python. While we provide Python installation on hardware, we don’t offer Python training yet.\nWe are committed to being the sole organization in France that can certify R users and developers. The French government has authorized us to issue an official certification akin to a diploma. Our goal is to elevate R proficiency across various fields in France. Our clients include businesses and individuals, with many investing their resources to learn proper software and programming skills.\nDo you host online or in-person events?\nI chose not to host online events. It’s a very opinionated choice because most meetups switched to online formats during the pandemic. At ThinkR, we are a fully remote company, and I spend my day on Zoom. While remote training is effective, I’ve found that in-person events work better for our user group.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people who are unable to attend physical events in the future?\nOne of the main challenges we face as a group is finding female speakers. I try to avoid having only male speakers, but I only get female speakers every fifth or sixth event, which is not enough. I encourage other R user group organizers to recognize our power to give a voice to different kinds of people. I push myself to include more female speakers. Sometimes, I encounter highly qualified women who hesitate to speak, while less experienced men are more willing. It’s challenging, but I strive to maintain a balanced representation.\nI consciously avoid engaging with speakers who lack substance, ensuring I have time to encourage qualified women to share their knowledge. Despite my efforts, female representation remains below 20%. A few years ago, my colleague Diane and I tried to connect with the R-Ladies Paris group. Many men are actively engaged there, and I wonder why that is.\nThere are many skilled women in the R community, which includes biologists and geneticists. There’s no excuse for the lack of female representation. We must remember our influence and endorse individuals who truly represent our values.\nWhat are some trending topics in R in your R User Group?\nI’ve noticed a decline in interest in statistics over the past two to five years. During meetups, we rarely discuss statistics. The machine learning and AI fields aren’t well-represented in R, possibly because most people in these fields use Python. It could also be due to regional differences or my network.\nYou had a Meetup “Raddicts x RTE – {webr} – Shinyproxy and return of the Reconteres 2024” on 19th June, can you share more on the topic covered? Why this topic?\nFor this event, we had two male speakers. Colin Fay discussed {webr}, a new JavaScript capability for launching user insights in the browser. This is powerful for deploying Shiny applications. Valentin Cadoret talked about new Shinyproxy functionalities, and tools that enhance the deployment of Shiny applications. So we focused heavily on Shiny once again."
  },
  {
    "objectID": "posts/r-addicts-paris-promoting-diversity-in-r/index.html#how-do-i-join",
    "href": "posts/r-addicts-paris-promoting-diversity-in-r/index.html#how-do-i-join",
    "title": "R Addicts Paris: Promoting Diversity in R",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "",
    "text": "On October 31, 2024, the Health Technology Assessment (HTA) Working Group convened for its first general meeting, marking the beginning of an exciting industry-wide initiative to elevate the role of R within the HTA community. The gathering featured 35 members, including co-chairs and founding members Gregory Chen, Anders Gorst-Rasmussen, Dominic Muston, and Joseph Rickert, with participants bringing varied expertise from across the HTA landscape. Hosted on video, the kickoff set the stage for collaboration, innovation, and tangible impacts on the development and application of R tools in health technology assessments. You can watch the recording here."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#opening-remarks-and-vision",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#opening-remarks-and-vision",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Opening Remarks and Vision",
    "text": "Opening Remarks and Vision\n Gregory Chen and Anders Gorst-Rasmussen opened the meeting with a vision of collaboration, emphasizing the importance of a shared, flexible structure within the HTA Working Group. The co-chairs highlighted two initial workstreams designed to channel the group’s efforts without restricting the scope of potential projects. This framework underscores the group’s commitment to evolve in response to member feedback and industry needs."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#workstream-1-building-connections-across-the-hta-ecosystem",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#workstream-1-building-connections-across-the-hta-ecosystem",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Workstream 1: Building Connections Across the HTA Ecosystem",
    "text": "Workstream 1: Building Connections Across the HTA Ecosystem\n Anders Gorst-Rasmussen and Dominic Muston introduced the first workstream, focusing on building connections across diverse stakeholders within HTA. This foundational effort aims to foster a common perspective and identify relevant challenges and opportunities. By bridging gaps between different sectors within HTA, Workstream 1 seeks to create a solid framework for addressing complex issues in health technology evaluation and supporting innovation across the industry."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#workstream-2-r-tools-for-hta-identification-curation-and-education",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#workstream-2-r-tools-for-hta-identification-curation-and-education",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Workstream 2: R Tools for HTA – Identification, Curation, and Education",
    "text": "Workstream 2: R Tools for HTA – Identification, Curation, and Education\n Gregory Chen and Joseph Rickert presented Workstream 2, which takes a hands-on approach toward bolstering R’s role in HTA. Key goals include identifying relevant R packages, curating high-quality, production-ready tools, and proactively enhancing documentation and user resources. The working group will also promote these tools through blogs, webinars, and other educational efforts to foster a culture of learning and improvement around R for HTA. The ultimate aim is to ensure that the HTA community has access to well-documented, robust R tools and resources that meet industry needs."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#next-steps-how-members-can-contribute",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#next-steps-how-members-can-contribute",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Next Steps: How Members Can Contribute",
    "text": "Next Steps: How Members Can Contribute\nThe HTA Working Group’s GitHub repository serves as the central hub for collaboration, providing access to meeting materials, discussion threads, and project updates. Members are encouraged to engage actively by commenting onIssue #1 with a brief statement about their backgrounds, opening new issues to propose ideas, and suggesting solutions to emerging challenges. This repository promises to be a lively and evolving resource as the working group’s projects advance."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#group-discussion-setting-the-foundation-for-future-initiatives",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#group-discussion-setting-the-foundation-for-future-initiatives",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Group Discussion: Setting the Foundation for Future Initiatives",
    "text": "Group Discussion: Setting the Foundation for Future Initiatives\nThe group discussion allowed members to share insights, generate new ideas, and identify priorities for the working group’s next steps. The discussion was lively and constructive, underscoring the potential of this initiative to drive meaningful contributions to the HTA field."
  },
  {
    "objectID": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#upcoming-meeting",
    "href": "posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html#upcoming-meeting",
    "title": "Health Technology Assessment (HTA) Working Group Kickoff: Building a Collaborative Vision in R for HTA",
    "section": "Upcoming Meeting",
    "text": "Upcoming Meeting\nThe next meeting of the HTA Working Group is scheduled for Wednesday, November 27, 2024, from 17:00 to 18:00 CET. Members are encouraged to join, contribute to ongoing discussions, and help shape the next steps of this impactful initiative. If you have not received an invitation, please reach out to Joseph Rickert via email.\nThe HTA Working Group has set forth on a promising path, and this first meeting demonstrated the collaborative spirit and commitment to progress that will drive its success. Stay tuned for more updates as the group’s efforts take shape and begin to impact the HTA community."
  },
  {
    "objectID": "posts/aligning-belief-and-profession-using-r-in-protecting-the-penobscot-nation-traditional-lifeways-r-consortium/index.html",
    "href": "posts/aligning-belief-and-profession-using-r-in-protecting-the-penobscot-nation-traditional-lifeways-r-consortium/index.html",
    "title": "Aligning Beliefs and Profession: Using R in Protecting the Penobscot Nation’s Traditional Lifeways",
    "section": "",
    "text": "Jan Paul, Water Quality Lab Coordinator at Penobscot Nation, sampling in field\n\n\nIn a recent interview by the R Consortium, Angie Reed, Water Resources Planner for the Penobscot Indian Nation, shared her experience learning and using R in river conservation and helping preserve a whole way of life. Educated in New Hampshire and Colorado, Angie began her career with the Houlton Band of Maliseet Indians, later joining the Penobscot Indian Nation. Her discovery of R transformed her approach to environmental statistics, leading to the development of an interactive R Shiny application for community engagement.\npαnawάhpskewi (Penobscot people) derive their name from the pαnawάhpskewtəkʷ (Penobscot River), and their view of the Penobscot River as a relative guides all of the Water Resources Program’s efforts. This perspective is also reflected in the Penobscot Water Song, which thanks the water and expresses love and respect. Angie has been honored to:\n\nwork for the Water Resources Program,\ncontribute to the Tribal Exchange Network Group,\nengage young students in environmental stewardship and R coding, blending traditional views with modern technology for effective environmental protection and community involvement, and\nwork with Posit to develop the animated video about Penobscot Nation and show it at the opening of posit:conf 2024\n\nPlease tell us about your background and how you came to use R as part of your work on the Penobscot Indian Nation.\nI grew up in New Hampshire and completed my Bachelor of Science at the University of New Hampshire, followed by a Master of Science at Colorado State University. After spending some time out west, I returned to the Northeast for work. I began by joining the Houlton Band of Maliseet Indians in Houlton, Maine, right after finishing my graduate studies in 1998. Then, in 2004, I started working with the Penobscot Indian Nation. Currently, I work for both tribes, full-time with Penobscot and part-time with Maliseet.\nMy first encounter with R was during an environmental statistics class taught by a former USGS employee, Dennis Helsel during a class he taught for his business Practical Stats. He introduced us to a package in R called R Commander. Initially, I only used it for statistics, but soon, I realized there was much more to R. I began teaching myself how to use ggplot for graphing. I spent months searching and learning, often frustrated, but it paid off as I started creating more sophisticated graphs for our reports.\nWe often collaborate with staff from the Environmental Protection Agency (EPA) in Region One (New England, including Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, Vermont and 10 Tribal Nations). One of their staff, Valerie Bataille, introduced us to R Carpentries classes. She organized a free class for tribal staff in our region. Taking that class was enlightening; I realized there was so much more I could have learned earlier, making my journey easier. This experience was foundational for me, marking the transition from seeing R as an environmental statistics tool to recognizing its broader applications. It’s a bit cliché, but this journey typifies how many people discover and learn new skills in this field.\nThe Penobscot Nation views the Penobscot River as a relative or family. How does that make water management for the Penobscot River different from other water resource management?\nIf you watch The River is Our Relative, the video delves deeper into seeing the river from a relative, beautiful, and challenging perspective. This view fundamentally shifts how I perceive my work, imbuing it with a deeper meaning that transcends typical Western scientific approaches to river conservation. It’s a constant reminder that my job aligns with everything I believe in, reinforcing that there’s a profound reason behind my feelings.\nWorking with the Penobscot Nation and other tribal nations to protect their waters and ways of life is an honor and has revealed the challenges of conveying the differences in perspective to others. Often, attempts to bridge the gap get lost in translation. Many see their work as just a job, but for the Penobscot people, it’s an integral part of their identity. It’s not merely about accomplishing tasks; it’s about their entire way of life. The river provides sustenance, acts as a transportation route, and is a living relative to whom they have a responsibility.\nHow does using open source software allow better sharing of results with Penobscot Nation citizens?\nMy co-worker, Jan Paul, and I had the pleasure of attending and presentingat posit::conf 2023 and working with Posit staff to create an animated video that describes what we do and how opensource and Posit tools help us do it. It was so heart-warming to watch the video shown to all attendees at the start of conf, and was a great introduction to my shameless ask for help during my presentation and through a table where I offered a volunteer sign-up sheet/form, I was humbled by the number of generous offers and am already receiving some assistance on a project I’ve been eager to accomplish. Jasmine Kindness, One World Analytics, is helping me recreate a Tableau viz I made years ago as an interactive, map-based R Shiny tool.\n\nI find that people connect more with maps, especially when it comes to visualizing data that is geographically referenced. For instance, if there’s an issue in the water, people can see exactly where it is on the map. This is particularly relevant as people in this area are very familiar with the Penobscot River watershed. My aim is to create tools that are not only interactive but also intuitive, allowing users to zoom into familiar areas and understand what’s happening there.\nThis experience has really highlighted the value of the open source community. It’s not just about the tools; it’s also about the people and the generosity within this community. The Posit conference was a great reminder of this, andthe experience of working with someone so helpful and skilled has truly reinforced how amazing and generous the open source community is.\nHow has your use of R helped to achieve more stringent protections for the Penobscot River?\nBefore we started using open source tools, my team and I had been diligently working to centralize our data management system, which significantly improved our efficiency. A major shift occurred when we began using R and RStudio (currently Posit) to extract data from this system to create summaries. This has been particularly useful in a biennial process where the State of Maine requests data and proposals for upgrading water quality classifications.\nIn Maine, water bodies are classified into four major categories: AA, A, B, and C. If new data suggests that a water body, currently classified as a lower grade, could qualify for a higher classification, we can submit a proposal for this upgrade. In the past we have facilitated upgrades for hundreds of miles of streams, however it took much longer to compile the data. For the first time in 2018 we used R and RStudio to prepare a proposal to the Maine Department of Environmental Protection (DEP) to upgrade the last segment of the Penobscot River from C to B. Using open source tools, we were able to quickly summarize data and compile data into a format that could be used for this proposal, a task that previously took a significantly longer time. DEP accepted our proposal because our data clearly supported the upgrade. In 2019, the proposal was passed and we anticipate this process continuing to be easier in the future.\nYou are part of a larger network of tribal environmental professionals, working together to learn R and share data and insights. Can you share details about how that works?\n\n\n\nJan Paul, Water Quality Lab Coordinator at Penobscot Nation, sampling in field\n\n\nI’m involved in the Tribal Exchange Network Group (TXG), which is a national group of tribal environmental professionals like myself and is funded by a cooperative agreement with the Office of Information Management (OIM) at the Environmental Protection Agency (EPA). We work in various fields, such as air, water, and fisheries, focusing on environmental protection. Our goal is to ensure that tribes are well-represented in EPA’s Exchange Network, and we also assist tribes individually with managing their data.\nSince attending a Carpentries class, I’ve been helping TXG organize and host many of them. We’ve held one every year since 2019, and we’re now moving towards more advanced topics. In addition to trainings, TXG provides a variety of activities and support, including small group discussions, 1-on-1 assistance and conferences. Although COVID-19 disrupted our schedule we are planning our next conferencefor this year.\nOur smaller, more conversational monthly data drop-in sessions always include the opportunity to have a breakout room to work on R. People can come with their R-related questions, or the host might prepare a demo.\nOur 1-on-1 tribal assistance hours allows Tribes tosign up for help with issues related to their specific data. I work with individuals on R code for various tasks, such as managing temperature sensor data or generating annual assessment reports in R Markdown format. This personalized assistance has significantly improved skill building and confidence among participants and are particularly effective as they use real data and often result in a tangible product, like a table or graph, which is exciting for participants. We’ve also seen great benefits, especially in terms of staff turnover. When staff members leave, the program still has well-documented code, making it easier for their successors to pick up where they left off. These one-on-one sessions.\nAdditionally, I’ve been involved in forming a Pacific Northwest Tribal coding group, which still doesn’t have an official name as it is only a few months old. It began from discussions with staff from the Northwest Indian Fisheries Commission (NWIFC) and staff from member Tribes. And I am thrilled to say we’ve already attracted many new members from staff of the Columbia River Inter-Tribal Fish Commission (CRITFC). This group is a direct offshoot of the TXG efforts with Marissa Pauling of NWIFC facilitating, and we’re excited about the learning opportunities it presents.\nOur work, including the tribal assistance hours, is funded through a grant that reimburses the Penobscot Nation for the time I spend on these activities. As we move forward with the coding group, planning to invite speakers and organize events, it’s clear there’s much to share with this audience, possibly in future blogs like this one. This work is all part of our broader effort to support tribes in their environmental data management endeavors. If anyone would like to offer their time toward these kinds of assistance, they can use the TXG google form to sign up.\nHow do you engage with young people?\nI am deeply committed to engaging the younger generation, especially the students at Penobscot Nation’s Indian Island school (pre-K through 8th grade). In our Water Resources Program at Penobscot Nation, we actively involve these students in our river conservation efforts. We see our role as not just their employees but as protectors of the river for their future.\n\n\n\nSampling for Bacteria\n\n\nOur approach includes hands-on activities like taking students to the river for bacteria monitoring. They participate in collecting samples and processing them in our lab, gaining practical experience in environmental monitoring. This hands-on learning is now being enhanced with the development of the R Shiny app I’m working on with Jasmine, to make data interpretation more interactive and engaging for the students.\nRecognizing their budding interest in technology, I’m also exploring the possibility of starting a mini R coding group at the school. With students already exposed to basic coding through MIT’s Scratch, advancing to R seems a promising and exciting step.\nBeyond the Penobscot Nation school, we’re extending our reach to local high schools like Orono Middle School. We recently involved eighth graders, including two Penobscot Nation citizens, in our bacteria monitoring project. This collaboration has motivated me to consider establishing an R coding group in these high schools, allowing our students continuous access to these learning opportunities.\n\n\n\nProcessing bacteria sample\n\n\nMy vision is to create a learning environment in local high schools where students can delve deeper into data analysis and coding. This initiative aims to extend our impact, ensuring students have continuous access to educational opportunities that merge environmental knowledge with tech skills and an appreciation of Penobscot people, culture and the work being done in our program.\nOver the years, witnessing the growth of students who participated in our programs has been immensely gratifying. . A particularly inspiring example is a young Penobscot woman, Shantel Neptune, who did an internship with us through the Wabanaki Youth in Science (WaYS) Program a few years back , then a data internship through TXG and is now a full-time employee in the Water Resources Program. Shantel is also now helping to teach another young Penobscot woman, Maddie Huerth, about data collection, management, analysis and visualization while she is our temporary employee. We’re planning sessions this winter to further enhance their R coding skills, a critical aspect of their professional development.\nIt’s essential to me that these women, along with others, receive comprehensive training. Our program’s success hinges on it being led by individuals who are not only skilled but who also embody Penobscot Nation’s values and traditions. Empowering young Penobscot citizens to lead these initiatives is not just a goal but a necessity. Their growth and development are vital to the continuity and integrity of our work, and I am committed to nurturing their skills and confidence. This endeavor is more than just education; it’s about preserving identity and ensuring our environmental efforts resonate with the Penobscot spirit and needs."
  },
  {
    "objectID": "posts/r-ladies-bariloche-in-argentina-fostering-a-different-approach/index.html",
    "href": "posts/r-ladies-bariloche-in-argentina-fostering-a-different-approach/index.html",
    "title": "R-Ladies Bariloche in Argentina: Fostering a Different Approach to Leadership",
    "section": "",
    "text": "Lina Moreno, founder and organizer of the R-Ladies Bariloche chapter in Argentina, recently shared her journey with the R Consortium. A biologist focusing on evolutionary ecology, she discussed her experience building a local R community, the challenges of maintaining engagement post-pandemic, and her efforts to foster discussions on leadership and gender equity within academia. Through her work, she aims to create an inclusive space for women in data science and strengthen the R community in Bariloche.\nPlease share your background and involvement with the RUGS group.\nI am a biologist working on evolutionary ecology, I did a bachelor in Sciences in another Argentinian province and then moved to Bariloche to start my PhD. (That was 16 years ago!) I spent a couple of years working in the field (I study reptiles, mainly lizards, and their adaptations to cold environments), and then I had to analyze the data. When I started my main analysis, I could only do it in R. At that time, my boss told me to start with R immediately, so I started searching online. I am doing this kind of work in my home country, so finding resources was complex. I had to work on a comparative analysis and phylogenies, which was difficult initially. However, I started studying and meeting people who taught me, which was awesome.\nAfter several years, I encountered a problem I couldn’t resolve. I turned to Google and found a helpful community of ladies. They assisted me a lot and saved me from a tight spot. After some communication, they suggested starting an R-Ladies community in Bariloche. I met with them in person when I traveled to Buenos Aires. They convinced me to start a Bariloche chapter, and by the end of 2019, a few of my colleagues and I, mainly biologists working in the same area, created the Bariloche chapter.\nWhat are some challenges you have faced in organizing this group?\nWe are currently facing some difficulties as people seem unwilling to get involved. As a result, we are exploring new strategies such as combined meetups (online and in person), and together with other R-Ladies groups. We also plan to organize three or four meetups this year. Despite our efforts, we are getting discouraged by the lack of response, but we will see how it goes.\nDuring the pandemic, there were five organizers, three of us with young children, so it was pretty difficult. We started a study group for the R for Data Science book, which had recently been translated into Spanish. We also organized meetups, mainly led by us. Surprisingly, there was good attendance during the pandemic, with around 40 people each time, similar to before the pandemic. However, after returning to in-person meetups, the attendance dropped significantly. The most crowded meetup had only 15 people, whereas before, we used to have two meetups on the same subject, both with 40 attendees.\nWe are attempting to integrate virtual and in-person components, which has proven challenging. We aim to introduce a beginner’s course in R through a meetup to help attendees gain confidence for future meetups. Our meetups typically have a good turnout, but there is a lack of interest in specific topics, particularly those related to gender bias and women’s issues. Despite this, we are putting in a significant effort. Last year, we participated in a round table during a conference in Bariloche, focusing on gender bias and the difficulties of being a woman in Academia, and it received a lot of support, especially from women. The rest of the group is currently working on documenting our experience at that round table. I am not participating as I have been busy with other responsibilities.\nLast year we surveyed people on how they feel R-Ladies is contributing to their careers, its influence on leadership abilities, their reasons for abandoning our events, or why they were too busy to attend. We have received some responses, but not as many as we expected.\nHowever, we have enough data to write a paper about it. We’re also looking into the topic of leadership. We are opening our minds and exploring the possibilities of supporting the R community here in Bariloche, but it’s quite challenging at the moment.\nCan you share what the R community is like in Argentina?\nThe field of artificial intelligence and machine learning is rapidly evolving, which greatly helps incorporate knowledge in R. The leading software used for this purpose is R and Python. R is more popular than Python, as it has been around longer and is more user-friendly. Many people from academia with expertise in machine learning are transitioning to private industries. Regarding statistical analysis in biology, tools such as the Vegan package and those incorporating GAM (Generalized Additive Models) are commonly used. Tools that can handle multiple effects simultaneously are in high demand in ecology.\nWould you like to talk about any recent activity from the group?\nIt was exciting what happened after the conference we participated in. As women, we are trying to maintain an open community. Initially, the organizers needed to learn how to manage an open group without a leader or a head, where everyone is considered equal. The participants ranged from students to established researchers, which ignited discussions about leadership and how women and minority groups navigate the world. We are accustomed to a robust and assertive leadership style, often associated with being at the top. However, as women, we wanted a different kind of leadership. This led to discussions on creating a new type of leadership that doesn’t adhere to the traditional patriarchal model. The manuscript the group is working on currently revolves around creating a new style of leadership that focuses on nurturing individuals to become better persons, researchers, or workers.\nThe topics discussed in the manuscript revolve around how we can lead differently. These discussions were not limited to our group; we engaged with several groups from Argentina and Spain who also expressed a similar desire for a different kind of leadership. It is interesting to note that as women and minority groups, we want to be in positions to make meaningful decisions, especially given that our work as biologists primarily tackles environmental issues. Despite historically shying away from more traditional forms of leadership, we are now advocating for different styles. This shared sentiment has brought us closer to other minority groups, and we believe it’s an important topic that needs further discussion. It’s important to recognize that women have a different approach, and it doesn’t make us weaker than men; it simply signifies that we have a unique way of contributing."
  },
  {
    "objectID": "posts/r-ladies-bariloche-in-argentina-fostering-a-different-approach/index.html#how-do-i-join",
    "href": "posts/r-ladies-bariloche-in-argentina-fostering-a-different-approach/index.html#how-do-i-join",
    "title": "R-Ladies Bariloche in Argentina: Fostering a Different Approach to Leadership",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/r-ladies-rome-empowering-women-in-data-science-through-collaboration-and-innovation/index.html",
    "href": "posts/r-ladies-rome-empowering-women-in-data-science-through-collaboration-and-innovation/index.html",
    "title": "R-Ladies Rome: Empowering Women in Data Science Through Collaboration and Innovation",
    "section": "",
    "text": "Federica Gazzelloni, co-organizer of R-Ladies Rome, recently spoke with the R Consortium about the fast-growing R community in Rome. The group collaborates with R user groups worldwide and has successfully attracted a diverse audience to its events. Federica also contributes to the R community through package development and is currently working on a book about using R for health metrics and tracking the spread of infectious diseases.\nThe group is hosting an online event titled “Building Reproducible Pipelines with R, Docker, and Nix” on the 29th of July. R users from around the world are invited to attend this event.\nPlease share about your background and involvement with the RUGS group.\nI am Federica Gazzelloni, an actuary and statistician interested in health studies. I am writing a book about health metrics and the spread of infectious diseases. As the lead organizer of R-Ladies Rome, one of the R user groups sponsored by the R Consortium, I am grateful for the support that enables us to organize monthly talks, tutorials, and workshops. Our events provide an inclusive and accessible learning environment free of charge, featuring exciting speakers and various engagement opportunities. Additionally, we have held events in partnership with R-Ladies New York, R-Ladies Paris, and Tunis R User Group and created a branded website: rladiesrome.org!\nR-Ladies Rome started in 2023 and has grown significantly since then. Our events consistently reach a substantial audience. For instance, our latest event with Isabella Velasquez garnered over 100 RSVPs. During Data Viz Month, we received unexpected attention from the open tech community of learners. Our followers on Meetup have reached over 1.1k, and our social media presence is steadily growing.\nCan you share what the R community is like in Rome?\nSince the kick-off of the chapter in 2023, R-Ladies Rome has played a pivotal role in fostering a dynamic community. We have successfully brought together an international group of R enthusiasts, ranging from beginners to experienced data scientists, creating a supportive and engaging environment for all. The popularity of the R language within the open source community, particularly for statistical analysis and medical research, is evident in Rome. R offers a wide range of libraries that can be easily applied to various topics, making it very convenient for users. Although Python is gaining attention in research and providing another accessible option for statistical analysis, the medical statistical community seems to prefer R over Python due to its extensive capabilities and strong community support.\nOur events have consistently attracted significant attention and participation. For example, our latest event with Isabella Velasquez garnered over 100 RSVPs. We have also received unexpected attention during Data Viz Month from the open tech community of learners. Our Meetup followers have reached over 1.1k, and our social media presence is steadily growing.\nThe R community in Rome is expected to grow, with R-Ladies Rome at its heart, driving engagement and promoting the use of R for various applications. We are excited to continue growing and evolving, providing valuable learning opportunities and fostering connections within the community.\nWhat trends do you currently see in R language?\nWe have reviewed all the events that R-Ladies’ groups have organized in the past years and, after considering the rebranding of RStudio to Posit PBC and RMarkdown to Quarto, realized that several exciting trends in the R language are shaping its usage and development within the data science community. Analyzing event titles, attendee numbers, and activity on past recordings, we found that events containing “Introduction” or “Tutorials” impact learners most, highlighting the growing interest in learning R for data analytics, reproducible research, and dynamic reporting.\nMoreover, integrating R with other programming languages and platforms is gaining significant attention. The interoperability between R and languages like Python, HTML, or Java allows users to enhance their skills across multiple tools within a single environment. This has expanded R’s capabilities, making it a versatile choice for a diverse range of users.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nWe’ve been using Canva extensively for various tasks and found ChatGPT very helpful in crafting storytelling content. To enhance the planning and execution of events, Copilot assists with its excellent collaborative typing, saving time. Additionally, having a Meetup pro-account is valuable, mainly as R-Ladies Rome is part of the broader R Ladies group. It helps us connect with a wider audience while using Google Forms aids communication and prevents missing information. We also use YouTube and have our channel, which is very useful for sharing past events recordings and making them available online to ensure accessibility for those unable to attend live events.\nYou have a Meetup on “Building reproducible pipelines with R, Docker and Nix”, can you share more on the topic covered? Why this topic?\nWe have an upcoming Meetup titled “Building reproducible pipelines with R, Docker and Nix” , featuring speaker Bruno Rodrigues. This topic was chosen based on feedback from our organizers, Silvana Acosta and Rafael Ribeiro, who polled our audience to identify a favorite speaker. Bruno Rodrigues emerged as a popular choice, highlighting the growing interest in robust and reproducible data science workflows.\nIn this session, Bruno Rodrigues will guide us through setting up reproducible data pipelines using R, Docker, and Nix. These tools ensure that data analyses are consistent and can be easily shared and replicated across different environments. By learning to use Docker and Nix alongside R, our community members will gain valuable skills to enhance the reliability and reproducibility of their data science projects. This event aligns with our mission to provide practical and impactful learning opportunities that meet the evolving needs of the data science community.\nPlease share about a project you are currently working on or have worked on using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nOne of the key projects I am currently working on involves a quarto-book titled “Health Metrics and the Spread of Infectious Diseases with R”, which CRC Press will publish at the end of this year. This book aims to provide comprehensive insights into the intersection of health metrics, such as DALYs and infectious disease dynamics, using advanced statistical methods and machine learning techniques in R. The goal is to equip readers with the knowledge and tools to analyze and interpret health data effectively, thereby contributing to the broader field of public health.\nIn addition to the book, I have developed a couple of R data packages to aid in data analysis and visualization. One is “oregonfrogs,” which is expected to go on CRAN very soon. This package focuses on classification modeling for detecting frog habitats, utilizing spatial techniques. It provides a valuable function, longlat_to_utm(). The development of these packages showcases R’s versatility in handling complex ecological data and emphasizes the importance of open source tools in advancing scientific research. Through these projects, I aim to demonstrate the practical applications of R in public health and environmental science, fostering a deeper understanding and appreciation of data-driven methodologies."
  },
  {
    "objectID": "posts/r-ladies-rome-empowering-women-in-data-science-through-collaboration-and-innovation/index.html#how-do-i-join",
    "href": "posts/r-ladies-rome-empowering-women-in-data-science-through-collaboration-and-innovation/index.html#how-do-i-join",
    "title": "R-Ladies Rome: Empowering Women in Data Science Through Collaboration and Innovation",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\n\n\n\ngd2md-html: xyzzy Mon Jul 29 2024\n\n\nLearn more"
  },
  {
    "objectID": "posts/promoting-r-in-nigeria-how-unilorin-r-user-group-is-making-an-impact/index.html",
    "href": "posts/promoting-r-in-nigeria-how-unilorin-r-user-group-is-making-an-impact/index.html",
    "title": "Promoting R in Nigeria: How Unilorin R User Group is Making an Impact",
    "section": "",
    "text": "Dr. M.K. Garba and Ezekiel Ogundepo, organizers of the University of Ilorin, shortened to Unilorin R User Group, recently spoke with the R Consortium about their efforts to promote R programming in Nigeria and foster a thriving local R community. They discussed the group’s origins, their experiences teaching R across academia and industry, and the impact of their inaugural event. Dr. Garba and Ezekiel also shared their plans for future workshops and highlighted their outreach strategies to engage learners and expand R’s reach in Nigeria. Ilorin is the capital city of Kwara State and is located in the western region of Nigeria.\nDr. M. K. Garba\nEzekiel Ogundepo\nPlease share your background and involvement with the RUGS group.\nDr. Garba: I am Dr. M.K. Garba, a lecturer in the Department of Statistics at the University of Ilorin. I organize the University of Ilorin R User Group, and my co-organizer and fellow instructor is Ezekiel.\nI was introduced to R programming by a senior colleague in my department around 2011 or 2012, and I have been using R personally since then. During my PhD, I utilized R programming continuously from start to finish. In 2015 or 2016, I taught R programming as a course to a group of senior-level students just a year before graduation. I continued teaching it for several years before the course was handed over to another instructor.\nAlthough I am no longer assigned as the lecturer for this course, I am motivated to share my knowledge and experiences with students. This desire led to the establishment of the R User Group. The group is not just for students in the Statistics department; it welcomes participants from other departments as long as they are interested in learning R programming.\nEzekiel: I am a statistician consultant with Data Science Nigeria. Additionally, I help Dr. Garba in teaching R programming. Dr. Garba was my lecturer at the University of Ilorin, where he served as my co-supervisor during my training. He introduced me to R programming in 2014, and we focused on statistical computing using this language. Since then, I have been using R programming across various industries.\nIn 2018, I became a Tidyverse instructor for R Studio and developed several R packages, including bulkreadr and forstringr packages. I am also a member of R Champion, an organization dedicated to promoting R programming in Nigeria and abroad.\nWhat is the local R community like in Nigeria? Is R being used in Academia and Industry?\nDr. Garba: I’ll focus on academia and leave the industry to Ezekiel. While I am a tenured staff member at the University of Ilorin, I also serve as a visiting professor at several universities in my state. In any course I teach, I introduce my students to R programming. I am pleased to share that one or two of these institutions have adopted R as the programming language for their statistical computing courses.\nEvery university typically offers at least one statistical computing course, and many institutions have embraced R. Some may not use R exclusively; instead, they combine it with other software like Stata, GenSTAT, or SAS. However, due to my introduction of R, it has gained traction in their programs. While some students hesitated to abandon their previous software, they embraced using R easily.\nEzekiel: We actively promote R programming across various industries in Nigeria. For example, we implement R programming solutions at Data Science Nigeria, where I work as a consultant. Two months ago, we organized a boot camp that invited numerous instructors and trainers to teach attendees about programming languages such as Python, R, data science, machine learning, and AI. I had the opportunity to teach R to those participants. Additionally, we collaborate with several biotechnology companies in Nigeria, both in industry and academia.\nPlease tell us about the first event from your R User Group. What topics were covered, and what kind of response did you receive for the event?\nDr. Garba: The first meetup took place after a two-week delay primarily because our targeted audience, the students at the University of Ilorin, were on break. Once they returned, we allowed them to settle in a few weeks before organizing our meeting. It was held virtually, and we were pleased with both the attendance and the feedback we received.\nI was thrilled with the responses, especially since the participants were selected from various departments, not just those related to statistics or mathematics. We began the session with the basics, and those with intermediate knowledge could also learn and engage with the material effectively.\nEzekiel served as the instructor for this first meetup. We have a calendar in place and assigned roles for upcoming sessions. I invited him to share insights about what we taught during the meeting, which mainly focused on introductory concepts.\nEzekiel: We introduced the participants to an introductory level of programming, teaching them how to install the software and use the essential components of the R programming language. We covered various concepts, including data types and structures, to prepare them for more advanced topics in future meetings. While there were some issues due to the large number of attendees, everyone enjoyed the event.\nWhat are your plans for the group in the coming year? How many events are you hoping to host, and what topics do you plan to cover?\nDr. Garba: Based on our schedule, I want to cover numerous topics, and I plan to invite many instructors, both national and international. We will discuss reproducibility in research, specifically using RStudio Project and version control for this purpose. Additionally, we want to focus on data visualization using the ggplot2 package.\nWe have a range of interesting topics on data analysis, various tidyverse libraries, and different aspects of geostatistics. These subjects will be valuable for participants from both academia and industry. R programming applications extend to areas of statistics, including econometrics, which are included in our calendar. Additionally, we will have a session on building a personal portfolio using Quarto.\nDo you plan to host your events in person or online?\nDr. Garba: We will have in-person sessions. As I mentioned, our primary focus is the students who were just getting settled then. That is why we initially opted for online sessions. However, there is no way we won’t conduct in-person classes, especially when it comes to practical demonstrations of what we are teaching. The students need to showcase their learning in person.\nWhat tools and techniques do you plan to use to promote your events?\nDr. Garba: We use the Meetup platform where students can register to participate in discussions about our training sessions. When participants have questions, they can raise them, and we respond accordingly. We also encourage other participants to answer questions if they have the expertise; if no one else can answer, we step in. This platform is where we share information about our meetup schedules.\nAdditionally, we have individual Twitter handles and LinkedIn profiles that we use to disseminate information. On the day of our training sessions, we stream the events live on Facebook. Although we also have a YouTube account, we encountered an issue and could not stream on that platform that day. However, the event was successfully streamed live on Facebook.\nWe promoted the initiative using hashtags like #rstats #DataScience #LearnR, which we knew would help retrieve any other relevant information related to R. We contacted the entire R ecosystem, including groups likeR OpenSciand other organizations. In Nigeria, we have numerous R user groups and we shared our message with them. They were also instrumental in helping us promote it. Overall, this strategy worked perfectly."
  },
  {
    "objectID": "posts/promoting-r-in-nigeria-how-unilorin-r-user-group-is-making-an-impact/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/promoting-r-in-nigeria-how-unilorin-r-user-group-is-making-an-impact/index.html#how-do-i-build-an-r-user-group",
    "title": "Promoting R in Nigeria: How Unilorin R User Group is Making an Impact",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.htm"
  },
  {
    "objectID": "posts/diving-into-r-with-isabella-velasquez-perspectives-from-r-ladies-seattle/index.html",
    "href": "posts/diving-into-r-with-isabella-velasquez-perspectives-from-r-ladies-seattle/index.html",
    "title": "Diving into R with Isabella Velasquez: Perspectives from R-Ladies Seattle",
    "section": "",
    "text": "Isabella Velasquez, co-organizer of R-Ladies Seattle, recently spoke with the R Consortium about her journey with R and the group’s recent activities. Isabella started as a beginner but has become a key figure in the R community thanks to the supportive and collaborative learning environment. R-Ladies Seattle regularly hosts in-person, hybrid, and online events, such as casual happy hours, lightning talks, and collaborations with other user groups. The group engages its members through creative activities and uses tools like GitHub for event planning. Their commitment to inclusivity and continuous learning helps maintain a dynamic and supportive community for R users in Seattle.\nR-Ladies Seattle is seeking speakers for an upcoming lightning talks session. If you are interested in presenting, please contact Isabella.\nPersonal website | Twitter | Mastodon\nPlease share your background and involvement with the RUGS group.\nI first encountered R when I started my graduate program in 2014. I was pursuing a Master’s in Analytics in Chicago. The program mainly revolved around using R. At that time, I was a complete beginner and had to start from the basics, like installing R. Since the program was fairly new, there wasn’t a well-structured curriculum for introducing R. It was assumed that students would either pick it up or already have some knowledge. The coursework focused on R from there.\nMy older brother Gustavo was a great resource when I started learning R and picking up the necessary skills. He is a highly proficient R user, so I asked him for help. He introduced me to many tools that made it much easier for a beginner to work in RStudio and pick up the tidyverse syntax. The main course curriculum was open to different approaches to using R, which provided flexibility in learning the tools and skills that interested me the most.\nAfter completing my program in 2016, I landed my first job as a data analyst. I began using R and regularly working with data. Back then, Twitter was buzzing with activity. I stayed enthusiastic and continued learning from the community. My brother and I collaborated to solve problems and acquire new skills. At work, my team had diverse tool proficiency; some were adept in Excel, while others had data expertise. Eventually, we formed a learning community and collectively mastered R. We utilized R to generate presentations, reports, visualizations, and clean up data. It was fantastic to have a small community at work and a larger one outside through social media.\nOne of my colleagues, Chaya Jones, at my previous workplace, where I worked as a data analyst, was one of the original co-organizers for R-Ladies Seattle. The R user group had just started in 2018, and she invited me to join and give one of the earliest presentations for R-Ladies Seattle. Over time, the membership grew, and eventually, I became one of the co-organizers. My role involved coordinating events, finding speakers, and other related tasks.\nI am very fortunate because I got into R in a friendly and collaborative environment. During graduate school, I collaborated with classmates and gained valuable knowledge from my brother. Later, I landed a new data analyst job and had a whole team of people who were interested in learning and using R. It has truly been a joy, and I feel appreciative for how well things have worked out and for the length of time that I’ve been able to use R.\nCan you share what the R community is like in Seattle?\nAs I mentioned, my workplace involved various programming languages, but there were quite a few R users. We used to have these small study groups where we discussed creating an R Markdown template for our company and shared Shiny apps and other similar things. The field I worked in was education, but in Seattle, you see a lot of R being used in bioinformatics and scientific research related to diseases. It’s very popular among those groups, and they have solid user groups where they grow and learn together. Many members of R Ladies Seattle are from organizations like Fred Hutch, where the emphasis on using R is very strong, which is pretty great.\nEvery month, R-Ladies Seattle hosts a casual happy hour. We have good chips and salsa, and it’s a great opportunity for members to join, chat, and have a good time. Additionally, after the Cascadia R Conference in June, we will have a social hour where people can keep the conversation going in a relaxed setting. We will also host a social hour at the end of posit::conf in August, and R-Ladies who didn’t attend the conference are more than welcome to join and hang out. We organize many social events, so there are plenty of opportunities to connect with us.\nWe have some exciting events related to R coming up. We are currently looking for speakers for a lightning talk session, where individuals can quickly share the projects they are working on or a tool they love. It’s a low-pressure way to join in, and we welcome anyone who would like to sign up and participate.\nOur focus is primarily on in-person and hybrid events. While we have seen an explosion of online events after COVID-19, it’s important to uphold the Seattle community by providing opportunities for local participation. Generally, our events are held in person, with occasional hybrid events. However, we are also excited about organizing online events with Seattle residents in mind at a convenient time for the Pacific Time Zone. Our offering of in-person, hybrid, and online events provides a unique experience for our user group in Seattle.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people who are unable to attend physical events in the future?\nOne thing we implemented was to think of events that could generate high engagement. For example, with our Hex sticker, we organized a competition for all R-Ladies members to participate by submitting their designs, followed by a voting process. It was a lot of fun, both creatively and in terms of getting everyone involved. We strive to come up with similar engaging activities. Additionally, when appropriate, we reach out to other user groups in the area to explore collaboration opportunities, co-hosting events, or simply support each other’s promotions to foster a strong sense of community.\nOne method we have tried for planning events is using GitHub discussions to log our ideas for events and determine which events are the most popular based on comments and upvotes. This helps guide our future event planning.\nWhat trends do you currently see in R language and your industry? Any trends you see developing shortly?\nEvery year, we send out a survey to inquire about people’s interests and what they like to see. The responses are usually a mix of technical content, with many requests for intermediate-level information. There’s a lot of interest from people in Seattle who use R in some capacity or are members of R-Ladies Seattle. They are looking for opportunities to upskill based on their existing knowledge of R. Additionally, there are many requests for information about career advancement and available positions.\nThere are various job titles related to data, such as data scientist and data engineer. Many people have questions about the career prospects in this field, including the potential for advancement and available options. These are common topics of discussion.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nI now work at Posit, formerly RStudio, in a marketing role. I still get to work with R a lot, which is great for creating dashboards to track various metrics. I’ve been focusing on defining metrics of success and similar tasks.\nRecently, I created a dashboard in Shiny that refreshes daily to compile the information I need for my to-do list. Every morning, I check my Shiny dashboard to see my daily tasks. It pulls information from my project management tool, so I only have to update one place to see an aggregated view of my month. It was fun to do this in R with Shiny.\nRecently, I worked on creating a custom template in Quarto for the upcoming R Medicine Conference website. The website is built entirely on Quarto, a new tool similar to R Markdown. My work specifically involved designing the events page to display previous events and provide links to the event page and YouTube playlist. It’s exciting to learn and work with new tools like Quarto."
  },
  {
    "objectID": "posts/diving-into-r-with-isabella-velasquez-perspectives-from-r-ladies-seattle/index.html#how-do-i-join",
    "href": "posts/diving-into-r-with-isabella-velasquez-perspectives-from-r-ladies-seattle/index.html#how-do-i-join",
    "title": "Diving into R with Isabella Velasquez: Perspectives from R-Ladies Seattle",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/new-year-same-unwavering-committment/index.html",
    "href": "posts/new-year-same-unwavering-committment/index.html",
    "title": "A new year and the same, unwavering commitment",
    "section": "",
    "text": "As we open our first round for Infrastructure Steering Committee call for proposals and R User Groups’ submissions, we want to take a moment to reiterate our mission as the R Consortium.\nThe R Consortium promotes the growth and development of the R language and its ecosystem by supporting technical and social infrastructure, fostering community engagement, and driving industry adoption.\nWe work to ensure a thriving, diverse global R community by providing resources, facilitating collaboration, and advocating for the use of R in multiple industry sectors. We provide funding for technical infrastructure through grants and working groups. We provide funding for social infrastructure through grants for R user groups and events around the world.\nWe provide a neutral space where industry, academia, and government can collaborate on mission critical processes and standards.\nOur efforts in support of the R language and the community that keeps it growing and relevant are a privilege and we are committed to ensuring that our actions are in compliance with our code of conduct.\nWe hope that you and your organization will join us in support of the R language and our community. We have a lot of work to do and we are excited to see the new and familiar faces come together for another fantastic year."
  },
  {
    "objectID": "posts/conectaR-podcasts-and-datathons-san-carlos-r-user-group-in-costa-rica/index.html",
    "href": "posts/conectaR-podcasts-and-datathons-san-carlos-r-user-group-in-costa-rica/index.html",
    "title": "ConectaR, Podcasts, and Datathons: How the San Carlos R User Group in Costa Rica is Connecting Latin America’s Data Lovers",
    "section": "",
    "text": "Frans van Dunné, the organizer of the San Carlos R User Group, recently discussed with the R Consortium the development of the R community in Costa Rica and the broader Latin American (LATAM) region. He also talked about the growth of events such as the ConectaR conference and the success of the Data Latam podcast, which he co-hosts to delve into data science in Latin America. Additionally, Frans highlighted the challenges of building a data-driven community in a rural area and the creative methods they’ve employed to connect people through R.\nPlease share your background and involvement with the RUGS group.\nI have a background in biology, and during my PhD in tropical ecology, I encountered some statistical questions that I needed to solve through programming. That’s when I started learning to program, initially with Perl. Eventually, I discovered that I enjoyed solving data-related problems through programming, and that led me to R. It was around 2001 when I first started programming in R.\nEventually, I married and emigrated to Costa Rica (my wife is Tica). Knowing no one in the area, I started an R User Group to connect with people and navigate the area.\nVery soon after arriving in Costa Rica, I established my town’s San Carlos R user group. Initially, we held our meetings in-person, but I soon discovered that some attendees traveled for hours by bus to reach San Carlos. Realizing the impracticality, I decided to move our meetings online, and to my surprise, it worked out well. This change occurred even before the pandemic, and we began to see people from Peru and other distant locations joining our group. San Carlos is a small rural area with a population of around 50,000, so having individuals from different parts of Latin America join us was truly amazing.\nOne of the first San Carlos R User Group meetings - February 2016, Ciudad Quesada, Costa Rica\nWe had to stop our online meetings because Meetup informed us that, according to their policy before the pandemic, we wouldn’t be able to use their platform if we didn’t hold physical meetings. The world is different now, but that was the situation back then.\nCan you share what the local R community is like in San Carlos?\nParticipants of ConectaR 2019 - January 2019, San José Costa Rica\nWe collaborated with the University of Costa Rica to organize an event that brought together industry, academia, and citizen science professionals for a conference focused on R. The event is called Conecta R. We started in 2019 and held the latest edition this year, Conecta R 2024. When we started, we wanted to understand R’s current status and usage in the LATAM region. It only confirmed that R is widely used in academia. Most statistics courses have transitioned from licensed software to R. R is also used widely in industry.\nParticipants of the Tidymodels workshop during ConectaR 2024, March 2024, San José, Costa Rica\nAt ixpantia, the company I co-founded, we work with clients in various industries, such as consumer packaged goods, retail, oil and gas, and energy production. Additionally, a significant number of clients utilize our financial services.\nWould you like to tell us about your recent events?\nWe’ve resumed our monthly online meetings for the San Carlos R user group. The meetings now take place on the first Saturday of the month in the morning, and anyone is welcome to join through Meetup.com. Our last meeting was held recently, and it was great to see familiar faces returning.\nAdditionally, we have a podcast called Data Latam, which covers topics related to data science, not just R. We aim to release a new episode every month. We run this podcast in parallel with meetings, serving a similar purpose. It’s about providing examples and even role models of professionals working with data to show that you don’t need to be an IT professional or a programmer to work with data.\nPlease share more about the Data Latam podcast. How did you come up with the idea of starting it? Would you like to highlight a few of your favorite podcasts from this series?\nThe story behind the Data Latam podcast is funny. The co-host, Diego May, and I met through an R Package I wrote to access data from an open-data platform he had developed. We shared an interest in using data and data science to help the development of LATAM and agreed to start a podcast to get to know each other better. Within two months, we had the first opportunity to start a project, and that is when we founded ixpantia, which brings best practices in data science, data engineering, and data strategy to LATAM.\nWe have done 110 podcasts to date! It seems like a lot, but we learn so much from every conversation that it hardly feels like an effort. Some of my personal favorites that are related to R include Episode 109 with Noam Ross, where we talked about rOpenSci, episode 98 with Sherly Tarazona about her work and R-Ladies Lima, episode 85 with Tareef Kawaf from Posit and episode 75 with Jorge Ahumada about the work they do at Wildlife Insights. I could go on, but pointing to the complete list at www.datalatam.com makes more sense. I’m sure there is something for everyone interested in data there.\nDo you recommend any techniques for planning for or during the event? (Github, Zoom, other.) Can these techniques be used to make your group more inclusive to people who cannot attend physical events in the future?\nOnline events are great. I live in a rural area, and attending a physical event, even here in Costa Rica, requires a long three-hour drive to the capital. We have done that and will do it again, but having the option to go online is much more practical and has a broader reach.\nWhen we started our first online meetings, we used Google Hangouts, which would fry my laptop after one hour. These tools have improved so much over the last few years, largely pushed by the boom in remote work during the pandemic. We still like Zoom and its functionality for setting up and executing events, including registration.\nParticipants of the Datathon 2019 in San Carlos, August 2019, Santa Clara, Costa Rica\nWe have organized two datathons (similar to a hackathon but focused on data) that were incredibly enjoyable and well-attended. The key to their success was our partnerships. One datathon was organized in collaboration with the Costa Rican government, and the other involved two local universities: The University of Costa Rica (UCR) and the Costa Rica Institute of Technology (TEC). I still meet people who attended these events and have fond memories of them."
  },
  {
    "objectID": "posts/conectaR-podcasts-and-datathons-san-carlos-r-user-group-in-costa-rica/index.html#how-do-i-join",
    "href": "posts/conectaR-podcasts-and-datathons-san-carlos-r-user-group-in-costa-rica/index.html#how-do-i-join",
    "title": "ConectaR, Podcasts, and Datathons: How the San Carlos R User Group in Costa Rica is Connecting Latin America’s Data Lovers",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 75,492 members in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html",
    "href": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html",
    "title": "R Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!",
    "section": "",
    "text": "The R Consortium is excited to announce the opening of our call for proposals for the 2024 Infrastructure Steering Committee (ISC) Grant Program on March 1st, 2024. This initiative is a cornerstone of our commitment to bolstering and enhancing the R Ecosystem. We fund projects contributing to the R community’s technical and social infrastructures.\nSubmit your proposal here!"
  },
  {
    "objectID": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#enhancing-the-r-ecosystem-technical-and-social-infrastructures",
    "href": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#enhancing-the-r-ecosystem-technical-and-social-infrastructures",
    "title": "R Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!",
    "section": "Enhancing the R Ecosystem: Technical and Social Infrastructures",
    "text": "Enhancing the R Ecosystem: Technical and Social Infrastructures\nOur past funding endeavors have spanned a variety of projects, illustrating our dedication to comprehensive ecosystem support:\n\nTechnical Infrastructure: Examples include R-hub, a centralized tool for R package checking, enhancements in popular packages like mapview and sf, and ongoing infrastructural development for R on Windows and macOS.\nSocial Infrastructure: Initiatives such as SatRDays, which facilitates local R conferences, and projects for data-driven tracking of R Consortium activities."
  },
  {
    "objectID": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#focused-funding-areas",
    "href": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#focused-funding-areas",
    "title": "R Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!",
    "section": "Focused Funding Areas",
    "text": "Focused Funding Areas\nThe ISC is particularly interested in projects that align with technical or software development that aids social infrastructure. It’s important to note that conferences, training sessions, and user groups are supported through the RUGS program, not the ISC grants."
  },
  {
    "objectID": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#ideal-isc-projects",
    "href": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#ideal-isc-projects",
    "title": "R Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!",
    "section": "Ideal ISC Projects",
    "text": "Ideal ISC Projects\nWe look for proposals that:\n\nHave a broad impact on the R community.\nPossess a clear, focused scope. Larger projects should be broken down into manageable stages.\nRepresent low-to-medium risk and reward. High-risk, high-reward projects are generally not within our funding scope.\n\nProjects unlikely to receive funding are those that:\n\nOnly impact a small segment of the R community.\nSeek sponsorship for conferences, workshops, or meetups.\nAre highly exploratory."
  },
  {
    "objectID": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#important-dates",
    "href": "posts/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march 1st/index.html#important-dates",
    "title": "R Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!",
    "section": "Important Dates",
    "text": "Important Dates\n\nFirst Grant Cycle: Opens March 1, 2024, and closes April 1, 2024.\nSecond Grant Cycle: Opens September 1, 2024, and closes October 1, 2024.\n\nYou can learn more about submitting a proposal here.\nWe eagerly await your proposals and are excited to see how your ideas will propel the R community forward. Let’s build R together!"
  },
  {
    "objectID": "posts/a-new-r-community-in-ahmedabad/index.html",
    "href": "posts/a-new-r-community-in-ahmedabad/index.html",
    "title": "A New R Community in Ahmedabad, India, focused on Clinical Research and Pharmaceutical Industries",
    "section": "",
    "text": "The R Consortium recently interviewed Sanket Sinojia, organizer of the Ahmedabad R User Group (ARUG). With over 14 years of experience in statistical programming and data sciences in the clinical research industry, Sanket spearheaded the formation of ARUG to create a dedicated community focused on applying R in clinical research and pharmaceutical industries.\nSince its official setup in 2023, ARUG has rapidly grown into a vibrant group with over 100 active members. The community fosters collaboration, knowledge-sharing, and mentorship, contributing significantly to the broader R ecosystem. Sanket’s dedication to data science and community building is evident in his efforts to organize impactful events, mentor new members, and drive the group’s growth.\nPlease share about your background and involvement with the RUGS group.\nI’ve been working in statistical programming and data sciences in the clinical research industry for more than 14 years, which naturally led me to explore tools that enhance data analysis and visualization. My journey with the Ahmedabad R Users Group (ARUG) began when I recognized the growing need for a dedicated community focused on applying R in our field. I was sitting with my industry friends Paresh Parekh, Paresh Paghdar, Parin Shah, and Rahul Pandya, discussing what we could do to bring the Ahmedabad R community together. After a few days, when we met again, I proposed setting up the ARUG. They welcomed and fully supported the vision.\nWhile the group was initially formed in 2021, its formal setup was completed in 2023 with collaboration from the R Consortium. Since then, I’ve been organizing events, facilitating discussions, and contributing to the group’s growth. My passion for data science and community building drives my commitment to ARUG. Beyond organizing, I also mentor new members, helping them navigate the complexities of R. It’s incredibly rewarding to see the community thrive and to witness the impact of our collective efforts on advancing the field. ARUG is the first city-based group in India associated with R Consortium and the only R user group focused on Clinical Research & Pharmaceutical Industries.\nCan you share what the R community is like in Ahmedabad?\nAhmedabad, a world heritage city known for its rich history and vibrant culture, is also known for its Pharma Industry. Ahmedabad is now emerging as a significant hub for clinical research, data sciences, and pharmaceutical innovation. The R community in Ahmedabad is vibrant and rapidly growing, especially within these sectors. With over 100 active members, our community is a diverse mix of seasoned professionals and enthusiastic newcomers. This diversity fosters a collaborative environment where knowledge-sharing and mentorship flourish. The enthusiasm and engagement at our events reflect the community’s dedication to advancing their skills and contributing to the broader R ecosystem. We’ve seen a significant increase in participation and interest, indicating the strong potential for R to drive innovation and efficiency in our industry. The city’s dynamic and innovative spirit resonates through our community, making it an exciting place for anyone passionate about data science and clinical research.\nYou had a meetup on July 21st, 2024. Can you share more about the topic covered? Why this topic?\nThe meetup was a highly anticipated event entitled ‘R Evolution: Shaping the Future of Clinical Trials.’ We chose this topic because it aligns perfectly with the emerging demand for R in our industry and aims to make our attendees aware of the transformative potential R brings to clinical research. Here’s a quick recap:\nI started the event by taking attendees through the inspiring journey of the Ahmedabad R Users Group (ARUG). I shared key updates, our association with the R Consortium, and outlined ARUG’s long-term goals. The overwhelming response, with event registration filling up within 24 hours, highlighted the high expectations and enthusiasm of our attendees!\nSunil Gupta, a renowned industry expert, delivered an incredible presentation on ‘R Made Easier for SAS Programmers.’ His insights, tips, and tricks on transitioning to R were invaluable, offering a comprehensive learning experience.\nFollowing his session, we enjoyed a vibrant networking session, making new connections and reconnecting with old friends.\nChintan Patel captivated us with a simplified demonstration of creating Kaplan Meier Plots using R. His comprehensive topic coverage inspired many to delve deeper into graphing with R.\nMitesh Patel then presented ‘R Shiny in Action,’ explaining the fundamentals and applications of R Shiny, complete with a live demonstration of three case studies. His session highlighted R Shiny’s potential as a game-changer in data visualization.\nI then hosted a dynamic round table discussion on conferences, joined by Parin Shah, Purvi Kalra, and Saumil Tripathi. They shared invaluable tips on conference preparation, R trends, and enhancing presentation confidence.\nFinally, Krupa Trivedi, Nidhi Shah, and Nikunj Kothari organized a thrilling ‘Test Your R Skills’ quiz. The live, time-bound quiz with an instant leaderboard brought a fun and competitive spirit to the hall.\nThe event wrapped up with Rahul Pandya’s vote of thanks, where we celebrated our presenters, the ARUG event team, and quiz winners.\nThe ARUG Event Team – Ankit Vadodariya, Dishant Parikh, Krupali Ladani, Krupa Trivedi, Nidhi Shah, Nikunj Kothari, Paresh Paghdar, Paresh Parekh, Parin Shah, Purvi Kalra, Rahul Pandya, and Sanket Sinojia – successfully organized the entire event. Their hard work and dedication ensured a seamless and impactful experience for all attendees.\nWho was the target audience for attending this event?\nOur target audience primarily includes professionals and researchers from the clinical and pharmaceutical industries. This encompasses data scientists, statistical programmers, biostatisticians, clinical trial analysts, and anyone interested in leveraging R for data analysis and visualization in these fields. We also welcome newcomers who are eager to learn and contribute to this dynamic industry. By targeting this specific audience, we ensure our content is highly relevant and impactful, addressing real-world challenges and opportunities our members face. Additionally, our events offer networking opportunities that can lead to collaborations.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nFor planning and executing our events, we rely on a combination of tools such as GitHub for collaborative project management and repositories, Zoom for virtual sessions, and Meetup and LinkedIn ARUG pages for continuous engagement and communication. These tools not only streamline our processes but also enhance accessibility. By utilizing these technologies, we can include members who cannot attend physical events, making our group more inclusive. We share our event summaries and slides on GitHub, ensuring that valuable information is accessible to all members. Additionally, we are considering recording sessions and sharing them on platforms like YouTube to further extend the reach of our events. Using these tools also allows us to gather feedback and improve future events, ensuring we meet the evolving needs of our community. This approach helps us maintain a vibrant and connected community, regardless of geographical limitations.\nWe would like to get to know you more personally. Can you please tell me about yourself? For example, hobbies/interests or anything you want to share about yourself.\nOutside of my professional life, I have several passions that I pursue with great enthusiasm. I enjoy blogging and sharing my thoughts on data science, industry trends, and personal reflections. The mountains always call me, and I find peace and inspiration in hiking and exploring nature. Additionally, I write poetry in my local language, allowing me to express my creativity and connect with my cultural roots. These hobbies provide a balanced and enriching life, complementing my professional endeavors.\nApart from ARUG, I volunteer with organizations like CDISC, PHUSE, Pharmaverse, and RinPharma, contributing to various projects such as SDTM IG v3.4 development, CDISC Primer development, and Shiny for Submission. These experiences offer me a unique perspective and a sense of tranquility that I bring into my work, enhancing my creativity and problem-solving abilities. Engaging in these activities helps me maintain a holistic approach to my professional and personal life.\nI cherish spending time with my family, especially with my adorable daughter Saanvi. My better half, Niza, always supports and encourages me in all aspects of life. She is dedicated to taking care of our family and provides unwavering support that allows me to pursue my passions and professional goals."
  },
  {
    "objectID": "posts/a-new-r-community-in-ahmedabad/index.html#how-do-i-join",
    "href": "posts/a-new-r-community-in-ahmedabad/index.html#how-do-i-join",
    "title": "A New R Community in Ahmedabad, India, focused on Clinical Research and Pharmaceutical Industries",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/recap-r-validation-hub-community-meeting/index.html#key-insights",
    "href": "posts/recap-r-validation-hub-community-meeting/index.html#key-insights",
    "title": "Recap: R Validation Hub Community Meeting",
    "section": "Key Insights:",
    "text": "Key Insights:\n\nValidation Perspectives: The meeting underscored the need for each organization to define “validation” in a way that suits its context, while the R Validation Hub offers a baseline for common understanding.\nStatistical Methodology Challenges: Discussions acknowledged the challenges in achieving exact results across different programming languages due to inherent differences in statistical methodologies.\nOpen Source Contributions: The importance of returning testing code to package developers was highlighted, reinforcing the open-source ethos of collaboration and quality enhancement.\nResource Availability: The slides from the meeting are accessible on GitHub here. Although the meeting wasn’t recorded, the community is encouraged to join the R Validation Hub mailing list for future updates and meeting invites here."
  },
  {
    "objectID": "posts/recap-r-validation-hub-community-meeting/index.html#looking-forward",
    "href": "posts/recap-r-validation-hub-community-meeting/index.html#looking-forward",
    "title": "Recap: R Validation Hub Community Meeting",
    "section": "Looking Forward:",
    "text": "Looking Forward:\nThe meeting reiterated the significance of the R Validation Hub as a central point for validation discussions and resources. Future community meetings are tentatively scheduled for May 21, August 20, and November 19, offering opportunities for further engagement and contribution to the evolving conversation around R validation.\n\nJoin the R Validation Hub mailing list!"
  },
  {
    "objectID": "posts/ann-arbor-r-user-group-harnessing-the-power-of-r/index.html",
    "href": "posts/ann-arbor-r-user-group-harnessing-the-power-of-r/index.html",
    "title": "Ann Arbor R User Group: Harnessing the Power of R and GitHub",
    "section": "",
    "text": "The R Consortium talked to Barry Decicco, founder, and organizer of the Ann Arbor R User Group, based in Ann Arbor, Michigan. Barry shared his experience working with R as a statistician and highlighted the current trends in the R language in his industry. He also emphasized the significance of organizing regular events and effective communication for managing an R User Group (RUG).\nPlease share about your background and involvement with the RUGS group.\nThroughout my professional career, I have gained extensive experience in various industries as a statistician. Statisticians are often thought of as either staying in one industry for their entire career or frequently transitioning between them. I have followed the latter path, having held positions at Ford Motor Company, their spinoff Visteon, the University of Michigan School of Nursing, the University of Michigan Health System, Nissan Motor Company, Volkswagen Credit (as a contractor), Michigan State University, and currently Quality Insights.\nI have been using the R programming language consistently for several years now. I have extensively worked with R during my tenure at Michigan State University as a member of the Center for Statistical Training and Research (CSTAT). CSTAT serves as the university’s statistical laboratory. Our team heavily relied on R as our preferred software for statistical analysis.\nOur reporting process involved using R Markdown reports. Steven Pierce, the assistant director, developed a highly complex and upgradeable system using R Markdown to process data. This system allowed us to initiate a report and then trigger the R Markdown file to process the data and generate the final datasets for each report. Another R Markdown file was then called to render the report. This streamlined process enabled us to produce about 40 PDF reports within 45 minutes. The process remained relatively straightforward when we needed to make modifications, such as changing the reporting period from fiscal years to calendar years or adding or subtracting individuals, units, or departments.\nI have recently started a new job primarily working with the SAS programming language. Initially, I will focus on gaining proficiency in this area. After that, I will transition to performing more in-depth analysis and ad hoc reporting, requiring me to use additional tools and resources. I have also moved to a new system where we use Hive or Hadoop through Databricks. As part of my role, I am responsible for taking over the current reporting system and identifying future reporting needs. This will require me to use R extensively.\nBefore the COVID pandemic, the R users group met in Ann Arbor. However, the pandemic dealt a major blow to the group, and we are still recovering from its impact. In our efforts to revive the group, we continued with the same theme as before: a mix of programming and statistics. However, we have been focusing more on programming and simpler analysis to make it easier to get the group restarted. We have also introduced some new presenters covering topics such as machine learning pipelines in their presentations.\nCan you share what the R community is like in Ann Arbor?\nR has become a popular programming language in academia and will likely remain relevant in this field. However, general coding and applications are more prevalent in the industrial sector. Python is gaining popularity because it attracts a broader range of programmers, including those who are not data or analytics specialists. Therefore, R will continue to be a significant but specialized tool.\nCurrently, I have noticed a significant decrease in the usage of SAS. This trend is driven by the dislike of license fees among individual and corporate users. The matter is further complicated by corporate accounting practices, where different funding sources may have varying spending restrictions. As a result, organizations may end up incurring higher salary expenses because of the complexity of corporate accounting processes.\nIf a company spends a fixed amount, say $10,000, on SAS licenses yearly, it might not like it. But then, it may hire additional staff to do the same work SAS did earlier. The salary of these people, and other associated costs, may come from a different funding source. As a result, the company may spend a significant amount of money, ranging from $120,000 to $150,000 annually, to replace a smaller amount of $10,000 to $20,000 annually. However, whether this arrangement is acceptable would depend on the funding source.\nDo you have an upcoming meeting planned? What are your plans for the RUG for this year?\nOur next presenter, Brittany Buggs, Staff Data Analyst at Rocket Mortgage, will demonstrate the usage of the GT package for generating tables. Additionally, we are striving to establish closer integration with the Ann Arbor chapter of the American Statistical Association to foster mutual support and collaboration between the groups. We have been conducting hybrid meetings catering to in-person and virtual attendees. Ann Arbor Spark, a local startup business development organization, has generously provided us with a physical meeting space. Our meetings follow a hybrid format, recognizing the convenience and accessibility it offers to many individuals.\nThis year, I aim to have more presenters as I have been doing all the presentations by myself. I plan to raise awareness about R, R Markdown, and Quarto and show people how these tools can be useful. I will promote these tools at the University of Michigan and other companies.\nWhat trends do you currently see in the R language?\nWhen it comes to data analysis, R has a clear advantage. The tidyverse syntax is easy to understand, even for those unfamiliar with data tables or Pandas-like programming paradigms.\nWhen working with data tables, both base R and Pandas use programming languages that differ significantly from English, which can make understanding them difficult. On the other hand, R Markdown has a notable advantage in that it makes it easy and quick to generate HTML documents. For instance, my former supervisor at C-STAT spent much time creating visually appealing PDF documents because his reports were highly customized. However, if your main goal is to produce polished reports relatively quickly, R Markdown is the better option.\nI understand that my main focus is the transition to Quarto. As someone who used to work with R Markdown, I have been learning more about Quarto and adjusting to its features. However, I am concerned about how new users may react to Quarto. I plan to give presentations throughout the year to gauge their responses and better understand any potential issues that may arise.\nMoreover, I’ve noticed that many people are unaware of R Markdown’s capabilities. To address this, I conducted an introductory session on R Markdown for a group at the University of Michigan. During my thirty-minute presentation, the participants were surprised by the diverse functionalities of R Markdown, as they were used to working with JavaScript and basic R. Although I had inferior knowledge compared to some of the individuals in the group, my ability to perform certain tasks using R Markdown impressed them.\nOne of the benefits of R Markdown is its ability to run multiple languages, with each language being executed chunk by chunk. I hope Quarto will also support this feature.\nIn the past, I have presented on calling R from SAS and SAS from R. During these presentations, I demonstrated how to run a SAS job within an R chunk. However, this approach has a limitation. For it to work, SAS must be accessible from the computer running the R code. This means the SAS installation must be on the computer or a network drive that the computer recognizes as a local drive. On a certain occasion, while using Enterprise Guide on a Linux machine, I faced a problem. I couldn’t locate the executable file (EXE) for SAS from my computer, which obstructed me from executing a SAS job.\nIt is now possible for individuals to use R Markdown with their preferred programming languages. For instance, R Markdown can be used with Pandas for most cases, which can help individuals produce visually appealing reports quickly. With this approach, all the work can be done within Pandas, and users need only basic knowledge of R. Therefore, Quarto can be seen as a language for report writing only. I will keep an eye on this situation and evaluate its effectiveness.\nI want to highlight the smooth combination of Git and GitHub with R. I use GitHub frequently in my work, though I am not very skilled because RStudio IDE fulfills most of my requirements. I rarely face conflicts due to my carelessness; I must interact with Git and GitHub manually.\nI highly recommend the book “Happy Git with R” as an essential resource for beginners. This comprehensive guide provides a step-by-step approach to setting up and using Git and GitHub effectively in R.\nWhen using Git in conjunction with R, you can access a detailed transaction history that can be reviewed anytime. I have found this feature incredibly useful and have been able to recover important work using this method. As a data management instructor at MSU, I have also taught my students how to execute this process manually. However, having R Studio automatically handle this task is much more convenient.\nIn fact, I used SPSS to conduct a project and leveraged GitHub as an experiment. I utilized the data management capabilities of RStudio and found the results satisfactory.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nI suggest that RUG organizers should arrange regular monthly meetings. It would be advantageous to fix these meetings on the same day and time every month, as it will help attendees get accustomed to the routine and know when to expect them.\nIn my years of working with different groups, I have noticed that if we don’t consciously communicate regularly, our communication will become less effective over time. This can lead to a lack of new ideas and engagement, and we may unintentionally exclude potential participants.\nFor almost 20 years, I have been part of a group that communicated through a university mailing list. However, we faced difficulties as the list was not easily discoverable through search engines like Google. This made it challenging for new individuals to find or contact us. We have taken steps to tackle this problem by introducing Meetup as a new tool that can be used alongside or instead of our traditional mailing list. The main benefit of Meetup is that it is easily searchable on Google, which makes it simple for anyone to locate and get in touch with our group.\nI want to emphasize the importance of effective communication. Neglecting communication efforts can cause a decline in communication quality. I have personally witnessed this happening in different groups, and I have seen others experiencing similar challenges."
  },
  {
    "objectID": "posts/ann-arbor-r-user-group-harnessing-the-power-of-r/index.html#how-do-i-join",
    "href": "posts/ann-arbor-r-user-group-harnessing-the-power-of-r/index.html#how-do-i-join",
    "title": "Ann Arbor R User Group: Harnessing the Power of R and GitHub",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 65,000 members in 35 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "",
    "text": "Quick update on the 2024 R User Groups (RUGS) Program. The review of the first batch of grants is in progress, marking the beginning of the awarding phase. But there’s still plenty of time for you to apply!\nInterested in building up your own R User Group and creating a strong R community where you live? R Consortium would like to help!"
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#apply-now",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#apply-now",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "Apply now!",
    "text": "Apply now!"
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#rugs-program-highlights",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#rugs-program-highlights",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "2024 RUGS Program Highlights:",
    "text": "2024 RUGS Program Highlights:\n\nUser Group Grants: Support for enhancing user engagement and user-centric initiatives.\nConference Grants: For organizing or attending events aligned with R Consortium goals.\nSpecial Projects Grants: For groundbreaking ideas needing an initial push.\n\nFor details and to apply, visit here. Your participation is pivotal for the growth of the R language."
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#r-user-groups-strengthening-global-connections",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#r-user-groups-strengthening-global-connections",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "R User Groups: Strengthening Global Connections",
    "text": "R User Groups: Strengthening Global Connections\nWith 74 active groups and over 67,000 members, R communities are a melting pot of knowledge and innovation. Discover what other RUGS organizers are doing and how they have solved tough problems restarting in person meetings or finding good locations or communicating effectively with their community… on our blog. Many RUGS case studies are available."
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#key-dates",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#key-dates",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "Key Dates:",
    "text": "Key Dates:\nApplication Period: Open through September 30th, 2024, but don’t wait!\nNote: Grants are not for software development or technical projects. For those, consider the ISC Grant Program. Learn more here.\nJoin us in building the worldwide R community. Apply now and be part of the journey!"
  },
  {
    "objectID": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#apply-now-1",
    "href": "posts/2024-rugs-program-progress-reviewing-grants-empowering-r-communities/index.html#apply-now-1",
    "title": "2024 RUGS Program Progress: Reviewing Grants and Empowering R Communities",
    "section": "Apply now!",
    "text": "Apply now!"
  },
  {
    "objectID": "posts/the-impact-of-r-on-academic-excellence-in-manchester-uk/index.html",
    "href": "posts/the-impact-of-r-on-academic-excellence-in-manchester-uk/index.html",
    "title": "The Impact of R on Academic Excellence in Manchester, UK",
    "section": "",
    "text": "The R Consortium recently spoke with the organizing team of the R User Group at the University of Manchester (R.U.M.). R.U.M. aims to bring together R users of all levels to share R best practices, expertise and knowledge. The group is open to all staff and postgraduate researchers at the University of Manchester, UK.\nDuring the discussion, the team shared details about their recent events and their plans for this year. They also discussed the latest trends in the R programming language and how they are utilizing it in their work.\nMartín Herrerías Azcué\nResearch Software Engineer\nUniversity of Manchester\nAnthony Evans\nResearch Software Engineer\nUniversity of Manchester\nLana Bojanić\nResearcher PhD Candidate\nUniversity of Manchester\nRowan Green\nPhD Student in Evolutionary Microbiology \nThe University of Manchester\nPlease share about your background and involvement with the RUGS group.\nMartin: My name is Martin, and I joined the University of Manchester a year ago. They assigned me to manage the R user group, which was previously under Camila’s leadership. Although I am officially in charge, this is a collaborative effort between all of us who are present in this meeting, along with some others who couldn’t join. I work in Research IT and mainly use R for projects assigned to me by other people.\nAnthony: My name is Anthony and I work at Research IT with Martin at the University of Manchester. I first came into contact with R when I was a student. Later, I became a helper at many of the university’s R training courses based on the Carpentries training courses. Camila, who was Martin’s predecessor, was also a trainer at R and she formed the R Users Manchester group. I volunteered to help her with the group a year ago, and it just turned a year old. After that, I continued to be a part of the group.\nLana: Hi there, my name is Lana. I am a PhD student and research assistant at the Division of Psychology and Mental Health at the University of Manchester. I have been using R for the past six years, ever since my Master’s degree. I have been a part of the group since its inception and have been running R introduction sessions for beginners within my division for a couple of years now. When I learned the group was being formed, I contacted Camila a year ago. This makes us founding members of the group.\nRowan: Hello, my name is Rowan Green. I am currently a PhD student in the Department of Earth and Environmental Sciences. For my research work, I use R extensively for simulation modeling bacteria, analyzing lab data, and creating visualizations. The best thing about using R is that it produces much prettier visualizations than other options available to us as biologists. We have a lot of master’s and undergraduate students coming through the lab. I often give them pre-written scripts they can tweak to create their plots. It’s exciting to see them working hard to produce their plots.\nCamilla mentioned starting a group to share knowledge about R on a university-wide level. I found this a great opportunity to participate and learn from others’ presentations during the meetings. It has been an enriching experience so far.\nCan you share what the R community is like in Manchester?\nAnthony: In industries such as banking and finance, R is frequently used to create graphs to showcase econometric data in an easy-to-understand manner. The graphical capabilities of this programming language make it a popular choice in these fields. The university we’re in has access to the Financial Times, which is known for producing visually stunning graphs. Interestingly, they also use an R package called FT plot tools, which is a specialized package solely for their use. So, it’s safe to say that R has a significant presence in the banking and finance sectors.\nAre your meetups virtual or in-person? What topics have you covered recently? What are your plans for the group in the future?\nMartin: Our events are a mix of in-person and online meetings. There have been talks about developing packages, data visualization, automating reports, and working with tables. We usually cover topics we are confident about or know people from the university are working on. However, we are also trying to get external speakers to come and talk. It’s challenging, but we are doing our best to make it happen. We are currently accepting proposals from potential speakers.\nOur book club has mostly or completely taken place online.\nLana:  Bookclub was mostly online. During the summer book club, we were reading R for Data Science. We covered a chapter or two chapters each time. We had the book’s second edition, and people from all over the university joined the club.\nWe were discussing the possibility of changing the format of Tidy Tuesdays. We received feedback that people don’t have enough time to come up with something extra creative every month. Additionally, there has been a need for more practice. Therefore, we plan to redesign Tidy Tuesdays to be more practice-oriented than creativity-oriented. We will be implementing these changes this year.\nAnthony: We’ve recently had several discussions on useful packages, particularly in R. Some packages that were developed and published were custom-made. We also had presentations on the cosinor and cosinor2 packages, which are used for fitting curves, and an R update package for validating clinical prediction models.\nThere are two other R groups in Manchester. Our aim for this year is to establish communication with them and collaborate in a coordinated manner. (Editor’s Note: We recently talked with the Manchester R User Group.) Currently, our group solely focuses on the internal R community at the University of Manchester.\nAny techniques you recommend using for planning for or during the event?\nRowan: I’m not sure if everyone would agree with me, but I think we did well in the format of our meetings. We started with brief, brief talks – within an hour – followed by questions and discussions, which worked well.\nHowever, the harder part has been promoting and informing people about the meetings. Sometimes, word of mouth has been more effective than emails and posters. I noticed that they were interested in attending when I encouraged my lab group, who all use R. But without any scheduled reminders and someone to encourage them, it may be difficult to get people to come.\nLana: It’s important to identify everyone’s strengths or specialties within the organizing group, as they will probably be useful in the first few events. After that, you can expand your network within the community, which is easy to do since people are easily reachable. This will allow you to find interesting topic ideas and strengths to draw from.\nWhat trends do you currently see in R language?\nMartin: I’ve noticed a growing interest in Shiny lately, as I manage a pilot server for the university and have seen an increase in users over time. There have also been several inquiries about using R within our high-performance computer cluster, which may be something we can offer to the university. This interest is not surprising, given the current hype around machine learning.\nA trending area that applies to multiple platforms, not just R, is towards reproducible research and compatibility between different programming languages. This means that R can be integrated with Python and other languages to create a documented and integrated pipeline. I’ve been experimenting with SnakeMake, which works well with R, but it would be great to see more integration from the R side, perhaps through the common workflow language or another similar tool.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nRowen: Recently, I wrote a preprint of a paper where we simulated the growth and mutation of bacteria using differential equations and R programming language. To perform the simulation, we utilized high-performance computing, which enabled us to simulate various ways the bacteria could grow by adjusting the rates of reactions occurring within the cells. This simulation required high-performance computing to be feasible for running multiple simulations.\nAfter running simulations, we came up with some ideas to test in the lab. Our focus was on measuring mutation rates, and we used statistical analysis to estimate them through R. We have been striving to ensure reproducibility, and as a result, we have annotated all the data tables and R scripts with the paper.\nIt has been an interesting journey for me. I had to tidy up my messy scripts and think about how someone else would perceive them. I had to ensure they made sense. However, the project was fascinating as I generated hypotheses using R, tested them, and analyzed and visualized them with the same tool. R is a complete tool that can handle all aspects of the process, making it a brilliant choice."
  },
  {
    "objectID": "posts/the-impact-of-r-on-academic-excellence-in-manchester-uk/index.html#how-do-i-join",
    "href": "posts/the-impact-of-r-on-academic-excellence-in-manchester-uk/index.html#how-do-i-join",
    "title": "The Impact of R on Academic Excellence in Manchester, UK",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "",
    "text": "Recently, Kamil Sijko of the Warsaw R User Groupdiscussed with the R Consortium his transition from academia to leading data science in the business sector. He noted the current dormancy of Warsaw’s R community and the eagerness to revive its dynamic, pre-COVID meetups. The group’s latest meeting explored new, interactive formats to engage its diverse membership better."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#please-share-about-your-background-and-involvement-with-the-rugs-group.",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#please-share-about-your-background-and-involvement-with-the-rugs-group.",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "Please share about your background and involvement with the RUGS group.",
    "text": "Please share about your background and involvement with the RUGS group.\nDuring my early academic years at the University of Social Sciences in Warsaw, we explored several interesting projects, one of which was ‘webiR’ in 2009. This project was an attempt to blend R’s capabilities with web application development, which was not very common at the time. We developed webiR a few years before the advent of Shiny in 2012 with the idea of making R more accessible to non-technical users.\nWhile webiR might not be widely remembered today, unlike the widely successful Shiny, it represented our early efforts to simplify data analysis. The application allowed users to choose survey questions they were interested in, and then it would automatically select suitable analyses through a set of heuristics. This approach aimed to eliminate the need for users to understand the underlying R functions, making data analysis more approachable.\nAlthough webiR wasn’t a major success, it was a valuable learning experience and a stepping stone in exploring how R could be used innovatively, especially in web development. These kinds of exploratory projects contribute to the ongoing evolution and versatility of R, which we continue to see today.\nLater, I transitioned to working at research institutes, including a government-funded Polish Educational Research Institute. Now, I’m in the business sector. I serve as the Head of Data Science at Transition Technologies Science, a company that operates in the medical industry. We collaborate with pharmaceutical companies, universities, and medical scientists. My role involves leveraging data science in various aspects of the medical field."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#can-you-share-what-the-r-community-is-like-in-warsaw-poland",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#can-you-share-what-the-r-community-is-like-in-warsaw-poland",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "Can you share what the R community is like in Warsaw, Poland?",
    "text": "Can you share what the R community is like in Warsaw, Poland?\nThe situation is dormant, but it’s good timing for a reboot. There have been no revised activities since the pandemic ended. Before COVID, though, this was a hot topic of discussion. There were frequent meetups, including Python and data science gatherings. These meetups were unique, and I found them slightly unconventional in a good way. For example, Python meetups often focused on deep learning and applications in risk management or insurance.\nBut with R meetups, there was a broader spectrum of topics, often venturing far beyond conventional subjects. I found this diversity particularly refreshing, especially as many academics were involved, exploring a wide range of innovative applications.\nOne of the things that stood out was the involvement of women from the Warsaw University of Technology, who ran the ‘R Ladies’ in Warsaw. They organized numerous workshops, which were quite popular. These workshops offered an accessible entry point into data science for those looking to change careers. One interesting observation made was that R is often seen as more approachable as a first language for newcomers from different backgrounds.\nWe also have a strong scientific group in Warsaw led by Professor Biecek, a fervent advocate of R and leader of MI2.AI. His work in Explainable AI is cutting-edge, making us feel connected to a vibrant local scene. Another point raised was the curiosity about local technological developments, not just the global cutting-edge advancements.\nI recall an initiative named ‘PoweR’ – a three-week crash course in data science that attracted about 500 participants. I didn’t participate myself, but it was impressive. Also, the fields of science like medicine, statistics, econometrics, spatial sciences, and humanities were highlighted. R is extremely popular in these areas, allowing for exploration of unique and diverse topics.\nIt’s clear there’s a strong desire to revive these meetups and initiatives, as they foster a unique learning environment and community spirit."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#you-had-a-meetup-on-december-11th-2023.-can-you-share-more-on-the-topic-covered-why-this-topic",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#you-had-a-meetup-on-december-11th-2023.-can-you-share-more-on-the-topic-covered-why-this-topic",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "You had a Meetup on December 11th, 2023. Can you share more on the topic covered? Why this topic?",
    "text": "You had a Meetup on December 11th, 2023. Can you share more on the topic covered? Why this topic?\nIn our recent meeting, we deviated from the usual format of workshops and lectures, opting for a more unique approach that we may not repeat. Instead, we engaged in a peer-to-peer discussion, which was feasible due to the small number of attendees. We focused on two main topics. The first was understanding what people miss most about our meetings, as I aim to incorporate these elements when I reboot them. The second topic was exploring future directions for our meetings.\nWe delved into the different types of participants attending our meetings. One group comprises those familiar with R and eager to learn about advanced techniques, for whom lectures are ideal. Another group includes individuals transitioning from other fields to data science. We also considered students, particularly those favoring Python over R, and I believe it’s important to dispel any misconceptions about career prospects in R.\nAdditionally, we discussed members of the open source community around Warsaw, recognizing their contributions during events like hackathons. Another interesting aspect was the companies’ involvement, not just in recruitment but also in sharing their work with the community.\nAn unaddressed yet intriguing aspect was attendees transitioning within the data science field, seeking insights into new companies and trends. I also want to focus more on social interactions beyond just having pizza and experiment with ideas like speed dating or extended interactions with lecture presenters.\nLastly, we considered the language of our meetings. Operating in Poland, we debated whether to conduct some sessions in English, stream them, or post them on YouTube to reach a broader audience. I’m excited to experiment with these ideas, which could significantly enhance our meetings."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#who-is-the-target-audience-for-attending-this-event",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#who-is-the-target-audience-for-attending-this-event",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "Who is the target audience for attending this event?",
    "text": "Who is the target audience for attending this event?\nUp to this point, our focus has primarily been on individuals who are already interested in R and seeking to deepen their knowledge with expert insights. That’s been our main audience. The other significant group consists of those completely new to the field who are looking to be introduced to data science through R. These are the two main types of participants we usually have.\nWe aim to be more inclusive; of course, there’s the ‘R Ladies’ initiative. The ‘R Ladies’ essentially engage in the same activities as the rest of our groups, but they cater to a different audience. The content and structure of their sessions are similar to what we offer to other participants. Still, they focus on creating an inclusive environment for women interested in data science and R."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "Any techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?",
    "text": "Any techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nThere were various opinions, but one perspective really resonated with me. COVID took away our in-person meetups, and although there was an attempt to transition them to a virtual environment, it wasn’t the same. We miss face-to-face interactions and being in the same physical space together. That’s something special.\nThere were instances where, despite people already gathering in the room, we had to announce that the expert wouldn’t be able to come and would instead join via Zoom. This often led to disappointment, with some attendees leaving the room immediately, as they weren’t interested in a virtual presentation. After all, there’s plenty of similar material available online.\nOne comment struck me: even though we could have experts from RStudio (now posit) or other places speak to us from across the ocean about their latest developments, this information is already accessible on platforms like YouTube. The experience is likely to be similar. In terms of using Zoom or similar virtual platforms, we’re leaning towards not pursuing that path for future meetups."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#we-would-like-to-get-to-know-you-more-on-the-personal-side.-can-you-please-tell-me-about-yourself-for-example-hobbiesinterests-or-anything-you-want-to-share-about-yourself.",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#we-would-like-to-get-to-know-you-more-on-the-personal-side.-can-you-please-tell-me-about-yourself-for-example-hobbiesinterests-or-anything-you-want-to-share-about-yourself.",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "We would like to get to know you more on the personal side. Can you please tell me about yourself? For example, hobbies/interests or anything you want to share about yourself.",
    "text": "We would like to get to know you more on the personal side. Can you please tell me about yourself? For example, hobbies/interests or anything you want to share about yourself.\n\nA fun fact about me is my deep involvement in an initiative focused on teaching children creative computer skills. I’ve found it incredibly rewarding to help kids learn how to use technology creatively. It’s a lot of fun, both for me and the children. For instance, I recently prepared workshops on creating Electronic Dance Music (EDM). These workshops cover aspects like sampling and looping. I find this work enjoyable and immensely fulfilling, as it combines my passion for technology with the joy of teaching and engaging with children.\nAdditionally, in my work with CoderDojo, I’ve had the opportunity to engage children in programming projects, including a special focus on encouraging a group of girls. We utilized ’Kodu Game Lab‘ for these sessions, a platform that offers a more immersive, video game-like environment for coding. This platform enabled the children to learn programming concepts in a playful manner, such as coding a robot to follow or avoid objects and even creating their own simple games.\nA key moment came when the girls highlighted a significant limitation: the lack of relatable characters in the games, noting the predominance of robots and other figures but a conspicuous absence of princesses or characters they could identify with. This feedback was invaluable and led us to adapt our approach. We creatively worked around this limitation by incorporating an object—a ‘tag’—which we collectively imagined as a princess needing rescue. This improvisation turned into a unique game by the end of the day.\nThis experience was not just fun but also enlightening, underscoring the importance of CoderDojo’s approach in offering unique insights into how different groups perceive technology. It highlighted the need to understand and address diverse perspectives and requirements in technology, especially when introducing young minds to the world of programming."
  },
  {
    "objectID": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#how-do-i-join",
    "href": "posts/rebooting-warsaw-r-community-2024-kamil-sijko-journey-future-aspirations/index.html#how-do-i-join",
    "title": "Rebooting the Warsaw R Community in 2024: Insights from Kamil Sijko’s Journey and Future Aspirations",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 65,000 members in 35 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute."
  },
  {
    "objectID": "posts/reviving-sheffield-r-user-group-and-building-tools-for-thyroid-cancer-prediction/index.html",
    "href": "posts/reviving-sheffield-r-user-group-and-building-tools-for-thyroid-cancer-prediction/index.html",
    "title": "Reviving Sheffield R User Group and Building Tools for Thyroid Cancer Prediction",
    "section": "",
    "text": "Neil Shephard, co-organizer of the Sheffield R User Group in Sheffield, United Kingdom (also on fosstodon), recently spoke to the R Consortium about his journey from Genetic Epidemiology to Research Software Engineering with R. He also discussed the revival of the Sheffield R User group and the challenges of organizing inclusive and hybrid events. Neil also highlighted the group’s successful participation in Hacktoberfest and shared insights into his current R projects, including developing tools for thyroid cancer prediction and deploying Shiny applications.\n\nPlease share your background and involvement with the RUGS group.\nI have a background in biology. I studied zoology and genetics at the undergraduate level and then pursued a master’s degree in genetic epidemiology, focusing on identifying genes involved in human diseases. Specifically, I worked on complex diseases such as rheumatoid arthritis and related autoimmune diseases initially and breast cancer. During my master’s program, I was taught programming and learned some C, although that was quite a long time ago, around 25 years ago. While I never really took to C programming, I was also introduced to the statistical package Stata, which I found very user-friendly and appreciated its strong community support.\nAs time passed, I began to hear more and more about R. This was around 2000, a few years after R was first released. One of the things I had started doing was writing literate documents in LaTeX. I would write a LaTeX document, and Stata could output tables to LaTeX, which I could then include in my document and render to PDF. I found this a much more efficient way to work reproducibly than traditional word processors and spreadsheets.\nI was exploring R and discovered Friedrich Liesch’s package Sweave, which interweaved LaTeX and R code. It was really the precursor to RMarkdown. I also started using Linux as my operating system and became interested in the free open source software movement.\nAround 2004 I made a conscious choice to switch from Stata to R because of its open source licensing and extensibility. While Stata allowed me to write my functions and modules, I found R more open as it isn’t owned by a company, and I didn’t need a license, which I typically relied on my employers to provide.\nI decided to invest my time learning R for all my work because it would benefit me in the long run, as I could take the knowledge and skills and use them anywhere. When I switched careers from genetic statistician to medical statistician in a clinical trials unit at the University of Sheffield, I continued using R, although I was in a minority, as most colleagues at the time used Stata or SPSS.\nI continued using R and convinced a few others to join me. We supported each other, and around 2015 the SheffieldR user group was initiated by Anna Krystalli. I attended the meetings and found them really useful as they brought together people from the university and beyond who shared a passion for using R in their research, showing each other how they used R in their work. It was a great way to discover new features. I attended those meetings until around 2019, when I switched jobs to work for a startup tech company and switched to using Python and Java for work. Soon after, SheffieldR fizzled out due to lockdown in 2020.\nAfter working for a tech company for a few years, I returned to the University of Sheffield as a Research Software Engineer, where I’m currently employed. This role has given me more opportunities to use R. I have been involved in a Python project from the beginning, but recently, I’ve also had the chance to work on a few R projects. I’ve missed the enjoyable and exciting R user group meetings that I used to attend.\nI was asked to improve Sheffield’s RSE (Research Software Engineering) community. As part of this, I joined the open science community movement, an international initiative that began in the Netherlands. They had an incubator program to establish open science communities in local areas, and I enrolled in that program to start an open science community in Sheffield. I’m quite a practical person and like to take action and help others, so I resolved to revive the Sheffield R user group as I had found it so useful in helping me learn what could be done with R earlier in my career.\nI briefly worked with Anna, who had started the SheffieldR group, but unfortunately, soon after I started to work with the RSE Team, she moved on and became an R consultant. Still, we had some overlap, and she was happy to share all the materials and the GitHub repository for the website with me. So, I took on the responsibility of organizing the group. I rewrote the website and switched it from R Markdown to Quarto to learn more about using Quarto, which had just been released. It wasn’t too difficult since the languages are pretty similar.\n Sheffield R User Group April 2024 Meetup “Profiling and Optimising your R code,” Speaker: Dan Brady, Research Software Engineer, University of Sheffield.\nI was joined by Grace Accad from the Data Analytics Service at the University of Sheffield to organize SheffieldR. She had been involved in R ladies and attended other R user groups, and I’ve been very grateful to her for her support and help in sharing the workload.\nWe have been hosting Sheffield R user group events for over a year, and they have been quite successful. We aim to hold the events every month during term time. I presented at our initial reboot session showing how to use Quarto and GitHub pages to put slides online, but we have been fortunate to find other speakers since then. However, Grace and I are primarily responsible for organizing and setting up the website and booking rooms. It’s not too demanding, but that’s my primary role in the group.\nCan you share what the R community is like in Sheffield? \n Sheffield R User Group January 2024 Meetup “Automating Health Economic Evaluation with R,” Speaker: Robert Smith, Dark Peak Analytics.\nI only have a little industry experience, having only worked for one company. However, I think R is more academic, although that is changing. In Sheffield, the company I worked for had a research department with only two people. So, at least in Sheffield, R is used in the industry. The Sheffield R user group aims to bring together people who use R in the area to create a community where they can ask questions and help each other. A data science learning community in Sheffield used to be more R-oriented but now includes people using pandas. I like that community as well.\nI strongly believe in the importance of connecting with people in person. The networking effect is natural and very beneficial. Building these connections and networks online while possible is more challenging, so I am focused on creating a local group to foster this. Most participants are from the University of Sheffield. However, there are also individuals from Sheffield Hallam University and outside academia, such as Simon Rolph from the UK Centre for Ecology and Hydrology, who gave an excellent talk on the targets package. We’ve also had talks with Robert Smith and Wael Mohammed of Dark Peak Analytics.\nOne of my challenges is that I have a daughter, so I usually need to be home in the afternoons to take care of her. I appreciate that attending events in the evenings isn’t possible for everyone. Finding a suitable time for everyone is difficult. If we have meetings at lunchtime, we get a lot of university attendees, but only a few from farther away because they would have to travel. You can please some of the people sometimes, but you can’t please all the people all the time.\nYour group recently hosted Hacktoberfest events. Can you share more about the topic covered? Why this topic? \nHacktoberfest celebrates open source software and encourages people to find their favorite open source project to contribute to. Our first meeting was on October 4th, and then we had one every other Friday throughout October.\nThe main objective was to help people get comfortable contributing to open source software, especially those who use R but may not be familiar with version control using Git and GitHub. In the first session, I used material from my job as a research software engineer, where I’ve been teaching a course Anna developed on using Git and GitHub for the past year or two. This course covers the basics of version control and includes a collaborative exercise using a GitHub repository.\nParticipants learned how to fork the repository, make changes locally, push their changes, and create pull requests. The following three weeks were dedicated to providing support, where others and I with experience in version control and using R were available to assist others. The goal was for people to help each other during this time and not rely solely on me or my colleagues as organizers, as some individuals may have more knowledge than others. It was great to see everyone coming together to support one another, as some people may have more expertise in specific areas than I do.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future? \nI have a GitHub issue template in place to help organize our meetings. I use GitHub to plan events because my memory is terrible. I’d likely forget something important if I didn’t have everything written down. Whenever we plan an event, we create a GitHub issue and assign it to me or Grace. It’s a checklist of tasks such as booking a room, setting dates and times, confirming speakers, obtaining consent for photography during the event, and listing places to advertise the event. This checklist helps us keep track of everything that needs to be done for each event.\nThe Sheffield R user group used to meet in a local pub. However, when we restarted the events, we decided that using more neutral spaces would be more inclusive, so we use university buildings now. We want to ensure everyone feels welcome, so we choose accessible venues for people with disabilities. It’s important to me that everyone can attend without any barriers.\nWe also run hybrid meetings, which I find challenging. When I have a group of people in the room, I naturally tend to speak to them. I have to remind myself to pay constant attention to the online participants. It’s helpful to have another organizer keeping an eye on the online side of things when people raise their hands. Despite the challenges, we continue with hybrid meetings because they’re a good way of allowing people to attend if they can’t make it in person.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nI’m working on a project with a PhD student trying to improve thyroid cancer prediction. When he approached me, he used SPSS for his analysis because that’s what one of my old colleagues had taught him. From now on, I encouraged him to switch to using R for all his work, and I’ve helped him set up version control for it.\nHe has learned to write Quarto documents with embedded R code to write the manuscript he wants to create. This has been very useful. He has also learned how to use a multiple imputation package that he hadn’t used before to summarize the results and check their consistency with the observed data. At one point, the PhD student and his supervisor wanted to create a website where people could enter various characteristics about a patient and receive a risk profile indicating whether the lumps in their thyroids were likely to be malignant. To achieve this, he revisited his knowledge of Shiny to get the website up and running. However, he was aware that it might be something they wanted to put into production. Consequently, he discovered the Golem package, which appears to be a handy tool for taking Shiny and developing it more rigorously for deployment to production. This has been the main focus of his recent work with R.\nI’ve been using Quarto and R for my blog and some small tasks lately. I’ve written several posts about pre-commit for linting code, which is really useful. I’m overdue writing one on how to use the lintr package and should find time to investigate the newer flint package too.\nI also had a project where the researchers used R and had a lot of code. I convinced them to organize their code into a more structured package format. I found DevTools and the usethis package to be very helpful for that. At the same time, I set up the package repository to use linter to ensure that all coding standards were followed in case they ever decided to release it to CRAN.\nI feel like a jack of all trades because I use Python, R, and a bit of Bash. I know a little about everything, but I’m not an expert at any one thing!\nHow do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 75,492 members in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/elevate-your-r-community-with-the-2024-rugs-grant-program/index.html",
    "href": "posts/elevate-your-r-community-with-the-2024-rugs-grant-program/index.html",
    "title": "Elevate Your R Community with the 2024 RUGS Grant Program",
    "section": "",
    "text": "The R Consortium is rolling out its 2024 R User Groups (RUGS) Grant Program, and it’s an opportunity you don’t want to miss. The program, which aims to foster vibrant R communities worldwide, is in full swing, and we are eagerly awaiting your application!\n\nApply here!\n\n\nWhy Apply and… For What?\nUser Group Grants: Boost engagement and initiate user-focused activities.\nConference Grants: Support for R-related events, either hosting or attending.\nSpecial Projects Grants: Kickstart innovative projects with the potential to impact the R community.\nWith 74 active groups and a thriving community of over 67,000 members, the RUGS network is a hub of innovation and knowledge sharing. Your participation could be the next milestone in this growth journey.\nExamples of some recent R Consortium sponsored RUGS activities:\n\nThe Cleveland R User Group’s Journey Through Pandemic Adaptations and Baseball Analytics\nR-Ladies Goiânia: Promoting Diversity and Inclusion in Local R Community\n\n\n\nKey Information\nApplication Deadline: September 30th, 2024. Don’t delay!\nEligibility: Open to initiatives aimed at community building, not software development (for that, see ISC Grant Program).\nBe part of shaping the future of R. Visit here for more details and to apply. Your contribution matters to the global R narrative. Apply now, and let’s grow together!\n\nFor details and to apply, visit here."
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "",
    "text": "Guest blog post contributed by Jasmine Daly, Principal Consultant & Founder of Daly Analytics, maintainer of 2 CRAN packages, and Beni Altmann, Student, assistant member of the CRAN Team working on CRAN submissions"
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#making-the-cran-submission-process-easy",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#making-the-cran-submission-process-easy",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "Making the CRAN Submission Process Easy",
    "text": "Making the CRAN Submission Process Easy\nAs we close out the first phase of the project - Improving the Skills of R Package Maintainers, also known as The CRAN Cookbook - we’re reflecting on its journey and impact. This initiative began with an ambitious but focused goal: to create a user-friendly, technical cookbook-style guide to help new R programmers and package maintainers navigate the CRAN submission process. The ultimate vision was to streamline this process, reduce common frustrations, and elevate the quality of open-source contributions to the R ecosystem.\nThe CRAN Cookbook aimed to provide clear, explainable solutions for frequent errors while supporting maintainers in producing high-quality software.\nWe’ve come a long way in a short time. We’re excited to share what we’ve accomplished!\nIf you want to help contribute, please see: https://github.com/r-devel/cran-cookbook/wiki/Contributors-Guide"
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#overview-of-what-we-have-currently-published",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#overview-of-what-we-have-currently-published",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "Overview of what we have currently published",
    "text": "Overview of what we have currently published\nAfter nearly 6 months of collaboration, we’ve published a comprehensive cookbook addressing the most common issues encountered during the CRAN submissions. Our work benefited greatly from Beni Altmann’s deep experience as a member of the CRAN team, where he has spent a lot of time interfacing with maintainers.\nThe CRAN Cookbook includes:\n\nGeneral Issues: Best practices and tips guidance for CRAN submissions.\nManuals & Documentation Issues: Tips on creating clear, accurate, and compliant help documentation files, using roxygen2, and creating examples, vignettes, and tests..\nCode Issues: Addressing common challenges in writing functions, managing file and directory operations, and handling installation and compute resources.\nDESCRIPTION File Issues: Essential guidance for crafting a compliant and informative DESCRIPTION file."
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#how-its-getting-used-by-the-cran-team",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#how-its-getting-used-by-the-cran-team",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "How it’s getting used by the CRAN Team",
    "text": "How it’s getting used by the CRAN Team\nThe CRAN team has already integrated the cookbook into their workflows. When encountering these common issues during package reviews, they refer maintainers to specific sections of the cookbook in their email correspondence. This approach not only expedites resolution but also empowers maintainers to tackle future challenges independently. It’s been gratifying to see the cookbook become a practical tool for fostering a more efficient submission process."
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#what-we-learned-or-impressions-of-working-on-this-project",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#what-we-learned-or-impressions-of-working-on-this-project",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "What we learned or impressions of working on this project",
    "text": "What we learned or impressions of working on this project\nJasmine: “I’m grateful for the opportunity to contribute a valuable resource to the R community in the form of new, user-friendly technical documentation. I deeply valued the experience of collaborating with my co-writer, Beni and working together to hopefully improve the CRAN submission process.”\nBeni: “We, the CRAN team, see the same kind of issues for most packages. The cookbook style resource fitted perfectly for this project. It allowed for a jigsaw-like approach, writing piece after piece and setting it all together in the end. I think we created a great resource for future CRAN package maintainers.”"
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#plausible-analytics-and-measuring-success-of-the-cran-cookbook",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#plausible-analytics-and-measuring-success-of-the-cran-cookbook",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "Plausible analytics and measuring success of the CRAN Cookbook",
    "text": "Plausible analytics and measuring success of the CRAN Cookbook\nWe’ve implemented Plausible Analytics to track engagement with the cookbook. By monitoring usage and feedback, we’ll continue refining the resource to better serve the R community."
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#thank-yous",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#thank-yous",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "Thank yous",
    "text": "Thank yous\nTo everyone who supported this project, thank you for helping us bring this vision to life. Whether you’re a new maintainer, a seasoned contributor, or part of the CRAN team, we hope the CRAN Cookbook proves to be an indispensable resource. Here’s to smoother submissions and stronger software in the R ecosystem!\nA heartfelt thank you to our community contributors, the steering committee, and the R Repositories Working Group. Your insights and feedback have been invaluable in shaping the CRAN Cookbook. This project would not have been possible without your support and collaboration!"
  },
  {
    "objectID": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#community-contributions-process",
    "href": "posts/user-friendly-technical-cookbook-style-cran-guide-for-new-r-programmers-ready/index.html#community-contributions-process",
    "title": "User-Friendly Technical Cookbook-Style CRAN Guide for New R Programmers Ready",
    "section": "Community contributions process",
    "text": "Community contributions process\nWe can use your help! We also developed a contributors guide to encourage community members to expand and improve the cookbook with their insights and experiences for often seen submission errors."
  },
  {
    "objectID": "posts/navigating-economic-challenges-through-community-the-journey-of-r-ladies-buenos-aires/index.html",
    "href": "posts/navigating-economic-challenges-through-community-the-journey-of-r-ladies-buenos-aires/index.html",
    "title": "Navigating Economic Challenges Through Community: The Journey of R-Ladies Buenos Aires",
    "section": "",
    "text": "Betsabe Cohen, organizer of R-Ladies Buenos Aires, recently spoke with the R Consortium about the growth and diversity of the R community in Argentina and its role in navigating the country’s economic challenges. Betsy shared insights into the group’s activities, including hosting workshops on tools like Quarto and plans to launch a Shiny-focused reading club. She also highlighted the importance of fostering inclusion and collaboration within the community locally and across Latin America.\nPlease share your background and involvement with the RUGS group.\nMy background is in sociology. I’m originally from Buenos Aires and have worked in the field for about 15 years. I became involved with the R community through some colleagues and a bit by chance. I discovered R when a friend, who was starting to use it, introduced me to it. She was already connected with the R community, specifically R-Ladies. A few years later, I became an organizer for the group.\nCan you share what the R community is like in Buenos Aires?\nR is primarily used in academia but is also prevalent in industry. The R community is very diverse, consisting of people from various backgrounds. We have industry professionals, researchers, and individuals from the government and non-profit sectors. I started using R in a non-profit environment. Our community includes a wide range of skill levels, from beginners to intermediate and advanced users, which adds to its diversity.\nData analysis has become a valuable skill in the job market. Argentina is experiencing a job crisis, making it crucial for people to access information. However, because much of this information is often in English, we aim to generate materials in Spanish and share them with our community, as linguistic barriers can be restrictive.\nCommunities like our group here in Buenos Aires are essential for people to access this information. However, it can be challenging for us as organizers, especially since we also navigate this crisis ourselves. Many of us juggle multiple jobs, making it challenging to find the time to teach and share information with others.\nBalancing these responsibilities can feel like double work, and that’s what we’re currently facing.\nYou had a Meetup on “Turn your data into visual stories with Quarto.” Can you share more about the topic covered? Why this topic?\nWe chose a topic beneficial for people searching for jobs related to data communication, visualization, and scientific reporting. Quarto is an excellent tool for this purpose. The R community and the RUGS have embraced tools that enhance communication, making it more manageable within the scientific community and the business environment. Quarto allows individuals to continue using R while also adapting to various workplaces.\nBy sharing Quarto with others and demonstrating its capabilities, we aim to help people communicate effectively. Since R is primarily taught in universities but needs a proper communication tool, this was a significant factor in our decision to support and assist others.\nAdditionally, I have some exciting news: we are planning to start a reading club focused on mastering Shiny for next year.\nWe are still preparing it. Shiny is widely used to make data accessible to users, which is part of our decision-making to support people during this challenging time. Reading this book alone is not the same as sharing the experience with others. There is significant value in sharing information and being part of a network, as it fosters community and support among us.\nDo you host your events in person or online? What kind of response do you get for each type of event?\nWe host both in-person and online events. Sometimes, we can hold events in both formats, but other times, we can only offer them online because the conditions are not ideal for a physical gathering. We record the live events and upload them to our YouTube channel.\nFor example, we organized a large event last year that attracted 80 university students. The venue was so full that no one else could enter, and the event generated significant engagement and views on YouTube afterwards.\nSome subjects are particularly appealing. Our goal is to reach as many people as possible, but I think a key point here is that inclusion is tied not only to gender but also to the economic dimensions of the issue.\nThe demand for the recordings we upload to YouTube and access to our meetings is influenced by the employment and economic crises we face. This challenge concerns the material aspects, such as accessing high-speed internet or owning a computer, and the time required to participate in these events. For instance, many people may work night shifts, making it difficult for them to attend events.\nWe typically schedule our meetings outside of working hours. The standard work schedule in Argentina runs from 9 AM to 6 PM, so we aim to hold our events around 7 PM to accommodate everyone. However, some individuals still need help to attend because they may have two jobs, leading them to plan to watch the YouTube recordings over the weekend.\nThis situation illustrates our understanding of inclusion; it is not solely about gender—thankfully, our country is making strides in that area—but also about addressing economic challenges.\nDo you recommend any techniques for planning for or during the event? (Github, Zoom, other.) Can these techniques be used to make your group more inclusive to people unable to attend physical events in the future?\nWe encourage working in pairs when conducting activities in a live classroom, mainly because only some have a computer. It creates an excellent dynamic for us, especially when participants have different skill levels. In our recent sessions, most people had their computers, but that was only sometimes the case. We use Post-it notes to address problems on individual computers. When everything is running smoothly, we engage in live coding, and participants can simply post their notes when they encounter issues.\nWe organize our roles carefully to ensure efficiency. One of us may demonstrate the general code while live coding, while other organizers take on different responsibilities. Dividing the roles helps us focus on smaller tasks and work together effectively.\nThis approach applies not only in-person but also during our Zoom meetings. However, people seem less open to sharing their stories virtually. There’s something unique about face-to-face interactions compared to being online. After COVID-19, many people grew weary of Zoom meetings, but there were still benefits to being connected virtually. I participated in events I would never have had the chance to join otherwise.\nThere’s something unique about sharing space. I think the Post-it notes work well for us, along with consistently sharing information and being well-prepared for the day.\nWhen someone is going to present live coding, they feel more comfortable knowing that they don’t have to worry about other tasks. We always make it a point to take care of everything by dividing responsibilities and staying organized beforehand.\nWe prepare everything we need for the day, from coffee and cookies to all the necessary materials. Someone is clearly assigned to each task, and I believe that’s the best approach. At least it works great for us!\nCan you share more about the journey of R-Ladies Buenos Aires?\nIt has been a long journey for us in Buenos Aires. Buenos Aires was Argentina’s first chapter, and many other chapters of our Slack account opened up. We still share the same main Slack, R Ladies Buenos Aires, along with the other provinces that are very important to us.\nI had the opportunity to travel to the country’s south to meet some of the organizers of R Ladies Bariloche, where we have another chapter. I also participated in events like LatinR, bringing chapters across Latin America together. That experience was amazing!\nI went to Uruguay last year, and it was fantastic to see so many R users from diverse backgrounds. It’s very exciting! The R User Groups are a great way to connect, and I always recommend them to others. People tend to respond very positively, and I am so proud to be part of this community.\nYou can reach out to R-Ladies Buenos Aires through the following:\nInstagram:https://www.instagram.com/rladiesba/?hl=en\nFacebook: https://www.facebook.com/RladiesBA/\nWebsite: https://rladiesba.netlify.app/\nX: https://twitter.com/rladiesba?lang=en"
  },
  {
    "objectID": "posts/navigating-economic-challenges-through-community-the-journey-of-r-ladies-buenos-aires/index.html#how-do-i-build-an-r-user-group",
    "href": "posts/navigating-economic-challenges-through-community-the-journey-of-r-ladies-buenos-aires/index.html#how-do-i-build-an-r-user-group",
    "title": "Navigating Economic Challenges Through Community: The Journey of R-Ladies Buenos Aires",
    "section": "How do I Build an R User Group?",
    "text": "How do I Build an R User Group?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nhttps://r-consortium.org/all-projects/rugsprogram.html"
  },
  {
    "objectID": "posts/bridging-gaps-tunis-r-user-groups-journey-in-democratizing-r-in-bioinformatics/index.html",
    "href": "posts/bridging-gaps-tunis-r-user-groups-journey-in-democratizing-r-in-bioinformatics/index.html",
    "title": "Bridging Gaps: Tunis R User Group’s Journey in Democratizing R in Bioinformatics",
    "section": "",
    "text": "Last year, the R Consortium had a conversation with Amal Tlili, the co-organizer of the Tunis R User Group, regarding the Use of R for Marketing and CRM in Tunisia. This year, Amal Boukteb and Hedia Tnani spoke to the R Consortium about the use of R for bioinformatics research in Tunisia and discussed the group’s efforts to bridge the gap between academia and industry. The Tunis R User Group hosts engaging virtual events to connect R enthusiasts across the MENA region and Worldwide. Their events promote the use of R and foster knowledge and skill development in data science and bioinformatics.\nHédia and Amal met during the Bioinformatics and Genome Analyses course at Pasteur Institute of Tunis in 2017. Amal joined Tunis R User Group as a Bioinformatics Event Organizer\nin 2023. With a deep commitment to inclusivity and empowerment, they’ve dedicated themselves to breaking down barriers faced by women and individuals from low-income countries when accessing education in these cutting-edge areas. By organizing workshops tailored to these communities, they aim to provide valuable skills and knowledge and foster a more diverse and equitable future in the bioinformatics field.\nPlease share about your background and involvement with the RUGS group.\nAmal: We are biologists, and our academic curriculum did not include any programming courses. However, with the advancement of sequencing technologies, biologists are now facing the challenge of analyzing vast amounts of genomic data. This is a significant challenge for us. For my PhD project, I was involved in RNA-Seq and RAD-Seq projects. To overcome this challenge, I attended a course on analyzing genomic data using Unix, where I met Hedia for the first time. Additionally, in the framework of my thesis project,  I had the opportunity to visit the Plant Immunity Group at RIKEN Yokohama in Japan for an internship. While there, I learned a lot from the talented scientists and their exciting research in bioinformatics.\nWhen it comes to learning R programming for biologists, no specific courses are available. The only courses that exist are general ones. So, to overcome this gap, I started learning by myself. I attempted to understand the concepts by reading through error messages, package tutorials, and watching YouTube tutorials.\nWe realized we faced the same challenge after discussing this issue with our colleagues. We have genomic data that we need to analyze, but the available courses are located outside of Tunisia, primarily in Europe. Unfortunately, we lack the financial support to attend these courses. Additionally, obtaining a student visa for a temporary stay to attend such courses is a complex process. This challenge is not only unique to Tunisians but also a struggle for Africans and many biologists from middle and low-income countries. Our Tunis R user group aims to help others overcome this challenge and bridge this gap.\nHedia: I studied agronomy first and then pursued a master’s degree in plant breeding from Spain. Later, I completed my PhD in genetics. I did not know programming or R during my studies in Tunisia and Spain. However, when I started my postdoc at the International Rice Research Institute (IRRI) in the Philippines, especially when I first faced analyzing genomics data, I felt out of my depth. With no programming experience, learning R seemed like a mountain too steep to climb. This is a familiar story for many biologists transitioning from wet to dry labs, where code replaces beakers. Despite the daunting challenge, I persevered and taught myself R; eventually, it became an invaluable tool for my research. I’m also thankful to the great mentors I had at IRRI who helped me accelerate my learning curve. My journey wasn’t easy, but it was incredibly rewarding.\nLearning bioinformatics can be challenging, especially in regions like Tunisia where resources are scarce and training abroad is so costly. Moreover, the need for bioinformatics training to solve biological problems has left many highly skilled biologists struggling to find a job in their field. Recognizing these obstacles, we formed a supportive community to facilitate collective learning and growth in bioinformatics and related fields such as data science and artificial intelligence.\nOur community is a friendly, inclusive, and welcoming space for anyone passionate about bioinformatics, data science, artificial intelligence, and beyond. We’re all about growing together and learning from each other in a supportive environment. Whether you’re just starting out or have lots of experience, we encourage you to dive in, ask questions, and share your insights. We all rise by lifting others. Don’t worry about asking the “wrong” question. Every question is a chance to understand and learn something new. Come join us and be part of our journey of discovery and growth. We can’t wait to learn with you!\nCan you share what the R community is like in Tunisia?\nHedia: In Tunisia, programming is mainly used in the industry, but it is not widely taught in the curriculum for biologists. This creates a gap between what is taught in the academic courses and what is required in the industry. As a result, individuals are expected to possess programming skills when they work in the industry. Still, they may not have been able to learn programming during their academic courses. This gap must be addressed to better prepare individuals for the job market.\nCan you please update us about the group’s recent activities?\nAmal: First, it is important to mention that Arabic is our native language in Tunisia. However, French is the predominant teaching language in many subjects, including biology and informatics. Despite this, we have decided to conduct our workshop in English for the Tunis user group for two main reasons. Firstly, we aim to bridge the gap between the academic skills acquired in French and English resources. Secondly, by using English as our teaching language, we can reach a broader audience of scientists who share our needs.\nWe decided to allow us the flexibility to choose speakers without language barriers. Our main goal is to reach a broad audience worldwide. During our workshop, we noticed participants worldwide, not just Tunisians. This is very important to us. We conducted workshops for biologists, such as the Genome-Wide Association Studies (GWAS) workshop, and we already have 5k views on our YouTube channel. It is interesting to see that people are very interested in our workshops. We also had the opportunity to collaborate with highly qualified researchers in their respective fields. Within our community, we were privileged to learn from Pr. Emerson Del Ponte generously shared his expertise using R for Plant Disease Epidemiology.\nWe aim not only to cover biological subjects but also those related to artificial intelligence. Recently, we conducted two successful workshops on Building a Chatbot with OpenAI, Shiny and R, and Bioinformatics Analysis using Chatlize and ChatGPT. We strive to have a balance between biological and AI-related subjects to make the experience easier for our participants with the help of artificial intelligence.\nWhat trends do you currently see in R language?\nHedia: In bioinformatics, there is a growing trend towards single-cell and spatial transcriptomics. Our latest event was an introduction to single-cell RNA-seq analysis. Additionally, packages based on OpenAI API are increasingly being used. For instance, many of those packages can be used by people who lack coding skills. This is particularly helpful because not all biologists possess coding skills, and it makes their work easier. Another trend we have noticed is using Quarto instead of R Markdown. Shiny is also gaining popularity in this field.\nWe have been receiving a lot of queries about bioinformatics workshops lately, particularly because they offer a diverse range of events, such as user groups. However, it can be challenging to find a specific topic. For instance, some R user groups may only hold one or two events yearly, whereas we host monthly bioinformatics events.\nWe value feedback from our attendees and gather suggestions from our latest events to improve our upcoming ones. Our events are designed to stay current with trends in the industry, and we often invite guest speakers to talk about relevant topics. For instance, during one of our workshops about Building a Chatbot with OpenAI, we had 200 participants whom we taught how to use R and create their chatbots. We learn from our experiences, and when we notice an interest in a particular area, we look to bring in speakers to teach on that subject.\nAny techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?\nHedia: Our organization had a sponsorship for our Zoom account, an important tool for hosting events. One of the features that we utilize is the captions option, which allows participants from all over the world to have captions in their language and helps them follow the workshop. This is particularly helpful for those who may have difficulty understanding English. We are very grateful to Appsilon for their sponsorship of our Zoom account.\nAmal: Thanks to Appsilon’s sponsorship, we have accepted more participants for our events. Previously, the number of participants was limited due to the capacity of our Zoom account. However, with this sponsorship, we can now handle up to 100 participants per event. This has made it easier for us to accept more subscribers and host successful workshops. We recently had an event with over 200 participants, which was a great success.\nHedia: We provide teaching materials for our speaker sessions on GitHub. You can find all the materials on YouTube and use them to reproduce what the speaker did during their session. We are always open to questions, especially if you encounter bugs while trying to reproduce the speaker’s work. Recently, we received an email from a participant experiencing a bug, and we had a great time figuring it out together. If you have any questions or problems, feel free to ask us for help, and we’ll do our best to assist you.\nAre your events online, in-person, or hybrid?\nHedia: We are considering organizing hybrid events in the future, and we are searching for funding. We only have sponsorship for our Zoom, so we need additional funds to make this happen. We plan to organize events at multiple universities across the MENA region so important speakers can be followed in person and online. Amal, who is based in Tunis, has been in contact with many universities and academic professionals in the area. We’re currently exploring the best ways to make these hybrid events a reality, ensuring a seamless and enriching experience for everyone involved. Our goal is to make these events as engaging and accessible as possible, fostering a true sense of community.\nWe want to organize events for online events and to provide something valuable to our community. When we meet in person, we can better understand their needs and challenges, which helps us to build and organize workshops that cater to their specific needs. Recently, Amal mentioned that some courses are not free in Tunisia, which can be a barrier for some people. Therefore, we aim to organize a free hybrid event for everyone who wants to join and learn with us. We hope to get funding for this initiative to provide this opportunity to all.\nPlease share about a project you are currently working on or have worked on in the past using the R language. Goal/reason, result, anything interesting, especially related to the industry you work in?\nAmal: For my PhD project, I conducted research on population genomics and RNA-seq to investigate the interaction between plants and parasitic plants. Our work shed light on the genetic diversity of Orobanche foetida, a parasitic plant posing a significant threat to faba beans in Tunisia. Additionally, through RNA-seq analysis, we identified a potential target gene for developing resistant varieties of faba beans against this parasitic plant. Furthermore, I recently completed a bachelor’s degree in biostatistics, specifically focusing on Aphid diversity in Tunisia.\nDuring my academic journey, R has been my primary tool for conducting comprehensive data analysis across all my research projects. After finishing my PhD, I aim to develop my expertise in bioinformatics further, specifically focusing on wheat genomics.\nHedia: I primarily use R as the main software for all my research projects. I am currently working on maintaining and improving a package called qsvaR. qsvaR is a tool that generates quality surrogate variable analysis for degradation correction in RNA cells. It contains functions that help remove the degradation effect in post-mortem brain tissue, making it a useful tool for generating basic data. We are currently working on a publication based on this work."
  },
  {
    "objectID": "posts/bridging-gaps-tunis-r-user-groups-journey-in-democratizing-r-in-bioinformatics/index.html#how-do-i-join",
    "href": "posts/bridging-gaps-tunis-r-user-groups-journey-in-democratizing-r-in-bioinformatics/index.html#how-do-i-join",
    "title": "Bridging Gaps: Tunis R User Group’s Journey in Democratizing R in Bioinformatics",
    "section": "How do I Join?",
    "text": "How do I Join?\nR Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 68,000 members in 33 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.\nLearn more"
  },
  {
    "objectID": "posts/decade-of-data-celebrating-10-years-of-innovation-at-the-new-york-r-conference/index.html",
    "href": "posts/decade-of-data-celebrating-10-years-of-innovation-at-the-new-york-r-conference/index.html",
    "title": "Decade of Data: Celebrating 10 Years of Innovation at the New York R Conference",
    "section": "",
    "text": "Come celebrate 10 YEARS of the New York R Conference! This year’s conference takes place May 16th & 17th with workshops May 15th. We are taking a trip down memory lane and looking back over the past nine years. Come listen to some of the all-time greats who will be gracing our stage once again, and we’re also adding some fresh and exciting new voices to the mix!\nThis year’s conference features an a-list lineup of speakers who will be sharing their expertise on a wide range of topics, including data visualization, machine learning, programming, AI and more.\nSpeakers include:\n\nHadley Wickham – Posit\nEmily Zabor – Cleveland Clinic\nAndrew Gelman – Columbia University\nZhangjun Zhou – Macy’s\nWes McKinney – Posit\nHilary Mason – Hidden Door\n\nAnd more will be announced soon!\nThere are also interactive workshops available to sharpen your skills and learn new techniques.\nWorkshops include:\n\nMachine Learning in R with Max Kuhn \nCausal Inference in R with Malcolm Barrett & Lucy D’Agostino McGowan\nExploratory Data Analysis with the Tidyverse with David Robinson\n\nUse promo code RSTATS20 for 20% off conference & workshop tickets (in-person & virtual). To secure your spot and learn more about the speaker lineup and workshops, visit rstats.ai/nyr. \nAlso, follow @rstatsai on Twitter to stay up to date with all conference details. \nBe a part of this extraordinary opportunity to acquire new skills, foster growth, and connect with the data science community."
  },
  {
    "objectID": "webinars/r-insurance-series.html#summary",
    "href": "webinars/r-insurance-series.html#summary",
    "title": "R/Insurance Series: For Everyone in Insurance or Actuarial Science",
    "section": "Summary",
    "text": "Summary\nThese four webinars focused on insurance and actuarial science. The webinars were led by two experts in the field, Georgios Bakoloukas, Head Model Development and Analytics at Swiss Re, and Benedikt Schamberger, Head Atelier Technology & AI Consulting at Swiss Re.\nThese sessions offered a hands-on exploration of the transition from Excel to basic R, highlighting the benefits of working with R and one possible way to straddle across Excel and R. The subsequent webinars then moved to production-level R, and ultimately to high-performance R applications.\nThe webinars were tailored to be accessible to all, requiring no previous experience with the R programming language or specialized knowledge in insurance or actuarial science. Anyone with basic spreadsheet experience or who is considering applying for a bank loan has the necessary background to benefit from these webinars.\n\nFrom Excel to Programming in R\nSpeaker: Georgios Bakoloukas, Head Model Development & Analytics, Group Risk Management, Swiss Re\n\n\nQuick summary:\nThis video provided an in-depth exploration into the enduring relevance of Excel in the workplace while also emphasizing the benefits of learning to code for increased flexibility and resilience. It highlighted the common working patterns shared between Excel and R, demonstrating how transitioning from traditional spreadsheet computing to best-practice programming can be highly beneficial.\nThe webinar featured a straightforward, specific example from the insurance industry to illustrate the advantages of using the R programming language. It also presented a practical approach for integrating the thought processes and methodologies of both Excel and R, showcasing how professionals can effectively straddle these two powerful tools in their work.\n\n\n\n\nFrom programming in R to putting R into production\nSpeaker: Georgios Bakoloukas, Head Model Development & Analytics, Group Risk Management, Swiss Re\n\n\nQuick summary:\nWe could solve problems using coding, but how could we help others solve the same problem in the future? Sharing data and solutions was critical for real-world insurance professionals and actuarial scientists.\nContinuing the example from the first webinar, Georgios illustrated ways to document and test the solution and made it available to others using R’s frameworks for packaging, Web API creation, and graphical user interface generation (Shiny).\n\n\n\n\nR performance culture\nSpeaker: Benedikt Schamberger, Head Atelier Technology & AI Consulting, Swiss Re\n\n\nQuick summary:\nPremature optimization was the root of all evil. But there were occasions when we needed to improve the performance of critical code. Benedikt covered how performance fit into R’s design, what tools were available to tune it, and examples of what other aspects should be considered beyond pure runtime.\n\n\n\n\nHigh performance programming in R\nSpeaker: Benedikt Schamberger, Head Atelier Technology & AI Consulting, Swiss Re\n\n\nQuick summary:\nIn this webinar, Benedikt discussed how comma-separated values (CSV) files were commonly used when working with data files, as they were easy to read for humans and supported by tools like Excel or R. However, these files had a downside in terms of performance and file size. To address this, the industry developed binary formats that were more efficient. Benedikt focused on the Arrow R package and the Parquet file format and how they could help save time and disk space."
  },
  {
    "objectID": "webinars/r-insurance-series.html#speakers",
    "href": "webinars/r-insurance-series.html#speakers",
    "title": "R/Insurance Series: For Everyone in Insurance or Actuarial Science",
    "section": "Speakers",
    "text": "Speakers\n\n\nGeorgios Bakoloukas, Head Model Development & Analytics, Group Risk Management, Swiss Re\nGeorgios’ team enables actuarial teams across the group to adopt best-practice programming and data science skills in daily work. Georgios is a Fellow of the Institute of Actuaries (IFoA) and Chair of IFoAs’ Programming for Actuarial Work Working Party.\n\n\n\nBenedikt Schamberger, Head Atelier Technology & AI Consulting, Swiss Re\nBenedikt recently joined the Model Development & Analytics team as a Senior Data Science Actuary. Previously, he worked for several years in Swiss Re’s Quantitative Financial Risk Management, validating financial models and risk aggregation methodologies. He supports the Atelier and R programming communities with questions surrounding infrastructure and other everyday challenges. He has an academic background in financial and actuarial mathematics."
  },
  {
    "objectID": "webinars/r-insurance-series.html#the-r-adoption-series",
    "href": "webinars/r-insurance-series.html#the-r-adoption-series",
    "title": "R/Insurance Series: For Everyone in Insurance or Actuarial Science",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series. If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/AdoptionOfRInJapansPharma.html#summary",
    "href": "webinars/AdoptionOfRInJapansPharma.html#summary",
    "title": "R/Adoption Series:The Adoption Of R in Japan’s Pharma Industry Confirmation",
    "section": "Summary",
    "text": "Summary\nThe Adoption of R in Japan’s Pharma Industry talk and panel discussion was led by key industry experts from the JPMA R Task Force Team. The webinar explored the usage and adoption of R in the pharmaceutical industry, specifically focusing on the findings of the JPMA Drug Evaluation Committee, R Task Force Team, and the JPMA Report. The report referenced various open source works and publications, including those from the R Consortium pilot submissions, Package Validation Hub, and webinar training."
  },
  {
    "objectID": "webinars/AdoptionOfRInJapansPharma.html#agenda",
    "href": "webinars/AdoptionOfRInJapansPharma.html#agenda",
    "title": "R/Adoption Series:The Adoption Of R in Japan’s Pharma Industry Confirmation",
    "section": "Agenda",
    "text": "Agenda\n\nGeneral Background by Rikimaru Nishimura\n\nPMDA: Highlighting the intricacies of submissions with R.\nJPMA R Task Force: Delving into past activities and shedding light on future initiatives.\n\nJPMA Survey Report by Rikimaru and Yuki Matsunaga\n\nBackground: Understanding the rationale and motivation behind the JPMA survey.\nResults: Discuss key findings and their implications for the industry.\n\nQ&A Session"
  },
  {
    "objectID": "webinars/AdoptionOfRInJapansPharma.html#speakers",
    "href": "webinars/AdoptionOfRInJapansPharma.html#speakers",
    "title": "R/Adoption Series:The Adoption Of R in Japan’s Pharma Industry Confirmation",
    "section": "Speakers",
    "text": "Speakers\n\nRikimaru Nishimura has worked as a Statistical Programmer for Janssen Pharmaceutical K.K. since February 2015. He is responsible for statistical analysis in clinical trials and e-Data submission to PMDA. Before working in the pharmaceutical industry, he has experience developing bank accounting and customer management systems in Japanese technology company. Also, he is a start-up member of the open-source software task force in Japan Pharmaceutical Manufacturers Association.\n\nYuki Matsunaga has worked as a Statistical Programmer, a Medical Scientific Expert, and a Medical Science Liaison for Novartis Pharma K.K. since April 2017. Recently, he works on new drug development and retrospective studies using medical real-world data such as electronic healthcare record and health claims data. Also, He is a member of the {admiralophtha} development team, and a start-up member of the open-source software task force in Japan Pharmaceutical Manufacturers Association."
  },
  {
    "objectID": "webinars/AdoptionOfRInJapansPharma.html#the-r-adoption-series",
    "href": "webinars/AdoptionOfRInJapansPharma.html#the-r-adoption-series",
    "title": "R/Adoption Series:The Adoption Of R in Japan’s Pharma Industry Confirmation",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a new series of webinars focused on the adoption of R.  Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series. If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/tidy-finance-webinar-series.html",
    "href": "webinars/tidy-finance-webinar-series.html",
    "title": "Tidy Finance Webinar Series",
    "section": "",
    "text": "Christoph Scheuch is an independent data science and business intelligence expert. He co-created and maintains the Tidy Finance project, a transparent, open source approach to research in financial economics. Alongside contributing to Tidy Finance, its maintainers have published in leading academic journals, including the Journal of Finance, Journal of Financial Economics, Review of Finance, and Journal of Econometrics. Christoph previously held the roles of Head of Artificial Intelligence, Director of Product, and Head of BI & Data Science at the social trading platform wikifolio.com. He was an external lecturer at the Vienna University of Economics and Business (WU), where he also obtained his PhD in finance as part of the Vienna Graduate School of Finance (VGSF)."
  },
  {
    "objectID": "webinars/tidy-finance-webinar-series.html#optimize-portfolios-using-the-markowitz-model",
    "href": "webinars/tidy-finance-webinar-series.html#optimize-portfolios-using-the-markowitz-model",
    "title": "Tidy Finance Webinar Series",
    "section": "Optimize Portfolios using the Markowitz Model",
    "text": "Optimize Portfolios using the Markowitz Model\nSeptember 4th, 2024 at 12:00 pm ET\nThis webinar introduces Modern Portfolio Theory and the importance of mean-variance analysis in finance. It covers the mathematics of portfolio optimization, expected returns, variances, and covariances. Participants will learn to construct efficient frontiers and implement the Markowitz model in R, from loading return data to optimizing portfolios and interpreting risk-return trade-offs.\nAgenda:\n\nIntroduction to modern portfolio theory\nUnderstanding the mathematics of portfolio optimization\nImplementing the Markowitz model in R"
  },
  {
    "objectID": "webinars/tidy-finance-webinar-series.html#evaluate-performance-using-the-capital-asset-pricing-model",
    "href": "webinars/tidy-finance-webinar-series.html#evaluate-performance-using-the-capital-asset-pricing-model",
    "title": "Tidy Finance Webinar Series",
    "section": "Evaluate Performance using the Capital Asset Pricing Model",
    "text": "Evaluate Performance using the Capital Asset Pricing Model\nOctober 9th, 2024 at 12:00 pm ET\nThis webinar covers the Capital Asset Pricing Model (CAPM), starting with its intuitive derivation and its importance in finance. Participants will gain an understanding of Alpha and Beta and their roles in performance assessment. The webinar also includes an overview of popular CAPM extensions. Participants will learn to calculate Alpha and Beta in R with a step-by-step guide, from loading return data to estimating CAPM and interpreting the estimation results.\nAgenda:\n\nIntroduction to the CAPM\nUnderstanding Alpha and Beta\nCalculating Alpha and Beta in R"
  },
  {
    "objectID": "webinars/tidy-finance-webinar-series.html#analyze-companies-using-financial-ratios",
    "href": "webinars/tidy-finance-webinar-series.html#analyze-companies-using-financial-ratios",
    "title": "Tidy Finance Webinar Series",
    "section": "Analyze Companies using Financial Ratios",
    "text": "Analyze Companies using Financial Ratios\nNovember 6th, 2024 at 12:00 pm ET\nThis webinar provides an overview of financial ratios and their importance in financial analysis. It covers categories such as liquidity, profitability, leverage, and efficiency. Participants will learn about financial statements, including the balance sheet, income statement, statement of cash flows, and statement of shareholders’ equity, with real-world examples. The webinar includes a step-by-step guide on calculating and interpreting financial ratios in R, from loading financial statement data to computing and interpreting key ratios.\nAgenda:\n\nIntroduction to financial ratios\nUnderstanding financial statements\nCalculating and interpreting financial ratios in R"
  },
  {
    "objectID": "webinars/tidy-finance-webinar-series.html#value-companies-using-discounted-cash-flow-analysis",
    "href": "webinars/tidy-finance-webinar-series.html#value-companies-using-discounted-cash-flow-analysis",
    "title": "Tidy Finance Webinar Series",
    "section": "Value Companies using Discounted Cash Flow Analysis",
    "text": "Value Companies using Discounted Cash Flow Analysis\nDecember 4th, 2024 at 12:00 pm ET\nSummary: This webinar provides an overview of company valuation methods with a focus on discounted cash flow (DFC) analysis. Participants will gain an understanding of DCF analysis and its components: forecasted cash flows, terminal value, and discount rate. The webinar includes steps to perform a DCF analysis and a guide to implementing DCF in R, from loading financial statement data to executing the analysis. The webinar concludes with interpreting the valuation results, offering practical insights into company valuation techniques.\nAgenda:\n\nIntroduction to company valuation\nUnderstanding DCF\nImplementing DCF in R"
  },
  {
    "objectID": "webinars/rix-reproducible-data-science-environments-with-nix.html#date-and-time-march-13-2025-1pm-eastern-time",
    "href": "webinars/rix-reproducible-data-science-environments-with-nix.html#date-and-time-march-13-2025-1pm-eastern-time",
    "title": "Rix: reproducible data science environments with Nix",
    "section": "Date and time: March 13, 2025, 1pm Eastern time",
    "text": "Date and time: March 13, 2025, 1pm Eastern time"
  },
  {
    "objectID": "webinars/rix-reproducible-data-science-environments-with-nix.html#register-here",
    "href": "webinars/rix-reproducible-data-science-environments-with-nix.html#register-here",
    "title": "Rix: reproducible data science environments with Nix",
    "section": "Register here!",
    "text": "Register here!\nReproducibility is critical for modern research, ensuring that results can be consistently replicated and verified. In this one-hour presentation, Bruno Rodrigues introduces Nix, a package manager designed for reproducible builds. Unlike other solutions, Nix ensures that R packages, R itself, and system-level dependencies are all correctly versioned. It can even replace containerization tools like Docker, working seamlessly on any operating system and CI/CD platform. To help beginners get started, Bruno developed an R package called {rix}, which he will demonstrate."
  },
  {
    "objectID": "webinars/rix-reproducible-data-science-environments-with-nix.html#speaker",
    "href": "webinars/rix-reproducible-data-science-environments-with-nix.html#speaker",
    "title": "Rix: reproducible data science environments with Nix",
    "section": "Speaker",
    "text": "Speaker\n\nBruno Rodrigues, Head of Stats and Data Strategy Departments, Ministry of Research and Higher Education, Luxemburg\n\nBruno is an experienced Data Scientist with demonstrated programming, advising and teaching skills. He uses machine learning and econometrics to solve complex problems.\nBruno holds a PhD in applied Economics from the University of Strasbourg."
  },
  {
    "objectID": "webinars/visualizing-survival-data-with-the-ggsurvfit-r-package.html",
    "href": "webinars/visualizing-survival-data-with-the-ggsurvfit-r-package.html",
    "title": "R/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package",
    "section": "",
    "text": "This webinar focused on the {ggsurvfit} R package, a tool designed to simplify the creation of time-to-event or survival analysis summary figures using {ggplot2}. It emphasized the package’s capability to produce high-quality, publication-ready Kaplan-Meier plots and other survival analysis figures with ease and efficiency. Overall, the webinar promised to be an informative session for statisticians, data analysts, and researchers interested in survival analysis, offering insights into how {ggsurvfit} could enhance their data visualization capabilities in R."
  },
  {
    "objectID": "webinars/visualizing-survival-data-with-the-ggsurvfit-r-package.html#speaker",
    "href": "webinars/visualizing-survival-data-with-the-ggsurvfit-r-package.html#speaker",
    "title": "R/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package",
    "section": "Speaker",
    "text": "Speaker\n\nDaniel D. Sjoberg (he/him) is a Software Engineer at Genentech. Previously, he was a Lead Data Science Manager at the Prostate Cancer Clinical Trials Consortium and a Senior Biostatistician at Memorial Sloan Kettering Cancer Center in New York City. He enjoys R package development, creating many packages available on CRAN, R-Universe, and GitHub. His research interests include adaptive methods in clinical trials, precision medicine, and predictive modeling. Daniel is the winner of the 2021 American Statistical Association (ASA) Innovation in Statistical Programming and Analytics award."
  },
  {
    "objectID": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#summary",
    "href": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#summary",
    "title": "From Vision to Action: The R Pfizer R Center of Excellence-led Journey to R Adoption",
    "section": "Summary",
    "text": "Summary\nThe webinar by the R consortium titled “From Vision to Action: The R Pfizer R Center of Excellence-led Journey to R Adoption” was not just a case study of Pfizer’s journey. It was a platform for sharing valuable insights and strategies applicable across industries and experience levels. Viewers can learn about the importance of an engaged R community and practical approaches to building and maintaining such a community within their organizations."
  },
  {
    "objectID": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#speaker",
    "href": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#speaker",
    "title": "From Vision to Action: The R Pfizer R Center of Excellence-led Journey to R Adoption",
    "section": "Speaker",
    "text": "Speaker\n\n\nNatalia Andriychuk is a Statistical Data Scientist in the R Center of Excellence SWAT (Scientific Workflows and Analytic Tools) team at Pfizer. In her current role, Natalia provides robust technical solutions to business lines across Pfizer utilizing strong technical knowledge of R, R packages, Shiny, and other associated data science and data analytics tools. She develops training on R and associated tools for Pfizer colleagues and helps to build an R community at Pfizer. Natalia is an advocate for the open source development as she passionately believes in the transformative power collaborative innovation and knowledge sharing."
  },
  {
    "objectID": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#the-r-adoption-series",
    "href": "webinars/from-vision-to-action-the-pfizer-r-center-of-excellence.html#the-r-adoption-series",
    "title": "From Vision to Action: The R Pfizer R Center of Excellence-led Journey to R Adoption",
    "section": "The R Adoption Series",
    "text": "The R Adoption Series\nThis is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series. If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org."
  },
  {
    "objectID": "webinars/webinars-auto-not-being-used.html",
    "href": "webinars/webinars-auto-not-being-used.html",
    "title": "R Consortium",
    "section": "",
    "text": "R/Adoption Series:The Adoption Of R in Japan’s Pharma Industry Confirmation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContainerization and R for Reproducibility and More\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscape the Data Dungeon: Unlock Scalable R Analytics and ML\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Vision to Action: The R Pfizer R Center of Excellence-led Journey to R Adoption\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Finance and Accessing Financial Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugmenting your Quarto website with Retrieval-Augmented Generation (RAG) using Select AI in Autonomous Database\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantification of Participation Risk using R and R Shiny\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR/Insurance Series: For Everyone in Insurance or Actuarial Science\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR/Medicine: Quarto for Reproducible Medical Manuscripts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRix: reproducible data science environments with Nix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Finance Webinar Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights from LatinR: Collaboration and Innovation in Data Science Webinar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR/Medicine Webinar Visualizing Survival Data with the {ggsurvfit} R Package\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWebinars\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "webinars/webinars.html",
    "href": "webinars/webinars.html",
    "title": "Webinars",
    "section": "",
    "text": "This is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series.  If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org\n\n\nLearn more: Rix: reproducible data science environments with Nix"
  },
  {
    "objectID": "webinars/webinars.html#the-r-adoption-series",
    "href": "webinars/webinars.html#the-r-adoption-series",
    "title": "Webinars",
    "section": "",
    "text": "This is a series of webinars focused on the adoption of R. Each session will include a case study and often include panels or discussions to enable those starting their journey to ask questions.\nR Consortium will keep this page updated with information on future webinars in the R Adoption series.  If there is some information that you are looking for specifically and you don’t see it here, feel free to email us at info@r-consortium.org\n\n\nLearn more: Rix: reproducible data science environments with Nix"
  },
  {
    "objectID": "webinars/webinars.html#archived-webinars-full-recordings-available",
    "href": "webinars/webinars.html#archived-webinars-full-recordings-available",
    "title": "Webinars",
    "section": "Archived Webinars – Full Recordings Available",
    "text": "Archived Webinars – Full Recordings Available\n\nLearn more: Quantification of participation risk using R and RShiny\n\nLearn more: Tidy Finance Webinar Series\n\nLearn more: Unlocking Insights from LatinR: Collaboration and Innovation in Data Science Webinar\n\nLearn more: Containerization and R for Reproducibility and More\n\nLearn more: R/Medicine: Quarto for Reproducible Medical Manuscripts\n\nLearn more: Tidy Finance and Accessing Financial Data\n\nLearn more: Escape the Data Dungeon: Unlock Scalable R Analytics and ML\n\nLearn more: From Vision to Action: The Pfizer R Center of Excellence-led journey to R Adoption\n\nLearn more: R/Insurance Series: For Everyone in Insurance or Actuarial Science\n\nLearn more: R/Medicine Webinar: Visualizing Survival Data with the {ggsurvfit} R Package\n\nLearn more: R/Adoption Series: The Adoption of R in Japan’s Pharma Industry Confirmation\n\nLearn more: R/Adoption Series: R and shiny in regulatory submission\n\nLearn More: R/Adoption Series: Learnings and Reflection from R Validation Case Studies\n\nJuliane Manitz, Senior Expert Biostatistician at EMD Serono\nDoug Kelkhoff, Principal Data Scientist / Statistical Software Engineer at Roche\nUday Preetham Palukuru, Standards lead at Merck & Co.\nEric Milliman, Senior Principal Data Scientist at Biogen\n\n\n\n  \n\nLearn More:  Teal: An R-Shiny Framework to Unlock the Power of Interactive Data Exploration   Chendi Liao, Principal Statistical Programmer Analyst, Roche Canada • Dony Unardi, Principal Data Scientist, Genentech\n\n\n\n  \n\nLearn More:  R Adoption Series: Introducing the Software Engineering Working Group and {mmrm}   Ben Arancibia, Data Scientist – Senior Manager At GSK • Yoni Sidi, Director of Modeling and Simulation at Sage Therapeutics\n\n\n\n\n\n  \n\nLearn More:  R/Database: Using R at Scale on Database Data  \nMark Hornick, Senior Director, Oracle Machine Learning • Sherry LaMonica, Consulting MTS, Oracle Machine Learning\n\n\n\n  \n\nLearn More:  Upskilling on Data Handling and Communication at Swiss Re  \nClaudio T. Rebelo, Model Validation Actuary for Group Risk Management at Swiss Re • Georgios Bakoloukas, Head Model Development & Analytics, Risk Management at Swiss Re • Daniela E. Damm, Divisional Operational Officer for Group Risk Management at Swiss Re\n\n\n\n  \n\nLearn More:  Using Metadata for Speedy Delivery Re  \nChristina Fillmore, Data Scientists and R developer at GSK • Yujie Zhao, is a Senior Scientist (Biostatistics) at Merck & Co., Inc • Keaven Anderson, Scientific Assistant VP of Methodology Research in the Biostatistics and Clinical Research Decision Sciences group at Merck\n\n\n\n  \n\nLearn More:  Using R in Regulatory Review  \nHye Soo Cho, Statistical Analyst, FDA/CDER • Tae Hyun (Ryan) Jung, Ph.D., Senior Statistical Reviewer in FDA/CDER/OTS/OB/DBVI • Paul Schuette, Scientific Computing Coordinator, FDA • Ning Leng, Director, Product Development Data Sciences, Roche • Coline Zeballos, R Strategy Lead, Roche\n\n\n\n  \n\nLearn More:  Speaking Different Languages  \nMichael Rimler, Head of Technical Excellence and Innovation at GlaxoSmithKline • Mike Stackhouse, Chief Innovation Officer at Atorus\n\n\n\n  \n\nLearn More:  Table Creation in R  \nGabriel Becker, Statistical Computing Consultant\n\n\n\n  \n\nLearn More:  R Management at Roche  \nKieran Martin, R Enablement Lead: PD Data Sciences at Roche • Tadeusz Lewandowski, Pan-Pharma collaboration product lead at Roche • Adrian Waddell, Chief Engineer NEST Project\n\n\n\n  \n\nLearn More:  R Training Strategies at Janssen  \nPaulo R. Bargo, Ph.D., Head of R&D Data and Advanced Analytics, Ethicon • Dan Hofstaedter, is a statistical programmer within the Janssen Clinical & Statistical Programming group • Gayathri Kolandaivelu, has over 13 years of experience in the pharmaceutical industry\n\n\n\n  \n\nLearn More:  Scaling R at GSK  \nAndy Nicholls, Head of Data Science within GSK Biostatistics"
  },
  {
    "objectID": "news/events.html",
    "href": "news/events.html",
    "title": "Events",
    "section": "",
    "text": "Title\nDates\nLocation\nType\n\n\n\n\nR/Medicine Webinar - Rix: reproducible data science environments with Nix\nMar 13, 2025\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Medicine 2025\nJun 10-13, 2025\nVirtual\n\n\n\nHandshake\n\n\n\n Conference\n\n\nuseR!2025\nAug 8-10, 2025\nDurham, NC - Duke University\n\n\n\nHandshake\n\n\n\n Conference"
  },
  {
    "objectID": "news/events.html#upcoming-events",
    "href": "news/events.html#upcoming-events",
    "title": "Events",
    "section": "",
    "text": "Title\nDates\nLocation\nType\n\n\n\n\nR/Medicine Webinar - Rix: reproducible data science environments with Nix\nMar 13, 2025\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Medicine 2025\nJun 10-13, 2025\nVirtual\n\n\n\nHandshake\n\n\n\n Conference\n\n\nuseR!2025\nAug 8-10, 2025\nDurham, NC - Duke University\n\n\n\nHandshake\n\n\n\n Conference"
  },
  {
    "objectID": "news/events.html#recently-completed-events-and-webinars",
    "href": "news/events.html#recently-completed-events-and-webinars",
    "title": "Events",
    "section": "Recently Completed Events and Webinars",
    "text": "Recently Completed Events and Webinars\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nDates\nLocation\nType\n\n\n\n\nQuantification of Participation Risk using R and R Shiny\nDecember 12, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nValue Companies using Discounted Cash Flow Analysis\nDecember 4, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nLatinR 2024\nNovember 18-22, 2024\nVirtual\n\n\n\nHandshake\n\n\n\n Conference\n\n\nR/Medicine Webinar: Containerization and R for Reproducibility and More\nNovember 19, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nAnalyze Companies using Financial Ratios\nNovember 6, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\n2024 Government & Public Sector R Conference\nOctober 29-30, 2024\nWashington, DC, USA\n\n\n\nHandshake\n\n\n\n Conference\n\n\nR/Pharma 2024 with new APAC Track\nOctober 29-31, 2024\nVirtual\n\n\n\nHandshake\n\n\n\n Conference\n\n\nUnlocking Insights from LatinR: Collaboration and Innovation in Data Science\nOctober 22, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nShiny in Production 2024\nOctober 9-10, 2024\nNewcastle upon Tyne, UK\n\n\n\nHandshake\n\n\n\n Conference\n\n\nEvaluate Performance using the Capital Asset Pricing Model\nOctober 9, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nEARL 2024\nSeptember 4-5, 2024\nBrighton, UK\n\n\n\nHandshake\n\n\n\n Conference\n\n\nOptimize Portfolios using the Markowitz Model\nSeptember 4, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nuseR! 2024\nJuly 8-11, 2024\nSalzburg, Austria\n\n\n\nHandshake\n\n\n\n Conference\n\n\nposit::conf 2024\nAugust 12-14, 2024\nSeattle, WA, USA\n\n\n\nHandshake\n\n\n\n Conference\n\n\nCascadia R Conference\nJune 21-22, 2024\nSeattle, WA, USA\n\n\n\nHandshake\n\n\n\n Conference\n\n\nNew York R Conference\nMay 16-17, 2024\nNew York City, NY, USA\n\n\n\nHandshake\n\n\n\n Conference\n\n\nR/Finance 2024\nMay 17-18, 2024\nChicago, IL, USA\n\n\n\nHandshake\n\n\n\n Conference\n\n\nSatRdays London 2024\nApril 27, 2024\nLondon, UK\n\n\n\nHandshake\n\n\n\n Conference\n\n\nR/Medicine: Quarto for Reproducible Medical Manuscripts\nMarch 20, 2024\nVirtual\n\n\n\nHandshake\n\n\n\n Conference\n\n\nNew Webinar: Tidy Finance and Accessing Financial Data\nMarch 6, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nEscape the Data Dungeon: Unlock Scalable R Analytics and ML\nFebruary 27, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nFrom Vision to Action: The Pfizer R Center of Excellence-led journey to R Adoption\nFebruary 8, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Insurance Series: High performance programming in R\nJanuary 31, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nDan Sjoberg presenting on Plotting Survival with {ggsurvfit}\nJanuary 25, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Insurance Series: R performance culture\nJanuary 24, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Insurance Series: From programming in R to putting R into production\nJanuary 17, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nR/Insurance Series: From Excel to Programming in R\nJanuary 10, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar\n\n\nThe use of R in Japan’s Pharma Industry\nJanuary 8, 2024\nVirtual\n\n\n\nChalkboard User\n\n\n\n Webinar"
  },
  {
    "objectID": "news/events.html#archived-events-and-webinars",
    "href": "news/events.html#archived-events-and-webinars",
    "title": "Events",
    "section": "Archived Events and Webinars",
    "text": "Archived Events and Webinars\n\nR and shiny in regulatory submission – December, 11 2023 • Virtual\nThis series was a collaborative effort by the R consortium, PhUSE, and PSI. The FDA and industry speakers shared their unique experiences with R-based and shiny-based submissions.\nPHUSE EU Connect 2023 – Nov 5 – 8, 2023 • Birmingham, UK\nThe PHUSE EU Connect 2023 was a key event for professionals in healthcare data science.\nR/Pharma – Oct 24 – 26, 2023 • Virtual\nThe R/Pharma conference in 2023 was a specialized event focusing on the use of R in pharmaceutical development.\nR government – October 19 – 20, 2023 • Washington DC\nThe 2023 Government & Public Sector R Conference was an event dedicated to exploring the use of the R programming language in government and public sector contexts. It featured a diverse lineup of speakers and workshops, focusing on various applications of R, including data analysis, machine learning, and policy research. The conference provided a platform for professionals and enthusiasts to share insights, innovations, and experiences in applying R in governmental and public sector projects.\nLatinR 2023 – October 18 – 20, 2023 • Montevideo, Uruguay\nLatinR 2023 was a Latin American conference focusing on the use of the R programming language in research and development.\nShiny in Production – October 12 – 13, 2023 • Newcastle, UK\nThe “Shiny in Production” conference, which took place in Newcastle Upon Tyne, UK, was centered around the application of Shiny and other web-based R packages. It attracted a diverse group of participants, ranging from experienced Shiny users to novices.\nBioC Europe – September 20 – 22, 2023 • Heidelberg, Germany\nThe European Bioconductor Conference 2023 is centered on new developments in the Bioconductor project and related fields of bioinformatics and computational biology. It includes workshops and keynote presentations for knowledge sharing and collaboration.\nPosit:conf – September 17 – 20, 2023 • Chicago, IL\nPosit::conf (2023) was two days of workshops and two days of conference keynotes and talks, with endless opportunities to connect with the data science community.\nR Validation Hub Community Meeting – June 27, 2023 • Virtual\nLast year, the R validation hub initiated a three-part presentation series on “case studies.” Eight pharma companies presented their implementation of the risk assessment framework. We briefly summarize common themes and differences in the approaches. For the majority of the meeting, we want to discuss common challenges and brainstorm ideas for possible future projects by the R Validation Hub.\nR/Medicine 2023 Virtual Conference – June 5-9, 2023 • Virtual\nThe R/Medicine conference provides a forum for sharing R based tools and approaches used to analyze and gain insights from health data.\nSatRday – Hosted By Jumping Rivers – April 22, 2023 • Hosted at King’s College London, UK\nHosted at King’s College, UK, this one-day event will feature talks on all things R! SatRdays events are for everyone with an interest in R, whether you’re a seasoned pro or just getting started. Learn More\nR/Adoption Series: Learnings and Reflection from R Validation Case Studies – March 30, 2023 • Virtual\nThe R Validation Hub will review the implementation of risk-based approaches to assess R package accuracy within a validated infrastructure and present our learnings from applied case studies. The discussion reflects the thinking of the R Validation Hub working group, which is a cross-industry initiative funded by the R Consortium.\nTeal: An R-Shiny Framework to Unlock the Power of Interactive Data Exploration – Feb 23, 2023 • Virtual\nTeal is an open-source framework for building interactive data exploration applications in R. Developed at Roche, Teal allows users to quickly and easily create dynamic visualizations and tabulations of their data. It provides a range of pre-built, customizable modules and enables users to interact with their data in real time. This allows users to quickly and easily explore their data, thus enabling fast insights generation.\n{MMRM} and Software Engineering Working Group – Jan 26, 2023 • Virtual\nIn this R Adoption Series Webinar, the R Consortium invites the ASA Software Engineering Working Group ASA BIOP SWE to share their experience of how the group formed and the types of problems they are trying to solve in the Open Source for the Pharmaceutical industry.\nUsing R at Scale on Database Data – December 8, 2022 • Virtual\nIn this webinar, Mark and Sherry present on how to increase overall solution performance with R tightly integrated with Oracle databases.\nA Survey of Changes around the Tidyverse Package in R – October 28, 2022 • Virtual\nThe Osun RUG, Nigeria hosts “A Survey of Changes around the Tidyverse Package in R” with special guest, Chief Scientist at RStudio, Hadley Wickham. The core tidyverse includes the packages that is likely used in everyday data analyses.\nUpskilling on Data Handling and Communication at Swiss Re – October 27, 2022 • Virtual\nIn this session, Swiss Re team members shared their approach to upskilling for data analytics before diving into an example of how to create automated (and stunning) actuarial reports. More Information\nUsing Metadata for Speedy Delivery – September 29, 2022 • Virtual\nIn this R Adoption Series Webinar, the R Consortium invited two Pharmaceutical organizations to share their experience in leveraging metadata for automation pieces of the clinical delivery workflow. More Information\nR/Medicine Conference 2022! – August 23 – 26, 2022 • Virtual\nAnnouncing R/Medicine 2022! The conference was fully virtual from August 23 through 26 and featured two days of workshops (included with the low registration fee!) and two days of keynotes featuring JJ Allaire and Frank Harrell. Check out the R Consortium Youtube to view the talks!\nRstudio::conf 2022 – July 25-28, 2022 • Washington DC\nA conference to connect, learn and celebrate all things R and RStudio! Sharpen your skills and celebrate the R Community together with an array of workshops and an inspiring lineup of speakers.\nuserR! 2022  – June 20 – 23, 2022 • Virtual\nNow in its 18th year is the official conference of the R Project for Statistical Computing. Keynotes include Sebastian Meyer, Amanda Cox, Julia Silge, Mine Dogucu and will showcase the afrimapr project supports the development of a community of practice in Africa around map-making in R\nR Conference – June 8-10, New York\nA conference that gathers data scientists and data professionals to explore, share, and inspire ideas, and to promote the growth of open source ideals\nIDEA, The R Consortium working group on Inclusion, Diversity, Equity, and Accessibility – June 4 \nWill be holding francophone satRdays event. More information should be available on the R Consortium Blog shortly\nR/ Finance – June 3-4, Chicago\nOne of the longest-running R conferences is the primary meeting for academics and Quants using R for finance. This single-track event is the place to talk time series, stochastic modeling, and meet some legendary R developers.\nR Adoption Series: Reporting Table Creation In R: Meeting Specific Needs With a General Framework – Apr 28, 8-9:30am PDT / 11am-12:30pm EDT / 4-5:30pm BST\nGabriel Becker, Scientist in the Bioinformatics and Computational Biology department at Genentech Research.\nGabe will present the rtables package in three contexts. First, he will briefly present the package itself and how it can be used to create reporting tables, including those suitable for regulatory submissions. He will then discuss where rtables fits in the larger process of filing-table creation within Roche. Finally, he will pivot to discussing what contributed to rtables’ success as a general framework intended to meet specific needs and what lessons those in Industry can draw from its development. \nRegister here or see the webinar home page for details."
  },
  {
    "objectID": "blog/how_to_post.html",
    "href": "blog/how_to_post.html",
    "title": "R Consortium Blog",
    "section": "",
    "text": "Topic\n\n\n\n\nCloning the Repo\n\n\nInitial Setup\n\n\nInstall R on Linux\n\n\nR Packages Installation Method #1\n\n\nR Packages Installation Method #2\n\n\nInstall the Vscode extension “Quarto”\n\n\nRunning the Project in a Live Preview\n\n\nAdding a Blog post\n\n\nUploading your Post\n\n\n\n\n\n\nOn our GitHub repository, click “Code“ and then “Open with GitHub Desktop”.\n\nIn GitHub Desktop click “Clone”\n\n\n\n\n\nIn Github Desktop click on “Fetch origin” to get the most up to date blog on your local computer.\n\nIn Github Desktop click on “Open in Visual Studio Code” to start working on your blog\n\nIn VSCode click on “View” and then “Terminal”\n\nIn the Vscode Terminal make sure you are on a Linux terminal by switching to Ubuntu (WSL)\n\n\n\n\nInstall R using sudo apt-get install r-base and sudo apt-get install r-base-dev\n\n\n\n\nInstall R packages on Linux; type R in terminal and then install.packages(‘rmarkdown’)\nGGPLOT2 installation: install.packages(“ggplot2”)\ndygraphs installation: install.packages(“dygraphs”)\nhere installation: install.packages(“here”)\n\n\n\n\nUse RStudio Desktop on Windows then click on “install”\n\nSearch for the package you want for example “here” package and click “install”\n\n\n\n\n\n\nRecommended (optional) in the Quarto Extension settings enable the “Render on Save” option\n\n\n\n\n\n\nIn VSCode click on “View” and then “Command Palette”\n\nSearch for “Quarto: Preview” and click on that command\n\n\n\n\n\nIn Github desktop click “Branch” and then “New branch” make a new branch for example “Adding-new-elephant-post”\n\n\nIn VSCode add a new Folder in the “posts” directory and name it. My new post folder is “Slides-Post”\n\nAdd a new index.qmd file (Quarto Markdown File) into the new post folder.\n\nStart editing your new blog post!\n\n\n\nIn Github desktop commit your changes and a short message for your changes, for my example I am committing to the “Add-Slides” branch.\n\nOnce committed, push it to the remote Github Repository. On the bottom left is an indication of a successful commit.\n\nMake a pull request in Github desktop and then 1 reviewer should check the post and make sure it is looking good!\n\n\nClick on “Create pull request” on Github\n\nApproval Process and Timing\n\nEmail info@r-consortium.org"
  },
  {
    "objectID": "blog/how_to_post.html#cloning-the-repo",
    "href": "blog/how_to_post.html#cloning-the-repo",
    "title": "R Consortium Blog",
    "section": "",
    "text": "On our GitHub repository, click “Code“ and then “Open with GitHub Desktop”.\n\nIn GitHub Desktop click “Clone”"
  },
  {
    "objectID": "blog/how_to_post.html#initial-setup",
    "href": "blog/how_to_post.html#initial-setup",
    "title": "R Consortium Blog",
    "section": "",
    "text": "In Github Desktop click on “Fetch origin” to get the most up to date blog on your local computer.\n\nIn Github Desktop click on “Open in Visual Studio Code” to start working on your blog\n\nIn VSCode click on “View” and then “Terminal”\n\nIn the Vscode Terminal make sure you are on a Linux terminal by switching to Ubuntu (WSL)\n\n\n\n\nInstall R using sudo apt-get install r-base and sudo apt-get install r-base-dev\n\n\n\n\nInstall R packages on Linux; type R in terminal and then install.packages(‘rmarkdown’)\nGGPLOT2 installation: install.packages(“ggplot2”)\ndygraphs installation: install.packages(“dygraphs”)\nhere installation: install.packages(“here”)\n\n\n\n\nUse RStudio Desktop on Windows then click on “install”\n\nSearch for the package you want for example “here” package and click “install”\n\n\n\n\n\n\nRecommended (optional) in the Quarto Extension settings enable the “Render on Save” option"
  },
  {
    "objectID": "blog/how_to_post.html#running-the-project-in-a-live-preview",
    "href": "blog/how_to_post.html#running-the-project-in-a-live-preview",
    "title": "R Consortium Blog",
    "section": "",
    "text": "In VSCode click on “View” and then “Command Palette”\n\nSearch for “Quarto: Preview” and click on that command"
  },
  {
    "objectID": "blog/how_to_post.html#adding-a-blog-post",
    "href": "blog/how_to_post.html#adding-a-blog-post",
    "title": "R Consortium Blog",
    "section": "",
    "text": "In Github desktop click “Branch” and then “New branch” make a new branch for example “Adding-new-elephant-post”\n\n\nIn VSCode add a new Folder in the “posts” directory and name it. My new post folder is “Slides-Post”\n\nAdd a new index.qmd file (Quarto Markdown File) into the new post folder.\n\nStart editing your new blog post!\n\n\n\nIn Github desktop commit your changes and a short message for your changes, for my example I am committing to the “Add-Slides” branch.\n\nOnce committed, push it to the remote Github Repository. On the bottom left is an indication of a successful commit.\n\nMake a pull request in Github desktop and then 1 reviewer should check the post and make sure it is looking good!\n\n\nClick on “Create pull request” on Github\n\nApproval Process and Timing\n\nEmail info@r-consortium.org"
  },
  {
    "objectID": "newsletters/R-Consortium-Q2-2024-Newsletter.html",
    "href": "newsletters/R-Consortium-Q2-2024-Newsletter.html",
    "title": "R Consortium Q2 2024 Newsletter",
    "section": "",
    "text": "Hello from the R Consortium! This quarterly newsletter puts together the latest updates about our organization’s activities, the progress each working group has made, upcoming R-related events, and recordings of past events. In short, all you need to know about our work to promote the R language and how we lead community initiatives. Please share this newsletter!\nAre you a member of the R community and want to submit your content for the newsletter? Email us at info@r-consortium.org, we’d love to include you!\nYou haven’t read the previous newsletters? You can find them on the R Consortium website here.\nAny suggestions for our next newsletter? Feel free to let us know here.\nYou’d like to sign up to automatically receive the newsletter? Click here.\n\n\n\nTechnical Projects and Working Groups\nAnnual Report\nUpcoming Events\nFree R-related Technology and Industry Webinars\nR Consortium Supports R User Groups Around the World!\nBuilding Extended R Packages to Improve R Infrastructure\n\n\n\n\n\n\nThe Infrastructure Steering Committee (ISC) conducts two open grant cycles to evaluate proposals from the community for projects that the committee believes will contribute to the technical infrastructure of the R ecosystem. During the second grant cycle of 2023, the ISC funded the following seven projects with a total of $80,000:\n\nTranslating R to Nepali\nTooling for internationalization of R help pages\nRStats Mastodon Server\nTaking r-universe to the next level\nCausal Inference in a Box\nR Kafka Client\nAccessibility Enhancements for the R Journal\n\nThe first grant cycle for 2024 has recently closed, and the ISC is evaluating ten proposals which are collectively requesting more than $200,000. These proposals include translating a Public Health Model into R, adapting R-universe technology for deploying R packages, and upgrading or extending several key R packages. The ISC expects to notify the teams submitting successful proposals by May 1, 2024.\n\n\n\nIn this section, we will highlight the progress of selected R Consortium working groups. This month we look at the R Submissions working group and the Risk Assessment workstream of the R Validation hub, which have recently achieved significant milestones.\n\n\nWith the active participation of the FDA, the R Consortium R Submissions working group is developing a series of Pilot or test submissions to uncover the challenges that must be overcome in making “all R” regulatory submissions straightforward, routine, and reproducible over a minimum six-year time horizon. Each Pilot submission builds on the previous pilot and includes additional steps. The objective of Pilot 3 is to extend the work done in the Pilot 2 study, which included wrapping a Shiny application into the submissions package, to build the AdaM data set from raw data. For each submission effort, the FDA review team recreates the study from the submission package, evaluates the correctness and reproducibility of the results, and documents discrepancies from previous pilot submission packages that they may observe.\nIn the most recent Pilot 3 submission, the FDA observed a discrepancy that was due to a difference in the coding of an imputation algorithm. The Pilot 3 statisticians used a subsetting algorithm that differed from the algorithm selected by the CDISC statisticians who built the ADaM data set used in Pilot 1 and Pilot 2. This was not a statistical error, but a failure to provide documentation at a sufficient level of detail for the FDA reviewers to make the appropriate adjustment. The episode illustrates the attention to detail required to achieve a smooth handoff to the FDA.\nAs the Pilot 3 team prepares their final submission, the Pilot 4 team is nearly ready with a submission package that will include the code required to unpack the package and have it deploy within a WebAssembly browser instance.\nFor more information on the R submission working group please visit their website."
  },
  {
    "objectID": "newsletters/R-Consortium-Q2-2024-Newsletter.html#table-of-contents",
    "href": "newsletters/R-Consortium-Q2-2024-Newsletter.html#table-of-contents",
    "title": "R Consortium Q2 2024 Newsletter",
    "section": "",
    "text": "Technical Projects and Working Groups\nAnnual Report\nUpcoming Events\nFree R-related Technology and Industry Webinars\nR Consortium Supports R User Groups Around the World!\nBuilding Extended R Packages to Improve R Infrastructure"
  },
  {
    "objectID": "newsletters/R-Consortium-Q2-2024-Newsletter.html#technical-projects-and-working-groups",
    "href": "newsletters/R-Consortium-Q2-2024-Newsletter.html#technical-projects-and-working-groups",
    "title": "R Consortium Q2 2024 Newsletter",
    "section": "",
    "text": "The Infrastructure Steering Committee (ISC) conducts two open grant cycles to evaluate proposals from the community for projects that the committee believes will contribute to the technical infrastructure of the R ecosystem. During the second grant cycle of 2023, the ISC funded the following seven projects with a total of $80,000:\n\nTranslating R to Nepali\nTooling for internationalization of R help pages\nRStats Mastodon Server\nTaking r-universe to the next level\nCausal Inference in a Box\nR Kafka Client\nAccessibility Enhancements for the R Journal\n\nThe first grant cycle for 2024 has recently closed, and the ISC is evaluating ten proposals which are collectively requesting more than $200,000. These proposals include translating a Public Health Model into R, adapting R-universe technology for deploying R packages, and upgrading or extending several key R packages. The ISC expects to notify the teams submitting successful proposals by May 1, 2024.\n\n\n\nIn this section, we will highlight the progress of selected R Consortium working groups. This month we look at the R Submissions working group and the Risk Assessment workstream of the R Validation hub, which have recently achieved significant milestones.\n\n\nWith the active participation of the FDA, the R Consortium R Submissions working group is developing a series of Pilot or test submissions to uncover the challenges that must be overcome in making “all R” regulatory submissions straightforward, routine, and reproducible over a minimum six-year time horizon. Each Pilot submission builds on the previous pilot and includes additional steps. The objective of Pilot 3 is to extend the work done in the Pilot 2 study, which included wrapping a Shiny application into the submissions package, to build the AdaM data set from raw data. For each submission effort, the FDA review team recreates the study from the submission package, evaluates the correctness and reproducibility of the results, and documents discrepancies from previous pilot submission packages that they may observe.\nIn the most recent Pilot 3 submission, the FDA observed a discrepancy that was due to a difference in the coding of an imputation algorithm. The Pilot 3 statisticians used a subsetting algorithm that differed from the algorithm selected by the CDISC statisticians who built the ADaM data set used in Pilot 1 and Pilot 2. This was not a statistical error, but a failure to provide documentation at a sufficient level of detail for the FDA reviewers to make the appropriate adjustment. The episode illustrates the attention to detail required to achieve a smooth handoff to the FDA.\nAs the Pilot 3 team prepares their final submission, the Pilot 4 team is nearly ready with a submission package that will include the code required to unpack the package and have it deploy within a WebAssembly browser instance.\nFor more information on the R submission working group please visit their website."
  },
  {
    "objectID": "newsletters/R-Consortium-Q2-2024-Newsletter.html#get-in-touch-with-the-r-consortium",
    "href": "newsletters/R-Consortium-Q2-2024-Newsletter.html#get-in-touch-with-the-r-consortium",
    "title": "R Consortium Q2 2024 Newsletter",
    "section": "Get in Touch with the R Consortium!",
    "text": "Get in Touch with the R Consortium!\nFollow us on social media or contact us here:https://www.r-consortium.org/contact"
  },
  {
    "objectID": "newsletters/R-Consortium-Q3-2023-Newsletter.html",
    "href": "newsletters/R-Consortium-Q3-2023-Newsletter.html",
    "title": "R Consortium Q3 2023 Newsletter",
    "section": "",
    "text": "R Consortium Q3 2023 Newsletter\n\n\nWelcome!\nHello from the R Consortium! This quarterly newsletter puts together the latest updates about our organization’s activities, the progress each working group has made, upcoming R related events, and recordings of past events. In short, all you need to know about the R Consortium! We hope you enjoy it.\nYou haven’t read the previous newsletter? You can find them on the RC website here. Any suggestions for our next newsletter? Feel free to let us know here. You’d like to sign up to automatically receive the newsletter? Click here.\n\n\n📣 New Executive Director Announcement – Welcome back, Joseph Rickert!\n\nThe R Consortium is pleased to announce that Joseph Rickert has been appointed to the position of Executive Director reporting directly to the Board of Directors.\nJoseph has been active in the R Community since he joined Revolution Analytics in 2009 and has held prominent, community-facing positions at both the R Consortium and RStudio (now renamed posit). He is deeply involved in multiple R Consortium technical working groups, is an organizer of the Bay Area useR Group (BARUG), and has been on the R/Medicine conference organizing committee since the first conference in 2018. Joseph served on the R Consortium Board of Directors from August 2016 to July 2023, serving as Chair from 2020.\nWelcome, Joseph, to your new position!\n\n\n\nFirst Publicly Available R-Based Submission Package Submitted to FDA (Pilot 3)\n\nThe R Consortium is pleased to announce that on August 28, 2023, the R Submissions Working Group successfully submitted an R-based test submission pilot 3 package through the FDA eCTD gateway! The FDA CDER staff are now able to begin their evaluation process. All submission materials can be found at:https://github.com/RConsortium/submissions-pilot3-adam-to-fda\nRead more about this big accomplishment and work on Pilot 4 here.\n\n\n\nISC Funded Projects Improving the R Ecosystem\n\nR Consortium Funded Project Extendr Provides Rust Extensions for R\nAndy Thomason, code performance consultant and lecturer at the University of London covering programming, physics and AI courses focused on game development, created an open source project to add Rust’s performance, reliability, and productivity to R. Andy created the Extendr package, a safe and user-friendly R extension interface for using Rust. The project was supported by a grant from the R Consortium.\n\n\nR User Groups Are Active Around the World!\n\nUse of R in Non-Profit Social Policy Research in New York\n\n\n\nUse of R for Pharma in Rosario, Argentina\n\n\n\nUtilizing R for Reproducible Open Science Research in Tucson, Arizona\n\n\n\n\nISC Call for Proposals Wrap Up\n\nMain announcement: Grants For R Language Infrastructure Projects Available Now!\nThe ISC is back with its second round of proposal calls and grant awards for 2023! The main objective is to strengthen the R ecosystem’s technical infrastructure and serve the R community better. Second Grant Cycle: September 1 to October 1, acceptance by November 1, contract by December 1.\nIf you missed the cycle this time, be sure to keep an eye out for next grant cycle in 2024!\n\n\n\nWorking groups updates\nR Certification\n\n\n\nChange in Leadership and Ongoing activities In late August Joseph Korszun stepped down as Lead of R Certification Working Group. Joseph had contributed extensively in organizing and leading the efforts to compile and prepare for alpha release of Clinical Analyst examination. He had been critical in forming this working group and contributed extensively to ensure a Minimal Viable Product. Uday Preetham Palukuru has taken over the activities as lead. Joseph Rickert continues to provide guidance to the working group. Ongoing activities include:Clarification of various R Certification Exam levels expected to be part of final releaseClean-up of GitHub issues and re-prioritization of outstanding issues Completion of reviewer feedback regarding existing questionnaire pertaining to various exam levelsDiscussion with Certiverse on using .yml files for hosting draft alpha examIdentification of select candidates to preview the alpha release and gather feedback\nUday Preetham Palukurupreetham.palukuru@merck.comJoseph Rickert Joseph.Rickert@procogia.com Further information: https://github.com/RConsortium/R-Certification-WG)\n\n\n\n\n\nR Tables for Regulatory Submission (RTRS)\n\n\n\nTables in Clinical Trials with R The version 1.0, the published version of the ebook, Tables in Clinical Trials with R is available at link: https://rconsortium.github.io/rtrs-wg.In this book we present various aspects of creating tables with the R language (R Core Team 2023) to analyze and report clinical trials data.The working group will present its work in R/Pharma in October.\nGabe Becker: gabembecker@gmail.comAdrian Waddell: adrian.waddell@gene.comJoseph Rickert: joseph.rickert@rstudio.comWorking Group github repository: https://github.com/RConsortium/rtrs-wg\n\n\n\n\n\nR Validation Hub\n\n\n\nRegulatory R Repository working group  In July, the working group presented its work in the Basel R conference. The recording is available here: https://youtu.be/qqfteqh9kXw?si=2sJwP079Tj0toHY4 In summary, after collecting requirements and gathering consensus on key assumptions to build on, the team is now getting ready to start its first MVP. Would you like to join? Check out our Benefits of participating PDF link\nColine Zeballos: coline.zeballos@gmail.com\n\n\n\n\n\n\nThe R Validation Hub was selected to give a talk at the upcoming R/Pharma virtual conference on October 24-26. Register here and see you there!\nColine Zeballos: coline.zeballos@gmail.com Juliane Manitz: juliane.manitz@emdserono.com\n\n\nThe slides from Doug’s Posit::conf 2023 Pharma Round Table presentation are available here: https://pharmar.github.io/events-positconf2023/#/title-slide\nDoug Kelkhoff: doug.kelkhoff@gmail.com\n\n\n\n\n\nSubmissions\n\n\n\nPilot 3 submissionThe R Consortium is pleased to announce that on August 28, 2023, the R Submissions Working Group successfully submitted an R-based test submission pilot 3 package through the FDA eCTD gateway! The pilot 3 test submission is an example of an all R submission package following eCTD specifications. These include the installation and loading of the proprietary {pilot3} R package and other open-source R packages, R scripts for the analysis data model (ADaM) datasets from pilot 3 and tables, listings, figures (TLFs) from pilot 1, analysis data reviewer’s guide (adrg), and other required eCTD components. The working group also began working on a pilot 4 project to explore the use of novel technologies such as Linux containers and WebAssembly software to bundle a Shiny application into a self-contained package in order to facilitate a smoother process for transferring and executing the application. Stay tuned for more about pilot 4 in the future.https://www.r-consortium.org/announcement/2023/09/11/first-publicly-available-r-based-submission-package-submitted-to-fda-pilot-3\nNing Leng: lengn@genecom Joseph Rickert: joseph.rickert@gmail.comFurther information: https://github.com/RConsortium/submissions-wg\n\n\n\n\n\n\nOBJSXP Now that we have a release on CRAN, the focus has shifted to finishing and merging the OBJSXP work into base R.\nMichael Lawrence Hadley Wickham Further information:https://github.com/RConsortium/OOP-WG\n\n\n\n\n\n\nUpcoming events – R Consortium will be there, will you?\nLatinR 2023 – Taking place in Montevideo, Uruguay from October 18-20, 2023 R government – In-person and Virtual from October 19-20, 2023 R/Pharma 2023 – Virtual from October 24th to 26th with workshops the week prior\n\n\nYou’ve missed a recent event?\nR/Basel, a useR! regional Conference July 21st, 2023, Roche Basel Campus New York R Conference – Held workshops from July 11-12 and Conference from July 13-14 2023 Cascadia R Conference – Taking place in Seattle, Washington from Saturday, August 19, 2023 Joint Statistical Meetings (JSM) – August 5 – 10, 2023, in Toronto, Canada R Project Sprint August 30 – September 1, 2023, Warwick UK Posit::conf including workshop: Leveraging & Contributing to the Pharmaverse for Clinical Trial Reporting in R was held this week in Chicago with Roche folks involved – see teaser video here https://www.youtube.com/watch?v=iOOiNG2t-Dc\n\n\nFollow the R Consortium on Social Media – We need you!\nIn this section, we highlight a few opportunities for getting more involved with the R Consortium.\n\n\n\nHelp promote the R Consortium message around the globe - Follow @RConsortium on Twitter (https://twitter.com/RConsortium), @RConsortium@fosstodon.org on Mastodon, and R Consortium on LinkedIn (https://www.linkedin.com/company/r-consortium)- We’re working on updating and improving the R Consortium YouTube account (https://www.youtube.com/c/RConsortium). There’s great content there, from events, with talks and presentations covering many R topics.- Like, comment, and share/retweet R Consortium content on an ongoing basis – new content appears frequently! \nParticipate in an R Consortium working group - Example: R in Business Working Group (https://github.com/RConsortium/RBusiness), is an R Consortium working group promoting and supporting the R programming environment and the R ecosystem in business practices and business research - R Consortium Working Groups…- Help develop a community-based collaboration platform- Organize and sponsor of events -Research relevant topics in depth Develop openly available courses/tutorials- Develop and maintain R packages"
  },
  {
    "objectID": "all-projects/2018-group-1.html",
    "href": "all-projects/2018-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nA unified platform for missing values methods and workflows\nDeveloping Tools and Templates for Teaching Materials\nMaintaining DBI\nOngoing infrastructural development for R on Windows and MacOS\nPSI application for collaboration to create online R package validation repository\nProposal to Create an R Consortium Working Group Focused on US Census Data\nhistoRicalg – Preserving and Transfering Algorithmic Knowledge\n\n\n\n\nFunded:\n$14,000\nProposed by:\nJulie Josse\nWebsite:\nhttps://cran.r-project.org/web/views/MissingData.html\nSummary:\nThe objective is to create a reference platform on the theme of missing data management and to federate contributors. This platform will be the occasion to list the existing packages, the available literature as well as the tutorials that allow to analyze data with missing data. New work on the subject can be easily integrated and we will create examples of analysis workflows with missing data. Anyone who would like to contribute to this exciting project can contact us.\n\n\n\nFunded:\n$10,000\nProposed by:\nFrançois Michonneau\nWebsite:\nhttps://datacarpentry.org/R-ecology-lesson/ and http://swcarpentry.github.io/r-novice-gapminder/\nSummary:\nThe first-class implementation of literate programming in R is one of the reasons for its success. While the seamless integration of code and text made possible by Sweave, knitr, and rmarkdown was designed for writing reproducible reports and documentation, it has also enabled the creation of teaching materials that combine text, code examples, exercises and solutions. However, while people creating lessons in RMarkdown are familiar with R, they often do not have a background in education or UX design. Therefore, they must not only assemble curriculum, but also find a way to present the content effectively and accessibly to both learners and instructors. As the model of open source development is being adapted to the creation of open educational resources, the difficulty to share materials due to a lack of consistency in their construction hinders the collaborative development of these resources.\nThis project will develop an R package that will facilitate the development of consistent teaching resources. It will encourage the use of tools and lesson structure that support and improve learning. By providing the technical framework for developing quality teaching materials, we seek to encourage collaborative lesson development by letting authors focus on the content rather than the formatting, while providing a more consistent experience for the learners.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nDBI, R’s database interface, is a set of methods declared in the DBI R package. Communication with the database is implemented by DBI backends, packages that import DBI and implement its methods. A common interface is helpful for both users and backend implementers.\nThe “Maintaining DBI” is a follow-up project to two previous projects supported by the R Consortium, and is mostly about providing ongoing maintenance and support for DBI, the DBItest test suite, and the three backends to open-source databases (RSQLite, RMariaDB and RPostgres) that have been implemented as part of the previous projects.\n\n\n\nFunded:\n$62,400\nProposed by:\nJeroen Ooms\nWebsite:\nhttps://github.com/r-hub/homebrew-cran#how-to-use\nSummary:\nThe majority of R users rely on precompiled installers and binary packages for Windows and MacOS that are made available through CRAN. This project seeks to improve and maintain tools for providing such binaries, and relieve some of the dependence on CRAN maintainers and R-core members for doing so. On Windows we will upgrade the Rtools compiler toolchain, and provide up-to-date Windows builds for the many external C/C++ libraries used by CRAN packages. For MacOS we will expand the r-hub “homebrew-cran” tap with formulas that are needed by CRAN packages but not available from upstream homebrew-core. Eventually we want to lay the foundation for a reproducible build system that is low maintenance, automated as much as possible, and which could be used by CRAN and other R package repositories.\n\n\n\nFunded:\n$4,000\nProposed by:\nLyn Taylor (on behalf of PSI AIMS SIG)\nWebsite:\nhttps://www.pharmar.org/\nSummary:\nThe documentation available for R packages currently widely varies. The Statisticians in the Pharmaceutical Industry (PSI) Application and Implementation of Methodologies in Statistics (AIMS) Special Interest Group (SIG) will collaborate with the R-Consortium and representatives from pharmaceutical companies on the setting up of an online repository /web portal, where validation which is of regulatory standard for R packages can be submitted and stored for free use. Companies (or individual R users) would still be liable to make their own assessment on whether the validation is suitable for their own use, however the online repository would serve as a portal for sharing existing regulatory standard validation documentation.\n\n\n\nFunded:\n$4,000\nProposed by:\nAri Lamstein\nWebsite:\nhttps://github.com/RConsortium/censusguide\nSummary:\nThe Proposal to Create an R Consortium Working Group Focused on US Census Data aims to make life easier for R programmers who work with data from the US Census Bureau. It will create a working group where R users working with census data can cooperate under the guidance of the Census Bureau. Additionally, it will publish a guide to working with Census data in R that aims to help R programmers a) select packages that meet their needs and b) navigate the various data sets that the Census Bureau publishes.\n\n\n\nFunded:\n$772\nProposed by:\nJohn C Nash\nWebsite:\nhttps://gitlab.com/nashjc/histoRicalg\nSummary:\nMany of the algorithms making up the numerical building-blocks of R were developed several decades ago, particularly in Fortran. Some were translated into C for use by R. Only a modest proportion of R users today are fluent in these languages, and many original authors are no longer active. Yet some of these codes may have bugs or need adjustment for new system capabilities. The histoRicalg project aims to document and test such codes that are still part of R, possibly creating all-R reference codes, hopefully by teaming older and younger workers so knowledge can be shared for the future. Our initial task is to establish a ***Working Group on Algorithms Used in R*** and add material to a website/wiki currently at https://gitlab.com/nashjc/histoRicalg. Interested workers are invited to contact John Nash."
  },
  {
    "objectID": "all-projects/2018-group-1.html#funded-isc-grants-2018-1",
    "href": "all-projects/2018-group-1.html#funded-isc-grants-2018-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nA unified platform for missing values methods and workflows\nDeveloping Tools and Templates for Teaching Materials\nMaintaining DBI\nOngoing infrastructural development for R on Windows and MacOS\nPSI application for collaboration to create online R package validation repository\nProposal to Create an R Consortium Working Group Focused on US Census Data\nhistoRicalg – Preserving and Transfering Algorithmic Knowledge\n\n\n\n\nFunded:\n$14,000\nProposed by:\nJulie Josse\nWebsite:\nhttps://cran.r-project.org/web/views/MissingData.html\nSummary:\nThe objective is to create a reference platform on the theme of missing data management and to federate contributors. This platform will be the occasion to list the existing packages, the available literature as well as the tutorials that allow to analyze data with missing data. New work on the subject can be easily integrated and we will create examples of analysis workflows with missing data. Anyone who would like to contribute to this exciting project can contact us.\n\n\n\nFunded:\n$10,000\nProposed by:\nFrançois Michonneau\nWebsite:\nhttps://datacarpentry.org/R-ecology-lesson/ and http://swcarpentry.github.io/r-novice-gapminder/\nSummary:\nThe first-class implementation of literate programming in R is one of the reasons for its success. While the seamless integration of code and text made possible by Sweave, knitr, and rmarkdown was designed for writing reproducible reports and documentation, it has also enabled the creation of teaching materials that combine text, code examples, exercises and solutions. However, while people creating lessons in RMarkdown are familiar with R, they often do not have a background in education or UX design. Therefore, they must not only assemble curriculum, but also find a way to present the content effectively and accessibly to both learners and instructors. As the model of open source development is being adapted to the creation of open educational resources, the difficulty to share materials due to a lack of consistency in their construction hinders the collaborative development of these resources.\nThis project will develop an R package that will facilitate the development of consistent teaching resources. It will encourage the use of tools and lesson structure that support and improve learning. By providing the technical framework for developing quality teaching materials, we seek to encourage collaborative lesson development by letting authors focus on the content rather than the formatting, while providing a more consistent experience for the learners.\n\n\n\nFunded:\n$26,500\nProposed by:\nKirill Müller\nWebsite:\nhttps://dbi.r-dbi.org/\nSummary:\nDBI, R’s database interface, is a set of methods declared in the DBI R package. Communication with the database is implemented by DBI backends, packages that import DBI and implement its methods. A common interface is helpful for both users and backend implementers.\nThe “Maintaining DBI” is a follow-up project to two previous projects supported by the R Consortium, and is mostly about providing ongoing maintenance and support for DBI, the DBItest test suite, and the three backends to open-source databases (RSQLite, RMariaDB and RPostgres) that have been implemented as part of the previous projects.\n\n\n\nFunded:\n$62,400\nProposed by:\nJeroen Ooms\nWebsite:\nhttps://github.com/r-hub/homebrew-cran#how-to-use\nSummary:\nThe majority of R users rely on precompiled installers and binary packages for Windows and MacOS that are made available through CRAN. This project seeks to improve and maintain tools for providing such binaries, and relieve some of the dependence on CRAN maintainers and R-core members for doing so. On Windows we will upgrade the Rtools compiler toolchain, and provide up-to-date Windows builds for the many external C/C++ libraries used by CRAN packages. For MacOS we will expand the r-hub “homebrew-cran” tap with formulas that are needed by CRAN packages but not available from upstream homebrew-core. Eventually we want to lay the foundation for a reproducible build system that is low maintenance, automated as much as possible, and which could be used by CRAN and other R package repositories.\n\n\n\nFunded:\n$4,000\nProposed by:\nLyn Taylor (on behalf of PSI AIMS SIG)\nWebsite:\nhttps://www.pharmar.org/\nSummary:\nThe documentation available for R packages currently widely varies. The Statisticians in the Pharmaceutical Industry (PSI) Application and Implementation of Methodologies in Statistics (AIMS) Special Interest Group (SIG) will collaborate with the R-Consortium and representatives from pharmaceutical companies on the setting up of an online repository /web portal, where validation which is of regulatory standard for R packages can be submitted and stored for free use. Companies (or individual R users) would still be liable to make their own assessment on whether the validation is suitable for their own use, however the online repository would serve as a portal for sharing existing regulatory standard validation documentation.\n\n\n\nFunded:\n$4,000\nProposed by:\nAri Lamstein\nWebsite:\nhttps://github.com/RConsortium/censusguide\nSummary:\nThe Proposal to Create an R Consortium Working Group Focused on US Census Data aims to make life easier for R programmers who work with data from the US Census Bureau. It will create a working group where R users working with census data can cooperate under the guidance of the Census Bureau. Additionally, it will publish a guide to working with Census data in R that aims to help R programmers a) select packages that meet their needs and b) navigate the various data sets that the Census Bureau publishes.\n\n\n\nFunded:\n$772\nProposed by:\nJohn C Nash\nWebsite:\nhttps://gitlab.com/nashjc/histoRicalg\nSummary:\nMany of the algorithms making up the numerical building-blocks of R were developed several decades ago, particularly in Fortran. Some were translated into C for use by R. Only a modest proportion of R users today are fluent in these languages, and many original authors are no longer active. Yet some of these codes may have bugs or need adjustment for new system capabilities. The histoRicalg project aims to document and test such codes that are still part of R, possibly creating all-R reference codes, hopefully by teaming older and younger workers so knowledge can be shared for the future. Our initial task is to establish a ***Working Group on Algorithms Used in R*** and add material to a website/wiki currently at https://gitlab.com/nashjc/histoRicalg. Interested workers are invited to contact John Nash."
  },
  {
    "objectID": "all-projects/2019-group-1.html",
    "href": "all-projects/2019-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nEnhancing usability of sample size calculations and power analyses in R with a Task View page and accompanying tutorials\nExpanding the ‘metaverse’; an R ecosystem for meta-research\nR-global: analysing spatial data globally\nsftraj: A central class for tracking and movement data\n\n\n\n\nFunded:\n$13,912\nProposed by:\nRichard Webster\nWebsite:\nhttps://cheori.org/samplesize/\nSummary:\nSample size calculation and power analysis are fundamental for study design, yet they are challenging to do in the R programming language due to limited inter-package documentation. It is difficult to find the required functionality within the sea of open source packages. Indeed, there is no systematic R resource that allows users to search for whether a particular study design and corresponding statistical test has a power analysis implemented in R.\nOur aims are to improve usability of power analyses performed in R, to facilitate proper design and analysis of data, and promote reproducible research.\nOur duel approach is to create a Task View page for sample size calculations & power analyses, as well as a series of tutorials to reduce the R users’ learning curve. Addressing the usability of sample size calculation / power analyses will benefit a broad spectrum of R users, as this is a vital component for study design, result interpretability and reproducibility.\n\n\n\nFunded:\n$20,171\nProposed by:\nMartin Westgate\nWebsite:\nhttps://rmetaverse.github.io\nSummary:\nEvidence synthesis is the process of identifying, collating and summarizing primary scientific research to provide reliable, transparent summaries such as systematic reviews and meta-analyses. Despite their importance for linking research with policy, however, evidence synthesis projects are often time-consuming, expensive, and difficult to update. Open and reproducible workflows would help address these problems, but these workflows are poorly supported by the current package environment, preventing access by new users and hindering uptake of the well-developed suite of statistical tools for meta-analysis in R. The metaverse project will integrate and expand tools to support evidence synthesis and meta-research in R; suggest flexible workflows to complete these projects in a straightforward and open manner; and provide a collector package allowing easy access to these developments for new and experienced users.\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttp://s2geometry.io/\nSummary:\nCurrently, a number of R spatial functions assume that coordinates are two-dimensional, taken from a “flat” space, and may or may not work for geographical (long/lat) coordinates, depicting points on a globe. This project will try to make such functions more robust and helpful for the the case of geographical coordinates. It will reconsider the concept of a bounding box, and build an interface to the S2 geometry library (http://s2geometry.io/), which powers several modern systems that assume geographic coordinates.\n\n\n\nFunded:\n$10,000\nProposed by:\nMathieu Basille\nWebsite:\nhttps://github.com/mablab/sftraj\nSummary:\nMovement defined broadly plays a central and growing role in fields as diverse as transportation, sport, ecology, music, medicine, and data science. Sampling movements results in tracking data, in the form of geographic (x,y,z) and temporal coordinates (t). Despite this common nature, there is a critical lack of standard infrastructure to deal with movement. With a sharp increase of the use of R for movement studies (more than 70 % of movement studies used R in 2018), the Movement community in R is at the same time very dynamic and very fragmented; in 2018 there was 57 packages that process, visualize and analyze tracking data, one third of which worked in isolation, not being linked to any other tracking package. We aim to develop a central trajectory class to support all stages of movement studies (pre-processing, post-processing and analysis).\nWe propose a sftraj package offering a generic and flexible approach. The only aim of the package will be to present a central class and basic functions to build, handle, summarize and plot movement data. Our project relies on three complementary pillars: a broad involvement of the movement community, a robust conceptual data model, and a sf-based implementation in R. The first stage of the work will specifically involve the Movement community in R. During this stage, we will open contributions of use cases for the package (using GitHub’s issue system), which set practical goals for the development of the package. Use cases describe the workflow that is expected from both users’ and developers’ perspectives, and thus the capabilities that a trajectory package needs to offer. The package specifications and development will aim at addressing all use cases described, to make sure the solution provided is relevant for a wide array of users and package developers."
  },
  {
    "objectID": "all-projects/2019-group-1.html#funded-isc-grants-2019-1",
    "href": "all-projects/2019-group-1.html#funded-isc-grants-2019-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nEnhancing usability of sample size calculations and power analyses in R with a Task View page and accompanying tutorials\nExpanding the ‘metaverse’; an R ecosystem for meta-research\nR-global: analysing spatial data globally\nsftraj: A central class for tracking and movement data\n\n\n\n\nFunded:\n$13,912\nProposed by:\nRichard Webster\nWebsite:\nhttps://cheori.org/samplesize/\nSummary:\nSample size calculation and power analysis are fundamental for study design, yet they are challenging to do in the R programming language due to limited inter-package documentation. It is difficult to find the required functionality within the sea of open source packages. Indeed, there is no systematic R resource that allows users to search for whether a particular study design and corresponding statistical test has a power analysis implemented in R.\nOur aims are to improve usability of power analyses performed in R, to facilitate proper design and analysis of data, and promote reproducible research.\nOur duel approach is to create a Task View page for sample size calculations & power analyses, as well as a series of tutorials to reduce the R users’ learning curve. Addressing the usability of sample size calculation / power analyses will benefit a broad spectrum of R users, as this is a vital component for study design, result interpretability and reproducibility.\n\n\n\nFunded:\n$20,171\nProposed by:\nMartin Westgate\nWebsite:\nhttps://rmetaverse.github.io\nSummary:\nEvidence synthesis is the process of identifying, collating and summarizing primary scientific research to provide reliable, transparent summaries such as systematic reviews and meta-analyses. Despite their importance for linking research with policy, however, evidence synthesis projects are often time-consuming, expensive, and difficult to update. Open and reproducible workflows would help address these problems, but these workflows are poorly supported by the current package environment, preventing access by new users and hindering uptake of the well-developed suite of statistical tools for meta-analysis in R. The metaverse project will integrate and expand tools to support evidence synthesis and meta-research in R; suggest flexible workflows to complete these projects in a straightforward and open manner; and provide a collector package allowing easy access to these developments for new and experienced users.\n\n\n\nFunded:\n$10,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttp://s2geometry.io/\nSummary:\nCurrently, a number of R spatial functions assume that coordinates are two-dimensional, taken from a “flat” space, and may or may not work for geographical (long/lat) coordinates, depicting points on a globe. This project will try to make such functions more robust and helpful for the the case of geographical coordinates. It will reconsider the concept of a bounding box, and build an interface to the S2 geometry library (http://s2geometry.io/), which powers several modern systems that assume geographic coordinates.\n\n\n\nFunded:\n$10,000\nProposed by:\nMathieu Basille\nWebsite:\nhttps://github.com/mablab/sftraj\nSummary:\nMovement defined broadly plays a central and growing role in fields as diverse as transportation, sport, ecology, music, medicine, and data science. Sampling movements results in tracking data, in the form of geographic (x,y,z) and temporal coordinates (t). Despite this common nature, there is a critical lack of standard infrastructure to deal with movement. With a sharp increase of the use of R for movement studies (more than 70 % of movement studies used R in 2018), the Movement community in R is at the same time very dynamic and very fragmented; in 2018 there was 57 packages that process, visualize and analyze tracking data, one third of which worked in isolation, not being linked to any other tracking package. We aim to develop a central trajectory class to support all stages of movement studies (pre-processing, post-processing and analysis).\nWe propose a sftraj package offering a generic and flexible approach. The only aim of the package will be to present a central class and basic functions to build, handle, summarize and plot movement data. Our project relies on three complementary pillars: a broad involvement of the movement community, a robust conceptual data model, and a sf-based implementation in R. The first stage of the work will specifically involve the Movement community in R. During this stage, we will open contributions of use cases for the package (using GitHub’s issue system), which set practical goals for the development of the package. Use cases describe the workflow that is expected from both users’ and developers’ perspectives, and thus the capabilities that a trajectory package needs to offer. The package specifications and development will aim at addressing all use cases described, to make sure the solution provided is relevant for a wide array of users and package developers."
  },
  {
    "objectID": "all-projects/callforproposals.html",
    "href": "all-projects/callforproposals.html",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "A major goal of the R Consortium is to strengthen and improve the infrastructure supporting the R Ecosystem. We seek to accomplish this by funding projects that will improve both technical infrastructure and social infrastructure.\nTechnical Infrastructure projects that have be funded include:\n\nR-hub, a centralized tool for checking R packages\nTesting DBI and improving key open source database backends.\nImprovements in packages such as mapview and sf\nImproving Translations in R\nOngoing infrastructural development for R on Windows and macOS\n\nSocial Infrastructure projects include:\n\nSatRDays, bootstrapping a system for local R conferences.\nData-Driven Discovery and Tracking of R Consortium Activities\n\nThe Infrastructure Steering Committee (ISC) projects should have a focus on technical infrastructure or involve software development to support social infrastructure. Conferences, training sessions, and user groups will be funded through the RUGS program.\nTo apply for an ISC grant please continue with the instructions below. To seek funding for a conference, training session or user group please apply through the RUGS program page.\n\n\nThe ISC is interested in projects that:\n\nAre likely to have a broad impact on the R community.\nHave a focused scope (a good example is the Simple Features for R project). If you have a larger project, consider breaking it up into smaller chunks (a good example of this done is with the DBI/DBItest project submission, where multiple proposals came in over time to address the various needs).\nHave a low-to-medium risk with a low-to-medium reward. The ISC tends not fund high-risk, high-reward projects.\n\nWhile all projects are considered, the ISC generally does not accept projects that:\n\nImpact only a small part of the R community\nRequest conference, workshop, or meetup sponsorship. For these, you should look at our user group program or connect with the marketing committee for larger events.\nAre very exploratory. These are better to be pursued through the working group program.\n\n\n\n\nPlease provide a 2 to 5 page proposal that describes the problem you want to solve. We expect submissions to include these components:\n\nThe Problem: What problem do you want to solve? Why is it a problem? Who does it affect? What will solving the problem enable? This section should include a brief summary of existing work, such as R packages that may be relevant. If you are proposing a change to R itself, you must include a letter of support from a member of R Core.\nThe Plan: How are you going to solve the problem? Include the concrete actions you will take and an estimated timeline. What are likely failure modes and how will you recover from them?\nThe Team: Who will work on the project? Briefly describe all participants, and the skills they will bring to the project.\nProject Milestones: Outline the milestones for development and how much funding will be required for each stage (as payments will be tied to project milestone completion). Each milestone should specify the work to be done and the expected outcomes, providing enough detail for the ISC to understand the scope of the project work and assess the likelihood of success.\nHow Can The ISC Help: Please describe how you think the ISC can help. If you are looking for a cash grant include a detailed itemized budget and spending plan. We expect that most of the budget will be allocated for labor costs. We do not cover indirect costs. The ISC grants cannot cover such things as travel, lodging, food, journal publication fees, or personal hardware. Cloud services may be covered if they are specific to the project and the project period. The ISC reserves the right to vet how funds are used for each project separately. If in doubt, please reach out to us. If you are seeking to start an ISC working group, then please describe the goals of the group and provide the name of the individual who will be committed to leading and managing the group’s activities. Also, describe how you think the ISC can help promote your project.\nDissemination: How will you ensure that your work is available to the widest number of people? Please specify the open-source or creative commons license(s) you will use, how you will host your code so that others can contribute, and how you will publicize your work. We encourage you to plan content to be shared quarterly on the R Consortium blog.\n\nThe ISC has a limited grant budget, and we want to ensure that funded projects deliver the maximum benefit to the community. Successful proposals show well-defined milestones, with initial work completed to minimize delivery risk, e.g., upfront research and well-defined action plans.\nIf you would like a template to help you structure your proposal, we encourage you to use one contributed by Steph Locke at https://github.com/RConsortium/isc-proposal.\nWe encourage you to seek feedback from the community before formally submitting your proposal. You are welcome to email individual committee members who might be particularly interested in your proposal to get their informal opinion, and you may want to publicize it more widely to get feedback from the broader R community.\n\n\n\nOnce you have completed your proposal, create a self-contained PDF and complete this form (requires signing in via a Google Account). When you submit the form, you should see a response page saying “Thank you for your proposal!” Soon thereafter, you will receive an email from forms-receipts-noreply@google.com with all the details of your submission. If you do not receive that email, please be sure to check your spam folder. If you do not see it, reach out to us as soon as possible.\nPlease note that the R Consortium utilizes a standard agreement for all funded projects selected in an effort to streamline the award process and to fund the greatest amount of projects as possible. The standard agreement is available for review in advance: Individual Consultant Agreement for R Consortium ISC Projects – 20170622.\nIf you have any questions please email proposal@r-consortium.org.\n\n\n\n\n\n\nMarch 1, 2025 – Grant Application period opens\nApril 1, 2025 – Grant Application period closes, 11:59pm US ET\nMay 1, 2025 – All accepted grantees are contacted by the ISC\nJune 1, 2025 – Deadline for acceptance of grant and contract. Public notification of grantees occurs shortly thereafter.\n\n\n\n\n\nSeptember 1, 2025 – Grant Application period opens\nOctober 1, 2025 – Grant Application period close, 11:59pm US ET\nNovember 1, 2025 – All accepted grantees are contacted by the ISC\nDecember 1, 2025 – Deadline for acceptance of grant and contract. Public notification of grantees occurs shortly thereafter.\n\n\n\n\n\nAll proposals will be read and reviewed by the Chair of the ISC and assigned to a committee member for detailed review. Proposals will be reviewed as a group, and you will be notified of the decision by the dates listed above.\n50% of the grant will be paid out when the contract is signed and 50% upon completion.\nAll accepted projects will be published on the R Consortium blog.\nWe review this process yearly to ensure that the process is as smooth as possible, and to incorporate the knowledge gained from putting it into practice. All decisions to accept or reject proposals will be made by R Consortium in its sole discretion and shall be final.\nIf you have any questions about the proposals or submission process write to proposal@r-consortium.org."
  },
  {
    "objectID": "all-projects/callforproposals.html#projects-the-isc-funds",
    "href": "all-projects/callforproposals.html#projects-the-isc-funds",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "The ISC is interested in projects that:\n\nAre likely to have a broad impact on the R community.\nHave a focused scope (a good example is the Simple Features for R project). If you have a larger project, consider breaking it up into smaller chunks (a good example of this done is with the DBI/DBItest project submission, where multiple proposals came in over time to address the various needs).\nHave a low-to-medium risk with a low-to-medium reward. The ISC tends not fund high-risk, high-reward projects.\n\nWhile all projects are considered, the ISC generally does not accept projects that:\n\nImpact only a small part of the R community\nRequest conference, workshop, or meetup sponsorship. For these, you should look at our user group program or connect with the marketing committee for larger events.\nAre very exploratory. These are better to be pursued through the working group program."
  },
  {
    "objectID": "all-projects/callforproposals.html#submitting-a-proposal",
    "href": "all-projects/callforproposals.html#submitting-a-proposal",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "Please provide a 2 to 5 page proposal that describes the problem you want to solve. We expect submissions to include these components:\n\nThe Problem: What problem do you want to solve? Why is it a problem? Who does it affect? What will solving the problem enable? This section should include a brief summary of existing work, such as R packages that may be relevant. If you are proposing a change to R itself, you must include a letter of support from a member of R Core.\nThe Plan: How are you going to solve the problem? Include the concrete actions you will take and an estimated timeline. What are likely failure modes and how will you recover from them?\nThe Team: Who will work on the project? Briefly describe all participants, and the skills they will bring to the project.\nProject Milestones: Outline the milestones for development and how much funding will be required for each stage (as payments will be tied to project milestone completion). Each milestone should specify the work to be done and the expected outcomes, providing enough detail for the ISC to understand the scope of the project work and assess the likelihood of success.\nHow Can The ISC Help: Please describe how you think the ISC can help. If you are looking for a cash grant include a detailed itemized budget and spending plan. We expect that most of the budget will be allocated for labor costs. We do not cover indirect costs. The ISC grants cannot cover such things as travel, lodging, food, journal publication fees, or personal hardware. Cloud services may be covered if they are specific to the project and the project period. The ISC reserves the right to vet how funds are used for each project separately. If in doubt, please reach out to us. If you are seeking to start an ISC working group, then please describe the goals of the group and provide the name of the individual who will be committed to leading and managing the group’s activities. Also, describe how you think the ISC can help promote your project.\nDissemination: How will you ensure that your work is available to the widest number of people? Please specify the open-source or creative commons license(s) you will use, how you will host your code so that others can contribute, and how you will publicize your work. We encourage you to plan content to be shared quarterly on the R Consortium blog.\n\nThe ISC has a limited grant budget, and we want to ensure that funded projects deliver the maximum benefit to the community. Successful proposals show well-defined milestones, with initial work completed to minimize delivery risk, e.g., upfront research and well-defined action plans.\nIf you would like a template to help you structure your proposal, we encourage you to use one contributed by Steph Locke at https://github.com/RConsortium/isc-proposal.\nWe encourage you to seek feedback from the community before formally submitting your proposal. You are welcome to email individual committee members who might be particularly interested in your proposal to get their informal opinion, and you may want to publicize it more widely to get feedback from the broader R community."
  },
  {
    "objectID": "all-projects/callforproposals.html#how-to-apply",
    "href": "all-projects/callforproposals.html#how-to-apply",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "Once you have completed your proposal, create a self-contained PDF and complete this form (requires signing in via a Google Account). When you submit the form, you should see a response page saying “Thank you for your proposal!” Soon thereafter, you will receive an email from forms-receipts-noreply@google.com with all the details of your submission. If you do not receive that email, please be sure to check your spam folder. If you do not see it, reach out to us as soon as possible.\nPlease note that the R Consortium utilizes a standard agreement for all funded projects selected in an effort to streamline the award process and to fund the greatest amount of projects as possible. The standard agreement is available for review in advance: Individual Consultant Agreement for R Consortium ISC Projects – 20170622.\nIf you have any questions please email proposal@r-consortium.org."
  },
  {
    "objectID": "all-projects/callforproposals.html#proposal-dates-for-2025",
    "href": "all-projects/callforproposals.html#proposal-dates-for-2025",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "March 1, 2025 – Grant Application period opens\nApril 1, 2025 – Grant Application period closes, 11:59pm US ET\nMay 1, 2025 – All accepted grantees are contacted by the ISC\nJune 1, 2025 – Deadline for acceptance of grant and contract. Public notification of grantees occurs shortly thereafter.\n\n\n\n\n\nSeptember 1, 2025 – Grant Application period opens\nOctober 1, 2025 – Grant Application period close, 11:59pm US ET\nNovember 1, 2025 – All accepted grantees are contacted by the ISC\nDecember 1, 2025 – Deadline for acceptance of grant and contract. Public notification of grantees occurs shortly thereafter."
  },
  {
    "objectID": "all-projects/callforproposals.html#the-process",
    "href": "all-projects/callforproposals.html#the-process",
    "title": "The 2025 ISC Grant Program",
    "section": "",
    "text": "All proposals will be read and reviewed by the Chair of the ISC and assigned to a committee member for detailed review. Proposals will be reviewed as a group, and you will be notified of the decision by the dates listed above.\n50% of the grant will be paid out when the contract is signed and 50% upon completion.\nAll accepted projects will be published on the R Consortium blog.\nWe review this process yearly to ensure that the process is as smooth as possible, and to incorporate the knowledge gained from putting it into practice. All decisions to accept or reject proposals will be made by R Consortium in its sole discretion and shall be final.\nIf you have any questions about the proposals or submission process write to proposal@r-consortium.org."
  },
  {
    "objectID": "all-projects/2017-group-2.html",
    "href": "all-projects/2017-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAn Earth data processing backend for testing and evaluating stars\nFuture Minimal API: Specification with Backend Conformance Test Suite\nQuantities for R\nRefactoring and updating the SWIG R module\n\n\n\n\nFunded:\n$5,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://r-spatial.github.io/stars/\nSummary:\nThe stars project enables the processing Earth imagery data that is held on servers, without the need to download it to local hard driver. This project will (i) create software to run a back-end, (ii) develop scripts and tutorials that explain how such a data server and processing backend can be set up, and (iii) create an instance of such a backend in the AWS cloud that can be used for testing and evaluation purposes.\n\n\n\nFunded:\n$10,000\nProposed by:\nHenrik Bengtsson\nWebsite:\nhttps://github.com/HenrikBengtsson/\nSummary:\nThe objective of the Future Framework implemented in the future package is to simplify how parallel and distributed processing is conducted in R. This project aims to provide a formal Future API specification and provide a test framework for validating the conformance of existing (e.g. future.batchtools and future.callr) and to-come third-party parallel backends to the Future framework.\n\n\n\nFunded:\n$10,000\nProposed by:\nInaki Ucar\nWebsite:\nhttps://github.com/r-quantities/quantities and https://www.r-spatial.org/r/2018/08/31/quantities-final.html\nSummary:\nThe ‘units’ package has become the reference for quantity calculus in R, with a wide and welcoming response from the R community. Along the same lines, the ‘errors’ package integrates and automatises error propagation and printing for R vectors. A significant fraction of R users, both practitioners and researchers, use R to analyse measurements, and would benefit from a joint processing of quantity values with errors.\nThis project not only aims at orchestrating units and errors in a new data type, but will also extend the existing frameworks (compatibility with base R as well as other frameworks such as the tidyverse) and standardise how to import/export data with units and errors.\n\n\n\nFunded:\n$10,000\nProposed by:\nRichard Beare\nWebsite:\nhttps://github.com/richardbeare/RConsortiumSwig\nSummary:\nThe Simplified Wrapper and Interface Generator (SWIG) is a tool for automatically generating interface code between interpreters, including R, and a C or C++ library. The R module needs to be updated to support modern developments in R and the rest of SWIG. This project aims to make the R module conform to the recommended SWIG standards and thus ensure that there is support for R in the future. We hope that this project will be the first step in allowing SWIG generated R code using reference classes."
  },
  {
    "objectID": "all-projects/2017-group-2.html#funded-isc-grants-2017-2",
    "href": "all-projects/2017-group-2.html#funded-isc-grants-2017-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAn Earth data processing backend for testing and evaluating stars\nFuture Minimal API: Specification with Backend Conformance Test Suite\nQuantities for R\nRefactoring and updating the SWIG R module\n\n\n\n\nFunded:\n$5,000\nProposed by:\nEdzer Pebesma\nWebsite:\nhttps://r-spatial.github.io/stars/\nSummary:\nThe stars project enables the processing Earth imagery data that is held on servers, without the need to download it to local hard driver. This project will (i) create software to run a back-end, (ii) develop scripts and tutorials that explain how such a data server and processing backend can be set up, and (iii) create an instance of such a backend in the AWS cloud that can be used for testing and evaluation purposes.\n\n\n\nFunded:\n$10,000\nProposed by:\nHenrik Bengtsson\nWebsite:\nhttps://github.com/HenrikBengtsson/\nSummary:\nThe objective of the Future Framework implemented in the future package is to simplify how parallel and distributed processing is conducted in R. This project aims to provide a formal Future API specification and provide a test framework for validating the conformance of existing (e.g. future.batchtools and future.callr) and to-come third-party parallel backends to the Future framework.\n\n\n\nFunded:\n$10,000\nProposed by:\nInaki Ucar\nWebsite:\nhttps://github.com/r-quantities/quantities and https://www.r-spatial.org/r/2018/08/31/quantities-final.html\nSummary:\nThe ‘units’ package has become the reference for quantity calculus in R, with a wide and welcoming response from the R community. Along the same lines, the ‘errors’ package integrates and automatises error propagation and printing for R vectors. A significant fraction of R users, both practitioners and researchers, use R to analyse measurements, and would benefit from a joint processing of quantity values with errors.\nThis project not only aims at orchestrating units and errors in a new data type, but will also extend the existing frameworks (compatibility with base R as well as other frameworks such as the tidyverse) and standardise how to import/export data with units and errors.\n\n\n\nFunded:\n$10,000\nProposed by:\nRichard Beare\nWebsite:\nhttps://github.com/richardbeare/RConsortiumSwig\nSummary:\nThe Simplified Wrapper and Interface Generator (SWIG) is a tool for automatically generating interface code between interpreters, including R, and a C or C++ library. The R module needs to be updated to support modern developments in R and the rest of SWIG. This project aims to make the R module conform to the recommended SWIG standards and thus ensure that there is support for R in the future. We hope that this project will be the first step in allowing SWIG generated R code using reference classes."
  },
  {
    "objectID": "all-projects/2022-group-2.html",
    "href": "all-projects/2022-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nD3po: R Package for Easy Interactive D3 Visualization With Shiny\nTooling and Guidance for Translations of Markdown-Based R Content  Quarto, R Markdown\nOnline Submission and Review Infrastructure for the R Journal\nUpgrading SatRdays Website Template\nBuilding the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure\n\n\n\n\nFunded:\n$8,000\nProposed by:\nMauricio “Pacho” Vargas Sepulveda\nSummary:\nThe D3po: R Package for Easy Interactive D3 Visualization With Shiny project plans to finish a new version of d3po and include maps and other plot types available in highcharts. This project aims to provide out-of-the-box high-quality visualizations with minimum time and coding effort.\nThe ultimate aim of the project is to produce a package that:\n\nOffers integration with Shiny\nEnables downloading the charts in different image formats (png, jpeg, svg)\nEnables downloading the data in different formats (json, csv, xlsx)\nCan produce high-quality results with a minimal number of lines of code\n\n“I figured out that d3po sounded like c3po from Star Wars, also a Chilean will read it as “dee three POH”, and “poh” is Chilean slang that reflects the “necessity is the mother of invention” spirit that Chileans have.” - Mauricio “Pacho” Vargas Sepulveda\n\n\n\nFunded:\n$8,000\nProposed by:\nMaëlle Salmon\nSummary:\nTooling and Guidance for Translations of Markdown-Based R Content (Quarto, R Markdown) focuses on the achievement of a first version of translated material, both technically (tooling to create an automatically translated document) and linguistically (glossary). With this proposal, the project will aim to share the rOpenSci workflow with others via the creation of an R package including extensive documentation.\n\n\n\nFunded:\n$22,000\nProposed by:\nSimon Urbanek\nSummary:\nThe Online Submission and Review Infrastructure for the R Journal ISC-funded project aims to address problems with the current all-manual revision infrastructure for submissions in the R Journal. The project proposes the development and deployment of an online, web-based system that ties into the existing status management infrastructure but allows for reviews and submission management to be performed online. The ISC funds will be used to assist with the development of an online front-end for the management of articles for the R Journal, including submission, checking, and peer-review tracking of articles. The system will leverage the existing rj and rjtools packages which provide the back-end, but will add a web interface to the process from submission to reviews and article management.\n\n\n\nFunded:\n$6,000\nProposed by:\nBen Ubah\nSummary:\nThe Upgrading SatRdays Website Template project addresses the SatRdays event website templates, which are used by the R community looking to run a SatRday event. The goal of this project is to upgrade the SatRdays website template with a view to make it easy for R community organizers to spin up their own SatRday website without deep knowledge of technologies like Hugo (upon which the current template is based using an R package like blogdown. There will also be documentation of this development with easy-to-follow instructions that are beginner-friendly.\n\n\n\nFunded:\n$25,000\nProposed by:\nOrhun Aydin\nSummary:\nThe Building the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure project proposes to deliver a set of self-contained online training modules on spatial and spatiotemporal data science with R. The modules will consist of focus-areas pertinent to topics frequently requested by the spatial R community using a large number of packages from CRAN Spatial Task View and Spatiotemporal Task View. The deliverable will provide the R Consortium and community with the materials needed to solicit more lessons from the community while ensuring uniformity across lessons."
  },
  {
    "objectID": "all-projects/2022-group-2.html#funded-isc-grants-2022-2",
    "href": "all-projects/2022-group-2.html#funded-isc-grants-2022-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nD3po: R Package for Easy Interactive D3 Visualization With Shiny\nTooling and Guidance for Translations of Markdown-Based R Content  Quarto, R Markdown\nOnline Submission and Review Infrastructure for the R Journal\nUpgrading SatRdays Website Template\nBuilding the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure\n\n\n\n\nFunded:\n$8,000\nProposed by:\nMauricio “Pacho” Vargas Sepulveda\nSummary:\nThe D3po: R Package for Easy Interactive D3 Visualization With Shiny project plans to finish a new version of d3po and include maps and other plot types available in highcharts. This project aims to provide out-of-the-box high-quality visualizations with minimum time and coding effort.\nThe ultimate aim of the project is to produce a package that:\n\nOffers integration with Shiny\nEnables downloading the charts in different image formats (png, jpeg, svg)\nEnables downloading the data in different formats (json, csv, xlsx)\nCan produce high-quality results with a minimal number of lines of code\n\n“I figured out that d3po sounded like c3po from Star Wars, also a Chilean will read it as “dee three POH”, and “poh” is Chilean slang that reflects the “necessity is the mother of invention” spirit that Chileans have.” - Mauricio “Pacho” Vargas Sepulveda\n\n\n\nFunded:\n$8,000\nProposed by:\nMaëlle Salmon\nSummary:\nTooling and Guidance for Translations of Markdown-Based R Content (Quarto, R Markdown) focuses on the achievement of a first version of translated material, both technically (tooling to create an automatically translated document) and linguistically (glossary). With this proposal, the project will aim to share the rOpenSci workflow with others via the creation of an R package including extensive documentation.\n\n\n\nFunded:\n$22,000\nProposed by:\nSimon Urbanek\nSummary:\nThe Online Submission and Review Infrastructure for the R Journal ISC-funded project aims to address problems with the current all-manual revision infrastructure for submissions in the R Journal. The project proposes the development and deployment of an online, web-based system that ties into the existing status management infrastructure but allows for reviews and submission management to be performed online. The ISC funds will be used to assist with the development of an online front-end for the management of articles for the R Journal, including submission, checking, and peer-review tracking of articles. The system will leverage the existing rj and rjtools packages which provide the back-end, but will add a web interface to the process from submission to reviews and article management.\n\n\n\nFunded:\n$6,000\nProposed by:\nBen Ubah\nSummary:\nThe Upgrading SatRdays Website Template project addresses the SatRdays event website templates, which are used by the R community looking to run a SatRday event. The goal of this project is to upgrade the SatRdays website template with a view to make it easy for R community organizers to spin up their own SatRday website without deep knowledge of technologies like Hugo (upon which the current template is based using an R package like blogdown. There will also be documentation of this development with easy-to-follow instructions that are beginner-friendly.\n\n\n\nFunded:\n$25,000\nProposed by:\nOrhun Aydin\nSummary:\nThe Building the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure project proposes to deliver a set of self-contained online training modules on spatial and spatiotemporal data science with R. The modules will consist of focus-areas pertinent to topics frequently requested by the spatial R community using a large number of packages from CRAN Spatial Task View and Spatiotemporal Task View. The deliverable will provide the R Consortium and community with the materials needed to solicit more lessons from the community while ensuring uniformity across lessons."
  },
  {
    "objectID": "all-projects/2022-group-1.html",
    "href": "all-projects/2022-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nIterdatasampler: Expanding the lterdatasampler package\nFemr: Finite Element Method for Solving PDEs in R\nContinuing to Improve R’s Ability to Visualise and Explore Missing Values\nDengue Data Hub\n\n\n\n\nFunded:\n$15,000\nProposed by:\nJulien Brun and Allison Horst\nSummary:\nExpanding the lterdatasampler Package addresses the need for accessible and relevant datasets in data science education. It aims to provide modern, curated, and approachable environmental data samples from the US Long Term Ecological Research Network (LTER) through the lterdatasampler R package. By offering datasets that save time for instructors, engage students with meaningful data, and foster discussions based on real-world questions.The package serves as a valuable resource for teaching introductory statistics and data science in R. The project seeks funding to expand the package to include data samples from all 28 LTER network sites, with the goal of modernizing course materials with real-world environmental datasets.\n\n\n\nFunded:\n$20,000\nProposed by:\nLaura Sangalli\nSummary:\nFemr: There is a need for implementing finite element methods (FEM) in R to solve partial differential equations (PDEs). PDEs are crucial mathematical tools used for modeling complex phenomena in various scientific and engineering fields. However, the absence of FEM implementations in R necessitates the reliance on external software, discouraging the statistical community from developing methods involving PDEs and hindering the learning of this essential mathematical tool. The goal of the project is to develop the femR package, which will provide a finite element basis for solving second-order linear elliptic PDEs on general two-dimensional spatial domains in R.\nThis package will complement the existing deSolve package and enable users to employ finite elements instead of finite differences for solving PDEs on more diverse spatial domains. The development process will include providing comprehensive examples and a final vignette to guide users in utilizing the package’s functionalities.\n\n\n\nFunded:\n$5,000\nProposed by:\nNicholas Tierney\nSummary:\nThe proposal for “Continuing to Improve R’s Ability to Visualise and Explore Missing Values” addresses missing values in data analysis. Missing values are often dropped by default in data analysis in various stages. There is often not even a warning displayed to alert the user of missing values being dropped or discarded. This means values can be dropped without the user knowing, leading to issues such as potential bias, where missing values might be occurring in high numbers in particular groups.\nThe proposal for the ISC-funded project addressed this problem in four parts:\n\nPart one: Initial evaluation of additional missing data visualizations\nPart two: Implementation of missing data visualizations\nPart three: Will provide tutorials and workflows.\nPart four: Future extensions and beyond\n\n\n\n\nFunded:\n$2,000\nProposed by:\nThiyanga Talagala\nSummary:\nThe Dengue Data Hub project helps addresses data packages related to Dengue. Dengue is a mosquito-borne viral disease that has spread fast throughout the world, primarily in urban and semi-urban regions. The goal of the Dengue Data Hub is to provide the research community with a unified dataset helpful for dengue research and reproducibility of research. The project proposes the creation of an R package for aggregating dengue data from several sources and the ability to share them in tidy format. Based on the proposal, there will also be tutorials and good documentation for using the “Dengue Data Hub” interface. This will motivate epidemiology researchers to utilize R to analyze their data."
  },
  {
    "objectID": "all-projects/2022-group-1.html#funded-isc-grants-2022-1",
    "href": "all-projects/2022-group-1.html#funded-isc-grants-2022-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nIterdatasampler: Expanding the lterdatasampler package\nFemr: Finite Element Method for Solving PDEs in R\nContinuing to Improve R’s Ability to Visualise and Explore Missing Values\nDengue Data Hub\n\n\n\n\nFunded:\n$15,000\nProposed by:\nJulien Brun and Allison Horst\nSummary:\nExpanding the lterdatasampler Package addresses the need for accessible and relevant datasets in data science education. It aims to provide modern, curated, and approachable environmental data samples from the US Long Term Ecological Research Network (LTER) through the lterdatasampler R package. By offering datasets that save time for instructors, engage students with meaningful data, and foster discussions based on real-world questions.The package serves as a valuable resource for teaching introductory statistics and data science in R. The project seeks funding to expand the package to include data samples from all 28 LTER network sites, with the goal of modernizing course materials with real-world environmental datasets.\n\n\n\nFunded:\n$20,000\nProposed by:\nLaura Sangalli\nSummary:\nFemr: There is a need for implementing finite element methods (FEM) in R to solve partial differential equations (PDEs). PDEs are crucial mathematical tools used for modeling complex phenomena in various scientific and engineering fields. However, the absence of FEM implementations in R necessitates the reliance on external software, discouraging the statistical community from developing methods involving PDEs and hindering the learning of this essential mathematical tool. The goal of the project is to develop the femR package, which will provide a finite element basis for solving second-order linear elliptic PDEs on general two-dimensional spatial domains in R.\nThis package will complement the existing deSolve package and enable users to employ finite elements instead of finite differences for solving PDEs on more diverse spatial domains. The development process will include providing comprehensive examples and a final vignette to guide users in utilizing the package’s functionalities.\n\n\n\nFunded:\n$5,000\nProposed by:\nNicholas Tierney\nSummary:\nThe proposal for “Continuing to Improve R’s Ability to Visualise and Explore Missing Values” addresses missing values in data analysis. Missing values are often dropped by default in data analysis in various stages. There is often not even a warning displayed to alert the user of missing values being dropped or discarded. This means values can be dropped without the user knowing, leading to issues such as potential bias, where missing values might be occurring in high numbers in particular groups.\nThe proposal for the ISC-funded project addressed this problem in four parts:\n\nPart one: Initial evaluation of additional missing data visualizations\nPart two: Implementation of missing data visualizations\nPart three: Will provide tutorials and workflows.\nPart four: Future extensions and beyond\n\n\n\n\nFunded:\n$2,000\nProposed by:\nThiyanga Talagala\nSummary:\nThe Dengue Data Hub project helps addresses data packages related to Dengue. Dengue is a mosquito-borne viral disease that has spread fast throughout the world, primarily in urban and semi-urban regions. The goal of the Dengue Data Hub is to provide the research community with a unified dataset helpful for dengue research and reproducibility of research. The project proposes the creation of an R package for aggregating dengue data from several sources and the ability to share them in tidy format. Based on the proposal, there will also be tutorials and good documentation for using the “Dengue Data Hub” interface. This will motivate epidemiology researchers to utilize R to analyze their data."
  },
  {
    "objectID": "all-projects/previous-top-level-projects.html",
    "href": "all-projects/previous-top-level-projects.html",
    "title": "Previous Top Level Projects",
    "section": "",
    "text": "R Inclusion, Diversity, Equity and Accessibility (IDEA) was a group broadly considering how the R Consortium could best encourage and support diversity and inclusion in the R Community.\nhttps://github.com/RConsortium/RCDI-WG/tree/master\n\n\n\n\nR-Hub was a platform for simplifying and improving the R package development process.\nR-Hub assisted R package developers by providing facilities to test packages across multiple architectures, build binaries, and publish, distribute and maintain their packages. Developed by Gábor Csárdi, it was being leveraged by R package developers to improve the quality of their packages and to enable support for their packages across multiple architectures.\nhttps://github.com/r-hub."
  },
  {
    "objectID": "all-projects/previous-top-level-projects.html#r-inclusion-diversity-equity-and-accessibility-idea",
    "href": "all-projects/previous-top-level-projects.html#r-inclusion-diversity-equity-and-accessibility-idea",
    "title": "Previous Top Level Projects",
    "section": "",
    "text": "R Inclusion, Diversity, Equity and Accessibility (IDEA) was a group broadly considering how the R Consortium could best encourage and support diversity and inclusion in the R Community.\nhttps://github.com/RConsortium/RCDI-WG/tree/master"
  },
  {
    "objectID": "all-projects/previous-top-level-projects.html#r-hub",
    "href": "all-projects/previous-top-level-projects.html#r-hub",
    "title": "Previous Top Level Projects",
    "section": "",
    "text": "R-Hub was a platform for simplifying and improving the R package development process.\nR-Hub assisted R package developers by providing facilities to test packages across multiple architectures, build binaries, and publish, distribute and maintain their packages. Developed by Gábor Csárdi, it was being leveraged by R package developers to improve the quality of their packages and to enable support for their packages across multiple architectures.\nhttps://github.com/r-hub."
  },
  {
    "objectID": "all-projects/2020-group-2.html",
    "href": "all-projects/2020-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nDevelopment and maintenance of the Windows build infrastructure (Top level project proposal)\nInteractive visualisations in R via R-to-JavaScript-transpilation\n\n\n\n\nFunded:\n$46,800\nProposed by:\nJeroen Ooms\nSummary:\nAs of R 4.0.0 (released April 2020), R for Windows uses a brand new toolchain bundle called rtools40. This version upgrades the mingw-gcc toolchains to version 8.3.0, and introduces a powerful new build system based on the widely used msys2 platform, which makes it easier to maintain R itself, as well as system libraries needed for developing R and R-packages.\nThe current project seeks to build out this system to improve tooling for building and debugging on Windows, and move towards a scalable build infrastructure, which is transparent, extensible, and fully automated. Thereby we can empower development on Windows, and support further growth of the R ecosystem while relieving work for CRAN and R-core members.\n\n\n\nFunded:\n$9,688\nProposed by:\nChun Fung Kwok\nWebsite:\nhttps://github.com/kcf-jackson/sketch and https://cran.r-project.org/package=sketch\nSummary:\nThis project aims to make creating flexible interactive visualisation accessible to a wider R community. By implementing an R-to-JavaScript transpiler, i.e. a program that translates R code into JavaScript code, it lets R users develop JavaScript(JS) applications using solely the R syntax. This eliminates the need to pick up an entire new language, makes it easy for R users to learn and experiment with JS technologies and gives direct and full access to all existing JS libraries. The transpiler is distributed as a regular R package, and it can be used standalone or to complement existing packages, including Rmarkdown, shiny and V8."
  },
  {
    "objectID": "all-projects/2020-group-2.html#funded-isc-grants-2020-2",
    "href": "all-projects/2020-group-2.html#funded-isc-grants-2020-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nDevelopment and maintenance of the Windows build infrastructure (Top level project proposal)\nInteractive visualisations in R via R-to-JavaScript-transpilation\n\n\n\n\nFunded:\n$46,800\nProposed by:\nJeroen Ooms\nSummary:\nAs of R 4.0.0 (released April 2020), R for Windows uses a brand new toolchain bundle called rtools40. This version upgrades the mingw-gcc toolchains to version 8.3.0, and introduces a powerful new build system based on the widely used msys2 platform, which makes it easier to maintain R itself, as well as system libraries needed for developing R and R-packages.\nThe current project seeks to build out this system to improve tooling for building and debugging on Windows, and move towards a scalable build infrastructure, which is transparent, extensible, and fully automated. Thereby we can empower development on Windows, and support further growth of the R ecosystem while relieving work for CRAN and R-core members.\n\n\n\nFunded:\n$9,688\nProposed by:\nChun Fung Kwok\nWebsite:\nhttps://github.com/kcf-jackson/sketch and https://cran.r-project.org/package=sketch\nSummary:\nThis project aims to make creating flexible interactive visualisation accessible to a wider R community. By implementing an R-to-JavaScript transpiler, i.e. a program that translates R code into JavaScript code, it lets R users develop JavaScript(JS) applications using solely the R syntax. This eliminates the need to pick up an entire new language, makes it easy for R users to learn and experiment with JS technologies and gives direct and full access to all existing JS libraries. The transpiler is distributed as a regular R package, and it can be used standalone or to complement existing packages, including Rmarkdown, shiny and V8."
  },
  {
    "objectID": "all-projects/submittingforpayment.html",
    "href": "all-projects/submittingforpayment.html",
    "title": "Submitting for payment",
    "section": "",
    "text": "Submitting for payment\nThe R Consortium provides financial support to a broad range of initiatives, in support of the global R development and user community. When organizations become members of the R Consortium, their membership dues help provide this funding, and help ensure the overall health of the ecosystem.\nThe R Consortium provides funding through a structured process. The primary funding categories are:\n\nISC Grants, which are allocated by the Infrastructure Steering Committee through an application process, and support code and community development efforts.\nRUGs Grants, which support local R User Groups.\n\nAll grant payments must be pre-approved. Please follow the formal process established by each working group to apply for funding.\n\nInvoicing for your grant\nStarting in October 2020, each grant recipient will receive a control number. Please ensure that you include this in all requests for payment. If you are unsure of your control number, please contact operations@r-consortium.org.\nWhen you are ready to submit for payment, please complete the payment request form. You will be asked to provide the following, so please have it ready:\n\nThe control number for your grant.\nA W9 form (if you are in the US and have a SSN/EIN) or an international wire form.\nThe signed contract or a PDF of the email approving your grant.\nA brief description of how the funding was used (e.g., project milestone, RUGs or R-Ladies meetup, etc).\n\nIf you have any questions, please contact operations@r-consortium.org."
  },
  {
    "objectID": "all-projects/2016-group-2.html",
    "href": "all-projects/2016-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nInteractive data manipulation in mapview\nR Documentation Task Force\n\n\n\n\nFunded:\n$9,100\nProposed by:\nTim Appelhans\nWebsite:\nhttps://github.com/environmentalinformatics-marburg/mapview_toolchain and https://cran.r-project.org/package=mapview\nSummary:\nThe ISC awarded $9,100 to Tim Appelhans, Florian Detsch and Christoph Reudenbach the authors of the Interactive data manipulation in mapview project which aims to extend the capabilities of R for visualizing geospatial data by implementing a two-way data exchange mechanism between R and JavaScript. The central idea is to extend the capabilities of existing tools to enhance the user experience of interactively working with geospatial data by implementing mechanisms for two way data transfer. For example, although htmlwidgets has proven itself to be a powerful framework for enabling interactive, JavaScript based data visualizations, data flow from R to Javascript runs on a one-way street. There is currently no way to pass manipulated data back into the user’s R environment. This project aims to first develop a general framework to provide a bridge between htmlwidgets and R to enable a workflow of R -&gt; htmlwidgets -&gt; R and then to use this framework to implement standard interactive spatial data manipulation tools for packages mapview and leaflet. The plan section of the project proposal provides considerable detail on the steps required to achieve the project’s goals.\n\n\n\nFunded:\n$10,000\nProposed by:\nAndrew Redd\nWebsite:\nhttps://github.com/RDocTaskForce/documentation\nSummary:\nAndrew Redd received $10,000 to lead a new ISC working group, The R Documentation Task Force, which has a mission to design and build the next generation R documentation system. The task force will identify issues with documentation that currently exist, abstract the current Rd system into an R compatible structure, and extend this structure to include new considerations that were not concerns when the Rd system was first implemented. The goal of the project is to create a system that allows for documentation to exist as objects that can be manipulated inside R. This will make the process of creating R documentation much more flexible enabling new capabilities such as porting documentation from other languages or creating inline comments. The new capabilities will add rigor to the documentation process and enable the the system to operate more efficiently than any current methods allow."
  },
  {
    "objectID": "all-projects/2016-group-2.html#funded-isc-grants-2016-2",
    "href": "all-projects/2016-group-2.html#funded-isc-grants-2016-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nInteractive data manipulation in mapview\nR Documentation Task Force\n\n\n\n\nFunded:\n$9,100\nProposed by:\nTim Appelhans\nWebsite:\nhttps://github.com/environmentalinformatics-marburg/mapview_toolchain and https://cran.r-project.org/package=mapview\nSummary:\nThe ISC awarded $9,100 to Tim Appelhans, Florian Detsch and Christoph Reudenbach the authors of the Interactive data manipulation in mapview project which aims to extend the capabilities of R for visualizing geospatial data by implementing a two-way data exchange mechanism between R and JavaScript. The central idea is to extend the capabilities of existing tools to enhance the user experience of interactively working with geospatial data by implementing mechanisms for two way data transfer. For example, although htmlwidgets has proven itself to be a powerful framework for enabling interactive, JavaScript based data visualizations, data flow from R to Javascript runs on a one-way street. There is currently no way to pass manipulated data back into the user’s R environment. This project aims to first develop a general framework to provide a bridge between htmlwidgets and R to enable a workflow of R -&gt; htmlwidgets -&gt; R and then to use this framework to implement standard interactive spatial data manipulation tools for packages mapview and leaflet. The plan section of the project proposal provides considerable detail on the steps required to achieve the project’s goals.\n\n\n\nFunded:\n$10,000\nProposed by:\nAndrew Redd\nWebsite:\nhttps://github.com/RDocTaskForce/documentation\nSummary:\nAndrew Redd received $10,000 to lead a new ISC working group, The R Documentation Task Force, which has a mission to design and build the next generation R documentation system. The task force will identify issues with documentation that currently exist, abstract the current Rd system into an R compatible structure, and extend this structure to include new considerations that were not concerns when the Rd system was first implemented. The goal of the project is to create a system that allows for documentation to exist as objects that can be manipulated inside R. This will make the process of creating R documentation much more flexible enabling new capabilities such as porting documentation from other languages or creating inline comments. The new capabilities will add rigor to the documentation process and enable the the system to operate more efficiently than any current methods allow."
  },
  {
    "objectID": "all-projects/2019-group-2.html",
    "href": "all-projects/2019-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAn External R Sampling Profiler\nCVXR\nFlipbooks\nR Package Risk Assessment Application\nRcppDeepState, a simple way to fuzz test compiled code in R packages\nSymbolic mathematics in R with SymPy\nTidy spatial networks in R\nd3po: R package for easy interactive D3 visualization with Shiny\nwebchem: accessing chemical information from the web\n\n\n\n\nFunded:\n$8,500\nProposed by:\nAaron Jacobs\nWebsite:\nhttps://github.com/atheriel/xrprof\nSummary:\nMany R users will be familiar with using the built-in sampling profiler ‘Rprof()’ to generate data on what their code is doing, and there are several excellent tools to facilitate understanding these samples (or serve as a front-end), including the ‘profvis’ package. However, the reach of these tools is limited: the profiler is “internal”, in the sense that it must be manually switched on to work, either during interactive work (for example, to profile an individual function), or perhaps by modifying the script to include ‘Rprof()’ calls before running it again. It cannot be used to understand R code that is already running, a capability that has proven extremely useful for diagnosing and fixing performance issues (or other bugs) in production environments.\nSeveral existing programming languages have one or more “external” profilers available, which can attach to a running process and read its memory contents to understand what is currently happening. This project aims to build such a tool for R.\n\n\n\nFunded:\n$9,500\nProposed by:\nDavid W Kang\nWebsite:\nhttps://github.com/cvxgrp/CVXR\nSummary:\nOptimization is at the core of statistical estimation and machine learning methodology. There are a number of R packages such as optimx, nloptr, ROI which either implement solvers for a wide variety of problems, or provide an interface to other solvers. The R package CVXR takes a different approach, implementing a Domain Specific Language (Fu, Narasimhan, and Boyd 2019) for formulating and solving convex optimization problems, just as cvxpy does for python. As shown in a number of examples on the CVXR website, the applications range from finance, machine learning, and to theoretical and applied statistics. Using a disciplined convex programming (DCP) approach, CVXR acts as a great tool for both prototyping and developing new methodologies as well as for quick, high-level, formulation and solution of statistical and machine learning problems.\n\n\n\nFunded:\n$6,699\nProposed by:\nEvangeline Reynolds\nWebsite:\nhttps://github.com/EvaMaeRey/flipbookr\nSummary:\nJust as classic flip books allow their readers to observe changes in a scene, coding Flipbooks allow readers to progressively track the changes of code and its output by “flipping” through their digital pages. Flipbooks are useful tools for communicating and teaching because they break down code for incremental, stepwise presentation so that audiences can easily understand each step. Flipbook-building tools automate the deconstruction and reconstruction of coding pipelines which means that building a Flipbook from existing code poses little additional burden to creators. The next stage for this project is to develop the current Flipbook-building tools into a reliable and easy-to-use R package (development is ongoing at https://github.com/EvaMaeRey/flipbookr) and also to provide educational guidance for creating Flipbooks.\n\n\n\nFunded:\n$16,800\nProposed by:\nAndrew Nicholls\nWebsite:\nhttps://www.pharmar.org/\nSummary:\nThe R Validation Hub is an active R Consortium Working Group. It is a cross-industry initiative whose mission is to enable the use of R by the Bio-Pharmaceutical Industry in a regulatory setting, where the output may be used in submissions to regulatory agencies. This project sits within phase 2 of the R Validation Hub’s road map. During this phase the group will develop several tools that can be used by those wishing to use R packages within a bio-pharmaceutical regulatory setting. The aim of this specific project is to standardise and simplify the risk assessment of R packages, reducing the burden of package evaluation/testing that would otherwise fall on internal R programming experts. The project will deliver a Shiny application to aid in the assessment and documentation of package risk.\n\n\n\nFunded:\n$34,000\nProposed by:\nToby Hocking\nWebsite:\nhttps://github.com/akhikolla/RcppDeepState\nSummary:\nAbstract: Fuzzers are computer programs that send other programs inputs that may fall outside the domain of expected values, thus revealing subtle bugs. DeepState is a testing framework that allows easy testing of C/C++ programs with sophisticated fuzzers, and supports multiple back-ends for testing. DeepState has been used to test critical C++ software, including Google’s leveldb. R has some simple random testers, but no coverage-driven fuzzers that learn to produce problematic inputs. We propose to create the R packages RcppDeepState and RcppDeepStateTools which will provide easy-to-use functions for using DeepState with R packages that use C/C++ code via Rcpp. This project will thus provide the first easy-to-use solution for R programmers that want to fuzz test their C/C++ code with existing tools such as AFL, and it will provide a framework for interfacing future coverage-driven fuzzers or symbolic execution tools. We also propose to use these new tools on a wide range of R packages in order to identify bugs in their C/C++ code.\nOne masters student will be recruited to implement this project during Jan-Dec 2020 at the School of Informatics, Computing, and Cyber Systems at Northern Arizona University. Interested students should apply by emailing a resume/CV along with a cover letter to project supervisors toby.hocking@nau.edu and alex.groce@nau.edu.\n\n\n\nFunded:\n$10,000\nProposed by:\nMikkel Meyer Andersen\nWebsite:\nhttps://github.com/r-cas/caracas/\nSummary:\nR’s ability to do symbolic mathematics is largely restricted to finding derivatives. There are many tasks involving symbolic math that are of interest to R users, e.g. inversion of symbolic matrices, limits and solving non-linear equations. Users must resort to other software for such tasks and many R users (especially outside of academia) do not readily have access to such software.\nThe Python library SymPy is open source, has a stable group of developers and is powerful. As such, R users can just switch to Python and SymPy for symbolic math. However it is often very convenient to stay in the same environment to use familiar syntax and to utilise available libraries (e.g. to generate problems using symbolic math together with the exams package or to first handle symbolic computations and then afterwards move on to a numerical evaluations of the results). We will achieve this by making SymPy functionality available for R users via an R package.\nCurrently only few R packages for doing symbolic mathematics are available: Two of these are Ryacas and rSymPy. Ryacas is built around Yacas, and although Yacas can solve many problems and is extensible, the community is relatively small and Yacas is not as powerful as SymPy for certain routine tasks (e.g. integration and solving equations). rSymPy on the other hand is based on technology that requires much technical work to install and use.\nThe website of the project is:\nhttps://github.com/r-cas/caracas/\nPlease contribute by testing, writing documentation, opening issues, submitting pull requests or something else!\n\n\n\nFunded:\n$9,000\nProposed by:\nLucas van der Meer, Robin Lovelace, Andrea Gilardi, Lorena Abad\nWebsite:\nhttps://luukvdmeer.github.io/sfnetworks/\nSummary:\nR is currently lacking a generally applicable, modern and easy-to-use way of handling all kinds of spatial networks. “Tidy spatial networks in R” aims to address this issue by developing and publishing the sfnetworks package. The package, and documentation around it, will provide a bridge between network analysis and spatial analysis communities. For this, an sfnetwork class that will work with both tidygraph and sf frameworks and functions. R-users will be encouraged to contribute and engage with the package development during a hackathon organized next to the eRum 2020.\n\n\n\nFunded:\n$4,000\nProposed by:\nMauricio Vargas Sepúlveda\nWebsite:\nhttps://github.com/pachamaltese/d3po\nSummary:\nR already features excellent visualization libraries such as D3 (via the r2d3 package), plotly or highcharter. However, though those enable the creation of great looking visualisations they have very steep learning curves, require understanding of JavaScript or rely on non-free software that might be out of reach for governments and NGOs. Our intention is to solve those problems by releasing d3po. It shall be an intermediate layer between the user and D3 by providing “templates”, enabling high quality interactive visualizations oriented to and designed to be used with Shiny and Rmarkdown, and also proving easy internationalization. Please join us, this needs D3 and R skilled minds!\n\n\n\nFunded:\n$6,000\nProposed by:\nEric Scott, Tamas Stirling\nWebsite:\nhttps://github.com/ropensci/webchem\nSummary:\nwebchem: accessing chemical information from the web\nA vast amount of chemical information is freely available on the internet. The data are used by millions of professionals around the world, for purposes like pharmaceutical research, chemical process design, or environmental impact assessment, to name a few. webchem is an R project that aims to help these professionals by providing a single point programmable access to all major chemical databases around the world. The project started in 2016 and currently supports more than 10 databases. If you are interested, join us and help us build the tool that biologists and chemists will absolutely love."
  },
  {
    "objectID": "all-projects/2019-group-2.html#funded-isc-grants-2019-2",
    "href": "all-projects/2019-group-2.html#funded-isc-grants-2019-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nAn External R Sampling Profiler\nCVXR\nFlipbooks\nR Package Risk Assessment Application\nRcppDeepState, a simple way to fuzz test compiled code in R packages\nSymbolic mathematics in R with SymPy\nTidy spatial networks in R\nd3po: R package for easy interactive D3 visualization with Shiny\nwebchem: accessing chemical information from the web\n\n\n\n\nFunded:\n$8,500\nProposed by:\nAaron Jacobs\nWebsite:\nhttps://github.com/atheriel/xrprof\nSummary:\nMany R users will be familiar with using the built-in sampling profiler ‘Rprof()’ to generate data on what their code is doing, and there are several excellent tools to facilitate understanding these samples (or serve as a front-end), including the ‘profvis’ package. However, the reach of these tools is limited: the profiler is “internal”, in the sense that it must be manually switched on to work, either during interactive work (for example, to profile an individual function), or perhaps by modifying the script to include ‘Rprof()’ calls before running it again. It cannot be used to understand R code that is already running, a capability that has proven extremely useful for diagnosing and fixing performance issues (or other bugs) in production environments.\nSeveral existing programming languages have one or more “external” profilers available, which can attach to a running process and read its memory contents to understand what is currently happening. This project aims to build such a tool for R.\n\n\n\nFunded:\n$9,500\nProposed by:\nDavid W Kang\nWebsite:\nhttps://github.com/cvxgrp/CVXR\nSummary:\nOptimization is at the core of statistical estimation and machine learning methodology. There are a number of R packages such as optimx, nloptr, ROI which either implement solvers for a wide variety of problems, or provide an interface to other solvers. The R package CVXR takes a different approach, implementing a Domain Specific Language (Fu, Narasimhan, and Boyd 2019) for formulating and solving convex optimization problems, just as cvxpy does for python. As shown in a number of examples on the CVXR website, the applications range from finance, machine learning, and to theoretical and applied statistics. Using a disciplined convex programming (DCP) approach, CVXR acts as a great tool for both prototyping and developing new methodologies as well as for quick, high-level, formulation and solution of statistical and machine learning problems.\n\n\n\nFunded:\n$6,699\nProposed by:\nEvangeline Reynolds\nWebsite:\nhttps://github.com/EvaMaeRey/flipbookr\nSummary:\nJust as classic flip books allow their readers to observe changes in a scene, coding Flipbooks allow readers to progressively track the changes of code and its output by “flipping” through their digital pages. Flipbooks are useful tools for communicating and teaching because they break down code for incremental, stepwise presentation so that audiences can easily understand each step. Flipbook-building tools automate the deconstruction and reconstruction of coding pipelines which means that building a Flipbook from existing code poses little additional burden to creators. The next stage for this project is to develop the current Flipbook-building tools into a reliable and easy-to-use R package (development is ongoing at https://github.com/EvaMaeRey/flipbookr) and also to provide educational guidance for creating Flipbooks.\n\n\n\nFunded:\n$16,800\nProposed by:\nAndrew Nicholls\nWebsite:\nhttps://www.pharmar.org/\nSummary:\nThe R Validation Hub is an active R Consortium Working Group. It is a cross-industry initiative whose mission is to enable the use of R by the Bio-Pharmaceutical Industry in a regulatory setting, where the output may be used in submissions to regulatory agencies. This project sits within phase 2 of the R Validation Hub’s road map. During this phase the group will develop several tools that can be used by those wishing to use R packages within a bio-pharmaceutical regulatory setting. The aim of this specific project is to standardise and simplify the risk assessment of R packages, reducing the burden of package evaluation/testing that would otherwise fall on internal R programming experts. The project will deliver a Shiny application to aid in the assessment and documentation of package risk.\n\n\n\nFunded:\n$34,000\nProposed by:\nToby Hocking\nWebsite:\nhttps://github.com/akhikolla/RcppDeepState\nSummary:\nAbstract: Fuzzers are computer programs that send other programs inputs that may fall outside the domain of expected values, thus revealing subtle bugs. DeepState is a testing framework that allows easy testing of C/C++ programs with sophisticated fuzzers, and supports multiple back-ends for testing. DeepState has been used to test critical C++ software, including Google’s leveldb. R has some simple random testers, but no coverage-driven fuzzers that learn to produce problematic inputs. We propose to create the R packages RcppDeepState and RcppDeepStateTools which will provide easy-to-use functions for using DeepState with R packages that use C/C++ code via Rcpp. This project will thus provide the first easy-to-use solution for R programmers that want to fuzz test their C/C++ code with existing tools such as AFL, and it will provide a framework for interfacing future coverage-driven fuzzers or symbolic execution tools. We also propose to use these new tools on a wide range of R packages in order to identify bugs in their C/C++ code.\nOne masters student will be recruited to implement this project during Jan-Dec 2020 at the School of Informatics, Computing, and Cyber Systems at Northern Arizona University. Interested students should apply by emailing a resume/CV along with a cover letter to project supervisors toby.hocking@nau.edu and alex.groce@nau.edu.\n\n\n\nFunded:\n$10,000\nProposed by:\nMikkel Meyer Andersen\nWebsite:\nhttps://github.com/r-cas/caracas/\nSummary:\nR’s ability to do symbolic mathematics is largely restricted to finding derivatives. There are many tasks involving symbolic math that are of interest to R users, e.g. inversion of symbolic matrices, limits and solving non-linear equations. Users must resort to other software for such tasks and many R users (especially outside of academia) do not readily have access to such software.\nThe Python library SymPy is open source, has a stable group of developers and is powerful. As such, R users can just switch to Python and SymPy for symbolic math. However it is often very convenient to stay in the same environment to use familiar syntax and to utilise available libraries (e.g. to generate problems using symbolic math together with the exams package or to first handle symbolic computations and then afterwards move on to a numerical evaluations of the results). We will achieve this by making SymPy functionality available for R users via an R package.\nCurrently only few R packages for doing symbolic mathematics are available: Two of these are Ryacas and rSymPy. Ryacas is built around Yacas, and although Yacas can solve many problems and is extensible, the community is relatively small and Yacas is not as powerful as SymPy for certain routine tasks (e.g. integration and solving equations). rSymPy on the other hand is based on technology that requires much technical work to install and use.\nThe website of the project is:\nhttps://github.com/r-cas/caracas/\nPlease contribute by testing, writing documentation, opening issues, submitting pull requests or something else!\n\n\n\nFunded:\n$9,000\nProposed by:\nLucas van der Meer, Robin Lovelace, Andrea Gilardi, Lorena Abad\nWebsite:\nhttps://luukvdmeer.github.io/sfnetworks/\nSummary:\nR is currently lacking a generally applicable, modern and easy-to-use way of handling all kinds of spatial networks. “Tidy spatial networks in R” aims to address this issue by developing and publishing the sfnetworks package. The package, and documentation around it, will provide a bridge between network analysis and spatial analysis communities. For this, an sfnetwork class that will work with both tidygraph and sf frameworks and functions. R-users will be encouraged to contribute and engage with the package development during a hackathon organized next to the eRum 2020.\n\n\n\nFunded:\n$4,000\nProposed by:\nMauricio Vargas Sepúlveda\nWebsite:\nhttps://github.com/pachamaltese/d3po\nSummary:\nR already features excellent visualization libraries such as D3 (via the r2d3 package), plotly or highcharter. However, though those enable the creation of great looking visualisations they have very steep learning curves, require understanding of JavaScript or rely on non-free software that might be out of reach for governments and NGOs. Our intention is to solve those problems by releasing d3po. It shall be an intermediate layer between the user and D3 by providing “templates”, enabling high quality interactive visualizations oriented to and designed to be used with Shiny and Rmarkdown, and also proving easy internationalization. Please join us, this needs D3 and R skilled minds!\n\n\n\nFunded:\n$6,000\nProposed by:\nEric Scott, Tamas Stirling\nWebsite:\nhttps://github.com/ropensci/webchem\nSummary:\nwebchem: accessing chemical information from the web\nA vast amount of chemical information is freely available on the internet. The data are used by millions of professionals around the world, for purposes like pharmaceutical research, chemical process design, or environmental impact assessment, to name a few. webchem is an R project that aims to help these professionals by providing a single point programmable access to all major chemical databases around the world. The project started in 2016 and currently supports more than 10 databases. If you are interested, join us and help us build the tool that biologists and chemists will absolutely love."
  },
  {
    "objectID": "all-projects/2020-group-1.html",
    "href": "all-projects/2020-group-1.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nConsolidating R-Ladies Global organisational guidance and wisdom\nDatabase interoperability for spatial objects in R\nHTTP testing in R Book\nMATTER 2.0: larger-than-memory data for R\nSpatiotemporal Data and Analytics\nThe RECON COVID-19 challenge: leveraging the R community to improve COVID-19 analytics resources\nsftrack v1.0: Stable API for a broad adoption\n\n\n\n\nFunded:\n$4,000\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://github.com/rladies/starter-kit\nSummary:\nR-Ladies Global is a successful, growing organization aiming at increasing gender diversity in the R community. R-Ladies Global is a Top-Level Project of the ISC. R-Ladies Global guidance for starting and running a chapter, as well as overseeing chapters around the world, and for the rotating curator account, grew organically. The information is fragmented and exists in different formats: several Markdown and PDF Documents and wiki entries in a GitHub repository. This impedes the optimal finding of resources by those who need them, and also impedes contributions. This project aims to consolidate existing R-Ladies Global guidance into a well-structured and continuously deployed online book, with its source open on GitHub, as ( R ) Markdown documents woven together, and whose maintenance will be an R-Ladies major priority task.\nThe project will create a web based manuscript containing all the necessary information to understand what the R-Ladies organization is about, its structure and how to contribute to its mission. Information will be collated and organized leveraging the experience of R-Ladies organizers and volunteers that, over the past 4 years, contributed to the establishment and growth of one of the most active and successful communities in the data science realm. This book will be a crucial resource for R-Ladies and other organizations that are looking to consolidate or create their own guidance.\n\n\n\nFunded:\n$6,000\nProposed by:\nEtienne Racine\nWebsite:\nhttps://github.com/r-spatial/sfdbi\nSummary:\nManipulating spatial data in R sometimes requires interaction with a spatial database: the data doesn’t fit in memory, or simply because this is where the data is. The `sf` package already supports the PostGIS spatial database, but this project will extend the compatibility and make it easier to integrate in the `dplyr` workflow (with `dbplyr`). We also want to make it easier to add support for new database backends. We’ll create a new `sfdbi` package to centralize the interface between `sf` and databases and remove dependencies in `sf`. If you want to contribute, or if you’d like to suggest a database, make sure to join the `sfdbi` repo.\n\n\n\nFunded:\n$16,000\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://github.com/ropensci-books/http-testing\nSummary:\nMore and more R packages access resources on the web, and play crucial roles in workflows: data access and updates for CRM reports (Hubspot APIs), for scientific publications (scientific web APIs, Open Science Framework). Like for all other packages, appropriate unit testing can make them more robust. Their unit testing brings special challenges: dependence of tests on a good internet connection, testing in the absence of authentication secrets, etc. Having tests fail due to resources being down or slow, during development or on CRAN, means a time loss for everyone involved (slower development, messages from CRAN). Although many packages accessing remote resources are well tested, there is a lack of resources around best practices for HTTP testing in packages using httr, crul, or curl. The best guidance to date about HTTP testing for R packages to our knowledge is a forum entry that pre-dates the development of relatively new packages for HTTP testing that have now been released on CRAN: vcr and webmockr by Scott Chamberlain, httptest by Neal Richardson, presser by Gábor Csárdi. This project aims at curating a free, central reference for developers of R packages accessing web resources, to help them have a faster and more robust development. We shall develop an useful guidance, in the form of a open-source web-based book.\n\n\n\nFunded:\n$35,000\nProposed by:\nOlga Vitek\nWebsite:\nhttps://github.com/kuwisdelu/matter\nSummary:\nThe project develops the MATTER 2.0 package for computing with larger-than-memory data in R. It extends the functionality of the existing MATTER package to any disk data format and in-memory layout. It also extends MATTER’s implementation with ALTREP to provide seamless interoperation with existing code, and various performance improvements critical for rapid prototyping of new statistical methods.\n\n\n\nFunded:\n$10,000\nProposed by:\nBenedikt Gräler\nWebsite:\nhttps://github.com/BenGraeler/STDataAndAnalytics/\nSummary:\nMany data sets are recorded irregular in space and time. Movement of people driving the spread of an disease, or the distribution of current and future cases are per se irregular spatiotemporal data and only two of many examples. Being able to easily visualise, aggregate and model irregular spatiotemporal data will help to better understand and forecast underlying processes. Filling the gap for irregular spatiotemporal data and providing direct interaction with analytical tools will ease the analysis for researchers. We will develop the sftime package to a mature state so that the suite of modern spatial and spatiotemporal data representations in R includes irregular spatiotemporal data. After doing this, we will modify the geostatistical modelling package gstat and the spatial copula modelling package spcopula to support the new data representation classes of sf, stars and sftime.\n\n\n\nFunded:\n$23,300\nProposed by:\nThibaut Jombart\nWebsite:\nhttps://www.repidemicsconsortium.org/2020-06-09-covid-challenge/\nSummary:\nThe RECON COVID-19 challenge aims to bring together the infectious disease modelling, epidemiology and R communities to improve analytics resources for the COVID-19 response via a website which will provide a platform to centralise, curate and update R development tasks relevant to the COVID-19 response. Similar to the Open Street Map Tasking Manager (tasks.hotosm.org), this platform will allow potential contributors to quickly identify outstanding tasks submitted by groups involved in the response to COVID-19 and ensure that developments follow the highest scientific and technical standards.\nWhile this project is aimed at leveraging R tools for helping to respond to COVID-19, we expect that it will lead to long-lasting developments of partnerships between the R and epidemiological communities, and that the resources developed will become key assets for supporting outbreak responses well beyond this pandemic.\n\n\n\nFunded:\n$5,000\nProposed by:\nMathieu Basille\nWebsite:\nhttps://github.com/mablab/sftrack\nSummary:\nsftrack’ is a modern approach for tracking data in R. In response to the large diversity of ad-hoc solutions, in part outdated, we propose a generic and flexible approach that support all stages of movement studies (pre-processing, post-processing and analysis). ‘sftrack’ provides two central classes for tracking data (points) and movement data (steps), and basic functions to build, handle, summarize and plot them. Version 1.0 of ‘sftrack’ will be finalized and submitted to CRAN, and will already incorporate converters from/to classes of major existing tracking packages. We will further work with all tracking package developers willing to fully integrate the solution offered by ‘sftrack’ into their package data flow."
  },
  {
    "objectID": "all-projects/2020-group-1.html#funded-isc-grants-2020-1",
    "href": "all-projects/2020-group-1.html#funded-isc-grants-2020-1",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nConsolidating R-Ladies Global organisational guidance and wisdom\nDatabase interoperability for spatial objects in R\nHTTP testing in R Book\nMATTER 2.0: larger-than-memory data for R\nSpatiotemporal Data and Analytics\nThe RECON COVID-19 challenge: leveraging the R community to improve COVID-19 analytics resources\nsftrack v1.0: Stable API for a broad adoption\n\n\n\n\nFunded:\n$4,000\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://github.com/rladies/starter-kit\nSummary:\nR-Ladies Global is a successful, growing organization aiming at increasing gender diversity in the R community. R-Ladies Global is a Top-Level Project of the ISC. R-Ladies Global guidance for starting and running a chapter, as well as overseeing chapters around the world, and for the rotating curator account, grew organically. The information is fragmented and exists in different formats: several Markdown and PDF Documents and wiki entries in a GitHub repository. This impedes the optimal finding of resources by those who need them, and also impedes contributions. This project aims to consolidate existing R-Ladies Global guidance into a well-structured and continuously deployed online book, with its source open on GitHub, as ( R ) Markdown documents woven together, and whose maintenance will be an R-Ladies major priority task.\nThe project will create a web based manuscript containing all the necessary information to understand what the R-Ladies organization is about, its structure and how to contribute to its mission. Information will be collated and organized leveraging the experience of R-Ladies organizers and volunteers that, over the past 4 years, contributed to the establishment and growth of one of the most active and successful communities in the data science realm. This book will be a crucial resource for R-Ladies and other organizations that are looking to consolidate or create their own guidance.\n\n\n\nFunded:\n$6,000\nProposed by:\nEtienne Racine\nWebsite:\nhttps://github.com/r-spatial/sfdbi\nSummary:\nManipulating spatial data in R sometimes requires interaction with a spatial database: the data doesn’t fit in memory, or simply because this is where the data is. The `sf` package already supports the PostGIS spatial database, but this project will extend the compatibility and make it easier to integrate in the `dplyr` workflow (with `dbplyr`). We also want to make it easier to add support for new database backends. We’ll create a new `sfdbi` package to centralize the interface between `sf` and databases and remove dependencies in `sf`. If you want to contribute, or if you’d like to suggest a database, make sure to join the `sfdbi` repo.\n\n\n\nFunded:\n$16,000\nProposed by:\nMaëlle Salmon\nWebsite:\nhttps://github.com/ropensci-books/http-testing\nSummary:\nMore and more R packages access resources on the web, and play crucial roles in workflows: data access and updates for CRM reports (Hubspot APIs), for scientific publications (scientific web APIs, Open Science Framework). Like for all other packages, appropriate unit testing can make them more robust. Their unit testing brings special challenges: dependence of tests on a good internet connection, testing in the absence of authentication secrets, etc. Having tests fail due to resources being down or slow, during development or on CRAN, means a time loss for everyone involved (slower development, messages from CRAN). Although many packages accessing remote resources are well tested, there is a lack of resources around best practices for HTTP testing in packages using httr, crul, or curl. The best guidance to date about HTTP testing for R packages to our knowledge is a forum entry that pre-dates the development of relatively new packages for HTTP testing that have now been released on CRAN: vcr and webmockr by Scott Chamberlain, httptest by Neal Richardson, presser by Gábor Csárdi. This project aims at curating a free, central reference for developers of R packages accessing web resources, to help them have a faster and more robust development. We shall develop an useful guidance, in the form of a open-source web-based book.\n\n\n\nFunded:\n$35,000\nProposed by:\nOlga Vitek\nWebsite:\nhttps://github.com/kuwisdelu/matter\nSummary:\nThe project develops the MATTER 2.0 package for computing with larger-than-memory data in R. It extends the functionality of the existing MATTER package to any disk data format and in-memory layout. It also extends MATTER’s implementation with ALTREP to provide seamless interoperation with existing code, and various performance improvements critical for rapid prototyping of new statistical methods.\n\n\n\nFunded:\n$10,000\nProposed by:\nBenedikt Gräler\nWebsite:\nhttps://github.com/BenGraeler/STDataAndAnalytics/\nSummary:\nMany data sets are recorded irregular in space and time. Movement of people driving the spread of an disease, or the distribution of current and future cases are per se irregular spatiotemporal data and only two of many examples. Being able to easily visualise, aggregate and model irregular spatiotemporal data will help to better understand and forecast underlying processes. Filling the gap for irregular spatiotemporal data and providing direct interaction with analytical tools will ease the analysis for researchers. We will develop the sftime package to a mature state so that the suite of modern spatial and spatiotemporal data representations in R includes irregular spatiotemporal data. After doing this, we will modify the geostatistical modelling package gstat and the spatial copula modelling package spcopula to support the new data representation classes of sf, stars and sftime.\n\n\n\nFunded:\n$23,300\nProposed by:\nThibaut Jombart\nWebsite:\nhttps://www.repidemicsconsortium.org/2020-06-09-covid-challenge/\nSummary:\nThe RECON COVID-19 challenge aims to bring together the infectious disease modelling, epidemiology and R communities to improve analytics resources for the COVID-19 response via a website which will provide a platform to centralise, curate and update R development tasks relevant to the COVID-19 response. Similar to the Open Street Map Tasking Manager (tasks.hotosm.org), this platform will allow potential contributors to quickly identify outstanding tasks submitted by groups involved in the response to COVID-19 and ensure that developments follow the highest scientific and technical standards.\nWhile this project is aimed at leveraging R tools for helping to respond to COVID-19, we expect that it will lead to long-lasting developments of partnerships between the R and epidemiological communities, and that the resources developed will become key assets for supporting outbreak responses well beyond this pandemic.\n\n\n\nFunded:\n$5,000\nProposed by:\nMathieu Basille\nWebsite:\nhttps://github.com/mablab/sftrack\nSummary:\nsftrack’ is a modern approach for tracking data in R. In response to the large diversity of ad-hoc solutions, in part outdated, we propose a generic and flexible approach that support all stages of movement studies (pre-processing, post-processing and analysis). ‘sftrack’ provides two central classes for tracking data (points) and movement data (steps), and basic functions to build, handle, summarize and plot them. Version 1.0 of ‘sftrack’ will be finalized and submitted to CRAN, and will already incorporate converters from/to classes of major existing tracking packages. We will further work with all tracking package developers willing to fully integrate the solution offered by ‘sftrack’ into their package data flow."
  },
  {
    "objectID": "all-projects/2021-group-2.html",
    "href": "all-projects/2021-group-2.html",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nPreparing CRAN for the Retirement of rgdal, rgeos and maptools\nR Package for the ICESat-2 Altimeter Data\nThe Future of DBI\nData Science and Machine Learning Training Workshop Using R Programming Language\n\n\n\n\nFunded:\n$17,000\nProposed by:\nEdzer Pebesma\nSummary:\nThe retirement of rgdal, rgeos, and maptools presents a significant impact on the CRAN community, these packages are scheduled for retirement by the end of 2023. In response, a proposal for an ISC Funded project has been put forward to tackle this challenge. Preparing CRAN for the Retirement of rgdal, rgeos and maptools focuses on finding suitable alternatives for the functionalities offered by the retiring packages and providing guidance to package maintainers on necessary adjustments and migration steps. By doing so, it aims to minimize disruption to CRAN packages and existing R scripts, ensuring the overall stability and robustness of the CRAN ecosystem. The retirement process will simplify the maintenance of the “R Spatial stack” and contribute to the long-term health of the CRAN ecosystem.\n\n\n\nFunded:\n$4,840\nProposed by:\nLampros Mouselimis\nSummary:\nR Package for the ICESat-2 Altimeter Data aims to create an R package specifically designed for accessing ICESat-2 satellite data through the OpenAltimetry API. Addressing the lack of existing R packages for downloading geospatial data in specific formats, the package will enable R users to download ICESat-2 data, list available data based on a bounding box or named location, create simple feature objects using the sf package, and visualize the output data using popular geospatial R packages such as leaflet or mapview. The proposed ISC-funded project will enhance the capabilities of R users working with geospatial datasets, facilitating data exploration, analysis, and visualization within the R environment for improved geospatial research and applications.\n\n\n\nFunded:\n$17,000\nProposed by:\nKirill Müller\nSummary:\nThe Future of DBI focuses on the advancements achieved with support from the ISC, including bringing the existing DBI backend, RSQLite, up to specification and implementing two new compliant backends, RMariaDB and RPostgres. This project mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Ensuring compatibility with evolving elements such as OS, databases, R, and other packages is vital for long-term success. The proposal also includes modules for redesigning the database interface, efficient storage, and arithmetic for big integers, decimals with fixed width and precision, investigating Apache Arrow as an interface, and relational data models with R, with the option to adjust the scope as needed.\n\n\n\nFunded:\n$5,200\nProposed by:\nTimothy A. Ogunleye\nSummary:\nWe want to conduct training workshops on data science and machine learning with R. Out of nearly 60 countries that form the continent, we carefully selected four countries – one from each of the North, South, West, and East Africa. Nigeria is considered for the West Africa, Kenya is chosen from the East Africa, Sudan from the North Africa, while Zimbabwe is selected from the South African countries. We have 2 volunteers each, who are experts in the field of data science and machine learning with R, from the selected countries. We have also recruited 2 tutors for each country, making a total of 8. These tutors would serve as training assistants to the coordinators. Training materials are to be prepared by the coordinators. Therefore, the coordinators are expected to teach the contents of the training materials."
  },
  {
    "objectID": "all-projects/2021-group-2.html#funded-isc-grants-2021-2",
    "href": "all-projects/2021-group-2.html#funded-isc-grants-2021-2",
    "title": "R Consortium",
    "section": "",
    "text": "The R Consortium Infrastructure Steering Committee periodically solicits proposals from the worldwide R community for projects which will help advance the state of the R ecosystem. Developers and organizations may apply to participate in the program and receive funding to help further a project or initiative.\nGrants funded in this group:\n\nPreparing CRAN for the Retirement of rgdal, rgeos and maptools\nR Package for the ICESat-2 Altimeter Data\nThe Future of DBI\nData Science and Machine Learning Training Workshop Using R Programming Language\n\n\n\n\nFunded:\n$17,000\nProposed by:\nEdzer Pebesma\nSummary:\nThe retirement of rgdal, rgeos, and maptools presents a significant impact on the CRAN community, these packages are scheduled for retirement by the end of 2023. In response, a proposal for an ISC Funded project has been put forward to tackle this challenge. Preparing CRAN for the Retirement of rgdal, rgeos and maptools focuses on finding suitable alternatives for the functionalities offered by the retiring packages and providing guidance to package maintainers on necessary adjustments and migration steps. By doing so, it aims to minimize disruption to CRAN packages and existing R scripts, ensuring the overall stability and robustness of the CRAN ecosystem. The retirement process will simplify the maintenance of the “R Spatial stack” and contribute to the long-term health of the CRAN ecosystem.\n\n\n\nFunded:\n$4,840\nProposed by:\nLampros Mouselimis\nSummary:\nR Package for the ICESat-2 Altimeter Data aims to create an R package specifically designed for accessing ICESat-2 satellite data through the OpenAltimetry API. Addressing the lack of existing R packages for downloading geospatial data in specific formats, the package will enable R users to download ICESat-2 data, list available data based on a bounding box or named location, create simple feature objects using the sf package, and visualize the output data using popular geospatial R packages such as leaflet or mapview. The proposed ISC-funded project will enhance the capabilities of R users working with geospatial datasets, facilitating data exploration, analysis, and visualization within the R environment for improved geospatial research and applications.\n\n\n\nFunded:\n$17,000\nProposed by:\nKirill Müller\nSummary:\nThe Future of DBI focuses on the advancements achieved with support from the ISC, including bringing the existing DBI backend, RSQLite, up to specification and implementing two new compliant backends, RMariaDB and RPostgres. This project mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Ensuring compatibility with evolving elements such as OS, databases, R, and other packages is vital for long-term success. The proposal also includes modules for redesigning the database interface, efficient storage, and arithmetic for big integers, decimals with fixed width and precision, investigating Apache Arrow as an interface, and relational data models with R, with the option to adjust the scope as needed.\n\n\n\nFunded:\n$5,200\nProposed by:\nTimothy A. Ogunleye\nSummary:\nWe want to conduct training workshops on data science and machine learning with R. Out of nearly 60 countries that form the continent, we carefully selected four countries – one from each of the North, South, West, and East Africa. Nigeria is considered for the West Africa, Kenya is chosen from the East Africa, Sudan from the North Africa, while Zimbabwe is selected from the South African countries. We have 2 volunteers each, who are experts in the field of data science and machine learning with R, from the selected countries. We have also recruited 2 tutors for each country, making a total of 8. These tutors would serve as training assistants to the coordinators. Training materials are to be prepared by the coordinators. Therefore, the coordinators are expected to teach the contents of the training materials."
  }
]