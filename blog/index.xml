<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>R Consortium</title>
<link>https://r-consortium.org/blog/</link>
<atom:link href="https://r-consortium.org/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Sun, 22 Jun 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Advanced Distance Metrics for High-Dimensional Clustering: introducing ‘distanceHD’ R-package</title>
  <dc:creator>R Consortium, Software Development</dc:creator>
  <link>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EC_vTG-_XCQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="distancehd-a-new-frontier-in-high-dimensional-clustering" class="level1">
<h1>DistanceHD: A New Frontier in High-Dimensional Clustering</h1>
<p>Greetings, data enthusiasts and R aficionados! Today, we delve into development in the realm of high-dimensional clustering with the introduction of the <code>distanceHD</code> package. This tool, crafted by Jung Ae Lee, Assistant Professor of Biostatistics at the University of Massachusetts Chan Medical School, addresses the need for robust, scalable, and statistically sound distance measures tailored specifically for high-dimensional settings.</p>
<section id="why-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="why-distancehd">Why <code>distanceHD</code>?</h2>
<p>Traditional distance metrics such as Euclidean or Mahalanobis distances often falter in high-dimensional spaces. These conventional methods, while effective in lower dimensions, struggle to detect meaningful clusters or outliers when faced with the complexity of high-dimensional data. This gap is particularly evident in fields like genomics, where the number of features (variables) often exceeds the number of samples.</p>
<p>The <code>distanceHD</code> package introduces three innovative distance metrics designed for high-dimensional clustering and outlier detection: the centroid distance, ridge Mahalanobis distance, and maximal data piling (MDP) distance. Each of these metrics offers unique benefits, making them invaluable tools in the data scientist’s arsenal.</p>
</section>
<section id="the-three-pillars-of-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="the-three-pillars-of-distancehd">The Three Pillars of <code>distanceHD</code></h2>
<section id="centroid-distance" class="level3">
<h3 class="anchored" data-anchor-id="centroid-distance">1. Centroid Distance</h3>
<p>Centroid distance, also known as Euclidean distance, calculates the distance between the centers of two groups. It is a straightforward metric but can be limited in high-dimensional spaces with correlated variables. However, it remains effective when variables are uncorrelated.</p>
</section>
<section id="ridge-mahalanobis-distance" class="level3">
<h3 class="anchored" data-anchor-id="ridge-mahalanobis-distance">2. Ridge Mahalanobis Distance</h3>
<p>The ridge Mahalanobis distance introduces a ridge correction constant, alpha, to ensure the covariance matrix is invertible — a common issue in high-dimensional analysis due to singularity problems. This adjustment allows for a more stable calculation of distances, bridging the gap between the centroid and MDP distances. When alpha is large, the ridge Mahalanobis distance approximates the centroid distance, while a smaller alpha brings it closer to the MDP distance.</p>
</section>
<section id="maximal-data-piling-mdp-distance" class="level3">
<h3 class="anchored" data-anchor-id="maximal-data-piling-mdp-distance">3. Maximal Data Piling (MDP) Distance</h3>
<p>The MDP distance is perhaps the most novel of the three metrics. It computes the orthogonal distance between the affine spaces spanned by each class, offering a unique direction vector that maximizes the distance between class projections. This metric shines in situations with highly correlated variables, such as gene expression data, and is particularly effective for classification problems.</p>
</section>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<p>The <code>distanceHD</code> package is not just a theoretical construct; it has real-world applications in clustering, classification, and outlier detection. For instance, in the context of outlier identification, the MDP distance can effectively discern outliers by maximizing the projection distance in a unique direction. This capability is demonstrated through sequential simulations, such as gene expression data with multiple features and patients, where traditional metrics may fall short.</p>
<p>In classification tasks, the MDP distance provides a high-dimensional, low-sample-size version of Fisher’s discriminant analysis, offering a powerful tool for binary predictions, such as disease status classification.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>While the <code>distanceHD</code> package is a significant leap forward, Jung Ae Lee plans to expand its functionalities further. Upcoming updates will focus on improving outlier detection processes and incorporating additional distance metrics to enhance the package’s versatility and applicability in various high-dimensional contexts.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The <code>distanceHD</code> package represents a significant advancement in the field of high-dimensional data analysis, offering robust tools for clustering, classification, and outlier detection. With its innovative metrics and practical applications, it is poised to become an essential resource for researchers and practitioners working with complex, high-dimensional datasets.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/thumbnail-advanced-distance-metrics-lee.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>An Accelerometry Biomarker Framework with Application in Vigilance in UK Biobank Data</title>
  <dc:creator>R Consortium, Healthcare</dc:creator>
  <link>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KiQAySB2rF4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="exploring-vigilance-with-accelerometry-insights-from-the-uk-biobank" class="level1">
<h1>Exploring Vigilance with Accelerometry: Insights from the UK Biobank</h1>
<p>Accelerometry data from wearable devices have opened new horizons in non-invasive health monitoring, providing a continuous and objective measure of physical activity. Michael Kane, MD Anderson Cancer Center, alongside Dmitri Wolson and Francesco Onarati at Takeda Pharmaceuticals, delves into using accelerometry as a biomarker for assessing vigilance, focusing on the potential to identify non-vigilant states such as excessive daytime sleepiness or narcolepsy-like symptoms. This analysis is rooted in data from the UK Biobank, a rich resource encompassing accelerometry, demographic, and lifestyle data of approximately 78,500 participants.</p>
<section id="understanding-the-data-and-its-challenges" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-data-and-its-challenges">Understanding the Data and Its Challenges</h2>
<p>The UK Biobank’s accelerometry data provides a wealth of information, with measurements taken at 100 Hz over a week for each participant. These data offer a high-resolution view of daily activity patterns, recorded across three axes (X, Y, Z) in milligravities. However, this study’s foundational challenge lies in its observational nature and reliance on self-reported outcomes to define vigilance states.</p>
<p>Vigilance and non-vigilance were distinguished using self-reported symptoms of narcolepsy and frequency of daytime naps. Non-vigilant participants reported narcolepsy symptoms often or always and took frequent naps, while vigilant participants did not report these symptoms or behaviors. Despite a robust overall dataset, the non-vigilant group comprised only 679 individuals, necessitating a careful matching process to ensure comparable analysis groups.</p>
</section>
<section id="propensity-score-matching-for-balanced-analysis" class="level2">
<h2 class="anchored" data-anchor-id="propensity-score-matching-for-balanced-analysis">Propensity Score Matching for Balanced Analysis</h2>
<p>To address imbalances and potential confounders in the observational data, propensity score matching was employed. This method allowed for the creation of matched pairs of vigilant and non-vigilant participants based on physical and lifestyle characteristics, including age, sex, ethnicity, BMI, smoking habits, alcohol use, and more. This rigorous matching resulted in 95 well-matched pairs, setting the stage for a focused exploration of accelerometry’s potential in assessing vigilance.</p>
</section>
<section id="transforming-accelerometry-data-into-spectral-images" class="level2">
<h2 class="anchored" data-anchor-id="transforming-accelerometry-data-into-spectral-images">Transforming Accelerometry Data into Spectral Images</h2>
<p>A critical step in the analysis involved transforming raw accelerometry data into a structured format conducive to machine learning. The data were downsampled to 33 Hz to focus on relevant daily movement frequencies. Subsequently, the data were segmented into five-minute blocks, and a Discrete Fourier Transform was applied to each block. This transformation yielded sorted spectral images, representing the energy expended at different frequencies without capturing the precise timing of activities within a day.</p>
</section>
<section id="convolutional-neural-network-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network-for-classification">Convolutional Neural Network for Classification</h2>
<p>Inspired by the architecture of AlexNet, a simplified convolutional neural network (CNN) was developed to classify participants as vigilant or non-vigilant based on the spectral images. The CNN architecture included convolutional layers, max pooling, and dense layers with dropout to prevent overfitting. Training involved 20-fold cross-validation at the subject level, ensuring that predictions were genuinely out-of-sample.</p>
<p>The CNN yielded an out-of-sample F1 score of 0.576 and an AUC of 0.539 at the sample level for participants aged 65 or younger. At the subject level, the F1 score was 0.539, and the AUC was 0.564. While these results indicate a weak association between accelerometry-derived biomarkers and vigilance states, they underscore the potential for further refinement and application in broader contexts.</p>
</section>
<section id="potential-applications-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="potential-applications-and-future-directions">Potential Applications and Future Directions</h2>
<p>The study highlights accelerometry’s promise as a non-invasive tool for assessing cognitive states and movement-related disorders. The association between accelerometry and vigilance, albeit modest, opens avenues for monitoring conditions where non-vigilance is a co-morbidity, such as sleep disorders, neurological conditions, and psychiatric disorders.</p>
<p>The findings also suggest potential applications in monitoring the effectiveness of treatments for conditions like narcolepsy, where stimulant medications may influence accelerometry patterns. Furthermore, the study indicates that stratifying by age could enhance the model’s predictive accuracy, given that younger participants tend to exhibit more movement.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Kane’s exploration into accelerometry as a biomarker for vigilance represents an exciting step forward in leveraging wearable technology for health monitoring. While the association between accelerometry and vigilance is currently weak, the study underscores the potential for accelerometry-derived insights to inform interventions across a range of conditions. The use of R for analysis and presentation further demonstrates the language’s versatility in handling complex datasets and machine learning models.</p>
<p>As the R community continues to evolve and embrace cutting-edge methodologies, studies like this exemplify the innovative applications of R in advancing healthcare research. The integration of accelerometry data into clinical and research settings promises to enhance our understanding of human physiology and behavior, paving the way for more personalized and effective health interventions.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/thumbnail-kane-accelerometry.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Bedside to Bench - Reinventing medicine with AI</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/OPib-OztZQc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="reinventing-medicine-with-ai-a-new-pathway-to-discovery" class="level1">
<h1>Reinventing Medicine with AI: A New Pathway to Discovery</h1>
<p>The landscape of medical research and discovery is ripe for a seismic shift, one that is being catalyzed by the integration of artificial intelligence (AI) into the healthcare domain. This paradigm shift was the core focus of Dr.&nbsp;Ziad Obermeyer’s keynote at R/Medicine 2025, where he explored the potential of AI to resurrect and revolutionize the “bedside to bench” pathway for medical discovery.</p>
<section id="from-bench-to-bedside-the-traditional-model" class="level2">
<h2 class="anchored" data-anchor-id="from-bench-to-bedside-the-traditional-model">From Bench to Bedside: The Traditional Model</h2>
<p>The traditional model of medical discovery often starts at the molecular level, focusing on genes, proteins, and signaling pathways. This approach has led to significant breakthroughs, particularly in areas like cancer and immunology, where targeted therapies have been transformative. However, this model is not without its limitations. As Dr.&nbsp;Obermeyer pointed out, many complex medical problems remain unsolved, and the traditional bench-to-bedside approach has largely overshadowed the alternative pathway — one that begins with observations at the bedside.</p>
</section>
<section id="ai-a-new-lens-for-medical-discovery" class="level2">
<h2 class="anchored" data-anchor-id="ai-a-new-lens-for-medical-discovery">AI: A New Lens for Medical Discovery</h2>
<p>AI, with its ability to process vast amounts of data and detect patterns invisible to the human eye, offers a powerful alternative. Dr.&nbsp;Obermeyer provided compelling examples of how AI can generate novel empirical observations from real-world data, thereby reinvigorating the bedside-to-bench pathway.</p>
<section id="the-case-of-knee-pain" class="level3">
<h3 class="anchored" data-anchor-id="the-case-of-knee-pain">The Case of Knee Pain</h3>
<p>One of the illustrative examples Dr.&nbsp;Obermeyer discussed was knee pain, a condition that has long eluded effective treatment through traditional molecular approaches. Historically, research on knee pain has zoomed in at a molecular level, focusing on inflammation markers and cartilage degradation. However, this approach has not significantly alleviated the widespread issue of knee pain, leading to an over-reliance on opioids as a treatment.</p>
<p>Dr.&nbsp;Obermeyer’s team leveraged AI to analyze knee X-rays, not to replicate human radiologist interpretations, but to predict patient-reported pain scores directly from the image data. This approach uncovered new insights into the anatomical and physiological factors contributing to knee pain, particularly among Black patients, thus addressing a known disparity in pain management and treatment outcomes.</p>
</section>
<section id="sudden-cardiac-death-predicting-the-unpredictable" class="level3">
<h3 class="anchored" data-anchor-id="sudden-cardiac-death-predicting-the-unpredictable">Sudden Cardiac Death: Predicting the Unpredictable</h3>
<p>Another poignant example involved the use of AI to predict sudden cardiac death, a condition notorious for its unpredictability. By analyzing ECG data linked to patient outcomes in Sweden, Dr.&nbsp;Obermeyer’s team developed a model that could identify individuals at high risk of sudden cardiac death with greater accuracy than traditional metrics. This predictive capability has the potential to optimize the allocation of defibrillators, ensuring they reach those most in need.</p>
</section>
</section>
<section id="implications-for-the-future-of-medicine" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-the-future-of-medicine">Implications for the Future of Medicine</h2>
<p>The implications of these findings are profound. By turning complex medical images into actionable data, AI not only enhances diagnostic precision but also opens new avenues for therapeutic interventions. This approach allows for a re-examination of established medical knowledge, potentially leading to new standards of care.</p>
<section id="bridging-disciplines" class="level3">
<h3 class="anchored" data-anchor-id="bridging-disciplines">Bridging Disciplines</h3>
<p>The integration of AI into medical research also underscores the importance of interdisciplinary collaboration. As Dr.&nbsp;Obermeyer noted, insights from fields such as computer science, economics, and behavioral science can enrich our understanding of health and disease, leading to more holistic and effective healthcare solutions.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Dr.&nbsp;Obermeyer’s keynote at R/Medicine 2025 highlighted the transformative potential of AI in medicine. By enabling a new cycle of discovery that starts at the bedside, AI promises to uncover new abstractions and insights, ultimately improving patient care and outcomes. As the R community continues to explore these frontiers, the collaborative efforts between data scientists, clinicians, and researchers will be crucial in unlocking the full potential of AI in healthcare.</p>
<p>With the power of AI and the collective wisdom of diverse disciplines, the future of medical discovery has the potential for advancements that were once thought unattainable.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/thumbnail-ai-ziad.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Bootstrap inference made easy: p-values and confidence intervals in one line of code</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EeAtvWF3twA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package" class="level3">
<h3 class="anchored" data-anchor-id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package">Simplifying Bootstrap Inference in R with the boot.pval Package</h3>
<p>In the realm of statistical analysis, ensuring the reliability of p-values and confidence intervals is paramount, especially when classical assumptions about data distribution do not hold. This is where bootstrap methods come into play, offering a robust alternative by relying on data-driven, empirical distributions rather than theoretical assumptions. Despite their utility, bootstrap methods are often underutilized due to perceived complexities in implementation. However, with advancements in R packages like <code>boot.pval</code>, bootstrap inference has become more accessible than ever.</p>
<section id="the-bootstrap-approach" class="level4">
<h4 class="anchored" data-anchor-id="the-bootstrap-approach">The Bootstrap Approach</h4>
<p>Introduced by Bradley Efron in 1979, the bootstrap method revolutionizes statistical inference by focusing on the empirical distribution of the data itself. Unlike traditional methods that start with a distributional assumption (e.g., normality), bootstrap methods begin with the actual data distribution. By resampling from this empirical distribution and calculating the test statistic repeatedly, we obtain an accurate approximation of its distribution. This allows for the computation of p-values and confidence intervals without reliance on stringent assumptions about data normality.</p>
</section>
<section id="the-role-of-boot.pval" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-boot.pval">The Role of boot.pval</h4>
<p>The <code>boot.pval</code> package in R, developed by Måns Thulin from Thulin Consulting AB, simplifies the process of applying bootstrap methods to a variety of statistical tests and models. From t-tests to regression coefficients in linear models, GLMs, survival models, and mixed models, <code>boot.pval</code> enables users to compute bootstrap p-values and confidence intervals efficiently—often with just a single line of code.</p>
</section>
<section id="key-features-and-benefits" class="level4">
<h4 class="anchored" data-anchor-id="key-features-and-benefits">Key Features and Benefits</h4>
<ul>
<li><strong>Ease of Use</strong>: The package allows for straightforward computation of bootstrap p-values and confidence intervals without needing to write complex custom functions.</li>
<li><strong>Integration</strong>: Built on top of established R packages like <code>boot</code>, <code>car</code>, <code>lme4</code>, and <code>survival</code>, it ensures compatibility and extends functionality.</li>
<li><strong>Customizability</strong>: Users can create custom bootstrap tests for unique statistical measures.</li>
<li><strong>Consistency</strong>: It ensures that the derived p-values and confidence intervals are consistent, addressing discrepancies often found in other implementations.</li>
</ul>
</section>
<section id="practical-application-a-case-study" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-a-case-study">Practical Application: A Case Study</h4>
<p>Using the sleep dataset in R, Thulin demonstrates how to replace a classic t-test with a bootstrap t-test using <code>boot.pval</code>. This approach not only simplifies the code but also enhances the robustness of the test against non-normal data distributions. The output from <code>boot.pval</code> mirrors that from traditional tests but is derived from a more reliable, data-centric approach.</p>
</section>
<section id="extending-beyond-simple-tests" class="level4">
<h4 class="anchored" data-anchor-id="extending-beyond-simple-tests">Extending Beyond Simple Tests</h4>
<p>The <code>boot.pval</code> package is not limited to simple t-tests; it supports complex models including linear regressions and survival models. By fitting a model using standard R functions like <code>lm()</code> or <code>glm()</code>, users can then apply <code>boot.summary()</code> from <code>boot.pval</code> to obtain detailed summaries including estimates, confidence intervals, and p-values—all bootstrapped for enhanced reliability.</p>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>Bootstrap methods provide a powerful tool for statistical inference when traditional assumptions do not hold. With packages like <code>boot.pval</code>, R users can integrate robust bootstrap techniques into their daily analysis workflows effortlessly. Whether dealing with straightforward comparisons or complex multivariable models, <code>boot.pval</code> offers a user-friendly yet powerful solution for making informed statistical decisions based on solid empirical evidence.</p>
<p>For those interested in delving deeper into bootstrap methods or seeking practical applications within R, exploring further resources such as <a href="https://www.modernstatisticswithr.com/">Thulin’s book “Modern Statistics with R”</a> or foundational texts on bootstrap methodology can be incredibly beneficial.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/thumbnail-bootstrap-inference-thulin.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Dengue Forecasting Addressing the Interrupted Effect from COVID-19 Cases</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/TNRH2WxA3J0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><em>Note: This project is <a href="http://localhost:4215/posts/empowering-dengue-research-through-the-dengue-data-hub/index.html">funded by the R Consortium</a></em></p>
<section id="navigating-interruption-forecasting-dengue-cases-amidst-covid-19" class="level1">
<h1>Navigating Interruption: Forecasting Dengue Cases Amidst COVID-19</h1>
<p>Dengue fever, a mosquito-borne disease, remains a significant health concern in tropical regions, particularly in countries near the equator. The dengue virus, primarily transmitted by Aedes mosquitoes, thrives in warm, humid conditions with regular rainfall—conditions that are prevalent in these regions. However, the onset of the COVID-19 pandemic introduced an unprecedented interruption in the usual dengue case patterns. This blog post delves into a study that explores how to accurately forecast dengue cases amidst the interruptions caused by the COVID-19 pandemic, using Sri Lanka as a case study.</p>
<p><strong>Understanding the Interruption</strong></p>
<p>During the COVID-19 pandemic, several factors contributed to an unusual pattern in dengue case reporting. These include:</p>
<ul>
<li>Misclassification of dengue as COVID-19 due to overlapping symptoms such as fever, headache, and fatigue.</li>
<li>Underreporting or delayed reporting due to lockdowns and mobility restrictions.</li>
<li>Reduced human-mosquito contact due to people spending more time indoors.</li>
<li>School and workplace closures, which are common sites for dengue transmission.</li>
<li>Travel restrictions, which reduced the spread of dengue to new areas.</li>
</ul>
<p>This period, referred to as the “interrupted period,” significantly affected the usual seasonal and annual patterns of dengue cases.</p>
<p><strong>Forecasting Strategies</strong></p>
<p>The study, presented by Thiyanga S. Talagala from the Department of Statistics at the University of Sri Jayewardenepura, Sri Lanka, investigates three modeling strategies to address this interruption in dengue case forecasting:</p>
<ol type="1">
<li><p><strong>Excluding the Interrupted Period</strong>: This approach involves using only post-COVID-19 data for model training, effectively ignoring the data from the interrupted period.</p></li>
<li><p><strong>Forecasting the Interrupted Period First</strong>: This method involves forecasting the interrupted period based on data up to 2019, then using the updated time series for model training.</p></li>
<li><p><strong>Down-Weighting the Interrupted Period</strong>: This strategy assigns lower weights to data points in the interrupted period, giving higher weights to uninterrupted periods.</p></li>
</ol>
<p>Data from 2007 to 2024 were used for model fitting, and data for 2025 served as the test set to evaluate the performance of these methods across 25 districts in Sri Lanka.</p>
<p><strong>Evaluating the Methods</strong></p>
<p>The study employed various accuracy measures, including Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), to compare the forecasting performance of each approach. The findings revealed that no single method outperformed across all districts. Instead, the effectiveness of each approach depended on the specific characteristics and historical patterns of each district.</p>
<p><strong>Insights and Implications</strong></p>
<p>The study’s insights underscore the importance of tailoring forecasting methods to the unique characteristics of each region. For instance, the down-weighting approach proved effective in areas where the usual dengue patterns persisted despite the interruption. In contrast, excluding the interrupted period worked best in districts that had shifted to a new normal post-COVID-19.</p>
<p>Furthermore, the study highlighted the influence of weather patterns on dengue transmission. Districts affected by specific monsoon periods or characterized by unique weather conditions showed distinct forecasting patterns.</p>
<p><strong>Conclusion</strong></p>
<p>Forecasting dengue cases amidst interruptions like COVID-19 is a complex task that requires adaptive approaches. The study by Talagala emphasizes that understanding the local context, including weather patterns and historical data, is crucial for accurate forecasting. This research not only contributes to improving dengue preparedness but also offers valuable insights for handling future public health interruptions.</p>
<p>For more detailed insights and to explore the methodologies used, you can access <a href="https://github.com/thiyangt/denguedatahub">the project on GitHub</a> and <a href="https://denguedatahub.netlify.app/">the main Dengue Data Hub site</a>.</p>


</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Epidemiology</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/thumbnail-dengue.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Ethical Considerations of Contrasts in Statistical Modeling of Medical Equity</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pAx92roI3VE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="ethical-choices-in-regression-analysis-a-case-study-from-seattle-childrens-hospital" class="level2">
<h2 class="anchored" data-anchor-id="ethical-choices-in-regression-analysis-a-case-study-from-seattle-childrens-hospital">Ethical Choices in Regression Analysis: A Case Study from Seattle Children’s Hospital</h2>
<p>In the world of statistical modeling, the choice of coding schemes for categorical variables is not merely a technical consideration but a decision laden with ethical implications. This was the focus of a recent presentation during the R/Medicine 2025 conference by Dwight Barry, Principal Data Scientist at Seattle Children’s Hospital, and Nicole Chicoine, DO, MPH, also at Seattle Children’s Hospital. The talk revolved around how these choices can influence the inferences drawn from regression analyses and ultimately impact healthcare delivery and research.</p>
<section id="the-hospitals-language-diversity" class="level3">
<h3 class="anchored" data-anchor-id="the-hospitals-language-diversity">The Hospital’s Language Diversity</h3>
<p>Seattle Children’s Hospital is a bustling 400-bed facility that handles over half a million patient visits annually. With such a diverse patient base, the hospital encounters more than 130 languages, with Spanish being the most common after English. To accommodate this linguistic diversity, the hospital has initiated its first all-Spanish speaking operating room, ensuring equitable care for non-English speaking patients. This commitment to inclusivity is mirrored in their research methodologies, where the focus is on equitable outcomes across different patient groups.</p>
</section>
<section id="understanding-coding-schemes" class="level3">
<h3 class="anchored" data-anchor-id="understanding-coding-schemes">Understanding Coding Schemes</h3>
<p>The choice of coding schemes in regression models is crucial as it can shape the conclusions drawn from the data. Barry highlighted three coding schemes used in R: treatment contrast, sum contrast, and weighted effect coding. Each scheme presents categorical variables in different ways, affecting the interpretation of the data.</p>
<ol type="1">
<li><p><strong>Treatment Contrast</strong>: This is the default coding in R, where one category is used as a reference against which others are compared. In a clinical setting, this could inadvertently privilege a particular group, often aligning with the English-speaking, white demographic, which can skew the narrative towards existing inequities.</p></li>
<li><p><strong>Sum Contrast</strong>: Here, the grand mean of all categories is used as the reference point. This approach decouples any single category from being the norm, promoting a more balanced view. In the context of healthcare, it shifts the focus from a single dominant group to an aggregate understanding, which can be crucial in addressing biases.</p></li>
<li><p><strong>Weighted Effect Coding</strong>: This method is a variant of the sum contrast, where each category level is weighted by its sample size. Although not a built-in feature in base R, the <code>wec</code> package facilitates its implementation. This approach provides a nuanced view by factoring in the prevalence of each category, which can be especially useful in diverse patient populations.</p></li>
</ol>
</section>
<section id="implications-for-healthcare-research" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-healthcare-research">Implications for Healthcare Research</h3>
<p>The choice of coding scheme is not just a statistical decision but an ethical one, as it affects how healthcare equity is perceived and addressed. Barry’s presentation underscored that while odds ratios may differ across coding schemes, the marginal effects remain consistent, suggesting that predictions are unaffected by these choices. However, the ethical ramifications are significant, as they influence which group is centered in the analysis.</p>
<p>In healthcare research, where categorical exposures like language group, race, or ethnicity lack a natural order, choosing the right coding scheme is vital. Sum contrasts, for instance, provide a means to avoid privileging any group, thereby promoting equity.</p>
</section>
<section id="broader-implications-and-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="broader-implications-and-recommendations">Broader Implications and Recommendations</h3>
<p>Barry’s insights extend beyond surgery to any healthcare condition where equity is a concern. The presentation emphasized the importance of presenting marginal effects alongside regression coefficients or odds ratios to provide a comprehensive view of the data. By decentering from a single reference point, researchers can challenge the dominant social narratives and highlight systemic inequities, paving the way for more inclusive and equitable healthcare practices.</p>
<p>In conclusion, the ethical dimensions of statistical modeling are as crucial as the statistical ones. As healthcare becomes increasingly data-driven, recognizing and addressing these ethical considerations is essential. By adopting coding schemes that promote equity, researchers and healthcare providers can ensure that their work contributes to a more just and equitable healthcare system.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/thumbnail-ethical-considerations.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Improving Reproducibility of Medical Research with Controlled Vocabularies</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/improving-reproducibility-of-medical-research-with-controlled-vocabularies/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/bf8NZTnz6NA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-reproducibility-in-medical-research-with-controlled-vocabularies" class="level1">
<h1>Enhancing Reproducibility in Medical Research with Controlled Vocabularies</h1>
<p>Hello R community! Today, let’s delve into an intriguing topic presented by Jonathan Pearce, a Senior Analyst at the Analysis Group, at the R/Medicine 2025 conference. Jonathan’s insightful presentation focused on improving the reproducibility of medical research through the use of controlled vocabularies for variable naming. Reproducibility in medical research is crucial, and Jonathan’s approach offers a structured methodology to enhance clarity and efficiency in data analysis.</p>
<section id="the-need-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="the-need-for-reproducibility">The Need for Reproducibility</h2>
<p>The reproducibility of medical research has been a growing concern. Successful replication of studies depends on various factors such as code correctness, thorough documentation, and clear communication of the methods used. While much emphasis is often placed on technical aspects like coding environments and data access, the crux of reproducibility lies in the precise and consistent implementation of the original work.</p>
</section>
<section id="introducing-controlled-vocabularies" class="level2">
<h2 class="anchored" data-anchor-id="introducing-controlled-vocabularies">Introducing Controlled Vocabularies</h2>
<p>Jonathan introduced the concept of controlled vocabularies for variable naming as a means to bolster reproducibility. This involves using a schema to label variables in a dataset consistently. This systematic approach encodes metadata directly into variable names, providing immediate context and enhancing the clarity of the data.</p>
<section id="example-of-controlled-vocabulary" class="level3">
<h3 class="anchored" data-anchor-id="example-of-controlled-vocabulary">Example of Controlled Vocabulary</h3>
<p>Consider a scenario where you have a dataset with multiple tables, each containing various types of data. For instance, if you’re tracking whether patients had an eGFR lab test during a baseline period, a variable name following a controlled vocabulary might be <code>labs_eGFR_baseline_ind</code>, where <code>ind</code> stands for indicator. This descriptive naming convention helps users instantly understand the data stored in the column.</p>
</section>
<section id="structured-naming-and-its-advantages" class="level3">
<h3 class="anchored" data-anchor-id="structured-naming-and-its-advantages">Structured Naming and Its Advantages</h3>
<p>Controlled vocabularies mandate a consistent format across the project, which can be crucial for downstream analyses. For example, a variable capturing the median value of an eGFR test might be named <code>labs_eGFR_baseline_median_value</code>, providing additional clarity such as the unit of measurement and the calculation method.</p>
<p>The benefits of controlled vocabularies extend to various facets of data analysis:</p>
<ul>
<li><strong>Regular Expressions:</strong> With consistently named variables, regular expressions can efficiently query subsets of data, facilitating tasks like data validation and report generation.</li>
<li><strong>Data Validation:</strong> By defining expected data types and constraints (e.g., numeric values for duration variables should be non-negative), controlled vocabularies simplify the validation process.</li>
<li><strong>Streamlined Workflows:</strong> Tasks such as creating summary tables, modeling, sensitivity analysis, and generating data dictionaries become more straightforward and reproducible.</li>
</ul>
</section>
</section>
<section id="practical-considerations" class="level2">
<h2 class="anchored" data-anchor-id="practical-considerations">Practical Considerations</h2>
<p>While controlled vocabularies offer significant advantages, there are practical considerations to keep in mind:</p>
<ul>
<li><strong>Balancing Detail and Brevity:</strong> It’s essential to avoid overly long variable names by using abbreviations judiciously.</li>
<li><strong>Initial Setup Effort:</strong> Defining a controlled vocabulary requires upfront work, but the long-term benefits often outweigh the initial investment.</li>
<li><strong>Avoiding Conflicts:</strong> Care must be taken with underscores and keywords to prevent conflicts during keyword searches in variable names.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Jonathan Pearce’s presentation highlighted the transformative potential of controlled vocabularies in enhancing the reproducibility of medical research. By embedding metadata directly within variable names, researchers can achieve greater clarity and consistency, ultimately leading to more reliable and efficient data analysis.</p>
<p>As we strive to make our work more sustainable and transparent, adopting practices like controlled vocabularies can help ensure that our research remains accessible and understandable, even months or years later.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/improving-reproducibility-of-medical-research-with-controlled-vocabularies/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/improving-reproducibility-of-medical-research-with-controlled-vocabularies/thumbnail-reproducibility-pearce.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Mix, Pour, Share: The rUM Cocktail for Biomedical Project Packaging</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/mix-pour-share-the-rum-cocktail-for-biomedical-project-packaging/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/03_5KrQA-mo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unveiling-rum-a-game-changer-for-biomedical-reproducibility" class="level1">
<h1>Unveiling rUM: A Game-Changer for Biomedical Reproducibility</h1>
<p>The reproducibility crisis in biomedical research is a formidable challenge that demands innovative solutions. At the forefront of addressing this issue is the rUM package, developed at the University of Miami, which promises to revolutionize how biomedical research projects are documented, shared, and analyzed. Here, we delve into the capabilities of <a href="https://raymondbalise.github.io/rUM/">rUM version 2.2</a>, named “rUM Runner,” and its potential to streamline research processes while promoting reproducibility.</p>
<section id="meet-the-innovators" class="level2">
<h2 class="anchored" data-anchor-id="meet-the-innovators">Meet the Innovators</h2>
<p>Kyle Gealis and Dr.&nbsp;Raymond Balise from the University of Miami’s Department of Public Health Sciences are the developers of rUM. They aim to bridge the gap between complex research needs and user-friendly tools, ensuring that even researchers with minimal programming experience can produce high-quality, reproducible work.</p>
</section>
<section id="what-is-rum" class="level2">
<h2 class="anchored" data-anchor-id="what-is-rum">What is rUM?</h2>
<p>While “rum” might first bring to mind thoughts of a tropical cocktail, in the context of biomedical research, rUM is an acronym for an R package designed to make research reproducibility more accessible. It facilitates the creation of comprehensive, CRAN-ready research packages with minimal coding effort. The package allows researchers to bundle entire projects, complete with analyses, datasets, documentation, and presentations, into a single distributable package.</p>
</section>
<section id="key-features-of-rum" class="level2">
<h2 class="anchored" data-anchor-id="key-features-of-rum">Key Features of rUM</h2>
<ol type="1">
<li><p><strong>CRAN-Ready Package Structures</strong>: With a single function call, rUM creates package structures that adhere to CRAN standards, simplifying the package development process.</p></li>
<li><p><strong>Automated Templates</strong>: R Markdown and Quarto manuscripts can be seamlessly integrated as package vignettes, providing a cohesive documentation of research efforts.</p></li>
<li><p><strong>Enhanced Dataset Documentation</strong>: rUM includes tools for documenting datasets with comprehensive metadata, ensuring that datasets are well-described and easy to understand.</p></li>
<li><p><strong>Presentation Integration</strong>: With rUM, creating Quarto RevealJS presentations within packages is straightforward. This feature allows researchers to share their findings in a visually engaging manner.</p></li>
<li><p><strong>Slide Deck Display and Sharing</strong>: Researchers can easily display and share slide decks stored within their packages, enhancing collaborative communication.</p></li>
</ol>
</section>
<section id="addressing-the-reproducibility-crisis" class="level2">
<h2 class="anchored" data-anchor-id="addressing-the-reproducibility-crisis">Addressing the Reproducibility Crisis</h2>
<p>The reproducibility crisis highlights the inconsistencies often found when attempting to replicate research findings, either with new data or the original datasets. rUM addresses this by providing a systematic approach to project organization, ensuring that all elements of the research process are documented and reproducible.</p>
<section id="the-workflow-from-data-to-package" class="level3">
<h3 class="anchored" data-anchor-id="the-workflow-from-data-to-package">The Workflow: From Data to Package</h3>
<p>The rUM package facilitates a complete workflow:</p>
<ul>
<li><p><strong>Analyzing Data</strong>: Take, for example, the pharmacokinetic dataset (medicaldata::theophylline). rUM assists in analyzing such datasets with integrated tools.</p></li>
<li><p><strong>Documenting with Metadata</strong>: Datasets are documented with comprehensive metadata, making them easier to understand and use by others.</p></li>
<li><p><strong>Creating Presentations</strong>: Researchers can create presentation slides featuring their analysis visualizations, making it easier to communicate findings.</p></li>
<li><p><strong>Bundling into a Package</strong>: Finally, all elements are bundled into a single, distributable package that is discoverable and reusable, addressing critical elements of reproducibility in medical research.</p></li>
</ul>
</section>
</section>
<section id="hands-on-with-rum" class="level2">
<h2 class="anchored" data-anchor-id="hands-on-with-rum">Hands-On with rUM</h2>
<p>Kyle Gealis and Dr.&nbsp;Raymond Balise showcased the practical application of rUM during their presentation, guiding attendees through the steps of installing rUM, creating packages, and developing presentations. They demonstrated how to edit the R profile, initialize a package project, and navigate through various functionalities such as adding licenses, checking package integrity, and documenting datasets.</p>
<section id="creating-and-sharing-presentations" class="level3">
<h3 class="anchored" data-anchor-id="creating-and-sharing-presentations">Creating and Sharing Presentations</h3>
<p>One of the standout features of rUM is its ability to create and share presentations directly from the package. Researchers can build slide decks and integrate them into their packages, making it easier to disseminate research findings.</p>
</section>
</section>
<section id="new-features-in-rum-runner" class="level2">
<h2 class="anchored" data-anchor-id="new-features-in-rum-runner">New Features in rUM Runner</h2>
<p>The new version of rUM introduces several enhancements aimed at improving collaborative communication and documentation:</p>
<ul>
<li><strong>Write Notes</strong>: Create dated progress notes to keep track of project developments.</li>
<li><strong>Readme Templates</strong>: Generate structured readme files, guiding users through the project’s contents and processes.</li>
<li><strong>Quarto Documents and SCSS</strong>: Write Quarto documents and add custom SCSS for personalized styling.</li>
</ul>
</section>
<section id="an-invitation-to-the-r-community" class="level2">
<h2 class="anchored" data-anchor-id="an-invitation-to-the-r-community">An Invitation to the R Community</h2>
<p>The developers of rUM invite the R community to explore and contribute to the package. They encourage feedback, ideas for new templates, and even pull requests on GitHub. The goal is to continuously enhance rUM’s functionality, ensuring it meets the evolving needs of the biomedical research community.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>rUM Runner is more than just a tool; it’s a step towards a more reproducible future in biomedical research. By simplifying the process of creating comprehensive research packages, rUM empowers researchers to focus on science while ensuring their work is transparent, discoverable, and reusable. Whether you’re a seasoned programmer or new to R, rUM offers a pathway to enhancing the reproducibility and impact of your research.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/mix-pour-share-the-rum-cocktail-for-biomedical-project-packaging/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/mix-pour-share-the-rum-cocktail-for-biomedical-project-packaging/thumbnail-rum-gealis-balise.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Model Evaluation: From Machine Learning to Generative AI</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Lq568n0pClc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="exploring-the-future-of-ai-evaluation-with-dr.-erin-ledell-at-rmedicine-2025" class="level1">
<h1>Exploring the Future of AI Evaluation with Dr.&nbsp;Erin LeDell at R/Medicine 2025</h1>
<p>As artificial intelligence evolves, so must the methodologies used to evaluate these systems. Dr.&nbsp;Erin LeDell, a prominent figure in the AI and R communities, addressed this critical transition in her keynote at R/Medicine 2025. Dr.&nbsp;LeDell, the Chief Scientist at Distributional, Inc.&nbsp;and founder of DataScientific, Inc., brings her extensive expertise to the forefront as she guides us through the intricate world of AI evaluation, moving from deterministic machine learning models to the more complex generative AI systems.</p>
<section id="from-deterministic-to-generative-a-paradigm-shift" class="level2">
<h2 class="anchored" data-anchor-id="from-deterministic-to-generative-a-paradigm-shift">From Deterministic to Generative: A Paradigm Shift</h2>
<p>In traditional machine learning (ML), models are deterministic – given the same input, they produce the same output. This predictability provides a clear framework for evaluation metrics such as accuracy, precision, recall, and others familiar to statisticians and data scientists. However, with the rise of large language models (LLMs) and generative AI, this predictability is challenged. These systems introduce non-determinism, meaning outputs can vary even with identical inputs, necessitating new evaluation frameworks.</p>
<p>Dr.&nbsp;LeDell emphasized that traditional accuracy-based metrics fall short when assessing generative AI systems. Instead, evaluation must consider coherence, consistency, and bias, along with the challenges of reproducibility in probabilistic AI systems. This shift leads to questions about how to ensure AI models are reliable and function as expected in real-world scenarios.</p>
</section>
<section id="dr.-erin-ledells-journey-with-r-and-ai" class="level2">
<h2 class="anchored" data-anchor-id="dr.-erin-ledells-journey-with-r-and-ai">Dr.&nbsp;Erin LeDell’s Journey with R and AI</h2>
<p>Dr.&nbsp;LeDell shared her journey from machine learning to generative AI, highlighting her longstanding experience with R. Since 2008, she has been deeply involved in machine learning, contributing to various R packages such as SuperLearner, Subsemble, and H2O, the latter of which she worked on extensively during her tenure at H2O.ai. Her work in AutoML led to the creation of the AutoML benchmark, setting standards for algorithm evaluation.</p>
<p>Her transition into generative AI coincided with the advent of tools like ChatGPT, pushing her to explore new methods for evaluating these complex systems. Dr.&nbsp;LeDell’s passion for using AI in healthcare was evident as she discussed her collaborations with medical companies, applying machine learning to tackle various health-related problems.</p>
</section>
<section id="evaluating-generative-ai-new-approaches" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-generative-ai-new-approaches">Evaluating Generative AI: New Approaches</h2>
<p>The talk delved into the architectural differences between traditional ML systems and modern AI applications, particularly generative AI systems. Dr.&nbsp;LeDell outlined the multi-component nature of these systems, where changes in one part can affect the whole, and the importance of monitoring these changes over time. She addressed the non-stationary behavior of generative AI, noting how external factors and updates from third-party providers can alter system performance.</p>
<p>A significant challenge with generative AI is its inherent non-determinism. Unlike traditional ML models, generative AI requires novel evaluation metrics that account for variability in outputs. Dr.&nbsp;LeDell introduced several frameworks and tools aimed at assessing these systems, emphasizing the role of humans in the evaluation process. Humans provide essential oversight, creating “golden” datasets and evaluating outputs, though this process is not always scalable.</p>
</section>
<section id="llm-as-judge-a-new-standard" class="level2">
<h2 class="anchored" data-anchor-id="llm-as-judge-a-new-standard">LLM as Judge: A New Standard</h2>
<p>One innovative approach Dr.&nbsp;LeDell highlighted is using LLMs themselves to evaluate AI outputs. This method involves deploying LLMs as judges to assess whether responses are correct, helpful, or safe. While this technique is automated and widely used, it presents challenges, such as potential biases if the same model is used for generation and evaluation. Dr.&nbsp;LeDell recommended using specialized LLMs designed for evaluation to mitigate these issues.</p>
</section>
<section id="practical-applications-and-tools" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications-and-tools">Practical Applications and Tools</h2>
<p>Dr.&nbsp;LeDell provided insights into practical applications of generative AI in healthcare, such as using LLMs for clinical note-taking and research acceleration. She described a retrieval-augmented generation (RAG) system for medical Q&amp;A, which combines traditional information retrieval with generative capabilities, enriching AI responses with context from specialized knowledge bases.</p>
<p>For those eager to explore AI evaluation further, Dr.&nbsp;LeDell pointed to several open-source tools, including the R package “vitals,” a port of the Python library “inspect,” developed by JJ Allaire. These tools provide a foundation for customizing evaluation metrics and integrating human oversight into the evaluation pipeline.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Dr.&nbsp;LeDell’s keynote at R/Medicine 2025 illuminated the evolving landscape of AI evaluation, underscoring the need for innovative methodologies to assess the next generation of AI models. Her insights into the intersection of AI and healthcare offer promising pathways for improving AI reliability and trustworthiness in critical applications.</p>
<p>As the R community continues to embrace these advancements, Dr.&nbsp;LeDell’s work encourages practitioners to think critically and creatively about AI evaluation.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/thumbnail-keynote-day2-model-evaluation-ledell.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>No More Copy-Paste: Automating Patient Inquiry Tracking in Pharma with Shiny</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/no-more-copy-paste-automating-patient-inquiry-tracking-in-pharma-with-shiny/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sRNxjGXZ0_0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="automating-patient-inquiry-tracking-in-pharma-with-shiny-a-game-changer-in-specialty-pharma-coordination" class="level1">
<h1>Automating Patient Inquiry Tracking in Pharma with Shiny: A Game-Changer in Specialty Pharma Coordination</h1>
<p>In the fast-paced world of specialty pharma coordination, the seamless flow of information and timely delivery of medication can be a matter of life and death for patients with rare diseases. The challenge? Managing patient support and prescription workflows often involves disparate tools, manual data wrangling, and time-consuming reporting. Tanya Cashorali, the founder of TCB Analytics, addressed this critical issue in her presentation at the R/Medicine conference, showcasing how an R Shiny application revolutionized these processes.</p>
<section id="meet-the-speaker-tanya-cashorali" class="level2">
<h2 class="anchored" data-anchor-id="meet-the-speaker-tanya-cashorali">Meet the Speaker: Tanya Cashorali</h2>
<p>Tanya Cashorali is the founder of TCB Analytics, a Boston-based data science consultancy with a strong focus on bio and pharma. She has an impressive background in biotech, having started her career analyzing genetic data at Children’s Hospital in 2005. Tanya has since contributed to building molecular applications at Dana Farber, conducted modeling work at GNS Healthcare to understand causal mechanisms of disease, and helped launch TCB Analytics after her tenure at Biogen.</p>
</section>
<section id="the-problem-manual-mayhem-in-specialty-pharma-coordination" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-manual-mayhem-in-specialty-pharma-coordination">The Problem: Manual Mayhem in Specialty Pharma Coordination</h2>
<p>For bio and pharma companies treating rare diseases, ensuring patients receive their medications on time is crucial. However, the process often involves multiple manual steps:</p>
<ul>
<li>Physicians write prescriptions that go to specialty pharmacies.</li>
<li>Biopharma companies ensure the availability of drugs.</li>
<li>Specialty pharmacies ship the drugs to patients.</li>
</ul>
<p>This workflow was previously managed through Excel sheets and lengthy email chains. The result? Manual mayhem, with room for errors, slow case preparation, and time-consuming weekly status meetings.</p>
</section>
<section id="the-solution-an-r-shiny-application" class="level2">
<h2 class="anchored" data-anchor-id="the-solution-an-r-shiny-application">The Solution: An R Shiny Application</h2>
<p>To tackle this challenge, Tanya and her team developed an R Shiny application that serves as a dynamic operational hub. This application integrates prescription fulfillment data with Smartsheet-tracked patient inquiries, providing a unified, interactive dashboard for users. Key features include:</p>
<ul>
<li><strong>Real-time Data Integration:</strong> The application merges daily Excel-based prescription data with live Smartsheet API feeds.</li>
<li><strong>Interactive Dashboard:</strong> Users can filter, sort, and export patient records while tracking key support metrics such as shipment history and open ticket status.</li>
<li><strong>Ticket Creation and Management:</strong> Users can create and manage tickets directly from the application, which syncs with Smartsheet to streamline communication between the market access team and specialty pharmacies.</li>
</ul>
</section>
<section id="impact-and-efficiency-gains" class="level2">
<h2 class="anchored" data-anchor-id="impact-and-efficiency-gains">Impact and Efficiency Gains</h2>
<p>The impact of this R Shiny application has been significant:</p>
<ul>
<li><strong>Streamlined Communication:</strong> The application replaces five daily emails, reduces meeting times from 30 to 10 minutes, and supports over 36 users, including sales teams and market access teams.</li>
<li><strong>Real-time Insights:</strong> The application provides a single source of real-time truth, enabling more productive case tracking and management.</li>
<li><strong>Data-Driven Decisions:</strong> With 400 patients and two drug products tracked, the application offers valuable data insights, such as time to resolution and issue frequency across specialty pharmacies.</li>
</ul>
</section>
<section id="lessons-learned" class="level2">
<h2 class="anchored" data-anchor-id="lessons-learned">Lessons Learned</h2>
<p>Tanya shared valuable lessons learned from the project:</p>
<ul>
<li><strong>Start Simple:</strong> Begin with sketches and iterate based on user feedback.</li>
<li><strong>Build Dashboards with People, Not Just for Them:</strong> Engage users early and often to ensure the solution meets their needs.</li>
<li><strong>Leverage Power Users:</strong> Identify and collaborate with power users who can provide valuable feedback and drive adoption.</li>
<li><strong>Avoid Overengineering:</strong> Use existing tools like R Shiny, Smartsheet, and pins to create efficient solutions without complex infrastructure.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The R Shiny application developed by TCB Analytics exemplifies the power of R in transforming workflows and improving patient outcomes in the pharma industry. By automating patient inquiry tracking, the application not only streamlines operations but also ensures that patients receive their medications promptly, ultimately saving lives.</p>
<p>As Tanya summarized, this project demonstrates that you don’t need a big vendor platform or a six-month roadmap to make a significant impact. With the right tools and a focus on user needs, R can drive meaningful change in healthcare and beyond.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Pharma</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/no-more-copy-paste-automating-patient-inquiry-tracking-in-pharma-with-shiny/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/no-more-copy-paste-automating-patient-inquiry-tracking-in-pharma-with-shiny/thumbnail-no-more-copy-paste-tanya.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>nonprobsvy – An R package for modern methods for non-probability survey</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/MnEZlFcpmCE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unveiling-the-nonprobsvy-package-a-leap-in-non-probability-sample-inference-in-r" class="level1">
<h1>Unveiling the <code>nonprobsvy</code> Package: A Leap in Non-Probability Sample Inference in R</h1>
<p>Greetings R community! Today, we’re thrilled to delve into the details of <code>nonprobsvy</code>, an R package crafted for inference based on non-probability samples. Presented by Maciej Beręsewicz from the Poznań University of Economics and Business and the Statistical Office in Poznań, this package is a tool for statisticians dealing with the challenges of non-probability samples in various research domains.</p>
<section id="addressing-non-probability-sample-challenges" class="level2">
<h2 class="anchored" data-anchor-id="addressing-non-probability-sample-challenges">Addressing Non-Probability Sample Challenges</h2>
<p>The core motivation behind the development of <code>nonprobsvy</code> stems from the limitations often encountered in official statistics due to declining response rates and the growing reliance on non-probability surveys for population inference. Such surveys, including big data, opt-in web panels, and social media data, often introduce selection bias, complicating accurate population characteristic estimations.</p>
<p>Beręsewicz, deeply rooted in survey sampling and methodology, recognized these challenges through his work at the university and the Statistical Office in Poznań. This package is a testament to his commitment to providing robust statistical methods that correct selection bias, making it a resource for researchers worldwide.</p>
</section>
<section id="the-power-of-nonprobsvy" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-nonprobsvy">The Power of <code>nonprobsvy</code></h2>
<p><code>nonprobsvy</code> integrates with the popular <code>survey</code> package in R, offering a toolkit for addressing non-probability sample biases. It categorizes its approaches into three main groups: prediction-based approach, inverse probability weighting, and doubly robust approach. Here’s a closer look at what it provides:</p>
<ol type="1">
<li><strong>Inverse Probability Weighting (IPW):</strong> Allows for correction of selection bias using known population totals or survey designs.</li>
<li><strong>Mass Imputation Estimators:</strong> Employs methods such as regression imputation and nearest neighbors to estimate missing data.</li>
<li><strong>Doubly Robust Estimators:</strong> Combines the strengths of both IPW and outcome modeling for improved estimations.</li>
<li><strong>High-Dimensional Data Handling:</strong> Features variable selection using techniques like SCAD, LASSO, or MCP, crucial for handling administrative data or surveys with extensive questionnaires.</li>
</ol>
</section>
<section id="a-user-friendly-package" class="level2">
<h2 class="anchored" data-anchor-id="a-user-friendly-package">A User-Friendly Package</h2>
<p>The <code>nonprobsvy</code> package is designed with user-friendliness in mind. Its main function, <code>nonprop()</code>, mimics existing R functions by utilizing formulas, ensuring a smooth transition for users familiar with R’s ecosystem. The package supports both analytical and bootstrap variance estimators, providing flexibility and robustness in variance estimation.</p>
<section id="unique-features" class="level3">
<h3 class="anchored" data-anchor-id="unique-features">Unique Features</h3>
<ul>
<li><strong>Full Integration with the Survey Package:</strong> Ensures compatibility and extends the capabilities of existing survey methods.</li>
<li><strong>Advanced Estimators:</strong> Implements state-of-the-art methods, including those recently accepted for publication, ensuring users have access to the latest developments in survey sampling.</li>
<li><strong>Extensive Documentation:</strong> Provides detailed explanations, equations, and use cases, guiding users through implementation and interpretation.</li>
</ul>
</section>
</section>
<section id="looking-ahead-future-developments" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead-future-developments">Looking Ahead: Future Developments</h2>
<p>Beręsewicz and his team have ambitious plans for the future of <code>nonprobsvy</code>. They aim to incorporate overlapping samples, replicate weights, and expand mass imputation methods beyond parametric approaches. There is also a focus on developing inference methods for quantiles and integrating mixed-mode data handling, reflecting the dynamic needs of contemporary research.</p>
<section id="community-involvement" class="level3">
<h3 class="anchored" data-anchor-id="community-involvement">Community Involvement</h3>
<p>The development team encourages feedback and suggestions from the community. By engaging with users on GitHub, they aim to continuously refine and enhance the package. If you have innovative ideas or encounter challenges, they’re eager to hear from you.</p>
</section>
</section>
<section id="call-to-action" class="level2">
<h2 class="anchored" data-anchor-id="call-to-action">Call to Action</h2>
<p><code>nonprobsvy</code> is available on CRAN, and its development version is hosted on GitHub. We invite you to explore this powerful package, test its capabilities, and contribute to its evolution. Your insights and experiences are invaluable in shaping its future.</p>
<p>For researchers, statisticians, and R enthusiasts, <code>nonprobsvy</code> offers a robust solution to the complexities of non-probability samples. Whether you’re tackling big data, social media analytics, or opt-in web panels, this package equips you with the tools needed to derive accurate, reliable inferences.</p>
<p>To learn more about the package, visit the <a href="https://cran.r-project.org/package=nonprobsvy">CRAN page</a> or <a href="http://github.com/ncn-foreigners/nonprobsvy">GitHub repository</a>. Let’s work together in advancing statistical methodologies and making impactful contributions to the R community.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/thumbnail-nonprobsvy.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Opening Remarks - Day 2</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/opening-remarks-day-2/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/HWJH9RiGFsc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="rmedicine-2025-day-2-a-celebration-of-r-in-medicine" class="level1">
<h1>R/Medicine 2025 Day 2: A Celebration of R in Medicine</h1>
<p>The R/Medicine 2025 conference, a flagship event brought to the community by the R Consortium, continues to be a focus of innovation and collaboration between R programming and medicine. With participants joining from diverse corners of the globe, including, just to name a few read off by Zabor during the talk, the Netherlands, Romania, London, Germany, and from US states like Florida, California, Minnesota, and Pennsylvania, the event shines as a testament to the universal appeal and utility of R in medical research and practice.</p>
<section id="acknowledgments-and-gratitude" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments-and-gratitude">Acknowledgments and Gratitude</h2>
<p>The second day of the conference commenced with a welcome extended by Emily Zabor, the event’s chair and a dedicated biostatistician at the Cleveland Clinic.</p>
<p>Zabor emphasized that the success of R/Medicine 2025 owes much to the support of its financial sponsors, Genentech and Posit, alongside the invaluable backing of the R Consortium. Thanks are also due to the organizing committee, whose dedication and expertise have been instrumental in crafting this enriching experience. And, of course, to all participants who contribute time, knowledge and energy.</p>
</section>
<section id="recap-of-day-1-highlights" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-day-1-highlights">Recap of Day 1 Highlights</h2>
<p>The first day of the conference was marked by an array of insightful presentations and discussions. Attendees were treated to a keynote by Ziad Obermeyer, who delved into the transformative potential of AI in the realm of medicine. The day unfolded with 9 regular talks and 2 lightning talks that spanned topics such as reproducibility, compliance, workflow automation, and clinical epidemiological applications.</p>
<p>A notable highlight was the presentation of competition winners in both the student and professional categories. Their analysis of vaccination and measles case rates for 2025 provided critical insights, despite the somewhat concerning data trends. The rigor and clarity of their presentations underscored the power of data-driven decision-making in public health.</p>
<section id="video-availability" class="level3">
<h3 class="anchored" data-anchor-id="video-availability">Video Availability</h3>
<p>For those who missed the live sessions, most of the presentations will be made available on the <a href="https://www.youtube.com/playlist?list=PL4IzsxWztPdmU2q31ZrTCASr78e0jpKux">R Consortium’s YouTube channel</a>. Participants are encouraged to watch for communications regarding the release of these videos, which will serve as a valuable resource for continued learning and inspiration.</p>
</section>
</section>
<section id="day-2-exciting-lineup-of-keynotes-and-talks" class="level2">
<h2 class="anchored" data-anchor-id="day-2-exciting-lineup-of-keynotes-and-talks">Day 2: Exciting Lineup of Keynotes and Talks</h2>
<p>Day Two promises another engaging lineup, starting with a keynote by Erin LeDell, focusing on model evaluation from machine learning to generative AI. This is followed by 6 regular talks and 11 lightning talks. Sessions will cover a broad spectrum of topics, including:</p>
<ul>
<li>Packages and tools for data management</li>
<li>Cohorts and APIs</li>
<li>Visualization and communication</li>
<li>Clinical and epidemiological applications</li>
<li>Statistical modeling, inference, and methodology</li>
</ul>
<p>This diversity of topics reflects the multifaceted nature of R’s applications in medicine, ensuring that there is something of interest for every attendee.</p>
</section>
<section id="community-and-networking" class="level2">
<h2 class="anchored" data-anchor-id="community-and-networking">Community and Networking</h2>
<p>The conference provides an excellent platform for networking and community building. With a few minutes between sessions, attendees are encouraged to engage in discussions and share ideas. This interaction fosters a sense of camaraderie and collaboration, essential for advancing the field.</p>
</section>
<section id="looking-ahead-future-webinars" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead-future-webinars">Looking Ahead: Future Webinars</h2>
<p>The R/Medicine conference is not limited to annual gatherings. Throughout the year, the <a href="https://r-consortium.org/webinars/webinars.html">R Consortium hosts webinars</a> that delve deeper into specific topics of interest. Last year saw two mid-year R/Medicine webinars, and this tradition of continuous learning and engagement is set to continue. Participants should stay tuned for announcements.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>R/Medicine 2025 stands as a vibrant celebration of the role of R in advancing medical research and practice. With an agenda packed with insightful talks, expert speakers, and a global community of attendees, the event embodies the spirit of innovation and collaboration. Participants are encouraged to immerse themselves in the wealth of knowledge shared and to continue engaging with the R community beyond the conference.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Events</category>
  <guid>https://r-consortium.org/posts/opening-remarks-day-2/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/opening-remarks-day-2/thumbnail-opening-remarks-day2.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Optimizing Public Healthcare Cost Recovery with R: A Use Case from Argentina</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/BzYtr9dfHjQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="optimizing-argentinas-public-healthcare-system-with-r-a-case-study-in-efficiency-and-sustainability" class="level1">
<h1>Optimizing Argentina’s Public Healthcare System with R: A Case Study in Efficiency and Sustainability</h1>
<p>In the realm of public health, the need to do more with less is a constant challenge. This is particularly true in Argentina, where the healthcare system is fragmented into three subsystems: public, social security, and private sectors. Each of these subsystems serves different populations and has its unique funding mechanisms and challenges. However, in the spirit of equity and quality healthcare access, programs like SUMAR have emerged as vital tools for supporting the uninsured population by strengthening the public subsystem. SUMAR provides financial incentives to healthcare providers for each service rendered to individuals with exclusive public coverage, funded by external sources such as the World Bank.</p>
<p>In this context, the Ministry of Health of the City of Buenos Aires has undertaken an innovative approach to optimize cost recovery processes via the implementation of open-source tools, particularly R, showcasing a practical application of data science in public health settings. This effort is spearheaded by the Operational Management of Health Information and Statistics, a team that uses R to enhance healthcare efficiency and sustainability.</p>
<section id="understanding-argentinas-healthcare-landscape" class="level2">
<h2 class="anchored" data-anchor-id="understanding-argentinas-healthcare-landscape">Understanding Argentina’s Healthcare Landscape</h2>
<p>Argentina’s healthcare landscape is characterized by its division into three main sectors:</p>
<ol type="1">
<li><strong>Public Sector</strong>: Comprising national, provincial, and municipal hospitals offering free universal care regardless of a person’s insurance status.</li>
<li><strong>Social Security Sector</strong>: Funded through payroll and catering to workers, retirees, and individuals with disabilities, providing mandatory coverage linked to formal employment.</li>
<li><strong>Private Sector</strong>: Offering voluntary, prepaid plans for those seeking additional or alternative coverage.</li>
</ol>
<p>The SUMAR program comes into play as a national policy aimed at better financing public healthcare by tying financial incentives directly to the services provided to uninsured individuals. It operates on a results-based funding model, which allocates resources based on service provision and health outcomes, with funding sourced primarily from the World Bank.</p>
</section>
<section id="leveraging-technology-for-sustainable-healthcare" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-technology-for-sustainable-healthcare">Leveraging Technology for Sustainable Healthcare</h2>
<p>The City of Buenos Aires is at the forefront of utilizing technology to optimize healthcare processes. The widespread adoption of the Electronic Health Record (EHR) system, known as the Hospital Management System (HMS), is a game-changer. HMS seamlessly integrates administrative and clinical workflows across public healthcare facilities, ensuring uniform data collection and management.</p>
<p>The data extracted from HMS is crucial for automating the SUMAR program. Each night, ETL (Extract, Transform, Load) jobs extract relevant data tables, such as patient encounters and diagnostics, which are then loaded into a central data warehouse. This setup forms the backbone of the automated SUMAR workflow in Buenos Aires.</p>
</section>
<section id="automating-the-sumar-process-with-r" class="level2">
<h2 class="anchored" data-anchor-id="automating-the-sumar-process-with-r">Automating the SUMAR Process with R</h2>
<p>The automation of the SUMAR program is a testament to the power of open-source tools like R. The data science team within the Ministry of Health employs R to automate processes and generate reports, ensuring a smooth and efficient workflow. Key outputs of this automated process include PDF invoices, weekly Excel reports, and performance indicator summaries.</p>
<p>The R-based workflow comprises three critical stages:</p>
<ol type="1">
<li><strong>Enrollment</strong>: Identifying individuals with public coverage using national registries.</li>
<li><strong>Detection of Basic Effective Coverage Services</strong>: Applying regex and logic rules across data sources to pinpoint eligible health services.</li>
<li><strong>Analysis of Health Performance Indicators</strong>: Generating comprehensive reports through R Markdown, ensuring data is transformed into actionable insights.</li>
</ol>
<p>The team’s dedicated R environment, which includes an R Studio server and GitLab for version control, facilitates collaborative development, ensuring the process is both reproducible and auditable.</p>
</section>
<section id="the-impact-of-automation-and-open-source" class="level2">
<h2 class="anchored" data-anchor-id="the-impact-of-automation-and-open-source">The Impact of Automation and Open Source</h2>
<p>The automation of the SUMAR program in Buenos Aires is not merely about efficiency—it represents a paradigm shift in how public healthcare can be managed. The steady increase in detected health services from January 2021 to April 2025 is a testament to the robustness and scalability of the automated processes. Each detected service translates into real funding, enhancing the capacity and accountability of the public healthcare system.</p>
<p>The use of R, with libraries like Tidyverse, StringR, WriteXL, and TinyTex, underscores the adaptability and sustainability of open-source solutions in public health. This approach not only saves time but also expands service coverage, ensuring that more individuals benefit from essential healthcare services.</p>
</section>
<section id="future-directions-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="future-directions-and-opportunities">Future Directions and Opportunities</h2>
<p>The success of the SUMAR program’s automation opens up new possibilities for further innovation within the public healthcare sector. While the current focus is on generating tables and reports, there is potential for developing more interactive data visualizations and dashboards using tools like Shiny or R Markdown’s interactive capabilities. Such advancements could provide deeper insights and facilitate data-driven decision-making at various levels of government.</p>
<p>In conclusion, the use of R in automating the SUMAR program in Buenos Aires highlights the transformative potential of data science in public health. By optimizing administrative workflows and enhancing data traceability, this initiative not only improves cost recovery efforts but also sets a benchmark for other regions to follow. As we look to the future, the continued adoption of open-source tools in healthcare promises to drive innovation and sustainability, ultimately benefiting populations most in need.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/thumbnail-optimizing-buenos-aires.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Preprocessing Electronic Health Records for Analysis-Ready Data in an Asthma Cohort</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EytsZg9Rqkg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="pre-processing-electronic-health-records-for-asthma-cohort-analysis-with-r" class="level1">
<h1>Pre-processing Electronic Health Records for Asthma Cohort Analysis with R</h1>
<p>Electronic health record (EHR) data has emerged as a critical tool for conducting large-scale biomedical research. However, the complexity, inconsistencies, and potential inaccuracies within EHR data pose significant challenges for researchers. Kimberly Lactaoen, a staff scientist at the University of Pennsylvania, sheds light on these challenges and offers solutions through her presentation at R/Medicine 2025. By utilizing the tidyverse suite in R, she demonstrates how to transform perplexing EHR data into analysis-ready datasets, focusing on an asthma cohort study.</p>
<section id="understanding-the-intricacies-of-ehr-data" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-intricacies-of-ehr-data">Understanding the Intricacies of EHR Data</h2>
<p>EHR data encompasses vast amounts of patient information, providing a realistic representation of patient populations. Despite its potential, EHR data is riddled with complexities, including inconsistent data entries, diverse formats, and missing values, which can misrepresent a patient’s true health status. Lactaoen’s presentation focuses on the importance of understanding how this data is collected to streamline exploratory analyses and reduce scripting stages.</p>
<section id="key-challenges-in-ehr-data-cleaning" class="level3">
<h3 class="anchored" data-anchor-id="key-challenges-in-ehr-data-cleaning">Key Challenges in EHR Data Cleaning</h3>
<ol type="1">
<li><p><strong>Encounter-Level vs.&nbsp;Patient-Level Data</strong>: One of the initial hurdles is discerning between encounter-level and patient-level data. For instance, demographic details like sex, race, and ethnicity remain constant across encounters, while variables like insurance and BMI may vary. Lactaoen highlights the significance of understanding data collection methods to efficiently script for the most recent demographic entries using functions such as <code>as_date()</code> from the <code>lubridate</code> package.</p></li>
<li><p><strong>Conflicting Patient Information</strong>: EHR datasets often contain conflicting information, especially in demographic variables like race and ethnicity. Lactaoen’s approach involved using the <code>case_when()</code> function from <code>dplyr</code> to resolve conflicts, ensuring consistent and distinct race and ethnicity variables.</p></li>
<li><p><strong>Inconsistent Diagnostic Codes</strong>: Diagnostic code descriptions can vary, complicating the grouping of patients based on diagnoses. Lactaoen addresses this by joining diagnostic codes with descriptions from the Center for Medicare and Medicaid Services using <code>left_join()</code>, ensuring consistency across datasets.</p></li>
<li><p><strong>Medication Relevance for Asthma Treatment</strong>: Selecting relevant medications for asthma treatment from EHR data is another challenge. Lactaoen’s team collaborated with asthma specialists to filter relevant medications, leveraging Excel and the <code>map_dfr()</code> function from the <code>purrr</code> package to compile a comprehensive list for analysis.</p></li>
<li><p><strong>Laboratory Test Result Variability</strong>: Laboratory test results, such as eosinophil data, often feature varying units of measurement. Lactaoen utilized the <code>case_when()</code> function to standardize these units, though issues like missing unit information remain a work in progress.</p></li>
</ol>
</section>
</section>
<section id="strategies-for-effective-ehr-data-pre-processing" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-effective-ehr-data-pre-processing">Strategies for Effective EHR Data Pre-processing</h2>
<p>Lactaoen’s presentation offers several strategies for overcoming these challenges:</p>
<ul>
<li><strong>Understand Data Collection</strong>: Familiarizing oneself with the data collection process is crucial for reducing exploratory analysis and scripting efforts.</li>
<li><strong>Identify and Resolve Conflicts</strong>: Be vigilant about conflicting information, which may not accurately reflect a patient’s health status.</li>
<li><strong>Collaborate with Domain Experts</strong>: Engaging with specialists, such as asthma experts, ensures that the data used is relevant and accurate for the study.</li>
<li><strong>Simplify and Standardize Data</strong>: Wherever possible, simplify data entries and standardize units to facilitate easier analysis.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Lactaoen’s insights into EHR data pre-processing underscore the importance of meticulous data cleaning and transformation. By leveraging R’s tidyverse suite, researchers can effectively prepare EHR data for analysis, paving the way for impactful biomedical research. Her emphasis on understanding data collection, resolving conflicts, collaborating with experts, and standardizing data provides a robust framework for researchers embarking on EHR-based studies.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/thumbnail-reprocessing-ehs-lactaoen.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>rainbowR: A community for LGBTQ+ folks who code in R</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gLlRaqNfjys" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="embracing-inclusivity-in-r-the-journey-of-rainbowr" class="level1">
<h1>Embracing Inclusivity in R: The Journey of rainbowR</h1>
<p>In the ever-evolving world of data science and statistical computing, R has become a beloved language, not just for its robustness and versatility, but also for its vibrant and inclusive community. A shining example of this inclusivity is rainbowR, a community dedicated to connecting, supporting, and promoting LGBTQ+ individuals who code in R. Founded by Ella Kaye of the University of Warwick, rainbowR has transformed into a thriving hub for LGBTQ+ coders and allies alike, fostering a sense of belonging and camaraderie through innovative initiatives and data-driven activism.</p>
<section id="origin-and-growth-of-rainbowr" class="level2">
<h2 class="anchored" data-anchor-id="origin-and-growth-of-rainbowr">Origin and Growth of rainbowR</h2>
<p>The inception of rainbowR dates back to the useR! Conference in 2017, when Ella Kaye engaged in a conversation that highlighted the need for a dedicated LGBTQ+ space within the R community. Fast forward to today, and rainbowR has grown exponentially, boasting a membership of over 100 individuals. This growth is not just a testament to the need for such a community but also to the welcoming atmosphere and the meaningful connections it fosters.</p>
</section>
<section id="monthly-meetups-and-buddy-scheme" class="level2">
<h2 class="anchored" data-anchor-id="monthly-meetups-and-buddy-scheme">Monthly Meetups and Buddy Scheme</h2>
<p>Central to rainbowR’s mission are its monthly online meetups, typically held on the fourth Wednesday of each month. These gatherings provide a relaxed and supportive environment where participants can discuss R-related topics, share resources, and showcase their work. The focus on creating a friendly space encourages open dialogue and fosters learning among members.</p>
<p>Another key initiative is the buddy scheme, which aims to facilitate deeper connections within the community. Every three months, members can opt into the scheme, where they are randomly paired with another member. An R script processes these pairings and generates personalized emails to introduce the paired individuals. This innovative approach not only eases the anxiety of meeting new people but also enriches the community fabric by fostering one-on-one connections.</p>
</section>
<section id="data-driven-activism" class="level2">
<h2 class="anchored" data-anchor-id="data-driven-activism">Data-Driven Activism</h2>
<p>rainbowR’s commitment to raising awareness about LGBTQ+ issues is further exemplified through its GitHub repository, Tidy Rainbow. This repository hosts a collection of LGBTQ+ datasets, providing valuable resources for data visualization and analysis. These datasets can be utilized for educational purposes, blog posts, or simply to practice data skills, making them a valuable asset for both community members and allies.</p>
</section>
<section id="engaging-with-literature-the-rainbow-r-book-club" class="level2">
<h2 class="anchored" data-anchor-id="engaging-with-literature-the-rainbow-r-book-club">Engaging with Literature: The Rainbow R Book Club</h2>
<p>In addition to its technical initiatives, rainbowR has ventured into the literary world with its book club. The club recently completed its first session, where participants delved into “Queer Data: Using Gender, Sex, and Sexuality Data for Action” by Kevin Gian. The success of this book club highlights the community’s commitment to broadening its understanding of LGBTQ+ issues through various mediums. Future book club sessions are in the pipeline, promising more engaging discussions and insights.</p>
</section>
<section id="future-plans-and-the-role-of-allies" class="level2">
<h2 class="anchored" data-anchor-id="future-plans-and-the-role-of-allies">Future Plans and the Role of Allies</h2>
<p>As rainbowR looks to the future, exciting plans are underway to ensure the community’s sustainability and impact. Ella Kaye, now a fellow of the Software Sustainability Institute, is utilizing her fellowship to nurture and solidify rainbowR’s foundations. This includes establishing clear engagement pathways, developing governance policies, and potentially becoming a legal entity.</p>
<p>A flagship event in the pipeline is the inaugural Rainbow R Conference, designed to bring the community together to share knowledge and celebrate diversity. Allies play a crucial role in this journey, and their involvement is highly valued within rainbowR. The conference organizing committee welcomes allies, further emphasizing the inclusive nature of this vibrant community.</p>
</section>
<section id="call-for-collaboration-and-community-building" class="level2">
<h2 class="anchored" data-anchor-id="call-for-collaboration-and-community-building">Call for Collaboration and Community Building</h2>
<p>rainbowR’s mission extends beyond its own community. By sharing knowledge and experiences with other R or queer communities, rainbowR aims to build a network of support and shared learning. Community managers interested in exploring best practices for community building are encouraged to reach out to Ella Kaye and explore potential collaborations.</p>
</section>
<section id="join-the-movement" class="level2">
<h2 class="anchored" data-anchor-id="join-the-movement">Join the Movement</h2>
<p>For those interested in joining this vibrant community, rainbowR offers an open invitation to LGBTQ+ individuals and allies. By visiting <a href="https://rainbow.org">rainbow.org</a>, you can learn more about the community, sign up for newsletters, and become part of a supportive network that celebrates diversity and inclusivity in the R ecosystem.</p>
<p>rainbowR is more than just a community; it’s a movement towards a more inclusive and supportive future for all who code in R. As the community continues to grow and evolve, it stands as a testament to the power of connection and the impact of collective action in the world of data science.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>LGBTQ+</category>
  <guid>https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/thumbnail-rainbowr.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Refactor or Preserve? Challenging ‘If It Ain’t Broken, Don’t Fix It’ Mindset in Shiny App Lifecycle</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/refactor-or-preserve-challenging-if-it-aint-broken-dont-fix-it-mindset-in-shiny-app-lifecycle/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/9agO0o2gP68" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="refactor-or-preserve-challenging-the-if-it-aint-broken-dont-fix-it-mindset-in-shiny-app-lifecycle" class="level1">
<h1>Refactor or Preserve: Challenging the “If It Ain’t Broken, Don’t Fix It” Mindset in Shiny App Lifecycle</h1>
<p>In the ever-evolving landscape of technology, even well-crafted software solutions eventually face obsolescence. This reality brings forth a critical question for developers: to refactor or not? Dror Berel, an independent consultant with a diverse background in statistics, R, and the pharmaceutical industry, delves into this conundrum using the Pharmaverse/Teal framework as a case study. His insights shed light on the benefits and risks of transitioning a functional Shiny application to a modern framework.</p>
<section id="the-lifecycle-of-software-and-the-scope-creep-phenomenon" class="level2">
<h2 class="anchored" data-anchor-id="the-lifecycle-of-software-and-the-scope-creep-phenomenon">The Lifecycle of Software and the Scope Creep Phenomenon</h2>
<p>Throughout his career, Dror Berel has navigated through various programming environments—from SAS and S+ to R, becoming an early adopter of R web applications. His journey has led him through the intricate process of managing messy data and transforming it into meaningful insights. A recurring challenge in this process is the phenomenon of “scope creep,” where the project’s scope gradually expands beyond its original intent. This often results in unwieldy, spaghetti-like code that demands constant patching.</p>
<p>Dror defines scope creep as the uncontrolled or gradual expansion of project scope, adding features or requirements without corresponding adjustments in resources. This incremental approach can lead to inefficiencies and the need for a complete overhaul. Dror argues that instead of perpetually patching code, building a better solution from scratch can be a more sustainable approach.</p>
</section>
<section id="the-innovation-adoption-curve-in-r-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="the-innovation-adoption-curve-in-r-frameworks">The Innovation Adoption Curve in R Frameworks</h2>
<p>Dror introduces the concept of the product adoption lifecycle, also known as the innovation adoption curve, to illustrate the evolution of R frameworks. Initially, solutions like R Base were created to address specific pain points. Over time, as these solutions gained popularity, they attracted early adopters, eventually reaching a broader audience. However, with the emergence of new challenges, frameworks like Tidyverse and Shiny were developed to address these issues.</p>
<p>Dror highlights the current landscape where modern frameworks, such as Teal and Rhino, are gaining traction, offering more advanced solutions for complex Shiny applications. He emphasizes the importance of understanding when to embrace these new frameworks and when to preserve existing solutions.</p>
</section>
<section id="the-case-for-refactoring-when-and-why" class="level2">
<h2 class="anchored" data-anchor-id="the-case-for-refactoring-when-and-why">The Case for Refactoring: When and Why?</h2>
<p>Refactoring is an integral part of the software lifecycle, but it requires careful consideration. Dror outlines scenarios when refactoring is justified:</p>
<ol type="1">
<li><p><strong>Deprecated Dependencies</strong>: When existing dependencies become outdated or unsupported, refactoring becomes necessary to ensure continued functionality.</p></li>
<li><p><strong>Scope Creep</strong>: If the current scope of the project exceeds its original limitations, refactoring can provide a more efficient and sustainable solution.</p></li>
<li><p><strong>Critical Pain Points</strong>: When the existing framework cannot adequately address a critical issue, adopting a new solution may be warranted.</p></li>
<li><p><strong>Trust in New Solutions</strong>: Refactoring should be pursued when there is confidence in the new solution’s longevity and support.</p></li>
</ol>
</section>
<section id="the-role-of-modern-frameworks-in-shiny-applications" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-modern-frameworks-in-shiny-applications">The Role of Modern Frameworks in Shiny Applications</h2>
<p>Dror delves into specific frameworks that have emerged to address the complexities of Shiny applications. He highlights the Pharmaverse open-source community’s ecosystem, particularly the Teal framework, which simplifies the development of Shiny apps by leveraging modules. This modular approach allows developers to focus on high-level objectives rather than getting bogged down in low-level details.</p>
<p>In addition to Teal, Dror mentions the Rhino framework, which provides recommendations for organizing files within an app, enhancing maintainability. Together with the Box package, these frameworks offer clear code quality, automation, and more, empowering developers to create robust Shiny applications.</p>
</section>
<section id="when-not-to-refactor-preserving-stability" class="level2">
<h2 class="anchored" data-anchor-id="when-not-to-refactor-preserving-stability">When Not to Refactor: Preserving Stability</h2>
<p>While refactoring offers numerous benefits, there are scenarios where it may not be necessary or advisable:</p>
<ol type="1">
<li><p><strong>Legacy Methodology</strong>: If replicating legacy methodologies is challenging and not well-understood, preservation may be the safer option.</p></li>
<li><p><strong>Overkill Features</strong>: Introducing features that do not significantly enhance functionality may lead to unnecessary complexity.</p></li>
<li><p><strong>Heavy Dependencies</strong>: Modern frameworks can introduce dependencies that may not align with project objectives, warranting a cautious approach.</p></li>
</ol>
</section>
<section id="conclusion-balancing-innovation-and-stability" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-balancing-innovation-and-stability">Conclusion: Balancing Innovation and Stability</h2>
<p>In conclusion, the decision to refactor or preserve an existing solution hinges on a variety of factors, including the project’s scope, the availability of modern frameworks, and the specific challenges faced. Dror Berel emphasizes the importance of being strategic and intentional in these decisions, weighing the risks and benefits to ensure long-term success.</p>
<p>For the R community, embracing new frameworks and technologies is essential for staying at the forefront of innovation. However, it is equally important to recognize when stability and preservation are the most prudent paths forward. By striking this balance, developers can ensure the longevity and effectiveness of their Shiny applications, ultimately delivering greater value to users and stakeholders.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/refactor-or-preserve-challenging-if-it-aint-broken-dont-fix-it-mindset-in-shiny-app-lifecycle/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/refactor-or-preserve-challenging-if-it-aint-broken-dont-fix-it-mindset-in-shiny-app-lifecycle/thumbnail-refactoring-dror.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Retrospective clinical data harmonisation reporting using R and Quarto</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/retrospective-clinical-data-harmonisation-reporting-using-r-and-quarto/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0rUcKR4fylw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-clinical-data-harmonization-with-r-and-quarto" class="level1">
<h1>Enhancing Clinical Data Harmonization with R and Quarto</h1>
<p>Data harmonization has emerged as a crucial component in ensuring the integrity and utility of pooled data sets in clinical research. Jeremy Selva, a Research Officer at the National Heart Center Singapore, delivered a talk at R/Medicine 2025 on “Retrospective Clinical Data Harmonization Reporting.” His presentation delved into data harmonization, offering practical solutions and workflows for creating comprehensive reports using R and Quarto.</p>
<section id="the-challenge-of-data-harmonization" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-of-data-harmonization">The Challenge of Data Harmonization</h2>
<p>Data harmonization is an indispensable part of the data cleaning process. It involves identifying similar variables across diverse data sets, grouping them based on generalized concepts, and transforming them into unified, harmonized variables for analysis. This process is particularly vital in clinical research, where data pooling from multiple sources can dramatically increase the statistical power to analyze rare outcomes.</p>
<p>However, as Jeremy highlighted, the path to effective data harmonization is fraught with challenges. Collaborators often send data in varying formats, making it difficult to match them against provided data dictionaries and input templates. This lack of uniformity necessitates a robust process to document and report the harmonization steps, serving as a bridge between data collaborators and the analysis team.</p>
</section>
<section id="the-importance-of-harmonization-reports" class="level2">
<h2 class="anchored" data-anchor-id="the-importance-of-harmonization-reports">The Importance of Harmonization Reports</h2>
<p>Jeremy emphasized the importance of transparency and accountability in data harmonization. A well-documented harmonization report can serve as a safeguard, providing clarity to collaborators and preempting potential issues that might arise from data mismanagement.</p>
<p>Despite the critical role of such reports, there is a dearth of resources providing detailed guidance on creating them, particularly using programming languages like R.</p>
</section>
<section id="leveraging-r-for-data-harmonization" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-r-for-data-harmonization">Leveraging R for Data Harmonization</h2>
<p>In his quest to streamline the data harmonization process, Jeremy explored various R packages. Although packages like <code>retroharmonize</code>, <code>Rmonize</code> and <code>psHarmonize</code> offer some functionality, they come with limitations, such as handling categorical data better than continuous data or presenting complex harmonization processes in Excel, which can be cumbersome.</p>
<p>To address these gaps, Jeremy developed his own R project template for creating harmonization reports. This template draws inspiration from the <code>ourpackage</code> and <code>ourcompanion</code> packages, providing a structured layout for data storage, code management, and report generation.</p>
<section id="common-issues-and-solutions" class="level3">
<h3 class="anchored" data-anchor-id="common-issues-and-solutions">Common Issues and Solutions</h3>
<p>Jeremy shared some common pitfalls encountered during data harmonization and how they can be mitigated using R:</p>
<ol type="1">
<li><p><strong>Data Versioning Issues</strong>: Collaborators may send multiple versions of the same data set. Using the <code>readr</code> package and functions like <code>problems</code>, Jeremy demonstrated how to catch and address issues early in the data import process.</p></li>
<li><p><strong>Automating Checks</strong>: By employing packages like <code>testthat</code> and <code>pointblank</code>, Jeremy automated the validation of data inputs, ensuring robustness against changes in data versions.</p></li>
<li><p><strong>Variable Mapping and Validation</strong>: Jeremy outlined a workflow for mapping variables, validating mappings, and preparing data for merging. This included creating interactive tables for collaborators to review and using validation functions to ensure data integrity.</p></li>
</ol>
</section>
</section>
<section id="automating-report-generation-with-quarto" class="level2">
<h2 class="anchored" data-anchor-id="automating-report-generation-with-quarto">Automating Report Generation with Quarto</h2>
<p>To tackle the challenge of generating extensive harmonization reports, Jeremy turned to Quarto, a publishing system that allows for dynamic report generation. By creating a Quarto book project, he automated the creation of harmonization reports for each cohort, ensuring consistency and efficiency.</p>
<section id="creating-harmonization-reports" class="level3">
<h3 class="anchored" data-anchor-id="creating-harmonization-reports">Creating Harmonization Reports</h3>
<p>The process involves:</p>
<ul>
<li><strong>Index and Quarto Files</strong>: Setting up essential files like <code>index.qmd</code> and <code>quarto.yml</code> to control the book’s content and structure.</li>
<li><strong>Automating Scripts</strong>: Developing an R script to render Quarto documents for each cohort, facilitating the creation of both reference and how-to guide documents.</li>
</ul>
</section>
</section>
<section id="visualizing-harmonization-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-harmonization-outcomes">Visualizing Harmonization Outcomes</h2>
<p>Jeremy also explored various visualization techniques to convey harmonization outcomes to collaborators and management. While traditional methods like Venn diagrams and Upset plots proved complex, he developed a heat map approach. This visualization provided a clear overview of cohort attributes, patient numbers, and variable availability—categorized by different colors and accompanied by legends for clarity.</p>
</section>
<section id="conclusion-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-and-future-directions">Conclusion and Future Directions</h2>
<p>Jeremy’s presentation underscored the critical role of data harmonization in clinical research and the power of R and Quarto in streamlining this process. By creating a robust documentation and reporting framework, researchers can enhance transparency, accountability, and efficiency in their data harmonization efforts.</p>
<p>As Jeremy noted, while the current template offers a solid foundation, there is always room for improvement, such as unit testing and clearer documentation. His work serves as a valuable starting point for researchers facing similar challenges, fostering a more seamless integration of data across diverse clinical studies.</p>
<ul>
<li><a href="https://jauntyjjs.github.io/RMedicine2025_harmonisation/#/title-slide">Slides</a></li>
<li><a href="https://github.com/JauntyJJS/harmonisation/">Repo</a></li>
</ul>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/retrospective-clinical-data-harmonisation-reporting-using-r-and-quarto/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/retrospective-clinical-data-harmonisation-reporting-using-r-and-quarto/thumbnail-harmonisation-selva.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>riskcalc.org: A Repository of Risk Calculators for Medical Decision Making</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4mo5V_rjUhM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-clinical-decision-making-with-riskcalc.org" class="level1">
<h1>Enhancing Clinical Decision-Making with Riskcalc.org</h1>
<p>In the rapidly evolving landscape of healthcare, the fusion of data science and clinical practice is creating unprecedented opportunities for personalized medicine. At the forefront of this intersection is <a href="https://riskcalc.org/">riskcalc.org</a>, a pioneering platform developed to aid clinicians and patients in making informed medical decisions. Alex Zajichek, a research data scientist at the Cleveland Clinic, recently provided an insightful overview of this platform at R/Medicine 2025, highlighting its capabilities, infrastructure, and future directions.</p>
<section id="the-genesis-of-riskcalc.org" class="level2">
<h2 class="anchored" data-anchor-id="the-genesis-of-riskcalc.org">The Genesis of Riskcalc.org</h2>
<p>Riskcalc.org emerged from the Cleveland Clinic’s Department of Quantitative Health Sciences, a hub of over 100 statisticians, data scientists, and researchers. This department is dedicated to providing quantitative support across various research activities, from clinical trials to precision medicine. The platform was conceptualized to serve as a free, accessible resource for clinicians and patients, facilitating individualized medical decision-making through a collection of predictive models.</p>
</section>
<section id="core-functionality-and-infrastructure" class="level2">
<h2 class="anchored" data-anchor-id="core-functionality-and-infrastructure">Core Functionality and Infrastructure</h2>
<p>At its core, riskcalc.org hosts a suite of clinical risk calculators, each designed as a standalone R Shiny application. These calculators are predominantly regression models derived from published research studies. The platform garners significant engagement, with a monthly user base of 10,000 to 15,000.</p>
<p>The development process involves creating applications locally using R and Shiny. The models are integrated into the applications either as stored R data objects or by hardcoding them directly into the app’s code. For transparency, the code is pushed to GitHub, allowing users to inspect the application’s backend functionality. The live interaction with riskcalc.org occurs via an open-source Shiny server hosted on AWS, a cost-effective infrastructure primarily incurring costs for compute resources.</p>
</section>
<section id="recent-developments-and-enhancements" class="level2">
<h2 class="anchored" data-anchor-id="recent-developments-and-enhancements">Recent Developments and Enhancements</h2>
<p>The platform has seen several recent enhancements. All source codes for the applications are now publicly accessible on the department’s GitHub page, with each application featuring a link to its source code. The homepage of riskcalc.org has undergone a redesign to improve user interface and navigation, with icons representing different disease areas leading users to relevant risk calculators.</p>
<p>Moreover, an R package has been developed to streamline the creation of risk calculators. The package’s main function, <code>risk_calculator</code>, allows users to generate a directory containing application files preconfigured with standard boilerplate elements. Users can then customize these files with specific model details, facilitating the rapid development of new calculators.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>Looking forward, several key areas for development and improvement have been identified:</p>
<ol type="1">
<li><p><strong>Integration and Workflow Enhancement</strong>: There is a push to more formally integrate GitHub into the workflow through CI/CD processes, ensuring that the code on GitHub is directly connected to the live website. This integration would aid in managing package versions and R itself on the server, mitigating compatibility issues during application development.</p></li>
<li><p><strong>Standardization and Expansion</strong>: Efforts are underway to generalize the concept of a risk calculator to include not just regression models but any mathematical object that predicts clinical outcomes, such as machine learning models. A standardized framework is being sought to power the backend consistently, regardless of model methodology.</p></li>
<li><p><strong>Model Monitoring and Updating</strong>: The team is exploring ways to monitor model performance over time, beyond the point of initial development. This ongoing evaluation would ensure that models remain relevant and accurate in clinical settings.</p></li>
<li><p><strong>Broader Community and Research Ecosystem</strong>: Riskcalc.org aims to become a one-stop shop for clinical risk prediction. This vision includes fostering community involvement for model validation and performance ranking, developing APIs for programmatic access to model outputs, and creating a research ecosystem to integrate and compare various models for improved clinical predictions.</p></li>
</ol>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>The platform has been a collaborative effort, with contributions from numerous co-developers and principal investigators. Special acknowledgment is given to Mike Kattan, the former department chair and a world-renowned expert in clinical risk prediction, whose vision and leadership were instrumental in the creation of riskcalc.org.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Riskcalc.org represents a significant stride towards integrating data science with clinical practice, providing a robust tool for personalized medical decision-making. With its ongoing developments and future plans, the platform is poised to enhance its impact and utility in the healthcare domain.</p>
<p>For more information on this talk and to access the slides, visit Alex Zajichek’s <a href="https://www.zajichekstats.com/presentations/riskcalc-a-repository-of-risk-calculators-for-medical-decision-making/">presentation</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Insurance/Risk</category>
  <guid>https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/thumbnail-riskcalc.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>R/Medicine 2025 - Closing Remarks - Final Day - Michael Kane</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ad5V0PBYl_M" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="closing-remarks-from-rmedicine-2025-by-michael-kane-md" class="level1">
<h1>Closing Remarks from R/Medicine 2025 by Michael Kane, MD</h1>
<p>As R/Medicine 2025 concludes its second and final day, Michael Kane, MD, from the Anderson Cancer Center, delivered the closing remarks, encapsulating the essence and future direction of this unique conference dedicated to the intersection of R programming and healthcare. Kane, a co-founder of R/Medicine, provided insights into the conference’s achievements and aspirations, leaving the audience with a sense of community and purpose.</p>
<section id="acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<p>Kane began by expressing gratitude to the organizing committee, with a special nod to Emily Zaber, who chaired this year’s event. The seamless execution of the conference, he noted, is a testament to the dedication and behind-the-scenes effort of the team. The importance of organization and meticulous planning cannot be overstated, and this year’s smooth proceedings are a reflection of such diligence.</p>
</section>
<section id="a-conference-for-the-community" class="level2">
<h2 class="anchored" data-anchor-id="a-conference-for-the-community">A Conference for the Community</h2>
<p>Emphasizing the core philosophy of R/Medicine, Kane reiterated that this conference is designed to be a platform for the community. The healthcare space is expansive, with myriad groups engaged in cutting-edge research that often goes underrepresented. R/Medicine aims to bridge this gap by providing a forum for practitioners and methodologists alike to share their work, explore collaborative opportunities, and contribute to ongoing projects.</p>
<p>The conference’s commitment to inclusivity was evident in the diverse international participation this year. Attendees from South America, Europe, and other regions enriched the discussions with their unique perspectives and innovations. This global engagement underscores the universal applicability and potential of R in transforming healthcare.</p>
</section>
<section id="towards-a-continuous-engagement" class="level2">
<h2 class="anchored" data-anchor-id="towards-a-continuous-engagement">Towards a Continuous Engagement</h2>
<p>Looking ahead, Kane shared the committee’s vision of making R/Medicine a continuous engagement rather than a once-a-year event. The introduction of periodic webinars is a step in this direction, allowing for ongoing dialogue and knowledge exchange throughout the year. By maintaining a steady flow of information and interaction, R/Medicine seeks to foster a vibrant and dynamic community that stays connected and informed about the latest developments in healthcare.</p>
</section>
<section id="invitation-to-participate" class="level2">
<h2 class="anchored" data-anchor-id="invitation-to-participate">Invitation to Participate</h2>
<p>In closing, Kane extended an open invitation to all participants to become more involved in R/Medicine. Whether by submitting proposals for future conferences, contributing to ongoing projects, or joining the organizing committee, the opportunities for involvement are numerous. The committee is keen on remaining dynamic and responsive to emerging healthcare challenges, and fresh perspectives are always welcome.</p>
<p>Kane’s remarks concluded with heartfelt thanks to all attendees and participants, with a promise of even more exciting developments in the coming year. As R/Medicine 2025 draws to a close, the community looks forward to another year of innovation, collaboration, and progress in using R to revolutionize healthcare.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <guid>https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/thumbnail-closing-remarks-day2-finalday-michael-kane.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>R/Medicine 2025 Opening Remarks - Thursday</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rmedicine-2025-opening-remarks-thursday/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0Qv_rFgoULA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="rmedicine-2025-opening-remarks-by-emily-zabor" class="level1">
<h1>R/Medicine 2025: Opening Remarks by Emily Zabor</h1>
<p>Welcome to R/Medicine 2025! With the conference officially underway, attendees are in for an exciting lineup of sessions and discussions over the coming days.</p>
<p>The opening remarks were delivered by Emily Zabor, an Associate Staff Biostatistician at the Cleveland Clinic and an enthusiastic R user. Her roles span from the Department of Quantitative Health Sciences to the Taussig Cancer Institute and an academic appointment at the Cleveland Clinic Lerner College of Medicine. With a strong background in early phase clinical trial design, statistical methods for observational studies, prediction models, and survival analysis, Emily brings a wealth of expertise to her role as Chair of the organizing committee for this year’s conference.</p>
<section id="gratitude-and-recognition" class="level2">
<h2 class="anchored" data-anchor-id="gratitude-and-recognition">Gratitude and Recognition</h2>
<p>Emily expressed heartfelt gratitude to the R Consortium for hosting the R/Medicine 2025 conference. The R Consortium continues to play a crucial role in supporting the R community with events, webinars, and support for various R groups, including R-Ladies. Their efforts not only facilitate the current conference but also bolster the R ecosystem throughout the year.</p>
<p>A special thanks was also extended to financial sponsors, Genentech and Posit, whose generous contributions have kept registration fees relatively low, enabling the inclusion of workshops and demos at a flat rate. Scholarships based on financial need are also made possible by these sponsors, ensuring a diverse set of participants can join the conference.</p>
<p>The organizing committee, chaired by Emily herself, received commendations for their dedication and creativity in bringing the conference to life. Some members have been involved since the conference’s inception in 2018, showcasing their commitment and knowledge. Attendees are encouraged to thank them for their efforts.</p>
</section>
<section id="a-global-and-accessible-gathering" class="level2">
<h2 class="anchored" data-anchor-id="a-global-and-accessible-gathering">A Global and Accessible Gathering</h2>
<p>R/Medicine 2025 continues its tradition of being a global and accessible event, running virtually to accommodate participants from around the world. This format, adopted during the pandemic, has allowed the conference to reach a diverse international audience. With greetings extended from Emily to all time zones, the virtual format enables knowledge sharing and networking across borders.</p>
</section>
<section id="conference-overview-and-highlights" class="level2">
<h2 class="anchored" data-anchor-id="conference-overview-and-highlights">Conference Overview and Highlights</h2>
<p>The conference kicked off with three days of engaging workshops, demos, and panels. These days were structured into two tracks, making it impossible to attend every session. However, participants can look forward to <a href="https://www.youtube.com/playlist?list=PL4IzsxWztPdmU2q31ZrTCASr78e0jpKux">accessing video recordings on the R Consortium’s YouTube channel</a> after the conference concludes. This provides a great opportunity to revisit sessions or catch those that were missed.</p>
<p>Workshop highlights included:</p>
<ul>
<li>Introduction to R workshops in both English and Spanish</li>
<li>R package development with GitHub pages and package down</li>
<li>Survival analysis with tidy models</li>
<li>Data visualization using parameterization</li>
<li>Reproducibility with Ricks and Nix</li>
<li>Personal R administration</li>
<li>LLMs using Elmer</li>
<li>Teal Mastery</li>
</ul>
<p>The structure also featured panels of R educators and sessions focused on reproducibility and more.</p>
</section>
<section id="looking-forward" class="level2">
<h2 class="anchored" data-anchor-id="looking-forward">Looking Forward</h2>
<p>Opening the first day is a keynote by Zead Obermeyer, focusing on “Reinventing Medicine with AI.” The day will continue with 9 regular talks and 2 lightning talks covering topics such as reproducibility, compliance, workflow automation, and clinical and epidemiological applications.</p>
<p>Attendees will also hear from winners of the data analysis competition on measles vaccination and case rates in 2025 in both professional and student categories.</p>
<p>Participants are encouraged to engage actively in the conference by joining Zoom sessions, participating in the chat, asking questions, and connecting with fellow attendees. Before the keynote kicks off, attendees were invited to introduce themselves in the chat and share their locations, fostering a sense of community.</p>
</section>
<section id="stay-tuned" class="level2">
<h2 class="anchored" data-anchor-id="stay-tuned">Stay Tuned</h2>
<p>In addition to the conference, R/Medicine hosts mid-year webinars, and participants are encouraged to keep an eye out for these events. The webinars focus on topics such as reproducible data science environments with Nix and containerization in R. <a href="https://r-consortium.org/webinars/webinars.html">For more information on webinars, attendees can visit the R Consortium’s website.</a></p>
<p>With an exciting program ahead, the R/Medicine 2025 conference promises to be a dynamic and enriching experience for the R community. Enjoy the conference, engage with peers, and make the most of the sessions and opportunities to learn and connect.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Events</category>
  <guid>https://r-consortium.org/posts/rmedicine-2025-opening-remarks-thursday/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rmedicine-2025-opening-remarks-thursday/thumbnail-opening-remarks-day-one-emily.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
