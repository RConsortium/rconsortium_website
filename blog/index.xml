<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>R Consortium</title>
<link>https://r-consortium.org/blog/</link>
<atom:link href="https://r-consortium.org/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Sat, 21 Jun 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>{redquack}: An R Package for Memory Efficient REDCap-to-DuckDB Workflows</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/PWLRL0R7s3Y" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="breaking-through-memory-limitations-in-redcap-introducing-the-redquack-package" class="level1">
<h1>Breaking Through Memory Limitations in REDCap: Introducing the {redquack} Package</h1>
<p>In today’s data-driven healthcare environment, managing large datasets efficiently is crucial. The REDCap platform, a free electronic health record software, is widely used by over 7,000 institutions across the globe. Its ability to handle complex, longitudinal data and support multiple instruments or assessments makes it a favored choice for clinical research. However, with the exponential growth of data, researchers often encounter memory constraints when trying to extract and analyze vast amounts of information.</p>
<p>Dylan Pieper from the University of Pittsburgh addressed this challenge head-on at the R/Medicine 2025 conference. His innovative solution, the {redquack} package, is designed to optimize data workflows between REDCap and DuckDB, providing a memory-efficient alternative for processing large datasets.</p>
<section id="the-challenge-of-handling-large-datasets-in-redcap" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-of-handling-large-datasets-in-redcap">The Challenge of Handling Large Datasets in REDCap</h2>
<p>At the School of Pharmacy, University of Pittsburgh, data scientists manage a REDCap database containing clinical data from over 200 outpatient treatment centers. This database is extensive, with nearly 3 million rows across 400 columns. Such large datasets pose a significant challenge when using traditional methods like the {REDCapR} package, which attempts to load all data into memory, often resulting in failures due to hardware limitations.</p>
<p>REDCap stores its data using a MySQL backend, which is typically managed by an institution’s IT department. Direct interfacing with this database is not recommended, pushing researchers to rely on APIs and packages to access the data. However, as datasets grow, these methods become inefficient and sometimes infeasible.</p>
</section>
<section id="the-redquack-package-a-solution-for-seamless-data-extraction" class="level2">
<h2 class="anchored" data-anchor-id="the-redquack-package-a-solution-for-seamless-data-extraction">The {redquack} Package: A Solution for Seamless Data Extraction</h2>
<p>The {redquack} package emerged as a solution to these memory constraints by leveraging the power of DuckDB, a fast and portable SQL database management system. DuckDB’s columnar storage format makes it particularly suited for large-scale data processing, allowing data to be stored outside of R’s memory.</p>
<p>The package introduces a novel batch processing approach to data extraction. By breaking down data into manageable chunks, researchers can efficiently process portions of the dataset without ever exceeding memory limits. This method involves:</p>
<ol type="1">
<li><strong>Batch Processing</strong>: Data is extracted in configurable batches of record IDs, minimizing memory usage.</li>
<li><strong>Column Optimization</strong>: The package automatically optimizes column types across batches, enhancing query performance.</li>
<li><strong>Detailed Logging</strong>: Users can track extraction progress through comprehensive logs, aiding in debugging and process monitoring.</li>
<li><strong>Integration with Tidyverse</strong>: The resulting DuckDB connection can be seamlessly integrated with tidyverse workflows, allowing analysts to use familiar dplyr syntax for data manipulation.</li>
</ol>
</section>
<section id="practical-implementation-and-benefits" class="level2">
<h2 class="anchored" data-anchor-id="practical-implementation-and-benefits">Practical Implementation and Benefits</h2>
<p>Using {redquack} is straightforward. Researchers need to provide their REDCap API credentials and configuration preferences to the <code>redcap_to_duckdb()</code> function. This function handles the extraction process, and the resulting DuckDB connection can be immediately utilized for data analysis.</p>
<p>The package includes several quality-of-life features, such as sound notifications (a “quack” on success) for long-running operations. This user-friendly approach empowers researchers to work with datasets that exceed memory constraints without compromising their existing workflows.</p>
</section>
<section id="real-world-applications-at-the-university-of-pittsburgh" class="level2">
<h2 class="anchored" data-anchor-id="real-world-applications-at-the-university-of-pittsburgh">Real-World Applications at the University of Pittsburgh</h2>
<p>Dylan Pieper’s presentation showcased practical examples from the School of Pharmacy, where the {redquack} package has streamlined the data pipeline from REDCap to analysis. By eliminating memory constraints, the package has enabled clinical researchers, data scientists, and analysts to work more efficiently with large datasets. This is particularly beneficial for those handling complex, multi-form projects or longitudinal studies where traditional extraction methods fall short.</p>
<p>The package is designed to be scalable and consistent, ensuring reliable data exports as projects grow in size. While it currently focuses on data reading, there is potential for future enhancements, such as supporting additional database drivers and expanding its capabilities.</p>
</section>
<section id="a-collaborative-future" class="level2">
<h2 class="anchored" data-anchor-id="a-collaborative-future">A Collaborative Future</h2>
<p>The development of {redquack} highlights the importance of collaboration within the R community. By sharing insights and innovations, researchers can collectively overcome the challenges posed by large-scale data management. The package is available on CRAN and GitHub, inviting contributions and feedback from the wider community.</p>
<p>As REDCap continues to evolve, tools like {redquack} will play a pivotal role in ensuring that researchers can harness the full potential of their data without being hindered by technical limitations. Dylan Pieper’s work is a testament to the power of open-source collaboration and the continuous drive for innovation within the R ecosystem.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/</guid>
  <pubDate>Sat, 21 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/thumbnail-redquack.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>AOUSDOHtools: R Package for Social Determinants of Health Survey data in All of Us Research Program</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nQum-dWBM3I" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unraveling-the-aousdohtools-package-empowering-research-in-social-determinants-of-health" class="level1">
<h1>Unraveling the AOUSDOHtools Package: Empowering Research in Social Determinants of Health</h1>
<p>Hello, R community! Today we dive into the innovative R package, AOUSDOHtools, designed to streamline the analysis of Social Determinants of Health (SDOH) data. This package, presented by Zhirui Deng, a biostatistician from the University of Pittsburgh School of Nursing, is a game-changer for researchers working within the All of Us Research Program. Let’s explore how this tool enhances research efforts in health equity.</p>
<section id="understanding-the-all-of-us-research-program" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-all-of-us-research-program">Understanding the All of Us Research Program</h2>
<p>The All of Us Research Program, an initiative by the National Institutes of Health (NIH), aims to gather comprehensive data from over a million participants across the United States. This vast data collection includes health records, lab results, and survey responses, focusing significantly on health equity by enrolling participants traditionally underrepresented in research. The diversity and complexity of this data present unique challenges, particularly when it comes to analyzing SDOH data.</p>
</section>
<section id="challenges-with-sdoh-data" class="level2">
<h2 class="anchored" data-anchor-id="challenges-with-sdoh-data">Challenges with SDOH Data</h2>
<p>SDOH surveys collect detailed information on non-clinical factors impacting health, such as housing, education, stress, and social support. While invaluable, this data often comes in a raw, messy format, spread across multiple rows per participant, and lacking a built-in scoring system. Researchers face the daunting task of manually cleaning and computing these variables for analysis, a process fraught with potential inconsistencies.</p>
</section>
<section id="introducing-aousdohtools-the-r-package" class="level2">
<h2 class="anchored" data-anchor-id="introducing-aousdohtools-the-r-package">Introducing AOUSDOHtools: The R Package</h2>
<p>To address these challenges, Dre Dong and the team developed the AOUSDOHtools R package. This tool automates the entire process of recoding, scoring, and outputting clean, personal variables ready for analysis. Based on a user guide by Dr.&nbsp;Koleck and colleagues (2024), the package standardizes scoring logic across 14 SDOH constructs, such as Neighborhood Cohesion, Social Support, and Perceived Stress.</p>
<p>The package operates seamlessly within the All of Us Researcher Workbench, a secure cloud-based platform. It supports both RStudio and Jupyter environments, ensuring flexibility and ease of use for researchers. The package’s vibrant hex sticker, featuring symbols of housing, education, food, and income, embodies key SDOH components and adds a touch of whimsy for sticker enthusiasts.</p>
</section>
<section id="how-aousdohtools-works" class="level2">
<h2 class="anchored" data-anchor-id="how-aousdohtools-works">How AOUSDOHtools Works</h2>
<p>The package includes 30 functions for scoring 14 constructs across various SDOH domains, such as Neighborhood Cohesion, Neighborhood Disorder, Food Insecurity, Housing Insecurity, and Housing Quality. Each construct is thoughtfully organized, with some offering sub-scores for more granular analysis.</p>
<p>The workflow is simple: load the package and your SDOH survey data, and call one of the scoring functions like <code>calculate_cohesion</code> or <code>calculate_disorder</code>. The function outputs a tidy dataset—one row per person with the computed score. This straightforward process eliminates the need for manual data wrangling, allowing researchers to focus on analysis.</p>
</section>
<section id="a-peek-inside-the-scoring-functions" class="level2">
<h2 class="anchored" data-anchor-id="a-peek-inside-the-scoring-functions">A Peek Inside the Scoring Functions</h2>
<p>Take, for instance, the <code>calculate_cohesion</code> function. It extracts neighborhood-related questions, maps responses from “strongly agree” to “strongly disagree,” averages them, and returns a clean cohesion score for each participant. This automation relieves researchers from the burden of writing complex scoring algorithms, promoting consistency and reproducibility.</p>
</section>
<section id="staying-current-and-collaborative" class="level2">
<h2 class="anchored" data-anchor-id="staying-current-and-collaborative">Staying Current and Collaborative</h2>
<p>Released on March 26 and available on CRAN and GitHub, AOUSDOHtools is continuously updated to reflect changes in the All of Us platform. The development team welcomes feedback, feature requests, and collaboration ideas via email or GitHub issues. This open development approach fosters a thriving research community.</p>
</section>
<section id="why-aousdohtools-matters" class="level2">
<h2 class="anchored" data-anchor-id="why-aousdohtools-matters">Why AOUSDOHtools Matters</h2>
<p>By making SDOH data easier to use, share, and reproduce, AOUSDOHtools lays the groundwork for robust research in health equity. The package empowers researchers to explore how social factors like living conditions and social support influence health outcomes, aligning with the All of Us program’s mission.</p>
<p>Researchers can become registered All of Us researchers, access the survey data via the Researcher Workbench, and install the package from CRAN or GitHub. This accessibility encourages diverse research efforts and collaborations within the R community.</p>
</section>
<section id="engage-with-aousdohtools" class="level2">
<h2 class="anchored" data-anchor-id="engage-with-aousdohtools">Engage with AOUSDOHtools</h2>
<p>For those eager to contribute, the development team appreciates input via GitHub issues or direct email communication. They are open to feedback and committed to refining the package to meet the evolving needs of the research community.</p>
<p>In conclusion, AOUSDOHtools is a testament to the power of R in advancing research on social determinants of health. It simplifies complex data processes, enabling researchers to focus on impactful analyses and contribute to the broader goal of health equity. Thanks to Dre Dong and the development team for their dedication to this vital work.</p>
<p>For more information and to explore the package, visit the <a href="https://github.com/zhd52/AOUSDOHtools">GitHub repository</a> or <a href="https://cran.r-project.org/package=AOUSDOHtools">CRAN page</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/thumbnail-AOUSDOHtools-deng.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Examining Factors Associated with Depressive Severity Among Cancer Survivors</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4vQJghIanQg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="understanding-the-psychological-burden-of-cancer-insights-into-depressive-symptoms-among-survivors" class="level1">
<h1>Understanding the Psychological Burden of Cancer: Insights into Depressive Symptoms Among Survivors</h1>
<p>Cancer, a formidable adversary in the realm of health, extends its profound impact beyond the physical, creeping into the psychological well-being of those it touches. The study presented by Andre Williams from the Christine E. Lynn College of Nursing at Florida Atlantic University, at R/Medicine 2025, dives deeply into this often overshadowed aspect of cancer survivorship—depression. This comprehensive analysis offers invaluable insights into the mental health challenges faced by cancer patients and survivors and underscores the need for integrated care models that address both physical and mental health.</p>
<section id="the-psychological-toll-of-cancer" class="level2">
<h2 class="anchored" data-anchor-id="the-psychological-toll-of-cancer">The Psychological Toll of Cancer</h2>
<p>Cancer survivors face a multitude of challenges that encompass the physical, emotional, and financial spectrums. While advancements in detection and treatment have increased survival rates, they have also prolonged the duration of living with the disease and its psychological ramifications. Among these, depression stands out as a significant concern, affecting not just the quality of life but also treatment adherence, physical health outcomes, and mortality rates. Cancer patients are particularly susceptible to depression due to a complex interplay of physiological and psychological factors.</p>
</section>
<section id="exploring-the-correlates-of-depression-in-cancer-survivors" class="level2">
<h2 class="anchored" data-anchor-id="exploring-the-correlates-of-depression-in-cancer-survivors">Exploring the Correlates of Depression in Cancer Survivors</h2>
<p>Despite the established link between cancer and depression, there remains a critical need to explore the specific demographic, socioeconomic, and health-related factors contributing to this mental health burden. Previous research, often limited by smaller sample sizes, has struggled to generalize findings across the broader U.S. cancer survivor population. Addressing this gap, Williams and his team leveraged the National Health Interview Survey (NHIS) data, a robust, nationally representative resource, to examine these factors.</p>
<section id="research-methodology" class="level3">
<h3 class="anchored" data-anchor-id="research-methodology">Research Methodology</h3>
<p>The study utilized NHIS data from 2022, focusing on individuals who reported a cancer diagnosis. The primary research question aimed to uncover the demographic, socioeconomic, and health-related factors associated with increased depressive symptomatology among these individuals. Depressive symptomatology was measured using the Patient Health Questionnaire-8 (PHQ-8), with a score of 10 or higher indicating moderate or greater depressive symptoms.</p>
<p>For the analysis, various R packages, including <code>survey</code>, <code>tidyverse</code>, <code>modelsummary</code>, and <code>data.table</code>, were employed. The team conducted survey logistic regression to evaluate the associations between depressive symptoms and various independent variables.</p>
</section>
<section id="key-findings" class="level3">
<h3 class="anchored" data-anchor-id="key-findings">Key Findings</h3>
<p>The analysis revealed several significant associations with moderate or greater depressive symptoms among cancer survivors:</p>
<ul>
<li><strong>Socioeconomic Factors</strong>: Poverty, lower levels of education, and lack of private health insurance were significantly associated with increased depressive symptoms, highlighting the impact of financial and educational disparities on mental health.</li>
<li><strong>Demographic Factors</strong>: Female gender, younger age, and living alone were demographic variables linked to heightened depressive symptoms, suggesting a greater vulnerability among certain groups.</li>
<li><strong>Healthcare Access and Utilization</strong>: Delays in care, unmet care needs due to cost, frequent emergency visits, and overnight hospitalizations were associated with increased depressive symptoms. These findings underscore the importance of accessible and affordable healthcare in addressing mental health issues.</li>
<li><strong>Co-occurring Conditions</strong>: Mild or greater anxiety symptomatology was significantly associated with increased depressive symptoms, emphasizing the interconnectedness of mental health conditions.</li>
</ul>
</section>
</section>
<section id="implications-for-healthcare-practice" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-healthcare-practice">Implications for Healthcare Practice</h2>
<p>The study’s findings have crucial implications for healthcare practice:</p>
<ol type="1">
<li><p><strong>Targeted Screening and Intervention</strong>: Routine use of validated tools like PHQ-8 or PHQ-9 for assessing depression is vital, alongside considering broader social determinants of health in patient evaluations.</p></li>
<li><p><strong>Holistic Support</strong>: Interventions should address not only psychological needs but also socioeconomic factors and healthcare access issues, advocating for a comprehensive approach to patient support.</p></li>
<li><p><strong>Integrated Care Models</strong>: Incorporating mental health support into oncology care is essential to ensure mental health is recognized and addressed as a vital component of cancer treatment and survivorship.</p></li>
</ol>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>As the discussion concluded, the need for further research was highlighted, including the potential to extend the study to pediatric cancer patients and include a control group for comparison. Such future endeavors would enrich the understanding of depressive symptoms in cancer survivors and inform targeted interventions.</p>
<p>This study, leveraging the power of R for data analysis, exemplifies the critical role of large-scale public health datasets in understanding the psychosocial challenges faced by cancer survivors. By integrating mental health considerations into cancer care, we can guide clinical decision-making and develop precision mental health interventions within oncology settings.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/thumbnail-examining-factors-williams.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>kidney.epi R Package for Facilitating Research in Diabetes, Kidney, Heart, and Other Diseases</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/kidneyepi-r-package-for-facilitating-research-in-diabetes-kidney-heart-and-other-diseases/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pE3iZBegdr0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="empowering-chronic-kidney-disease-research-with-the-kidney.epi-r-package-an-insight-from-rmedicine-2025" class="level1">
<h1>Empowering Chronic Kidney Disease Research with the <code>kidney.epi</code> R Package: An Insight from R/Medicine 2025</h1>
<p>Chronic Kidney Disease (CKD) is an escalating global health issue, affecting approximately 700 million individuals worldwide and leading to 3.2 million deaths annually. Despite its prevalence, CKD is often overlooked in health prevention programs and clinical trials, resulting in a significant awareness gap. Alarmingly, only 10-20% of those with CKD know they have the condition. Early detection and management are crucial to mitigate the progression to end-stage renal disease and prevent further complications.</p>
<section id="the-growing-ckd-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-growing-ckd-challenge">The Growing CKD Challenge</h2>
<p>The prevalence of CKD has surged nearly twofold over the past three decades, now affecting nearly 10% of the global population. CKD is more common than cardiovascular diseases, diabetes, and chronic respiratory conditions. Age-standardized rates for CKD have increased, unlike many other non-communicable diseases where rates have declined. This trend suggests a future increase in CKD cases. High-risk groups, such as individuals with diabetes, hypertension, and rheumatoid arthritis, show CKD prevalence rates ranging from 20% to 60%. Moreover, about 40% of those aged 65 and older live with CKD, underscoring its significance in geriatric care.</p>
<p>CKD’s impact extends to pharmacotherapy, as kidneys play a pivotal role in drug elimination. Reduced kidney function necessitates dosage adjustments or contraindications for certain medications. Despite CKD’s high prevalence, patients with the condition are often excluded from clinical trials. A staggering 80% of cardiovascular medication trials exclude CKD patients, including 40% that exclude early-stage CKD patients.</p>
</section>
<section id="world-health-organizations-response" class="level2">
<h2 class="anchored" data-anchor-id="world-health-organizations-response">World Health Organization’s Response</h2>
<p>The World Health Organization recently adopted a kidney health resolution to enhance prevention and control strategies for kidney diseases. This development is promising, highlighting the growing recognition of CKD’s global health burden.</p>
</section>
<section id="introducing-the-kidney.epi-r-package" class="level2">
<h2 class="anchored" data-anchor-id="introducing-the-kidney.epi-r-package">Introducing the <code>kidney.epi</code> R Package</h2>
<p>To address the research gap in CKD, the <code>kidney.epi</code> R package, developed by <a href="https://scientific-tools.org">Boris Bibkov</a>, offers a comprehensive toolkit for kidney-related data analysis. This package is a boon for researchers and data scientists, providing functions to calculate estimated glomerular filtration rate (eGFR) using multiple validated equations, categorize urine analysis results, and assign risk categories based on the KDIGO classification.</p>
<section id="key-features-of-the-kidney.epi-package" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-the-kidney.epi-package">Key Features of the <code>kidney.epi</code> Package</h3>
<ol type="1">
<li><p><strong>eGFR Calculation</strong>: The package supports over 15 equations for calculating eGFR, including the widely used CKD-EPI equation, accommodating both serum creatinine and cystatin C markers for adults and children.</p></li>
<li><p><strong>Kidney Transplantation Functions</strong>: It includes functions to calculate the Kidney Donor Profile Index (KDPI) and the Kidney Donor Risk Index (KDRI), crucial for transplantation research.</p></li>
<li><p><strong>User-Friendly Design</strong>: The package offers flexible label handling, allowing researchers to use datasets without reformatting variables like sex or ethnicity. Functions accept user-defined labels and measurement units, making it adaptable to various datasets.</p></li>
<li><p><strong>Automated Data Analysis</strong>: With the package, researchers can automate kidney-related calculations in screening programs, clinical trials, and observational studies, enhancing research accessibility and reproducibility.</p></li>
</ol>
</section>
<section id="applications-beyond-ckd" class="level3">
<h3 class="anchored" data-anchor-id="applications-beyond-ckd">Applications Beyond CKD</h3>
<p>While the package is tailored for CKD research, its applications extend to other fields like diabetology, cardiology, and gerontology. Knowing eGFR is vital for monitoring medication appropriateness, particularly in high-risk groups.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The <code>kidney.epi</code> R package is a valuable tool for CKD research and beyond, facilitating early detection and management strategies. Its flexible design and comprehensive functions empower researchers to contribute to the global effort in reducing the CKD burden. As the research community embraces this package, it stands to enhance awareness, improve patient outcomes, and drive innovation in kidney health research.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Epidemiology</category>
  <guid>https://r-consortium.org/posts/kidneyepi-r-package-for-facilitating-research-in-diabetes-kidney-heart-and-other-diseases/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/kidneyepi-r-package-for-facilitating-research-in-diabetes-kidney-heart-and-other-diseases/thumbnail-kidney-boris.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>MIIPW: An R package for Generalized Estimating Equations with missing data integration</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/miipw-an-r-package-for-generalized-estimating-equations-with-missing-data-integration/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4OslUevy6AQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="tackling-missing-data-in-longitudinal-studies-with-the-miipw-r-package" class="level1">
<h1>Tackling Missing Data in Longitudinal Studies with the MIIPW R Package</h1>
<section id="introduction-to-longitudinal-data" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-longitudinal-data">Introduction to Longitudinal Data</h2>
<p>Longitudinal data, a cornerstone of numerous scientific fields, captures repeated measurements from the same subjects over time. This approach allows researchers to delve into changes within subjects, uncover trends, and identify temporal patterns. Such data is pivotal in biomedical, social, and behavioral sciences, enabling insights into patient biomarker levels, treatment responses, and disease progression. However, longitudinal data often presents challenges related to correlated measurements, rendering standard statistical methods insufficient.</p>
</section>
<section id="addressing-missing-data-in-longitudinal-studies" class="level2">
<h2 class="anchored" data-anchor-id="addressing-missing-data-in-longitudinal-studies">Addressing Missing Data in Longitudinal Studies</h2>
<p>Missing data is a pervasive issue in longitudinal studies, often resulting from dropouts, loss to follow-up, or nonresponse. Traditional methods in R’s generalized estimating equations (GEE) packages tend to ignore or exclude these missing cases, potentially biasing results and diminishing statistical power. This is where the MIIPW package steps in, offering a robust solution for handling missing data through a combination of multiple imputation and inverse probability weighting techniques.</p>
</section>
<section id="the-miipw-r-package" class="level2">
<h2 class="anchored" data-anchor-id="the-miipw-r-package">The MIIPW R Package</h2>
<p>The MIIPW (Multiple Imputation and Inverse Probability Weighting) package is specifically designed to address missing data in marginal models used in longitudinal studies. Developed by Bhrigu Rajbongshi and his team at the Indian Institute of Technology (Indian School of Mines) Dhanbad, this package integrates advanced statistical techniques to provide accurate parameter estimation in the presence of incomplete data.</p>
<section id="key-features-of-miipw" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-miipw">Key Features of MIIPW</h3>
<ul>
<li><p><strong>Multiple Imputation and Inverse Probability Weighting</strong>: MIIPW combines these two techniques to correct biases and provide reliable estimates. The package supports five different methods for parameter estimation: mean score, SIPW, AIPW, miSIPW, and miAIPW.</p></li>
<li><p><strong>Covariance Structures</strong>: The package accommodates four covariance structures: AR-1, Exchangeable, Unstructured, and Independent, allowing users to model data appropriately.</p></li>
<li><p><strong>Model Selection using QIC</strong>: For model selection, MIIPW employs the Quasi-Information Criterion (QIC), helping researchers identify the best-fitting model for their data.</p></li>
<li><p><strong>Comprehensive Documentation and CRAN Availability</strong>: MIIPW is available on CRAN, complete with detailed documentation to assist users in effectively implementing its features.</p></li>
</ul>
</section>
</section>
<section id="practical-application-of-miipw" class="level2">
<h2 class="anchored" data-anchor-id="practical-application-of-miipw">Practical Application of MIIPW</h2>
<p>Using the MIIPW package involves several steps, from data preparation to model fitting and comparison. Here’s a brief overview of how to implement MIIPW in a real-world scenario:</p>
<ol type="1">
<li><p><strong>Data Preparation</strong>: Load the MIIPW package and your dataset. Define the longitudinal model formula and predictor matrix using the <code>make.predictorMatrix</code> function from the <code>mice</code> package.</p></li>
<li><p><strong>Model Fitting</strong>: Use functions like <code>mean_score</code>, <code>SIPW</code>, and <code>AIPW</code> to fit your model. Specify the number of imputations and the desired covariance structure.</p></li>
<li><p><strong>Model Comparison</strong>: Utilize the <code>QICw</code> function to compare models based on different covariance structures, selecting the one with the lowest QIC value as the best fit.</p></li>
</ol>
<p>The package’s integration with the <code>mice</code> package ensures flexibility and ease of use, making MIIPW a valuable tool for researchers dealing with complex longitudinal data.</p>
</section>
<section id="conclusion-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-and-future-directions">Conclusion and Future Directions</h2>
<p>The MIIPW package is a significant advancement in handling missing data within longitudinal studies. While it currently focuses on generalized estimating equations, there is potential for extending these methods to mixed-effect models, which would further enhance its applicability. The ongoing development aims to address computational challenges associated with random effects in mixed models, promising even greater utility for the research community.</p>
<p>The MIIPW package is a testament to the innovative work being done in the R community, providing researchers with robust tools to tackle the intricacies of longitudinal data analysis. By integrating state-of-the-art statistical techniques, MIIPW empowers researchers to derive meaningful insights from their data, ultimately advancing knowledge across various scientific domains.</p>
<p>For more information and to download the MIIPW package, visit <a href="https://CRAN.R-project.org/package=MIIPW">CRAN</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/miipw-an-r-package-for-generalized-estimating-equations-with-missing-data-integration/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/miipw-an-r-package-for-generalized-estimating-equations-with-missing-data-integration/thumbnail-MIIPW-bhrigu.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>How are Vaccination Rates and Case Rates Changing for Measles in 2025?</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/how-are-vaccination-rates-and-case-rates-changing-for-measles-in-2025/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Yk7jGc-E0Ys" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="celebrating-analytical-excellence-rmedicine-2025-professional-category-winners" class="level1">
<h1>Celebrating Analytical Excellence: R/Medicine 2025 Professional Category Winners</h1>
<p>The R/Medicine 2025 conference was marked by a remarkable array of data-driven insights, with the Professional Category of the data challenge spotlighting innovative work in the field. Harrison Plate and Shonushka Sawant from RSC Statistical Consulting delved into the dynamics of measles vaccination rates and case numbers across the United States and globally. Their entry not only earned them the top spot in the competition but also shed light on critical public health challenges and opportunities for intervention.</p>
<section id="an-overview-of-the-rmedicine-data-challenge" class="level2">
<h2 class="anchored" data-anchor-id="an-overview-of-the-rmedicine-data-challenge">An Overview of the R/Medicine Data Challenge</h2>
<p>The data challenge was an open invitation to participants to explore the evolving landscape of measles vaccination and case rates, using a diverse set of public datasets. The competition sought to evaluate the quality of analyses presented through Quarto documents, with a keen focus on tables and visualizations that tell a comprehensive data story.</p>
</section>
<section id="a-deep-dive-into-measles-vaccination-trends" class="level2">
<h2 class="anchored" data-anchor-id="a-deep-dive-into-measles-vaccination-trends">A Deep Dive into Measles Vaccination Trends</h2>
<p>Harrison and Shonushka’s presentation began by framing the current measles outbreak in the United States, which originated in an undervaccinated community in Texas and has since spread to multiple states and even neighboring countries. Despite measles being declared eliminated in the U.S. in 2000, recent years have seen its resurgence, largely attributable to declining vaccination rates.</p>
<p>Through meticulous data analysis, they highlighted a worrying trend: since 2020, median MMR (measles, mumps, and rubella) coverage across U.S. states has fallen below the 95% threshold required for herd immunity. This decline corresponds with the onset of the COVID-19 pandemic, an event that significantly disrupted healthcare access and vaccination routines.</p>
</section>
<section id="illustrating-change-visualizing-vaccination-data" class="level2">
<h2 class="anchored" data-anchor-id="illustrating-change-visualizing-vaccination-data">Illustrating Change: Visualizing Vaccination Data</h2>
<p>One of the strengths of their work was the effective use of visualizations to illustrate changes over time. Maps displaying MMR coverage across different years clearly showed the transition of states from meeting herd immunity thresholds to falling below critical levels. In 2023, a notable number of states reported coverage below 90%, underscoring the urgency of addressing vaccination gaps.</p>
<p>The analysis also delved into the factors contributing to these declines, such as healthcare worker shortages, increased poverty, and familial instability—all exacerbated by the pandemic. Their insights into socio-economic factors provided a comprehensive backdrop for understanding the broader implications of vaccination trends.</p>
</section>
<section id="global-perspective-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="global-perspective-and-future-directions">Global Perspective and Future Directions</h2>
<p>Beyond the U.S., Harrison and Shonushka extended their analysis to a global context, examining measles case trends in regions like Africa. By fitting statistical models to historical data, they offered forecasts that capture both seasonal patterns and recent fluctuations. Their work demonstrated the complex interplay between vaccination coverage and case rates, revealing that even small declines in coverage can lead to significant increases in measles cases.</p>
<p>In closing, their presentation emphasized three key takeaways:</p>
<ol type="1">
<li>The persistent decline in U.S. MMR coverage and its public health implications.</li>
<li>The disparity between absolute case counts and relative growth rates in different regions.</li>
<li>The inverse correlation between vaccination coverage and measles incidence, highlighting the critical need for maintaining high vaccination rates.</li>
</ol>
</section>
<section id="looking-forward-plans-for-further-research" class="level2">
<h2 class="anchored" data-anchor-id="looking-forward-plans-for-further-research">Looking Forward: Plans for Further Research</h2>
<p>Harrison and Shonushka expressed plans to investigate substate data and explore international comparisons between countries with different healthcare systems. Their commitment to continuing this line of inquiry underscores the importance of data-driven approaches in addressing public health challenges.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Harrison Plate and Shonushka Sawant’s innovative analysis and thoughtful presentation has provided a roadmap for future research and intervention strategies. As the R community continues to grow and evolve, research like theirs highlight the profound impact of collaborative, data-driven exploration.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Epidemiology</category>
  <guid>https://r-consortium.org/posts/how-are-vaccination-rates-and-case-rates-changing-for-measles-in-2025/</guid>
  <pubDate>Thu, 19 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/how-are-vaccination-rates-and-case-rates-changing-for-measles-in-2025/thumbnail-professional-competition-winner.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Identifying Measles Immunity Gaps in the US: A Comprehensive Analysis by Iko Musa</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/identifying-measles-immunity-gaps-in-the-us/</link>
  <description><![CDATA[ 





<section id="identifying-measles-immunity-gaps-in-the-us-a-comprehensive-analysis-by-iko-musa" class="level1">
<h1>Identifying Measles Immunity Gaps in the US: A Comprehensive Analysis by Iko Musa</h1>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LKNOEayXstU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>In the realm of public health, understanding and managing infectious diseases is crucial. This is particularly true for measles, a highly contagious virus that can lead to severe health complications. The recent R/Medicine 2025 conference shone a spotlight on an exemplary study conducted by Iko Musa, a master’s student from the University of Jos, Nigeria. His research, titled “Identifying Measles Immunity Gaps in the US: Analysis of Vaccination Coverage, Geographic Risk, and Future Outbreak Projections,” provides critical insights into the current state of measles immunity and vaccination in the United States.</p>
<section id="the-changing-landscape-of-vaccination" class="level2">
<h2 class="anchored" data-anchor-id="the-changing-landscape-of-vaccination">The Changing Landscape of Vaccination</h2>
<p>Iko’s study addresses a timely issue: the declining measles vaccination rates in the U.S., which have dropped below the 95% threshold recommended for herd immunity. This decline poses a significant risk of outbreaks, making it imperative to understand where and why these gaps in immunity are occurring.</p>
</section>
<section id="research-objectives-and-methodology" class="level2">
<h2 class="anchored" data-anchor-id="research-objectives-and-methodology">Research Objectives and Methodology</h2>
<p>To tackle this issue, Iko formulated several research objectives: 1. Analyze the temporal trends of measles cases in the U.S. from 1990 to 2025. 2. Identify geographic areas at high risk. 3. Assess the influence of geographical factors on measles outbreaks. 4. Compare U.S. measles data with global trends. 5. Project future measles case trajectories and their potential health impacts. 6. Pinpoint immunity gaps where vaccination coverage falls below 95%.</p>
<p>Iko employed a variety of analytical tools to achieve these objectives: - <strong>Temporal trend analysis</strong> using <code>ggplot2</code> for visualization. - <strong>Geospatial mapping</strong> with <code>ggplot2</code> maps and other tools to identify high-risk areas. - <strong>Comparative analysis</strong> to juxtapose U.S. data against global trends. - <strong>Time series forecasting</strong> to predict future outbreaks.</p>
</section>
<section id="key-findings" class="level2">
<h2 class="anchored" data-anchor-id="key-findings">Key Findings</h2>
<p><strong>Temporal Trends</strong> - The analysis revealed significant fluctuations in measles cases over the years, with notable outbreaks occurring periodically since 1989. A worrying trend is the recent increase in cases from 2020 through 2025.</p>
<p><strong>Geographical Risk</strong> - High-risk areas predominantly lie in the Mountainous regions and southern parts of the U.S., with states like Texas showing particularly high numbers of cases.</p>
<p><strong>Age Distribution</strong> - Most cases occur in individuals under 20 years old, emphasizing sustained transmission among children and teenagers.</p>
<p><strong>Global Comparison</strong> - The proportion of peak quarterly cases shows that U.S. trends are generally consistent with global patterns, though some differences exist in seasonal peaks.</p>
<section id="vaccination-rates-and-projections" class="level3">
<h3 class="anchored" data-anchor-id="vaccination-rates-and-projections">Vaccination Rates and Projections</h3>
<p>Current vaccination rates are alarmingly below the necessary threshold for herd immunity (95%). Forecasting models indicate that a decrease in vaccination rates could lead to significantly higher numbers of measles cases under various scenarios.</p>
</section>
</section>
<section id="implications-and-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="implications-and-recommendations">Implications and Recommendations</h2>
<p>The study underscores a critical need for targeted vaccination campaigns, especially focusing on school-aged children in high-risk states. Improving vaccination coverage by even 5% could prevent numerous cases and help restore herd immunity.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Iko Musa’s research not only highlights the challenges posed by declining measles vaccination rates but also provides a roadmap for intervention. His methodical approach and effective use of data visualization techniques make a compelling case for immediate public health action to close immunity gaps and protect communities across the United States.</p>
</section>
<section id="about-iko-musa" class="level2">
<h2 class="anchored" data-anchor-id="about-iko-musa">About Iko Musa</h2>
<p>Iko Musa is currently pursuing his Master’s degree in Field Epidemiology at the University of Jos, Nigeria. His academic focus is on community medicine, aiming to enhance public health through rigorous research and effective implementation of health policies. His work on measles immunity gaps has been recognized at R/Medicine 2025, reflecting his commitment to addressing critical global health issues through data-driven analysis.</p>
<p>For more information on R/Medicine and competition rules, please visit: - <a href="https://rconsortium.github.io/RMedicine_website/">R/Medicine</a> - <a href="https://rconsortium.github.io/RMedicine_website/Competition.html#congratulations-to-our-winners">Competition Rules</a></p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Epidemiology</category>
  <guid>https://r-consortium.org/posts/identifying-measles-immunity-gaps-in-the-us/</guid>
  <pubDate>Thu, 19 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/identifying-measles-immunity-gaps-in-the-us/thumbnail-iko-musa-student-competition-winner.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Introduction to R for Clinical Data</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/introduction-to-r-for-clinical-data/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/2-xbe46EUTw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="a-gentle-introduction-to-r-for-healthcare-professionals-and-researchers-at-rmedicine-2025" class="level1">
<h1>A Gentle Introduction to R for Healthcare Professionals and Researchers at R/Medicine 2025</h1>
<p>Welcome to the world of R programming tailored specifically for healthcare professionals and clinical researchers! As part of the R/Medicine 2025 conference, Stephan Kadauke and Rich Hanna curated an insightful pre-conference workshop titled “Introduction to R for Clinical Data.” This workshop is designed to bridge the gap between healthcare and data science by providing a comprehensive introduction to R and its application in clinical research.</p>
<section id="meet-your-instructors" class="level2">
<h2 class="anchored" data-anchor-id="meet-your-instructors">Meet Your Instructors</h2>
<section id="stephan-kadauke" class="level3">
<h3 class="anchored" data-anchor-id="stephan-kadauke">Stephan Kadauke</h3>
<p>Stephan is the Associate Director of the Cell Based Therapy Laboratory in the Department of Pathology at the Children’s Hospital of Philadelphia. He also serves as the Medical Director of the Cell and Gene Therapy Informatics Team. Stephan is passionate about using data to improve pediatric care, specifically for children undergoing bone marrow transplants and other cell therapies. He has developed curricula focused on Reproducible Clinical Data Analysis, demonstrating his commitment to improving healthcare through data-driven approaches.</p>
</section>
<section id="rich-hanna" class="level3">
<h3 class="anchored" data-anchor-id="rich-hanna">Rich Hanna</h3>
<p>Rich is a Data Scientist with the Cell and Gene Therapy Informatics Team at the Children’s Hospital of Philadelphia. With a background in biomedical and mechanical engineering, Rich specializes in automating clinical research workflows through advanced analytics and machine learning. His work is pivotal in supporting cell therapy research and enhancing patient care in pediatric medicine.</p>
</section>
</section>
<section id="course-resources" class="level2">
<h2 class="anchored" data-anchor-id="course-resources">Course Resources</h2>
<ul>
<li><strong>Course GitHub Repo</strong>: <a href="https://github.com/skadauke/intro-to-r-for-clinical-data-rmed2025">Introduction to R for Clinical Data</a></li>
<li><strong>Course Website</strong>: <a href="https://stephan-kadauke.quarto.pub/intro-to-r-for-clinical-data-rmed2025/">Introduction to R for Clinical Data</a></li>
</ul>
</section>
<section id="workshop-overview" class="level2">
<h2 class="anchored" data-anchor-id="workshop-overview">Workshop Overview</h2>
<section id="setting-the-stage" class="level3">
<h3 class="anchored" data-anchor-id="setting-the-stage">Setting the Stage</h3>
<p>The workshop commenced with a warm welcome and an interactive session to acquaint participants with the course’s objectives. Designed for healthcare professionals with minimal programming background, the workshop aims to demystify data analysis using R. Stephan and Rich have structured the course with interactive exercises, ensuring participants gain hands-on experience.</p>
</section>
<section id="importance-of-reproducibility" class="level3">
<h3 class="anchored" data-anchor-id="importance-of-reproducibility">Importance of Reproducibility</h3>
<p>A key highlight was the emphasis on reproducibility in clinical data analysis. Stephan shared a compelling case study from Duke University, where errors in data analysis led to significant repercussions. This case underscores the necessity of robust, reproducible workflows to prevent errors and improve patient outcomes.</p>
</section>
<section id="introduction-to-r-r-studio-and-quarto" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-r-r-studio-and-quarto">Introduction to R, R Studio, and Quarto</h3>
<p>Participants were introduced to the essential tools of the trade:</p>
<ul>
<li><strong>R</strong>: A powerful programming language for data analysis.</li>
<li><strong>R Studio</strong>: An integrated development environment for R, enhancing the user experience with features that aid coding and debugging.</li>
<li><strong>Quarto</strong>: A computational document format that integrates code, narrative, and visualizations, supporting reproducible research.</li>
</ul>
</section>
<section id="interactive-exercises" class="level3">
<h3 class="anchored" data-anchor-id="interactive-exercises">Interactive Exercises</h3>
<p>The workshop featured a series of interactive exercises, allowing participants to:</p>
<ul>
<li>Create and manipulate data frames.</li>
<li>Visualize data using ggplot2, a grammar of graphics for R.</li>
<li>Transform and tidy data using the dplyr package.</li>
<li>Develop reproducible workflows by integrating Quarto documents.</li>
</ul>
</section>
<section id="data-visualization-and-transformation" class="level3">
<h3 class="anchored" data-anchor-id="data-visualization-and-transformation">Data Visualization and Transformation</h3>
<p>Rich led a session on data transformation, focusing on the dplyr package. Participants learned to:</p>
<ul>
<li>Select specific columns using the <code>select</code> function.</li>
<li>Filter rows based on logical conditions with <code>filter</code>.</li>
<li>Create new variables with <code>mutate</code>.</li>
<li>Group data and summarize it with <code>group_by</code> and <code>summarize</code>.</li>
</ul>
</section>
<section id="dashboards-and-interactive-visualization" class="level3">
<h3 class="anchored" data-anchor-id="dashboards-and-interactive-visualization">Dashboards and Interactive Visualization</h3>
<p>While time constraints limited a deep dive into dashboards, participants were introduced to the concept of interactive dashboards using Flex Dashboard and Plotly. These tools enable users to create dynamic, on-demand data visualizations, empowering healthcare professionals to make data-driven decisions efficiently.</p>
</section>
</section>
<section id="conclusion-and-further-learning" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-and-further-learning">Conclusion and Further Learning</h2>
<p>The workshop wrapped up with resources for continued learning. Participants were encouraged to explore the “R for Data Science” book by Garrett Grolemund and Hadley Wickham, available for free online. Additionally, generative AI tools like ChatGPT were recommended for troubleshooting and enhancing coding skills, with a caution to avoid entering sensitive information.</p>
<p>The course materials, including the GitHub repository and course website, remain accessible for further exploration and practice.</p>
<p>As the R community continues to grow, workshops like this play a pivotal role in equipping healthcare professionals with the skills to leverage data science for better patient care. We look forward to seeing how participants will apply their newfound knowledge to make a tangible impact in the healthcare sector.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/introduction-to-r-for-clinical-data/</guid>
  <pubDate>Thu, 19 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/introduction-to-r-for-clinical-data/thumbnail-introduction-to-r-for clinical-data.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Personal R Administration</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/personal-r-administration/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/m2eihAhl8so" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="personal-r-administration-streamlining-your-r-workflow" class="level1">
<h1>Personal R Administration: Streamlining Your R Workflow</h1>
<p>In the ever-evolving landscape of data science and software development, R remains a cornerstone for researchers, analysts, and programmers alike. However, managing R environments, handling package installations, and ensuring reproducibility can often feel like daunting tasks. At the R/Medicine 2025 conference, E. David Aja and Shannon Pileggi unveiled their workshop titled “Personal R Administration,” offering the R community invaluable insights into simplifying these processes, ensuring secure and efficient workflows, and fostering a more robust engagement with R projects.</p>
<section id="speakers" class="level2">
<h2 class="anchored" data-anchor-id="speakers">Speakers</h2>
<p><strong>E. David Aja</strong><br>
Software Engineer at Posit. Before his current role, he ventured through the realms of data science in the public sector, amassing a wealth of experience in deploying R across diverse computational landscapes.</p>
<p><strong>Shannon Pileggi</strong><br>
With a title of Lead Data Scientist at The Prostate Cancer Clinical Trials Consortium, Shannon brings her expertise to the fore. A frequent blogger and a pivotal member of the R-Ladies Global leadership team, she excels in automating data wrangling, crafting digestible data insights, and demystifying the learning curve for new material.</p>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<p>The workshop began with an open acknowledgment of the common pitfalls many R users face: fear of updating R versions, insecurely storing secrets, and the mystification surrounding package installations. Aja and Pileggi, through a blend of technical prowess and personal anecdotes, offered a roadmap to navigate these challenges.</p>
<section id="embracing-project-based-workflows" class="level3">
<h3 class="anchored" data-anchor-id="embracing-project-based-workflows">Embracing Project-Based Workflows</h3>
<p>The speakers underscored the importance of project-based workflows in R, highlighting strategies for maintaining a clean slate with each new session. This approach not only aids in minimizing clutter but also ensures that projects remain insulated from each other, reducing dependency conflicts and enhancing reproducibility.</p>
</section>
<section id="navigating-package-management-with-renv" class="level3">
<h3 class="anchored" data-anchor-id="navigating-package-management-with-renv">Navigating Package Management with <code>renv</code></h3>
<p>A significant portion of the workshop was dedicated to <code>renv</code>, a package that revolutionizes how R users manage dependencies within projects. By isolating project environments and leveraging a global cache, <code>renv</code> allows for seamless package installations and version management, mitigating the risk of disrupting existing projects when making updates.</p>
</section>
<section id="version-control-and-environment-management" class="level3">
<h3 class="anchored" data-anchor-id="version-control-and-environment-management">Version Control and Environment Management</h3>
<p>The discussion ventured into the realm of version control and the management of R versions across different projects. Tools like <code>rig</code> were introduced, offering a streamlined method to switch between R versions without the hassle, thereby fostering an environment where projects can be easily shared and reproduced across teams.</p>
</section>
<section id="security-practices-and-workflow-optimization" class="level3">
<h3 class="anchored" data-anchor-id="security-practices-and-workflow-optimization">Security Practices and Workflow Optimization</h3>
<p>Security practices, particularly around the handling of sensitive information within R scripts, were addressed. The speakers advocated for the use of environment variables and secure storage solutions to mitigate risks. Additionally, they provided insights into optimizing workflows through the use of RStudio addins and other productivity-enhancing tools.</p>
</section>
<section id="community-and-resources" class="level3">
<h3 class="anchored" data-anchor-id="community-and-resources">Community and Resources</h3>
<p>Aja and Pileggi emphasized the value of the R community, encouraging attendees to engage with forums, contribute to open-source projects, and leverage the wealth of resources available, including blogs, webinars, and comprehensive guides like the <code>R Packages</code> book.</p>
</section>
<section id="looking-ahead" class="level3">
<h3 class="anchored" data-anchor-id="looking-ahead"><strong>Looking Ahead</strong></h3>
<p>As R continues to evolve, so too do the tools and practices surrounding its use. This workshop served as a vital resource for R users seeking to refine their administration skills, promising a future where managing R environments is less about troubleshooting and more about innovation.</p>
<p>In closing, “Personal R Administration” was not just a workshop but a testament to the R community’s dedication to fostering a culture of continuous learning and improvement. For those looking to dive deeper into the topics covered, the speakers provided a wealth of resources, including links to the <code>renv</code> documentation, <code>rig</code> installation guides, and their own contributions to R package development.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion"><strong>Conclusion</strong></h2>
<p>Whether you’re a seasoned R veteran or a newcomer to the language, the “Personal R Administration” workshop offered a treasure trove of knowledge designed to streamline workflows, enhance project reproducibility, and secure your R coding practices. As we move forward, the insights shared by Aja and Pileggi will undoubtedly serve as a beacon for the R community, guiding us toward more efficient and enjoyable data science experiences.</p>
<p>For those interested in further exploring the themes of the workshop, the R/Medicine and R Consortium websites provide a gateway to a broader exploration of R’s capabilities within the medical field and beyond.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/personal-r-administration/</guid>
  <pubDate>Thu, 19 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/personal-r-administration/thumbnail-personal-r-administration.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>pretestcad: An R package to calculate PreTest Probability (PTP) for Coronary Artery Disease (CAD)</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/pretestcad-an-r-package-to-calculate-pretest-probability-ptp-for-coronary-artery-disease-cad/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/5hpTlmKvRU8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="automating-pretest-probability-calculations-for-coronary-artery-disease-with-the-pretestcad-r-package" class="level1">
<h1>Automating Pretest Probability Calculations for Coronary Artery Disease with the <code>pretestcad</code> R Package</h1>
<p>In the ever-evolving field of cardiology, clinicians face the constant challenge of keeping up with the latest risk assessment models for coronary artery disease (CAD). Traditionally, tools like HeartScore have been used to calculate a patient’s risk of cardiovascular events. However, these tools are limited by their one-patient-at-a-time approach. Enter the realm of R packages—powerful tools that can automate and streamline these calculations for multiple patients simultaneously. Among them, the <code>pretestcad</code> R package emerges as a novel solution, specifically designed to address the gap in pretest risk assessment for obstructive CAD.</p>
<section id="understanding-coronary-artery-disease-and-pretest-probability" class="level2">
<h2 class="anchored" data-anchor-id="understanding-coronary-artery-disease-and-pretest-probability">Understanding Coronary Artery Disease and Pretest Probability</h2>
<p>Coronary artery disease occurs when the coronary arteries become narrowed or blocked by fatty deposits known as plaques. This can result in chest pain, shortness of breath, or even heart attacks. Diagnosing CAD often involves invasive tests like coronary angiography or less invasive options such as CT scans. The concept of pretest probability comes into play here, providing an estimated likelihood that a patient has CAD before any diagnostic tests are performed. This estimation helps clinicians decide which diagnostic path to pursue, especially when certain tests are expensive or invasive.</p>
</section>
<section id="the-evolution-of-pretest-probability-models" class="level2">
<h2 class="anchored" data-anchor-id="the-evolution-of-pretest-probability-models">The Evolution of Pretest Probability Models</h2>
<p>As our understanding of CAD has grown, so too have the models for estimating pretest probability. The European Society of Cardiology (ESC) guidelines have evolved from simple models with three risk factors to more sophisticated ones that include family history, smoking, cholesterol levels, hypertension, and diabetes. This increased complexity makes manual calculations tedious and prone to error.</p>
<p>Jeremy, a research officer from the National Heart Center Singapore, recognized this challenge and sought to address it by developing the <code>pretestcad</code> R package. This package automates the calculation of pretest probability scores for CAD, drawing on a comprehensive collection of models from past to present. The package is designed to be flexible and user-friendly, accommodating missing data and providing clear error messages.</p>
</section>
<section id="key-features-of-the-pretestcad-r-package" class="level2">
<h2 class="anchored" data-anchor-id="key-features-of-the-pretestcad-r-package">Key Features of the <code>pretestcad</code> R Package</h2>
<p>The <code>pretestcad</code> package includes several pretest probability scores, such as the 2012 CAD Consortium 2 (CAD2) PTP scores, the 2017 PROMISE Minimal-Risk Score, and the 2020 Winther et al.&nbsp;Risk-Factor-weighted Clinical Likelihood (RF-CL) and Coronary Artery Calcium Score-Weighted Clinical Likelihood (CACS-CL) PTP. These scores are integral to the 2024 ESC Guidelines, and the package allows users to calculate them efficiently for multiple patients.</p>
<section id="handling-missing-data" class="level3">
<h3 class="anchored" data-anchor-id="handling-missing-data">Handling Missing Data</h3>
<p>One of the standout features of the <code>pretestcad</code> package is its ability to handle missing data. In real-world scenarios, patient data may be incomplete. The package includes a parameter called <code>max_na</code> that specifies the number of missing risk factors tolerated in calculations. This flexibility ensures that clinicians can still obtain useful probability estimates even when some data points are missing.</p>
</section>
<section id="integration-with-r-ecosystem" class="level3">
<h3 class="anchored" data-anchor-id="integration-with-r-ecosystem">Integration with R Ecosystem</h3>
<p>The package leverages the <code>purrr</code> package to perform calculations over patient datasets, demonstrating its seamless integration with the broader R ecosystem. This compatibility allows users to incorporate <code>pretestcad</code> into their existing R workflows without significant overhead.</p>
</section>
</section>
<section id="future-directions-and-community-engagement" class="level2">
<h2 class="anchored" data-anchor-id="future-directions-and-community-engagement">Future Directions and Community Engagement</h2>
<p>Jeremy’s presentation at the R/Medicine 2025 conference was not just an introduction to the <code>pretestcad</code> package but also a call to action for collaboration and feedback from the R community. While he has successfully submitted the package to CRAN, he recognizes the importance of user feedback, particularly from clinicians who will be the primary users of the tool.</p>
<p>Going forward, Jeremy plans to conduct user testing with clinicians to refine the package’s usability and error messaging. While he is cautious about overextending the project’s scope, potential future enhancements could include integration with platforms like Shiny or Jamovi, making the tool even more accessible to a wider audience.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The development of the <code>pretestcad</code> R package exemplifies how the R community can contribute to medical advancements by providing tools that streamline and automate complex calculations. By addressing the gap in pretest probability assessment for CAD, the package empowers clinicians to make informed decisions more efficiently, ultimately improving patient care.</p>
<p>As the package garners feedback and evolves, it promises to become an indispensable tool in the toolkit of cardiologists worldwide. Jeremy’s work is a testament to the power of the R language in transforming healthcare practices, and it highlights the potential for further innovations in the field.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Insurance/Risk</category>
  <guid>https://r-consortium.org/posts/pretestcad-an-r-package-to-calculate-pretest-probability-ptp-for-coronary-artery-disease-cad/</guid>
  <pubDate>Thu, 19 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/pretestcad-an-r-package-to-calculate-pretest-probability-ptp-for-coronary-artery-disease-cad/thumbnail-pretestcad-jeremy-selva.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Bridging the Gap: Introducing RHealth for Healthcare Predictive Modeling in R</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bridging-the-gap-introducing-rhealth-for-healthcare-predictive-modeling-in-r/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/kGcq2YQVWcc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="bridging-the-gap-introducing-rhealth-for-healthcare-predictive-modeling-in-r" class="level2">
<h2 class="anchored" data-anchor-id="bridging-the-gap-introducing-rhealth-for-healthcare-predictive-modeling-in-r">Bridging the Gap: Introducing RHealth for Healthcare Predictive Modeling in R</h2>
<p>In an era where healthcare is rapidly evolving with the integration of artificial intelligence, the disparity between traditional clinical research and cutting-edge AI tools poses a significant challenge. The R language, long trusted by clinicians and statisticians for its robust analytics capabilities, finds itself at a crossroads with the burgeoning field of deep learning predominantly led by Python. With Python boasting over 7,800 healthcare projects on GitHub compared to just 700 in R, there’s a clear gap in tool development focus. This divide hampers the ability of clinical researchers to leverage the latest AI advancements directly within the R ecosystem they are familiar with.</p>
<p>Enter RHealth, a revolutionary toolkit designed to empower the R community with the tools needed for advanced healthcare predictive modeling using deep learning. Spearheaded by Junyi Gao, a PhD candidate at the University of Edinburgh, in collaboration with notable researchers like Zhixia Ren, Ji Song, Liantao Ma, and Ewen M. Harrison, RHealth is a testament to interdisciplinary collaboration and innovation. This initiative, funded by the ISC grant from the R Consortium, aims to dismantle the barriers preventing R users from accessing state-of-the-art AI tools.</p>
</section>
<section id="why-rhealth" class="level2">
<h2 class="anchored" data-anchor-id="why-rhealth">Why RHealth?</h2>
<p>The primary mission of RHealth is to bridge the gap between R and the Python-based AI world. RHealth offers an open-source R package that mirrors the capabilities of PyHealth, a highly successful healthcare AI package in the Python ecosystem. PyHealth has set a precedent by garnering over 11,000 stars and 144,000 downloads on GitHub, signaling its widespread acceptance and utility. By replicating such a successful blueprint in R, RHealth aspires to bring similar capabilities to the R community.</p>
</section>
<section id="core-modules-of-rhealth" class="level2">
<h2 class="anchored" data-anchor-id="core-modules-of-rhealth">Core Modules of RHealth</h2>
<p>The development of RHealth focuses on four core modules that create a seamless pipeline from data to prediction:</p>
<p><strong>EHR Database Module</strong>: This module provides a standardized framework to ingest, process, and manage diverse EHR datasets. It supports major public datasets like MIMIC-III, MIMIC-IV, and eICU, and facilitates user-specific data formats (OMOP-CDM), ensuring data consistency for downstream modeling.</p>
<p><strong>EHR Code Mapping Module</strong>: One of the most critical aspects of healthcare data integration is harmonizing different medical coding systems. This module tackles the immense challenge of mapping between various coding systems such as ICD, CPT, and NDC. It simplifies the critical task of aligning terminology across datasets, thereby enhancing data interoperability.</p>
<p><strong>Prediction Task Module</strong>: This module provides a framework for defining clinical prediction tasks. It supports patient-level tasks for long-term predictions, inter-visit level tasks for predictions during specific encounters, and intra-visit level tasks for predictions across encounters.</p>
<p><strong>Healthcare Deep Learning Core Module</strong>: As the engine of the toolkit, this module offers a comprehensive suite of predictive models, including traditional machine learning methods and cutting-edge deep learning models optimized for healthcare. Models like RETAIN, Transformers, and graph neural networks are accessible natively within R, empowering R users with advanced analytical capabilities.</p>
</section>
<section id="empowering-clinical-researchers" class="level2">
<h2 class="anchored" data-anchor-id="empowering-clinical-researchers">Empowering Clinical Researchers</h2>
<p>RHealth is not just about providing tools but about empowering the healthcare community to innovate and contribute to improved healthcare outcomes. By lowering the technical barrier, RHealth enables rapid prototyping and validation of clinical risks and decision support tools directly within the trusted R environment. This democratization of AI tools in healthcare allows clinicians and statisticians to leverage their deep clinical knowledge alongside advanced AI techniques, thus enhancing the translation of research into practice.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>The journey of RHealth is just beginning. The team is actively developing additional modules and seeking further funding to expand its capabilities. Future enhancements include support for multi-modal data integration, clinical trial applications, and large language model enhancements. The goal is to continually refine and expand RHealth to meet the evolving needs of the healthcare community.</p>
<p>In conclusion, RHealth represents a significant milestone in the integration of R and AI for healthcare. It is a call to action for the R community to embrace and contribute to this open-source project, ensuring that the latest advancements in AI are accessible and usable by those who are at the forefront of healthcare research. By fostering a collaborative environment, RHealth aims to revolutionize healthcare predictive modeling and ultimately contribute to better patient outcomes.</p>


</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/bridging-the-gap-introducing-rhealth-for-healthcare-predictive-modeling-in-r/</guid>
  <pubDate>Wed, 18 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bridging-the-gap-introducing-rhealth-for-healthcare-predictive-modeling-in-r/thumb.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Demystifying LLMs with Ellmer</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/demystifying-llms-with-ellmer/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/skLmOuNjqEU?feature=shared" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unlocking-the-power-of-llms-with-r-a-practical-guide" class="level1">
<h1>Unlocking the Power of LLMs with R: A Practical Guide</h1>
<p>In the rapidly evolving landscape of Large Language Models (LLMs), the capabilities extend far beyond the familiar confines of ChatGPT or programming assistants like Copilot. The real magic begins when you access these models programmatically, integrating their vast knowledge and adaptability into your own applications, scripts, and workflows. At the heart of this exploration into the next frontier of LLM utility is the R language, facilitated by tools like the <code>ellmer</code> package and the innovative web framework, Shiny.</p>
<section id="speaker-joe-cheng" class="level2">
<h2 class="anchored" data-anchor-id="speaker-joe-cheng">Speaker: Joe Cheng</h2>
<p>Joe Cheng, the CTO of Posit, PBC, stands at the forefront of this exploration. As the original creator of the Shiny web framework and co-creator of <code>ellmer</code>, Joe’s workshop at R/Medicine 2025 offered attendees a deep dive into the practical aspects of integrating LLMs with R. His journey from skepticism to embracing the potential of LLMs underscores a broader narrative within the data science community about the transformative power of these models when approached with curiosity and innovative tools.</p>
<section id="from-skepticism-to-innovation" class="level3">
<h3 class="anchored" data-anchor-id="from-skepticism-to-innovation">From Skepticism to Innovation</h3>
<p>A year and a half ago, the consensus at Posit leaned towards skepticism regarding the hype surrounding AI and LLMs. The concern centered around the models’ black box nature and their apparent incompatibility with the principles of reproducible research and transparent methodologies. However, the turning point for Joe and his team came with the realization that the capabilities of LLMs defied their initial understanding and skepticism. This led to a series of internal hackathons aimed at demystifying LLMs for Posit employees, fostering a profound appreciation for the models’ potential when accessed programmatically.</p>
</section>
<section id="the-workshop-a-practical-introduction-to-llm-apis" class="level3">
<h3 class="anchored" data-anchor-id="the-workshop-a-practical-introduction-to-llm-apis">The Workshop: A Practical Introduction to LLM APIs</h3>
<p>Joe’s workshop provided a comprehensive introduction to utilizing LLM APIs within the R ecosystem, leveraging the <code>ellmer</code> package. Attendees learned how to configure R to interact with LLMs, customize model behavior through system prompts, integrate chatbots into Shiny applications, and employ LLMs for advanced natural language processing tasks. This hands-on approach equipped participants with the knowledge to embark on their own experiments with LLMs, pushing the boundaries of what’s possible in data analysis and application development.</p>
</section>
<section id="key-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h3>
<ul>
<li><strong>Programmatic Access to LLMs:</strong> The workshop emphasized the untapped potential of LLMs when accessed programmatically, allowing for more complex and tailored interactions than what standard interfaces like ChatGPT offer.</li>
<li><strong>Integration with R:</strong> By showcasing the integration of LLMs with R, particularly through the <code>ellmer</code> package, Joe highlighted the seamless bridge between cutting-edge AI models and the robust analytical capabilities of R.</li>
<li><strong>Empowering the R Community:</strong> The workshop not only showcased the technical possibilities but also served as a call to action for the R community to explore and innovate with LLMs, fostering a culture of experimentation and learning.</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>The journey from skepticism to embracing LLMs underscores a larger narrative within the tech community about the potential of these models to revolutionize data analysis, application development, and beyond. Joe Cheng’s workshop at R/Medicine 2025 stands as a beacon for R enthusiasts eager to explore this new frontier, armed with the knowledge and tools to unlock the full capabilities of LLMs.</p>


</section>
</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/demystifying-llms-with-ellmer/</guid>
  <pubDate>Wed, 18 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/demystifying-llms-with-ellmer/thumbnail-cheng-demystifying-llms-with-ellmer.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>rainbowR: Fostering an Inclusive Space for LGBTQ+ Coders in the R Community</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rainbow-r-inclusive-space-LGBTQ-coders/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gLlRaqNfjys" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="rainbowr-fostering-an-inclusive-space-for-lgbtq-coders-in-the-r-community" class="level1">
<h1>rainbowR: Fostering an Inclusive Space for LGBTQ+ Coders in the R Community</h1>
<p>In the vibrant and ever-evolving world of R programming, diversity and inclusion have become crucial pillars for fostering innovation and creativity. Today, we delve into the inspiring journey of rainbowR, a community dedicated to connecting, supporting, and promoting LGBTQ+ individuals who code in R. Founded seven years ago, rainbowR has grown into a thriving network with over 100 members, and it continues to champion data-driven activism and community building. Join us as we explore the origins, initiatives, and future plans of rainbowR—a community that believes in the power of inclusivity to strengthen the R ecosystem.</p>
<section id="speaker-ella-kaye" class="level2">
<h2 class="anchored" data-anchor-id="speaker-ella-kaye">Speaker: Ella Kaye</h2>
<p>Ella Kaye is a passionate advocate for diversity in the R community and a driving force behind rainbowR. Her journey began at the UseR! conference in 2017 when a chance conversation revealed the need for an LGBTQ+ community within the broader R landscape. Ella’s dedication has been instrumental in shaping rainbowR into a thriving network that connects and supports LGBTQ+ individuals while promoting awareness of LGBTQ+ issues through data-driven initiatives.</p>
</section>
<section id="the-genesis-of-rainbowr" class="level2">
<h2 class="anchored" data-anchor-id="the-genesis-of-rainbowr">The Genesis of rainbowR</h2>
<p>The seed for rainbowR was planted during a conversation at the UseR! conference in 2017. It was here that Ella Kaye realized the potential impact of creating a space where LGBTQ+ individuals could connect and share their experiences within the R community. The idea resonated with many, and rainbowR was born. Over the years, the community has grown and flourished, providing a supportive environment for members to engage in meaningful discussions and collaborations.</p>
</section>
<section id="initiatives-that-connect-support-and-promote" class="level2">
<h2 class="anchored" data-anchor-id="initiatives-that-connect-support-and-promote">Initiatives that Connect, Support, and Promote</h2>
<p>rainbowR’s mission is to connect, support, and promote LGBTQ+ individuals who code in R. To achieve these goals, the community has launched two main initiatives:</p>
<ol type="1">
<li><p><strong>Monthly Meetups</strong>: Held on the fourth Wednesday of each month on Zoom, these relaxed and friendly sessions offer a platform for members to chat about R, share resources, and showcase their work. The next meetup is scheduled for June 25th, providing an opportunity for participants to engage in a supportive setting.</p></li>
<li><p><strong>Buddy Scheme</strong>: Designed to foster deeper connections, this initiative randomly pairs members every three months. Participants fill out a form detailing their interests, and an R script generates pairings and sends introduction emails. This approach helps members overcome the nerves of meeting new people and encourages meaningful conversations.</p></li>
</ol>
</section>
<section id="data-driven-activism-and-community-engagement" class="level2">
<h2 class="anchored" data-anchor-id="data-driven-activism-and-community-engagement">Data-Driven Activism and Community Engagement</h2>
<p>rainbowR is committed to data-driven activism, hosting a GitHub repository called Tidy Rainbow that features LGBTQ+ datasets. These datasets serve as valuable resources for practicing data visualization, analysis, and teaching. The community also recently concluded its first rainbowR book club, where participants discussed “Queer Data: Using Gender, Sex, and Sexuality Data for Action” by Kevin Gian. The success of this initiative has paved the way for future book clubs.</p>
</section>
<section id="growing-the-community-and-future-plans" class="level2">
<h2 class="anchored" data-anchor-id="growing-the-community-and-future-plans">Growing the Community and Future Plans</h2>
<p>The past year has been transformative for rainbowR, with the community doubling in size. Ella Kaye’s efforts, including speaking engagements at conferences such as UseR! in Salzburg and Posit, have played a pivotal role in this growth. Social media strategies on platforms like Blue Sky and Mastodon have further amplified rainbowR’s reach.</p>
<p>Looking ahead, Ella’s fellowship with the Software Sustainability Institute will support plans to nurture and sustain rainbowR. This includes ensuring clear pathways for community engagement, establishing robust policies and governance, and becoming a legal entity. A flagship event, the first-ever rainbowR Conference, will bring the community together to learn and share best practices in R and software sustainability.</p>
</section>
<section id="a-call-to-action" class="level2">
<h2 class="anchored" data-anchor-id="a-call-to-action">A Call to Action</h2>
<p>Whether you’re a member of the LGBTQ+ community or an ally, rainbowR welcomes you to get involved. By joining, you gain access to a vibrant network of R enthusiasts, opportunities for collaboration, and a platform to promote LGBTQ+ issues within the R community. To learn more or join the community, visit <a href="https://rainbow.org">rainbow.org</a>.</p>
<p>In conclusion, rainbowR embodies the belief that a diverse and inclusive community enriches the R ecosystem. By fostering connections, supporting members, and promoting awareness, rainbowR continues to make a positive impact on the R community and beyond. We invite you to be a part of this transformative journey.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>LGBTQ+</category>
  <guid>https://r-consortium.org/posts/rainbow-r-inclusive-space-LGBTQ-coders/</guid>
  <pubDate>Wed, 18 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rainbow-r-inclusive-space-LGBTQ-coders/thumbnail-rainbowr.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Simplifying R Package Documentation with pkgdown and GitHub Pages</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/simplifying-r-package-documentation-with-pkgdown-and-github-pages/</link>
  <description><![CDATA[ 





<p><img src="https://r-consortium.org/posts/simplifying-r-package-documentation-with-pkgdown-and-github-pages/r-pkgdown.jpg" class="img-fluid" alt="R Package Development with pkgdown - Melissa Van Bussel"></p>
<p>Welcome to the world of R package development! If you’ve ever created an R package, you know that one of the most crucial aspects is its documentation. Good documentation not only makes your package more accessible to others but also enhances its usability. However, creating and maintaining a neat documentation website can be a daunting task. This is where <code>pkgdown</code> and GitHub Pages come into play, simplifying the process significantly.</p>
<section id="why-use-pkgdown" class="level2">
<h2 class="anchored" data-anchor-id="why-use-pkgdown">Why Use pkgdown?</h2>
<p><code>pkgdown</code> is designed to make it straightforward to turn your R package into a beautiful website. It automatically converts your R documentation into user-friendly, HTML formats, making it easier for users to navigate and understand the package’s functionalities.</p>
</section>
<section id="integrating-pkgdown-with-github-pages" class="level2">
<h2 class="anchored" data-anchor-id="integrating-pkgdown-with-github-pages">Integrating pkgdown with GitHub Pages</h2>
<p>GitHub Pages offers a seamless way to host your package’s documentation directly from your GitHub repository. Here’s a simplified workflow on how to deploy your <code>pkgdown</code> site using GitHub Pages:</p>
<ol type="1">
<li><p><strong>Create Your pkgdown Website</strong>: First, use <code>pkgdown</code> to automatically generate a website for your R package. This involves setting up configuration files that dictate how your documentation is built and structured.</p></li>
<li><p><strong>Set Up GitHub Pages</strong>: Configure GitHub Pages in your repository settings to point to the docs folder where <code>pkgdown</code> generates the website files.</p></li>
<li><p><strong>Customize Your Website</strong>: <code>pkgdown</code> provides various customization options, allowing you to tailor the aesthetics and functionality of your site. You can modify themes, layout, and even add custom CSS or JavaScript.</p></li>
<li><p><strong>Automate with GitHub Actions</strong>: To keep your documentation automatically updated with every push to your repository, you can use GitHub Actions. This CI/CD tool can be configured to rebuild your <code>pkgdown</code> site automatically whenever changes are made to the relevant parts of your codebase.</p></li>
<li><p><strong>Access Your Site</strong>: Once everything is set up, your package documentation will be accessible via a straightforward URL provided by GitHub Pages (typically <code>username.github.io/repository</code>).</p></li>
</ol>
</section>
<section id="benefits-of-using-pkgdown-and-github-pages" class="level2">
<h2 class="anchored" data-anchor-id="benefits-of-using-pkgdown-and-github-pages">Benefits of Using pkgdown and GitHub Pages</h2>
<ul>
<li><strong>Ease of Use</strong>: Both tools are designed with simplicity in mind, making it easy for R developers to get their documentation up and running without extensive web development experience.</li>
<li><strong>Automation</strong>: Integration with GitHub Actions means that any updates to your package are automatically reflected in the documentation, reducing manual maintenance efforts.</li>
<li><strong>Customization</strong>: While <code>pkgdown</code> provides sensible defaults, it also offers extensive customization options to match the look and feel of your project or personal branding.</li>
<li><strong>Visibility</strong>: Hosting on GitHub Pages enhances the visibility of your package, making it more accessible to potential users and contributors through search engines and direct links.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Creating an effective documentation website for your R package doesn’t have to be complicated. With tools like <code>pkgdown</code> and GitHub Pages, coupled with automation through GitHub Actions, you can ensure that your package is as user-friendly as possible. This not only helps in increasing its adoption but also in building a community around it.</p>
<p>By streamlining the process of building and deploying documentation websites, these tools allow you more time to focus on developing the core functionalities of your R packages.</p>


</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/simplifying-r-package-documentation-with-pkgdown-and-github-pages/</guid>
  <pubDate>Wed, 18 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/simplifying-r-package-documentation-with-pkgdown-and-github-pages/r-pkgdown.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>A Community-Powered Future for Regulatory R: Introducing Our Fundraising Campaign</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/community-powered-future-for-regulatory-r-introducing-our-fundraising-campaign/</link>
  <description><![CDATA[ 





<section id="a-community-powered-future-for-regulatory-r-introducing-our-fundraising-campaign" class="level1">
<h1>A Community-Powered Future for Regulatory R: Introducing Our Fundraising Campaign</h1>
<p>As many of you may have seen, we’ve officially launched a fundraising campaign for the <strong>Regulatory R Repository</strong> — a critical initiative built to support the safe, efficient, and confident use of R packages in regulated environments.</p>
<p>The <strong>Regulatory R Repository</strong> will provide a robust, <em>validation-ready collection of package metadata</em> using the R Validation Hub’s open-source <code>{riskmetric}</code> framework. Our goal is simple yet powerful: enable organizations to use R in their regulatory submissions.</p>
<section id="why-a-fundraising" class="level3">
<h3 class="anchored" data-anchor-id="why-a-fundraising">Why a fundraising?</h3>
<p>Until now, the project has been built entirely on volunteer contributions. This has helped us build momentum — but to <strong>scale delivery and ensure consistency</strong>, we need dedicated funding. Importantly, this project is <strong>company-agnostic</strong> by design. It lives under the umbrella of the <strong>R Consortium</strong>, not any single corporation like Roche or others, to ensure transparency, neutrality, and broad utility.</p>
</section>
<section id="is-it-just-for-pharma" class="level3">
<h3 class="anchored" data-anchor-id="is-it-just-for-pharma">Is it just for Pharma?</h3>
<p>While the pharmaceutical industry has been a key driver of this effort, our scope extends far beyond pharma. This repository will benefit <strong>any organization that must meet regulatory standards while using R</strong>. This includes universities, NGOs, and regulated industries such as <strong>agriculture, finance, insurance, and biotech</strong>. Wherever R is used in regulated or quality-sensitive contexts, the repository can provide assurance and clarity.</p>
</section>
<section id="what-will-we-deliver" class="level3">
<h3 class="anchored" data-anchor-id="what-will-we-deliver">What Will We Deliver?</h3>
<ul>
<li><p><strong>Tools for periodic assessment</strong> of public R packages</p></li>
<li><p><strong>Template projects for in-house deployments</strong>, for organizations managing private packages</p></li>
<li><p>A <strong>supplementary repository of metadata</strong> that supports the risk-assessment and governance of R environments in regulated settings</p></li>
</ul>
<p>We’re deeply grateful to everyone who has contributed so far — your work has laid the foundation for what’s next.</p>
</section>
<section id="why-open-source" class="level3">
<h3 class="anchored" data-anchor-id="why-open-source">Why Open Source?</h3>
<p>You might wonder: <em>“If some industries have the resources to build software, why do open-source projects still rely on funding and volunteer contributions?”</em></p>
<p>Open Source thrives on collaboration rooted in <strong>transparency and trust</strong>. The solutions created in this space aren’t owned by any one company—they belong to the <strong>global community</strong>. That’s what makes them so powerful.</p>
<p>Across all industries, there are countless <strong>smaller companies, research institutes, non-profits, and independent teams</strong> with brilliant ideas but limited budgets. Without access to costly, proprietary tools, their growth and potential impact are often restricted. Open Source breaks down these barriers—enabling them to move faster, innovate, and build on <strong>trusted, freely available technologies</strong>.</p>
<p>While large enterprises do support Open Source—by funding organizations like the <strong>R Consortium</strong>, sponsoring events, or encouraging their employees to contribute—these efforts are often <strong>indirect</strong>. Open Source may not be owned, but it still needs to be built, maintained, and evolved. And that takes real resources.</p>
<p>That’s where <strong>non-profit organizations and community fundraising</strong> play a vital role. They help fuel projects that are developed in parallel by volunteers around the world. Open Source isn’t free to create—it’s just <strong>freely shared</strong>. Ongoing support from both the community and companies that benefit from it is essential to keep it growing.</p>
</section>
<section id="contribute-now-to-support-open-source-software" class="level3">
<h3 class="anchored" data-anchor-id="contribute-now-to-support-open-source-software">Contribute now to support Open Source Software</h3>
<p>Fundraising initiatives help direct resources to high-impact projects—<strong>accelerating innovation, expanding access, and ensuring that open collaboration remains a driving force for progress</strong>.</p>
<p>Let’s build this resource together — for the benefit of the entire R community and every organization that relies on it to meet regulatory standards. 👉 <a href="https://pharmar.org/repository">https://pharmar.org/repository</a></p>


</section>
</section>

 ]]></description>
  <guid>https://r-consortium.org/posts/community-powered-future-for-regulatory-r-introducing-our-fundraising-campaign/</guid>
  <pubDate>Tue, 10 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/community-powered-future-for-regulatory-r-introducing-our-fundraising-campaign/r-regulatory-repo-main-image.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Brewing Success with R.U.M.: How Inclusivity Fuels Manchester’s Thriving R Community</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/brewing-success-with-rum-how-inclusivity-fuels-manchesters-thriving-r-community/</link>
  <description><![CDATA[ 





<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<tbody>
<tr class="odd">
<td>================== <strong>AnthonyEvans</strong></td>
<td>:=========================: <strong>MartinHerrerias Azcue</strong></td>
<td>:==============: <strong>RowanGreen</strong></td>
<td>:==============: <strong>SianBladon</strong></td>
<td>:=========================: <strong>Stavrina Dimosthenous</strong></td>
</tr>
</tbody>
</table>
<p>The R Consortium recently had the opportunity to interview Anthony Evans, <a href="https://www.linkedin.com/in/martinherrerias/">Martin Herrerias Azcue</a>, <a href="https://www.linkedin.com/in/rowan-green-microbes/?originalSubdomain=uk">Rowan Green</a>, <a href="https://www.linkedin.com/in/sian-bladon-2b324a61/">Sian Bladon</a>, and Stavrina Dimosthenous, organizers of the <a href="https://www.meetup.com/r-users-group-uni-manchester/">R User Group at the University of Manchester (R.U.M.)</a>. These leaders bring together a diverse community of students, researchers, and staff dedicated to advancing their skills in R programming. Their shared goal is to create an inclusive environment for learning and collaboration, which has driven the growth and success of the R.U.M. community.</p>
<section id="related-links" class="level3">
<h3 class="anchored" data-anchor-id="related-links">Related Links</h3>
<ul>
<li><a href="https://rumgroup.github.io/allaboutrum/">RUM website</a></li>
<li><a href="https://research-it.manchester.ac.uk/building-communities/">CaDiR</a></li>
</ul>
</section>
<section id="please-share-about-your-background-and-involvement-with-the-rugs-group." class="level2">
<h2 class="anchored" data-anchor-id="please-share-about-your-background-and-involvement-with-the-rugs-group.">Please share about your background and involvement with the RUGS group.</h2>
<p><strong>Tony:</strong> Yes, we’ve been involved in this group for about two years now. Initially, it was run by someone named Kamilla, who later moved to another university, and her role was taken over by Martin. Martin has been doing an excellent job leading the group, which mainly serves postgraduates, teaching staff, and research staff—really anyone enthusiastic about learning R and improving their skills, including a lot of newcomers.</p>
<p>When I first joined, my main goal was to improve my own R skills. Before that, I had been a helper in some R courses taught by the university, but I felt I could learn more and benefit from being part of a supportive community. The group is full of volunteers who are passionate about R and programming in general. They’re always willing to share their knowledge and help one another, which has been incredibly valuable. This spirit of sharing and collaboration creates a fantastic environment, especially in a university setting where research thrives on collective learning.</p>
<p><strong>Martin:</strong> I joined the group about two years ago. I had only been using R for about six months before that, so I didn’t have much experience with it. Our group had only a handful of people who knew R, and two of them left the University shortly after. Suddenly I found myself needing to support researchers who ran into issues with R, as well as managing projects like our pilot Shiny server. We had to find ways to support these types of projects. The R User Group became a valuable resource for us to stay connected with researchers actively using R and to continue learning the language ourselves.</p>
<p><strong>Rowan:</strong> I am a PhD student in evolution and ecology. When the R.U.M group was restarted, a general email was sent to the university. As someone who enjoys mentoring younger lab group members in R and learning about new R tools, I was interested in helping restart the group.</p>
<p><strong>Stavrina:</strong> As a Data Scientist and Data Visualization enthusiast, I used to run our Data Visualisation Club monthly meetups. I have taken a step back, but I was involved in the group’s initial creation and help a bit with organizing and strategizing now.</p>
</section>
<section id="can-you-share-what-the-local-r-community-is-like" class="level2">
<h2 class="anchored" data-anchor-id="can-you-share-what-the-local-r-community-is-like">Can you share what the local R Community is like?</h2>
<p><strong>Tony:</strong> The university’s local community is mostly composed of postgraduates, along with some researchers who are starting to use R in their work. Everyone in the community is very enthusiastic, eager to learn, and focused on improving their skills. It’s a highly motivated and self-sustaining group. Everyone in the R community is very friendly and welcoming. It’s a great, supportive environment.</p>
<p><strong>Martin:</strong> Most people in our R community come from humanities backgrounds. There’s a group in health economics that uses R extensively, as well as some in psychology and language studies. We also have a large group in genomics. It feels like there’s a wide range of experience—some researchers have been working with R for a long time, while many postgraduates are just starting to learn. As a group, it can be challenging to support both experienced users and beginners, but we do our best to meet everyone’s needs.</p>
<p><strong>Rowan:</strong> The local R community exists at multiple levels. It is often most active at a small scale within research groups, where members share advice. At the university level, R.U.M. brings together people from a broader variety of backgrounds. There is also a city-wide R community in Manchester, where quarterly talks are organized by <a href="https://datacove.co.uk/">Datacove</a>. These events bring together people from industry, public health, academia, and more.</p>
</section>
<section id="you-had-a-meetup-on-r-functions-for-visualization.-can-you-share-more-about-the-topic-covered-why-this-topic" class="level2">
<h2 class="anchored" data-anchor-id="you-had-a-meetup-on-r-functions-for-visualization.-can-you-share-more-about-the-topic-covered-why-this-topic">You had a Meetup on “<a href="https://www.meetup.com/r-users-group-uni-manchester/events/303918144/?eventOrigin=group_upcoming_events">R Functions [for visualization]</a>.” Can you share more about the topic covered? Why this topic?</h2>
<p><strong>Martin:</strong> Our previous event hadn’t gone as well as we hoped. We tried to cover a pretty complex topic—reproducible science using R on a Docker container with renv—but it wasn’t very well attended. So, we decided to shift our focus to beginner users and cover some basics that every R user should know but that we’ve noticed many beginners struggle with. The event covered the basics of function syntax and organizing code with functions. We also had a second talk that was a bit more advanced, focusing on using functions with the <a href="https://purrr.tidyverse.org/reference/map.html">purrr map function</a> to automate plot production. The goal was to attract a broader range of users, as our previous events have mainly catered to advanced users.</p>
<p><strong>Tony:</strong> We’ve noticed that many users haven’t been responding to the more advanced topics. In general, though, making code readable is crucial, especially for researchers who need others to reproduce their work. If the code is hard to understand, it complicates reproducibility, but organizing code with functions makes it much clearer. This is an essential aspect of programming, and it also ties into plotting, which is one of the most requested skills among students. Most students using R for research will need to create plots to convey complex conclusions and ideas. Plots are much more effective than raw data alone, and R produces some of the best visualizations out there. Even organizations like the <a href="https://www.ft.com/">Financial Times</a> use R for their high-quality graphs, so it’s a valuable and widely-used skill.</p>
<p><strong>Stavrina:</strong> A barrier to entry in any programming language or tool is sometimes seeing demonstrable evidence of how it can be useful to an individual, especially at undergraduate and early postgraduate level. Working within a University and Research environment, we all have to make plots and advanced visualizations. Sometimes, though, the extra step is standardizing and making that reproducible for high-throughput plotting. Combining visualizations with functions achieves just that and can serve as a practical and aspirational demonstration for our community.</p>
</section>
<section id="any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future" class="level2">
<h2 class="anchored" data-anchor-id="any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future">Any techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?</h2>
<p><strong>Tony:</strong> One technique we started using since COVID is hybrid teaching. We initially used Zoom, but then switched to Teams. This approach has been very inclusive because it allows people in distant locations, even in other countries, or those with long commutes to participate in our talks. In the past, everyone had to be physically on campus, which excluded those who lived further away. Now, with hybrid teaching, more people can join in, regardless of their location.</p>
<p><strong>Martin:</strong> Yes, we’ve noticed that this might have been part of the issue. Our last talk was advertised as in-person only because it was meant to be hands-on, Carpentry-style training. That may have contributed to the low attendance. It definitely makes a difference—when we make an event hybrid, we tend to get a lot more participation.</p>
<p><strong>Stavrina:</strong> We use conferencing software for all our meetings and make the invitation open to anyone outside the organization, we are lucky that we have access to meeting spaces that have suitable equipment for running hybrid meetings.</p>
</section>
<section id="what-trends-do-you-currently-see-in-r-language-and-your-industry-any-trends-you-see-developing-in-the-near-future" class="level2">
<h2 class="anchored" data-anchor-id="what-trends-do-you-currently-see-in-r-language-and-your-industry-any-trends-you-see-developing-in-the-near-future">What trends do you currently see in R language and your industry? Any trends you see developing in the near future?</h2>
<p><strong>Tony:</strong> Researchers and academic programs are increasingly looking to include R and RStudio in their teaching and research for two main reasons. First, data regulations have become much stricter over the past couple of years, and with R, you have complete control over where your data is stored. You know it’s not in the cloud or being transferred to any external organization, which helps in meeting university data compliance standards.</p>
<p>The second reason for the shift towards R is that it’s free from licensing restrictions. With some other software, licensing can be highly restrictive—you might only be allowed to use it in certain countries, like the UK, or only on campus. R, on the other hand, offers a more inclusive environment for research, allowing access without these geographic or licensing limitations. This flexibility is a big part of why R is becoming so popular within the research community.</p>
<p><strong>Martin:</strong> I completely agree. I couldn’t have put it better myself, but as Tony pointed out, R is becoming more and more popular. It’s gaining broader appeal and is now appreciated as a general scientific programming language rather than just a niche statistical tool. There’s a clear trend, as Tony described, toward open science and open source software, and R is becoming a significant part of that movement.</p>
<p><strong>Rowan:</strong> One big trend is the use of LLMs/AI both for writing code in R, and as a tool executed through R. We were really lucky to have a former R users group member, <a href="https://www.birmingham.ac.uk/research/arc/rsg/staff/kamilla-kopec-harding">Kamilla Kopec-Harding</a>, return to give a talk on both of these perspectives earlier this year.</p>
<p><strong>Sian:</strong> R remains relatively niche and widely recognized in bioinformatics, clinical trials, fintech, and marketing. However, <a href="https://www.linkedin.com/in/hadleywickham/">Hadley Wickham</a> and others’ contributions - through the <a href="https://www.tidyverse.org/">tidyverse</a> and packages like <a href="https://dplyr.tidyverse.org/">dplyr,</a> <a href="https://ggplot2.tidyverse.org/">ggplot2</a>, and <a href="https://roxygen2.r-lib.org/">roxygen2</a> - have significantly broadened R’s appeal and impact in recent years. From an anecdotal perspective, about a decade ago, it was rare to see job postings requiring R skills. Today, although R may not have the same reach as languages like Python, job searches for R roles now yield far more opportunities than before.</p>
</section>
<section id="how-do-i-join" class="level2">
<h2 class="anchored" data-anchor-id="how-do-i-join">How do I Join?</h2>
<p>R Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 75,492 members in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute.</p>
<p><a href="https://r-consortium.org/all-projects/rugsprogram.html" class="uri">https://r-consortium.org/all-projects/rugsprogram.html</a></p>


</section>

 ]]></description>
  <guid>https://r-consortium.org/posts/brewing-success-with-rum-how-inclusivity-fuels-manchesters-thriving-r-community/</guid>
  <pubDate>Mon, 09 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/brewing-success-with-rum-how-inclusivity-fuels-manchesters-thriving-r-community/rum-main-image.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Tidy topological machine learning with TDAvec and tdarec</title>
  <dc:creator>Jason Cory Brunson, Alexsei Luchinsky, Umar Islambekov</dc:creator>
  <link>https://r-consortium.org/posts/tidy-topological-machine-learning-with-tdavec-and-tdarec/</link>
  <description><![CDATA[ 





<section id="the-pitch" class="level2">
<h2 class="anchored" data-anchor-id="the-pitch">The Pitch</h2>
<p>Topological data analysis (TDA) is a pretty mature discipline at this point, but in the last several years its assimilation into machine learning (ML) has really taken off. Based on our experience, the plurality of experimental TDA tools are written in Python, and naturally Python is home to most of these applications.</p>
<p>That’s not to say that there are no R packages for TDA-ML. <a href="https://github.com/kisungyou/TDAkit">{TDAkit}</a>, <a href="https://github.com/shaelebrown/TDApplied">{TDApplied}</a>, and others provide tools for specific self-contained analyses and could be used together in larger projects. As with the broader R ecosystem, though, their integration can require some additional work. The combination of several low-level libraries and compounding package dependencies has also made this toolkit fragile, with several packages temporarily or permanently archived.</p>
<p>Meanwhile, the <a href="https://www.tidymodels.org/">Tidymodels</a> package collection has enabled a new generation of users, myself (JCB) included, to build familiarity and proficiency with conventional ML. By harmonizing syntax and smoothing pipelines, Tidymodels makes it quick and easy to adapt usable code to new data types, pre-processing steps, and model families. By using wrappers and extractors, it also allows seasoned users to extend their work beyond its sphere of convenience.</p>
<p>We therefore think that Tidymodels is an ideal starting point for a more sustained and interoperable collection for TDA-ML in R. Since much of the role of TDA in ML has been to extract and vectorize features from spatial, image, and other high-dimensional data, we present an extension to <a href="https://recipes.tidymodels.org/">{recipes}</a> for just this purpose. Assembling a comprehensive, general-purpose toolkit is a long-term project. Our contribution is meant to spur that project on.</p>
</section>
<section id="the-packages" class="level2">
<h2 class="anchored" data-anchor-id="the-packages">The Packages</h2>
<p>We present two packages: {TDAvec}, an interface to several efficient feature vectorizations, and {tdarec}, a {recipes} + <a href="https://dials.tidymodels.org/">{dials}</a> extension that integrates these vectorizations into Tidymodels. First, though, we need to introduce persistent homology and how it can be computed with R.</p>
<section id="computations-of-persistent-homology" class="level3">
<h3 class="anchored" data-anchor-id="computations-of-persistent-homology">Computations of persistent homology</h3>
<p>In predictive modeling, <a href="https://en.wikipedia.org/wiki/Persistent_homology"><strong>persistent homology</strong></a> (PH) is the workhorse of TDA.<sup>1</sup> In a nutshell, it measures topological patterns in data—most commonly clusters and enclosures—by the range of resolutions through which they persist. Several packages interface to lower-level libraries that compute PH for various data structures—all accept point clouds and distance matrices, but other structures are accepted where noted:</p>
<ul>
<li><a href="https://doi.org/10.48550/arXiv.1411.1830">{TDA}</a> <span class="citation" data-cites="Fasy2022">(Fasy et al. 2022)</span> interfaces to the Dionysus, PHAT, and GUDHI libraries and also accepts functions and rasters;</li>
<li><a href="https://tdaverse.github.io/ripserr/">{ripserr}</a> <span class="citation" data-cites="Wadhwa2025">(Wadhwa et al. 2025)</span>, a spinoff from <a href="https://joss.theoj.org/papers/10.21105/joss.00860">{TDAstats}</a>, interfaces to the Ripser and Cubical Ripser C++ libraries and also accepts rasters;</li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.06321">{TDApplied}</a> <span class="citation" data-cites="Brown2024">(Brown and Farivar 2024)</span> calls {TDA} and {TDAstats} but also interfaces with Python Ripser; and</li>
<li><a href="https://lmjl-alea.github.io/rgudhi/">{rgudhi}</a> <span class="citation" data-cites="Stamm2023">(Stamm 2023)</span> interfaces to Python GUDHI.</li>
</ul>
<p>Here is an example using the most mature package, {TDA}, to compute the PH for an alpha filtration of a sample from a torus:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> TDA<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">torusUnif</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">a =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">c =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-2">pd <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> TDA<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">alphaComplexDiag</span>(x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">maxdimension =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(pd<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>diagram, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">asp =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="https://r-consortium.org/posts/tidy-topological-machine-learning-with-tdavec-and-tdarec/index_files/figure-html/TDA-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>We rely for now on {ripserr} to compute PH, but a near-term upgrade will incorporate {TDA} as well.</p>
</section>
<section id="vectorizations-of-persistent-homology" class="level3">
<h3 class="anchored" data-anchor-id="vectorizations-of-persistent-homology">Vectorizations of persistent homology</h3>
<p>Vectorization is a crucial step to bridge TDA and ML. Numerous methods have been proposed, and research shows that ML performance on a specific task can depend strongly on the chosen method. Therefore, it is highly desirable to compare several approaches to a given problem and select the one found to be best-suited to it.</p>
<p>Although most proposed vectorization methods are available in free software, they are scattered across various R and Python packages. This complicates the comparison process, as researchers must search for available methods and adapt their code to the interface of each specific implementation. The goal of <a href="https://cran.r-project.org/package=TDAvec">{TDAvec}</a> <span class="citation" data-cites="Luchinsky2025">(Luchinsky and Islambekov 2025)</span> is to address this issue.</p>
<p>We (AL and UI) have consolidated all currently available vectorizations (of which we are aware) and implemented them in a single R library. Some of these vectorizations are parameter-free, but others rely on one or several hyperparameters. For ease of comparison, we also use a consistent interface, with a common camelcase naming convention, e.g.&nbsp;<code>computePersistenceLandscape()</code>. Additionally, several new vectorization methods developed by our group are also available within the TDAvec framework.</p>
<p>Here, for example, is how to compute the tropical coordinates proposed by <span class="citation" data-cites="Kalisnik2019">Kališnik (2019)</span> and a coarse vectorization of our own persistence block transformation <span class="citation" data-cites="Chan2022">(Chan et al. 2022)</span> for the degree-1 layer of the persistence diagram above:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(TDAvec)</span>
<span id="cb2-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">computeTropicalCoordinates</span>(pd<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>diagram, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">homDim =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         F1          F2          F3          F4          F5          F6 
  0.8904834   1.7756440   2.2856840   2.7673257  10.1883696   7.0749433 
         F7 
210.0180135 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">xy_seq <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, .<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">computePersistenceBlock</span>(</span>
<span id="cb4-3">  pd<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>diagram, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">homDim =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb4-4">  <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xSeq =</span> xy_seq, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ySeq =</span> xy_seq</span>
<span id="cb4-5">)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.3539504  0.2527690  0.0000000  0.2708638 51.0522531 62.6966904  0.0000000
[8] 66.3569136 84.8988826</code></pre>
</div>
</div>
<p>Notably, all vectorizations are written in C++ and exposed to R using {Rcpp}. We also utilize the Armadillo package for various matrix operations, which makes all computations extremely fast and efficient.</p>
</section>
<section id="tidy-machine-learning-with-persistent-homology" class="level3">
<h3 class="anchored" data-anchor-id="tidy-machine-learning-with-persistent-homology">Tidy machine learning with persistent homology</h3>
<p>{recipes} is the pre-processing arm of Tidymodels; mostly it provides <code>step_*()</code> functions that pipe together as recipe specifications, to later be applied directly to data or built into workflows. {dials} provides tuning functions for these steps as well as for model families provided by {parsnip}.</p>
<p><a href="https://tdaverse.github.io/tdarec/">{tdarec}</a> provides two primary families of steps:</p>
<ol type="1">
<li>Steps to <em>calculate persistent homology from data</em>, which share the naming pattern <code>step_pd_*()</code> for <strong>p</strong>ersistence <strong>d</strong>iagram. These steps rely on the engines above and are scoped according to the underlying mathematical object encoded in the data: Currently the {ripserr} engine handles point clouds (encoded as coordinate matrices or distance matrices) and rasters (encoded as numerical arrays). These steps accept list-columns of data sets and return list-columns of persistence diagrams.</li>
<li>Steps to <em>transform and vectorize persistence diagrams</em>, which share the naming pattern <code>step_vpd_*()</code> for <strong>v</strong>ectorized <strong>p</strong>ersistence <strong>d</strong>iagram. These steps rely on {TDAvec} and are scoped as there by transformation. They accept list-columns of persistence diagrams and return numeric columns (sometimes flattened from matrix output, e.g.&nbsp;multi-level persistence landscapes) that can be used by most predictive model families.</li>
</ol>
<p>Here is how to incorporate PH (using the default Vietoris–Rips filtration) and the persistence block transformation above into a pre-processing recipe:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">suppressMessages</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tdarec))</span>
<span id="cb6-2">dat <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">source =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torus"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sample =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(x))</span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">recipe</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> sample, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> dat) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|&gt;</span> </span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">step_pd_point_cloud</span>(sample, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">max_hom_degree =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|&gt;</span> </span>
<span id="cb6-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">step_pd_degree</span>(sample_pd, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">hom_degrees =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|&gt;</span> </span>
<span id="cb6-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">step_vpd_persistence_block</span>(</span>
<span id="cb6-7">    sample_pd_2,</span>
<span id="cb6-8">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">hom_degree =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">xseq =</span> xy_seq</span>
<span id="cb6-9">  ) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-&gt;</span> rec</span>
<span id="cb6-10">rec <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|&gt;</span> </span>
<span id="cb6-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prep</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">training =</span> dat) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|&gt;</span> </span>
<span id="cb6-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bake</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">new_data =</span> dat)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 299
  sample          sample_pd_2 sample_pd_2_pb_1 sample_pd_2_pb_2 sample_pd_2_pb_3
  &lt;list&gt;          &lt;list&gt;                 &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;
1 &lt;dbl [200 × 3]&gt; &lt;PHom&gt;                     0                0             39.7
# ℹ 294 more variables: sample_pd_2_pb_4 &lt;dbl&gt;, sample_pd_2_pb_5 &lt;dbl&gt;,
#   sample_pd_2_pb_6 &lt;dbl&gt;, sample_pd_2_pb_7 &lt;dbl&gt;, sample_pd_2_pb_8 &lt;dbl&gt;,
#   sample_pd_2_pb_9 &lt;dbl&gt;, sample_pd_2_pb_10 &lt;dbl&gt;, sample_pd_2_pb_11 &lt;dbl&gt;,
#   sample_pd_2_pb_12 &lt;dbl&gt;, sample_pd_2_pb_13 &lt;dbl&gt;, sample_pd_2_pb_14 &lt;dbl&gt;,
#   sample_pd_2_pb_15 &lt;dbl&gt;, sample_pd_2_pb_16 &lt;dbl&gt;, sample_pd_2_pb_17 &lt;dbl&gt;,
#   sample_pd_2_pb_18 &lt;dbl&gt;, sample_pd_2_pb_19 &lt;dbl&gt;, sample_pd_2_pb_20 &lt;dbl&gt;,
#   sample_pd_2_pb_21 &lt;dbl&gt;, sample_pd_2_pb_22 &lt;dbl&gt;, …</code></pre>
</div>
</div>
<p>The code chunk uses the additional step <code>step_pd_degree()</code> to extract degree-specific layers from multi-degree persistence diagrams; in this case, we are interested in vectorizing only 2-dimensional features. Despite this, we must also specify the degree of the features we want in the persistence block step.</p>
</section>
</section>
<section id="the-potential" class="level2">
<h2 class="anchored" data-anchor-id="the-potential">The Potential</h2>
<p>Many methods remain to be built into these tools, which will only reach their full potential through user feedback. Two issues in particular, <a href="https://github.com/uislambekov/TDAvec/issues/3">additional vectorizations</a> for {TDAvec} and <a href="https://github.com/tdaverse/tdarec/issues/2">additional engines</a> for {tdarec}, may remain open—or, ahem, persist—into the foreseeable future. We welcome bug reports, feature requests, and code contributions from the community!</p>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-Brown2024" class="csl-entry">
Brown, Shael, and Reza Farivar. 2024. <span>“<span>TDApplied</span>: <span>Machine Learning</span> and <span>Inference</span> for <span>Topological Data Analysis</span>.”</span> <a href="https://cran.r-project.org/package=TDApplied">https://cran.r-project.org/package=TDApplied</a>.
</div>
<div id="ref-Chan2022" class="csl-entry">
Chan, Kit C., Umar Islambekov, Alexey Luchinsky, and Rebecca Sanders. 2022. <span>“A <span>Computationally Efficient Framework</span> for <span>Vector Representation</span> of <span>Persistence Diagrams</span>.”</span> <em>Journal of Machine Learning Research</em> 23 (268): 1–33. <a href="http://jmlr.org/papers/v23/21-1129.html">http://jmlr.org/papers/v23/21-1129.html</a>.
</div>
<div id="ref-Fasy2022" class="csl-entry">
Fasy, Brittany T., Jisu Kim, Fabrizio Lecci, Clement Maria, David L. Millman, and Vincent Rouvreau. 2022. <span>“<span>TDA</span>: <span>Statistical Tools</span> for <span>Topological Data Analysis</span>.”</span> <a href="https://CRAN.R-project.org/package=TDA">https://CRAN.R-project.org/package=TDA</a>.
</div>
<div id="ref-Kalisnik2019" class="csl-entry">
Kališnik, Sara. 2019. <span>“Tropical <span>Coordinates</span> on the <span>Space</span> of <span>Persistence Barcodes</span>.”</span> <em>Foundations of Computational Mathematics</em> 19 (1): 101–29. <a href="https://doi.org/10.1007/s10208-018-9379-y">https://doi.org/10.1007/s10208-018-9379-y</a>.
</div>
<div id="ref-Luchinsky2025" class="csl-entry">
Luchinsky, Aleksei, and Umar Islambekov. 2025. <span>“<span>TDAvec</span>: <span>Computing Vector Summaries</span> of <span>Persistence Diagrams</span> for <span>Topological Data Analysis</span> in <span>R</span> and <span>Python</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2411.17340">https://doi.org/10.48550/arXiv.2411.17340</a>.
</div>
<div id="ref-Stamm2023" class="csl-entry">
Stamm, Aymeric. 2023. <span>“<span class="nocase">rgudhi</span>: <span>An Interface</span> to the <span>GUDHI Library</span> for <span>Topological Data Analysis</span>.”</span> <a href="https://lmjl-alea.github.io/rgudhi/">https://lmjl-alea.github.io/rgudhi/</a>.
</div>
<div id="ref-Wadhwa2025" class="csl-entry">
Wadhwa, Raoul, Matt Piekenbrock, Jacob Scott, Jason Cory Brunson, Emily Noble, and Xinyi Zhang. 2025. <span>“<span class="nocase">ripserr</span>: <span>Calculate Persistent Homology</span> with <span>Ripser-Based Engines</span>.”</span> <a href="https://cran.r-project.org/package=ripserr">https://cran.r-project.org/package=ripserr</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Exploratory modeling is another story.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://r-consortium.org/posts/tidy-topological-machine-learning-with-tdavec-and-tdarec/</guid>
  <pubDate>Wed, 04 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/tidy-topological-machine-learning-with-tdavec-and-tdarec/front-image.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>R Consortium Awards First Round of 2025 ISC Grants</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/r-consortium-awards-first-round-of-2025-isc-grants/</link>
  <description><![CDATA[ 





<p>The R Consortium’s Infrastructure Steering Committee (ISC) is proud to announce the first round of 2025 grant recipients. These projects represent a dynamic cross-section of innovation in R infrastructure—ranging from economic policy tools and ecological data pipelines to foundational software engineering improvements. Selected from a competitive pool of proposals, the following seven initiatives will receive support to enhance and expand the capabilities of the R ecosystem.</p>
<section id="econdataverse" class="level3">
<h3 class="anchored" data-anchor-id="econdataverse">econdataverse</h3>
<p>Lead: Christoph Scheuch, Christopher C. Smith, and Teal Emery<br>
Grant: $10,000</p>
<p>The econdataverse initiative was conceived as a unified ecosystem of packages for economic data access and analysis from sources like the IMF, World Bank, and OECD. By enforcing consistent function naming, tidy data formats, and cross-source compatibility, the project will work to significantly reduce the time spent on data acquisition and preparation and facilitate the creation of reproducible workflows. This work will support economic policy development through reproducible data workflows.</p>
</section>
<section id="maimer-unifying-camera-trap-data-in-r" class="level3">
<h3 class="anchored" data-anchor-id="maimer-unifying-camera-trap-data-in-r">Maimer – Unifying Camera Trap Data in R</h3>
<p>Leads: Stanislas Mahussi Gandaho, Marcus Rowcliffe, and Damiano Oldoni<br>
Grant: $12,000</p>
<p>An integrated R ecosystem for camera trap data analysis in ecology; the project aims to develop standardized interfaces to connect maimer with key packages (activity, camtrapDensity, camtraptor) and ensure compatibility with common data standards like Camera Trap Metadata Standard (CTMS). The project combines visualization, data transformation, and deep-learning-based animal detection in a tidyverse-friendly package.</p>
</section>
<section id="bridging-worlds-enhancing-r-igraph-with-c-core-innovations" class="level3">
<h3 class="anchored" data-anchor-id="bridging-worlds-enhancing-r-igraph-with-c-core-innovations">Bridging Worlds: Enhancing R igraph with C Core Innovations</h3>
<p>Lead: David Schoch, Kirill Müller, Maëlle Salmon<br>
Grant: $16,000</p>
<p>The ISC has previously granted funds in support of the igraph package. This round will support upgrades to igraph to include improved C core integration and improved documentation. You can contribute to the igraph package which is approaching its 1.0 release.</p>
</section>
<section id="r-package-binaries-for-linux-community-edition" class="level3">
<h3 class="anchored" data-anchor-id="r-package-binaries-for-linux-community-edition">R Package Binaries for Linux – Community Edition</h3>
<p>Lead: Dr.&nbsp;Patrick Schratz<br>
Grant: $10,000</p>
<p>Establish an R-based, open-source build system for R package binaries including the build processes (running in CI) of the publicly running service building CRAN package binaries. The build system is expected to be able to build packages for (common) Linux distributions and multiple architectures (for the start x86 and arm64, riscv64). The goal of the project is to increase installation speed and improve accessibility across Linux environments.</p>
</section>
<section id="fast-linter-for-r" class="level3">
<h3 class="anchored" data-anchor-id="fast-linter-for-r">Fast Linter for R</h3>
<p>Lead: Etienne Bacher<br>
Grant: $4,000</p>
<p>The project proposes to write a new linter for the R language that is fast and can apply automatic fixes. Eventually, this new linter would be integrated in air, a fast formatter for R code written entirely in Rust and created by Posit PBC.</p>
</section>
<section id="reviving-redoc" class="level3">
<h3 class="anchored" data-anchor-id="reviving-redoc">Reviving redoc</h3>
<p>Lead: Noam Ross in partnership with The Tribal Exchange Network Group (TXG)<br>
Grant: $10,000</p>
<p>This project will revive and enhance the R package <strong>redoc</strong>, designed to bridge the critical gap between reproducible R reporting workflows (R Markdown, Quarto) and the collaborative editing environment of Microsoft Word. Currently, generating Word documents from R is largely a one-way process, creating friction when collaborating with colleagues who use Word’s Track Changes features for feedback. <strong>redoc</strong> enables a unique <em>two-way</em> synchronization, allowing R users to incorporate edits made in Word back into their source R Markdown documents.</p>
</section>
<section id="enhancing-webchem" class="level3">
<h3 class="anchored" data-anchor-id="enhancing-webchem">Enhancing webchem</h3>
<p>Lead: Tamás Stirling, Eric Scott (contributor), Eduard Szöcs (original package author)<br>
Grant: $8,500</p>
<p>The project proposes enabling offline access to chemical databases, empowering chemistry professionals with faster, more reliable, and reproducible access to chemical data. They propose to develop functions that provide access to more data to strengthen the core purpose of that package – to provide easy access to chemical data.</p>
</section>
<section id="updates-on-our-top-level-projects" class="level2">
<h2 class="anchored" data-anchor-id="updates-on-our-top-level-projects">Updates on our Top-Level Projects</h2>
<p>Every so often, the ISC awards a project the status of Top-Level Project. This is a 3-year commitment to support the project. We do this when we believe that a project is fundamentally necessary to support the infrastructure of the language – how it is developed or distributed – or the project is fundamentally necessary to support the community – to help it grow and engage new audiences.</p>
<section id="r-ladies" class="level3">
<h3 class="anchored" data-anchor-id="r-ladies">R-Ladies+</h3>
<p>R-Ladies is a global organization that promotes gender diversity in the R programming community. It supports and empowers individuals of underrepresented genders through events, training, mentorship, and community-building initiatives. In 2025, R-Ladies will continue the core mission of supporting and growing a diverse R community while embarking on several exciting new initiatives. We will rebrand as R-Ladies+, updating our logo and visual identity across all platforms. To support this transition, we’ll develop a branding kit for chapters to easily apply the new look locally.</p>
<p>In May 2025 R-Ladies supports 244 chapters in 68 countries with 108,205 members. The organization is run 100% by volunteer effort. <a href="https://rladies.org/">The website</a> will continue featuring R-Ladies, chapters, news and blog posts, and we’ll begin translating key content into Spanish, French, and Portuguese. We’ll <a href="https://guide.rladies.org">keep improving our internal processes</a> by automating routine tasks, freeing up volunteer time for activities that help our members thrive.</p>
<p>The Chapter Mentoring Program and Code of Conduct will be updated and reworked and we will continue running the recently revamped <a href="https://rladies.org/directory/">R-Ladies Directory</a>, <a href="https://rladies.org/news/abstract-review-relaunch-2025/">Abstract Review Program</a> and <a href="https://rladies.org/news/rocur-relaunch-2025/">WeAreRLadies rotating curator</a>.</p>
</section>
<section id="r-universe" class="level3">
<h3 class="anchored" data-anchor-id="r-universe">R-Universe</h3>
<p><a href="https://r-universe.dev/search">The R-universe platform</a> continues to grow at a healthy pace to balance stability, new features, and maintainability of the project. Here are some of the most recent updates:</p>
<ul>
<li>Completed ARM64 support on Linux: R-universe now builds and checks MacOS/Linux binaries for packages with compiled code on both Intel and Arm hardware. Later this year we also plan to start testing with the experimental ARM64 R for Windows.<br>
</li>
<li>The build workflows have been refactored to better decouple the steps of preparing, building and checking a package, and automatically extract warnings and errors as annotations. This makes it easier to see what the problem is when a package fails to build and enables the front-end to deep-link directly to the relevant parts of the build logs on GitHub actions.<br>
</li>
<li>All R-universe infrastructure code under <a href="http://github.com/r-universe-org/">http://github.com/r-universe-org/</a> (workflows, actions, containers, scripts, server code), has been cleaned up, allowing anyone to see how everything works and suggest improvements.</li>
</ul>
</section>
</section>
<section id="supporting-our-community-through-our-core-mission" class="level2">
<h2 class="anchored" data-anchor-id="supporting-our-community-through-our-core-mission">Supporting our community through our core mission</h2>
<p>The R Consortium’s ISC is pleased to support these initiatives, which represent the community’s commitment to robust, open, and accessible tools for science, policy, and technology. We look forward to tracking their progress and welcome community feedback and participation as these projects evolve.</p>
<p>For updates, <a href="https://r-consortium.org/news">follow the R Consortium blog</a> and join our mailing list <a href="https://lists.r-consortium.org/g/Rconsortium-main">https://lists.r-consortium.org/g/Rconsortium-main</a></p>


</section>

 ]]></description>
  <guid>https://r-consortium.org/posts/r-consortium-awards-first-round-of-2025-isc-grants/</guid>
  <pubDate>Thu, 29 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/r-consortium-awards-first-round-of-2025-isc-grants/isc-grantees-2025-1.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Exploring {kuzco}: Making Computer Vision for R Easily Accessible</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/exploring-kuzco-making-computer-vision-for-r-easily-accessible/</link>
  <description><![CDATA[ 





<p><strong>Frank Hull</strong> is a director of data science &amp; analytics, leading a data science team in the energy sector, an open source contributor, and a developer of <a href="https://github.com/frankiethull/kuzco"><code>{kuzco}</code></a>, an R package that reimagines how image classification and computer vision can be approached using large language models (LLMs). With a passion for building tools that make advanced technology accessible to non-specialists, Frank has also contributed to the R ecosystem through multiple projects, and actively maintains his work on <a href="https://github.com/frankiethull">GitHub</a> and his <a href="https://frankiethull.github.io/about.html">personal site</a>.</p>
<p>In this interview, we explore the ideas behind <code>{kuzco}</code>, its use of LLMs, and how it differs from conventional deep learning frameworks like <code>{keras}</code> and <code>{torch}</code> in R. <code>{kuzco}</code> is open source and Frank states in the interview that the project is actively looking for contributions, both technical and non-technical. Feel free to contact him directly (frankiethull@proton.me for open source connections) to ask questions and find out more.</p>
<p><img src="https://r-consortium.org/posts/exploring-kuzco-making-computer-vision-for-r-easily-accessible/frankthull.png" class="img-fluid" style="width:60.0%"></p>
<section id="what-problem-does-kuzco-solve-that-existing-r-tools-like-keras-or-torch-dont" class="level2">
<h2 class="anchored" data-anchor-id="what-problem-does-kuzco-solve-that-existing-r-tools-like-keras-or-torch-dont">1. What problem does {kuzco} solve that existing R tools like {keras} or {torch} don’t?</h2>
<p><code>{keras}</code> and <code>{torch}</code> are fantastic tools, but they’re still rooted in the deep learning mindset. Essentially, they’re designed to make TensorFlow and PyTorch more accessible—but they still expect you to think like a machine learning engineer.</p>
<p>When you’re doing computer vision with these frameworks, you’re either building a model from scratch or adapting a pre-trained model by converting your image to a tensor and fitting it into that mold.</p>
<p>With <code>{kuzco}</code>, I wanted to break out of that paradigm entirely. This isn’t about training models or tuning hyperparameters. <code>{kuzco}</code> is for people—technical or not—who want to <em>understand</em> an image, not build a deep learning pipeline. Maybe your boss wants to drop in an image and ask a question about the image without writing code. That’s the power of combining LLMs with a simple interface.</p>
<p>The goal is to <strong>citizenize</strong> computer vision—turn it into something that’s driven by prompts and natural language instead of tensors and training loops.</p>
</section>
<section id="how-does-kuzco-leverage-large-language-models-llms-differently-from-traditional-image-classification-methods" class="level2">
<h2 class="anchored" data-anchor-id="how-does-kuzco-leverage-large-language-models-llms-differently-from-traditional-image-classification-methods">2. How does {kuzco} leverage large language models (LLMs) differently from traditional image classification methods?</h2>
<p>LLMs <em>are</em> neural networks, just like <code>{keras}</code> or <code>{torch}</code> models—but they’re trained on vastly more data and built to understand context and nuance in language and vision.</p>
<p>Instead of building a model from the ground up, <code>{kuzco}</code> lets you treat the LLM as an overtrained expert. You provide an image and a system prompt that tells the model to behave like a vision assistant. It doesn’t need re-training or manual feature engineering—you just ask it what you want to know.</p>
<p>That completely flips the usual process. You’re not staging images, defining tensors, or writing your own classifiers. You’re just describing your intent and letting the LLM take care of the rest.</p>
</section>
<section id="what-are-some-example-use-cases-where-kuzco-shinesespecially-in-areas-like-sentiment-or-text-extraction" class="level2">
<h2 class="anchored" data-anchor-id="what-are-some-example-use-cases-where-kuzco-shinesespecially-in-areas-like-sentiment-or-text-extraction">3. What are some example use cases where {kuzco} shines—especially in areas like sentiment or text extraction?</h2>
<p>A friend once asked me how to tell whether a tow truck driving past a traffic camera had a car on its bed—and if so, what kind of car. That’s incredibly hard to do with traditional computer vision. You’d need a specialized model, tons of labeled images, and lots of training.</p>
<p>With <code>{kuzco}</code> and an LLM, you can just hand over the image and ask, “Is there a car on this truck? What kind is it?” The model can return nuanced answers: “It looks like a silver Toyota Camry.”</p>
<p>And you can go even further—ask how many eyes are in the image, or where the eyes are located. You get image classification, object recognition, sentiment, and even spatial reasoning—all without traditional ML pipelines.</p>
</section>
<section id="how-easy-is-it-to-get-started-with-kuzco-if-i-already-have-ollama-and-an-r-environment-set-up" class="level2">
<h2 class="anchored" data-anchor-id="how-easy-is-it-to-get-started-with-kuzco-if-i-already-have-ollama-and-an-r-environment-set-up">4. How easy is it to get started with {kuzco} if I already have Ollama and an R environment set up?</h2>
<p>Pretty easy. If you have Ollama and R installed, you can use either <code>{pak}</code> or <code>{devtools}</code> to install <code>{kuzco}</code> from GitHub or R-universe. It’s not on CRAN yet, but everything else you need is in the README.</p>
</section>
<section id="can-kuzco-be-used-in-production-or-is-it-mainly-a-prototyping-and-exploration-tool" class="level2">
<h2 class="anchored" data-anchor-id="can-kuzco-be-used-in-production-or-is-it-mainly-a-prototyping-and-exploration-tool">5. Can {kuzco} be used in production or is it mainly a prototyping and exploration tool?</h2>
<p>Right now, I’d say it’s experimental—but promising. I built it as an open-source side project over the holidays, and it unexpectedly caught a lot of attention.</p>
<p>I’d love to see others contribute. There’s definitely room to grow: better error handling, output validation, more robust documentation. I’ve only focused on local LLMs through <code>{ellmer}</code> and <code>{ollamar}</code>, but it’d be pretty simple to add support for OpenAI, Claude, Perplexity, or other hosted LLMs.</p>
<p>If someone wants to help build out those back ends, or even help write better docs, I’d be thrilled to collaborate. That’s why I open-sourced it in the first place—to make something useful and invite others in.</p>


</section>

 ]]></description>
  <guid>https://r-consortium.org/posts/exploring-kuzco-making-computer-vision-for-r-easily-accessible/</guid>
  <pubDate>Thu, 22 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/exploring-kuzco-making-computer-vision-for-r-easily-accessible/frankthull.png" medium="image" type="image/png" height="152" width="144"/>
</item>
<item>
  <title>Quantifying Participation Risk with R and R Shiny: A New Frontier in Financial Risk Modeling</title>
  <dc:creator>R Consortium Community Assistant, Caitlyn Oda</dc:creator>
  <link>https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/</link>
  <description><![CDATA[ 





<p>Financial institutions are increasingly looking beyond traditional market risk to quantify and manage more complex forms of risk. <a href="https://r-consortium.org/webinars/quantification-of-participation-risk-using-r-and-rshiny.html">In a recent R Consortium webinar</a>, Goran Lovric, LL.M., and Simon Aigner, MSc, from Raiffeisenlandesbank Oberösterreich (RLB OÖ) unveiled a novel approach to modeling <em>participation risk</em> using R and R Shiny, empowering banks to analyze value fluctuations in corporate holdings with a reproducible, open-source solution.</p>
<p><img src="https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/goran.jpeg" class="img-fluid" style="width:40.0%"><img src="https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/simon.jpeg" class="img-fluid" style="width:40.0%"></p>
<section id="from-market-price-to-participation-value" class="level2">
<h2 class="anchored" data-anchor-id="from-market-price-to-participation-value">From Market Price to Participation Value</h2>
<p>“Participation risk,” explained Lovric, a seasoned expert with over 18 years in international financial risk management, “is the risk of changes in <em>value</em>, not price. That’s the key difference between market risk and participation risk.”</p>
<p>While traditional market risk models focus on short-term price movements of listed assets, participation risk pertains to long-term value changes in equity participations—often in non-listed or strategic holdings.</p>
<p><strong>An End-to-End Framework Using R</strong></p>
<p>The webinar provided an in-depth look at a full-stack modeling approach—from data sourcing to Shiny dashboard deployment. Aigner, an economic and business analytics professional at RLB OÖ, walked attendees through the process of acquiring live financial data using R packages and web scraping techniques.</p>
<p>Using the <code>ecb</code> R package, participants saw how to fetch interest rate curves directly from the European Central Bank. Then, leveraging web scraping with packages like <code>rvest</code>, <code>stringr</code>, and <code>xml2</code>, Aigner demonstrated how to extract key financial statements—such as cash flow data—from sources like Google Finance and Yahoo Finance.</p>
<p>These datasets form the foundation for estimating future cash flows and cost of equity, key components in the discounted cash flow model used to simulate value at risk (VaR) for participations.</p>
<p><img src="https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/data.png" class="img-fluid"></p>
</section>
<section id="the-r-and-shiny-app-simulation-reporting-and-deployment" class="level2">
<h2 class="anchored" data-anchor-id="the-r-and-shiny-app-simulation-reporting-and-deployment">The R and Shiny App: Simulation, Reporting, and Deployment</h2>
<p>Lovric emphasized the importance of simulating volatilities and correlations across sectors using peer data. “Once you have the right inputs—cash flow volatility, cost of capital, sector correlations—you can generate both diversified and non-diversified risk measures,” he said.</p>
<p>All of these capabilities are built into a custom R Shiny app that the speakers have generously made available under an MIT open license. Users can upload structured input files containing valuations, cash flow data, and cost of equity estimates, and the app runs Monte Carlo simulations to quantify value at risk (VaR) under different correlation scenarios.</p>
<p>One striking example from the presentation illustrated the power of diversification. “Let’s say a portfolio is worth €1.7 billion. If you ignore sector correlations, you’d get a risk of €9.9 billion—58%,” Lovric explained. “But if you incorporate actual correlations across different sectors, that drops to about €750 million, or 44.5%, over a one-year, 99.9% confidence interval.”</p>
<p>The tool includes a database-backed architecture for scalability, and Lovric detailed how it can be deployed on an internal server with a few additional scripts. This ensures compliance with banking regulations while preserving accessibility for teams across departments.<img src="https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/demo.png" class="img-fluid"></p>
</section>
<section id="a-launchpad-for-future-collaboration" class="level2">
<h2 class="anchored" data-anchor-id="a-launchpad-for-future-collaboration">A Launchpad for Future Collaboration</h2>
<p>By combining reproducibility, open data, and advanced modeling, the work of Lovric and Aigner illustrates the transformative potential of R in the finance sector. As Lovric noted, “This is not a black-box model. Everything—from the scraping scripts to the simulation logic—is transparent and modifiable.”</p>
<p>The full source code and Shiny app are available via Goran’s webinar repository (linked below). From finance to development, the Quantification of Participation Risk project offers a compelling blueprint for modern risk infrastructure.</p>
<section id="resources" class="level3">
<h3 class="anchored" data-anchor-id="resources">Resources</h3>
<ul>
<li><strong>Webinar Replay</strong>: <a href="https://www.youtube.com/watch?v=fb5x_6mVME4&amp;t=2s">https://www.youtube.com/watch?v=fb5x_6mVME4&amp;t=2s</a><br>
</li>
<li><strong>GitHub Repository</strong>: <a href="https://github.com/GoranLovric/RiskWebinar2024">https://github.com/GoranLovric/RiskWebinar2024</a></li>
<li><strong>Link To Slides</strong>: <a href="https://r-consortium.org/webinars/Quantification-of-Participation-Risk-Dec2024.pdf">https://r-consortium.org/webinars/Quantification-of-Participation-Risk-Dec2024.pdf</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/</guid>
  <pubDate>Wed, 21 May 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/quantifying-participation-risk-with-r-and-r-shiny-a-new-frontier-in-financial-risk-modeling/demo.png" medium="image" type="image/png" height="74" width="144"/>
</item>
</channel>
</rss>
