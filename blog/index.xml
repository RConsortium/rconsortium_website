<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>R Consortium</title>
<link>https://r-consortium.org/blog/</link>
<atom:link href="https://r-consortium.org/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Sun, 22 Jun 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Advanced Distance Metrics for High-Dimensional Clustering: introducing ‘distanceHD’ R-package</title>
  <dc:creator>R Consortium, Software Development</dc:creator>
  <link>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EC_vTG-_XCQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="distancehd-a-new-frontier-in-high-dimensional-clustering" class="level1">
<h1>DistanceHD: A New Frontier in High-Dimensional Clustering</h1>
<p>Greetings, data enthusiasts and R aficionados! Today, we delve into development in the realm of high-dimensional clustering with the introduction of the <code>distanceHD</code> package. This tool, crafted by Jung Ae Lee, Assistant Professor of Biostatistics at the University of Massachusetts Chan Medical School, addresses the need for robust, scalable, and statistically sound distance measures tailored specifically for high-dimensional settings.</p>
<section id="why-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="why-distancehd">Why <code>distanceHD</code>?</h2>
<p>Traditional distance metrics such as Euclidean or Mahalanobis distances often falter in high-dimensional spaces. These conventional methods, while effective in lower dimensions, struggle to detect meaningful clusters or outliers when faced with the complexity of high-dimensional data. This gap is particularly evident in fields like genomics, where the number of features (variables) often exceeds the number of samples.</p>
<p>The <code>distanceHD</code> package introduces three innovative distance metrics designed for high-dimensional clustering and outlier detection: the centroid distance, ridge Mahalanobis distance, and maximal data piling (MDP) distance. Each of these metrics offers unique benefits, making them invaluable tools in the data scientist’s arsenal.</p>
</section>
<section id="the-three-pillars-of-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="the-three-pillars-of-distancehd">The Three Pillars of <code>distanceHD</code></h2>
<section id="centroid-distance" class="level3">
<h3 class="anchored" data-anchor-id="centroid-distance">1. Centroid Distance</h3>
<p>Centroid distance, also known as Euclidean distance, calculates the distance between the centers of two groups. It is a straightforward metric but can be limited in high-dimensional spaces with correlated variables. However, it remains effective when variables are uncorrelated.</p>
</section>
<section id="ridge-mahalanobis-distance" class="level3">
<h3 class="anchored" data-anchor-id="ridge-mahalanobis-distance">2. Ridge Mahalanobis Distance</h3>
<p>The ridge Mahalanobis distance introduces a ridge correction constant, alpha, to ensure the covariance matrix is invertible — a common issue in high-dimensional analysis due to singularity problems. This adjustment allows for a more stable calculation of distances, bridging the gap between the centroid and MDP distances. When alpha is large, the ridge Mahalanobis distance approximates the centroid distance, while a smaller alpha brings it closer to the MDP distance.</p>
</section>
<section id="maximal-data-piling-mdp-distance" class="level3">
<h3 class="anchored" data-anchor-id="maximal-data-piling-mdp-distance">3. Maximal Data Piling (MDP) Distance</h3>
<p>The MDP distance is perhaps the most novel of the three metrics. It computes the orthogonal distance between the affine spaces spanned by each class, offering a unique direction vector that maximizes the distance between class projections. This metric shines in situations with highly correlated variables, such as gene expression data, and is particularly effective for classification problems.</p>
</section>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<p>The <code>distanceHD</code> package is not just a theoretical construct; it has real-world applications in clustering, classification, and outlier detection. For instance, in the context of outlier identification, the MDP distance can effectively discern outliers by maximizing the projection distance in a unique direction. This capability is demonstrated through sequential simulations, such as gene expression data with multiple features and patients, where traditional metrics may fall short.</p>
<p>In classification tasks, the MDP distance provides a high-dimensional, low-sample-size version of Fisher’s discriminant analysis, offering a powerful tool for binary predictions, such as disease status classification.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>While the <code>distanceHD</code> package is a significant leap forward, Jung Ae Lee plans to expand its functionalities further. Upcoming updates will focus on improving outlier detection processes and incorporating additional distance metrics to enhance the package’s versatility and applicability in various high-dimensional contexts.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The <code>distanceHD</code> package represents a significant advancement in the field of high-dimensional data analysis, offering robust tools for clustering, classification, and outlier detection. With its innovative metrics and practical applications, it is poised to become an essential resource for researchers and practitioners working with complex, high-dimensional datasets.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/thumbnail-advanced-distance-metrics-lee.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>An Accelerometry Biomarker Framework with Application in Vigilance in UK Biobank Data</title>
  <dc:creator>R Consortium, Healthcare</dc:creator>
  <link>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KiQAySB2rF4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="exploring-vigilance-with-accelerometry-insights-from-the-uk-biobank" class="level1">
<h1>Exploring Vigilance with Accelerometry: Insights from the UK Biobank</h1>
<p>Accelerometry data from wearable devices have opened new horizons in non-invasive health monitoring, providing a continuous and objective measure of physical activity. Michael Kane, MD Anderson Cancer Center, alongside Dmitri Wolson and Francesco Onarati at Takeda Pharmaceuticals, delves into using accelerometry as a biomarker for assessing vigilance, focusing on the potential to identify non-vigilant states such as excessive daytime sleepiness or narcolepsy-like symptoms. This analysis is rooted in data from the UK Biobank, a rich resource encompassing accelerometry, demographic, and lifestyle data of approximately 78,500 participants.</p>
<section id="understanding-the-data-and-its-challenges" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-data-and-its-challenges">Understanding the Data and Its Challenges</h2>
<p>The UK Biobank’s accelerometry data provides a wealth of information, with measurements taken at 100 Hz over a week for each participant. These data offer a high-resolution view of daily activity patterns, recorded across three axes (X, Y, Z) in milligravities. However, this study’s foundational challenge lies in its observational nature and reliance on self-reported outcomes to define vigilance states.</p>
<p>Vigilance and non-vigilance were distinguished using self-reported symptoms of narcolepsy and frequency of daytime naps. Non-vigilant participants reported narcolepsy symptoms often or always and took frequent naps, while vigilant participants did not report these symptoms or behaviors. Despite a robust overall dataset, the non-vigilant group comprised only 679 individuals, necessitating a careful matching process to ensure comparable analysis groups.</p>
</section>
<section id="propensity-score-matching-for-balanced-analysis" class="level2">
<h2 class="anchored" data-anchor-id="propensity-score-matching-for-balanced-analysis">Propensity Score Matching for Balanced Analysis</h2>
<p>To address imbalances and potential confounders in the observational data, propensity score matching was employed. This method allowed for the creation of matched pairs of vigilant and non-vigilant participants based on physical and lifestyle characteristics, including age, sex, ethnicity, BMI, smoking habits, alcohol use, and more. This rigorous matching resulted in 95 well-matched pairs, setting the stage for a focused exploration of accelerometry’s potential in assessing vigilance.</p>
</section>
<section id="transforming-accelerometry-data-into-spectral-images" class="level2">
<h2 class="anchored" data-anchor-id="transforming-accelerometry-data-into-spectral-images">Transforming Accelerometry Data into Spectral Images</h2>
<p>A critical step in the analysis involved transforming raw accelerometry data into a structured format conducive to machine learning. The data were downsampled to 33 Hz to focus on relevant daily movement frequencies. Subsequently, the data were segmented into five-minute blocks, and a Discrete Fourier Transform was applied to each block. This transformation yielded sorted spectral images, representing the energy expended at different frequencies without capturing the precise timing of activities within a day.</p>
</section>
<section id="convolutional-neural-network-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network-for-classification">Convolutional Neural Network for Classification</h2>
<p>Inspired by the architecture of AlexNet, a simplified convolutional neural network (CNN) was developed to classify participants as vigilant or non-vigilant based on the spectral images. The CNN architecture included convolutional layers, max pooling, and dense layers with dropout to prevent overfitting. Training involved 20-fold cross-validation at the subject level, ensuring that predictions were genuinely out-of-sample.</p>
<p>The CNN yielded an out-of-sample F1 score of 0.576 and an AUC of 0.539 at the sample level for participants aged 65 or younger. At the subject level, the F1 score was 0.539, and the AUC was 0.564. While these results indicate a weak association between accelerometry-derived biomarkers and vigilance states, they underscore the potential for further refinement and application in broader contexts.</p>
</section>
<section id="potential-applications-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="potential-applications-and-future-directions">Potential Applications and Future Directions</h2>
<p>The study highlights accelerometry’s promise as a non-invasive tool for assessing cognitive states and movement-related disorders. The association between accelerometry and vigilance, albeit modest, opens avenues for monitoring conditions where non-vigilance is a co-morbidity, such as sleep disorders, neurological conditions, and psychiatric disorders.</p>
<p>The findings also suggest potential applications in monitoring the effectiveness of treatments for conditions like narcolepsy, where stimulant medications may influence accelerometry patterns. Furthermore, the study indicates that stratifying by age could enhance the model’s predictive accuracy, given that younger participants tend to exhibit more movement.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Kane’s exploration into accelerometry as a biomarker for vigilance represents an exciting step forward in leveraging wearable technology for health monitoring. While the association between accelerometry and vigilance is currently weak, the study underscores the potential for accelerometry-derived insights to inform interventions across a range of conditions. The use of R for analysis and presentation further demonstrates the language’s versatility in handling complex datasets and machine learning models.</p>
<p>As the R community continues to evolve and embrace cutting-edge methodologies, studies like this exemplify the innovative applications of R in advancing healthcare research. The integration of accelerometry data into clinical and research settings promises to enhance our understanding of human physiology and behavior, paving the way for more personalized and effective health interventions.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/thumbnail-kane-accelerometry.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Bootstrap inference made easy: p-values and confidence intervals in one line of code</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EeAtvWF3twA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package" class="level3">
<h3 class="anchored" data-anchor-id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package">Simplifying Bootstrap Inference in R with the boot.pval Package</h3>
<p>In the realm of statistical analysis, ensuring the reliability of p-values and confidence intervals is paramount, especially when classical assumptions about data distribution do not hold. This is where bootstrap methods come into play, offering a robust alternative by relying on data-driven, empirical distributions rather than theoretical assumptions. Despite their utility, bootstrap methods are often underutilized due to perceived complexities in implementation. However, with advancements in R packages like <code>boot.pval</code>, bootstrap inference has become more accessible than ever.</p>
<section id="the-bootstrap-approach" class="level4">
<h4 class="anchored" data-anchor-id="the-bootstrap-approach">The Bootstrap Approach</h4>
<p>Introduced by Bradley Efron in 1979, the bootstrap method revolutionizes statistical inference by focusing on the empirical distribution of the data itself. Unlike traditional methods that start with a distributional assumption (e.g., normality), bootstrap methods begin with the actual data distribution. By resampling from this empirical distribution and calculating the test statistic repeatedly, we obtain an accurate approximation of its distribution. This allows for the computation of p-values and confidence intervals without reliance on stringent assumptions about data normality.</p>
</section>
<section id="the-role-of-boot.pval" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-boot.pval">The Role of boot.pval</h4>
<p>The <code>boot.pval</code> package in R, developed by Måns Thulin from Thulin Consulting AB, simplifies the process of applying bootstrap methods to a variety of statistical tests and models. From t-tests to regression coefficients in linear models, GLMs, survival models, and mixed models, <code>boot.pval</code> enables users to compute bootstrap p-values and confidence intervals efficiently—often with just a single line of code.</p>
</section>
<section id="key-features-and-benefits" class="level4">
<h4 class="anchored" data-anchor-id="key-features-and-benefits">Key Features and Benefits</h4>
<ul>
<li><strong>Ease of Use</strong>: The package allows for straightforward computation of bootstrap p-values and confidence intervals without needing to write complex custom functions.</li>
<li><strong>Integration</strong>: Built on top of established R packages like <code>boot</code>, <code>car</code>, <code>lme4</code>, and <code>survival</code>, it ensures compatibility and extends functionality.</li>
<li><strong>Customizability</strong>: Users can create custom bootstrap tests for unique statistical measures.</li>
<li><strong>Consistency</strong>: It ensures that the derived p-values and confidence intervals are consistent, addressing discrepancies often found in other implementations.</li>
</ul>
</section>
<section id="practical-application-a-case-study" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-a-case-study">Practical Application: A Case Study</h4>
<p>Using the sleep dataset in R, Thulin demonstrates how to replace a classic t-test with a bootstrap t-test using <code>boot.pval</code>. This approach not only simplifies the code but also enhances the robustness of the test against non-normal data distributions. The output from <code>boot.pval</code> mirrors that from traditional tests but is derived from a more reliable, data-centric approach.</p>
</section>
<section id="extending-beyond-simple-tests" class="level4">
<h4 class="anchored" data-anchor-id="extending-beyond-simple-tests">Extending Beyond Simple Tests</h4>
<p>The <code>boot.pval</code> package is not limited to simple t-tests; it supports complex models including linear regressions and survival models. By fitting a model using standard R functions like <code>lm()</code> or <code>glm()</code>, users can then apply <code>boot.summary()</code> from <code>boot.pval</code> to obtain detailed summaries including estimates, confidence intervals, and p-values—all bootstrapped for enhanced reliability.</p>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>Bootstrap methods provide a powerful tool for statistical inference when traditional assumptions do not hold. With packages like <code>boot.pval</code>, R users can integrate robust bootstrap techniques into their daily analysis workflows effortlessly. Whether dealing with straightforward comparisons or complex multivariable models, <code>boot.pval</code> offers a user-friendly yet powerful solution for making informed statistical decisions based on solid empirical evidence.</p>
<p>For those interested in delving deeper into bootstrap methods or seeking practical applications within R, exploring further resources such as <a href="https://www.modernstatisticswithr.com/">Thulin’s book “Modern Statistics with R”</a> or foundational texts on bootstrap methodology can be incredibly beneficial.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/thumbnail-bootstrap-inference-thulin.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Dengue Forecasting Addressing the Interrupted Effect from COVID-19 Cases</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/TNRH2WxA3J0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><em>Note: This project is <a href="http://localhost:4215/posts/empowering-dengue-research-through-the-dengue-data-hub/index.html">funded by the R Consortium</a></em></p>
<section id="navigating-interruption-forecasting-dengue-cases-amidst-covid-19" class="level1">
<h1>Navigating Interruption: Forecasting Dengue Cases Amidst COVID-19</h1>
<p>Dengue fever, a mosquito-borne disease, remains a significant health concern in tropical regions, particularly in countries near the equator. The dengue virus, primarily transmitted by Aedes mosquitoes, thrives in warm, humid conditions with regular rainfall—conditions that are prevalent in these regions. However, the onset of the COVID-19 pandemic introduced an unprecedented interruption in the usual dengue case patterns. This blog post delves into a study that explores how to accurately forecast dengue cases amidst the interruptions caused by the COVID-19 pandemic, using Sri Lanka as a case study.</p>
<p><strong>Understanding the Interruption</strong></p>
<p>During the COVID-19 pandemic, several factors contributed to an unusual pattern in dengue case reporting. These include:</p>
<ul>
<li>Misclassification of dengue as COVID-19 due to overlapping symptoms such as fever, headache, and fatigue.</li>
<li>Underreporting or delayed reporting due to lockdowns and mobility restrictions.</li>
<li>Reduced human-mosquito contact due to people spending more time indoors.</li>
<li>School and workplace closures, which are common sites for dengue transmission.</li>
<li>Travel restrictions, which reduced the spread of dengue to new areas.</li>
</ul>
<p>This period, referred to as the “interrupted period,” significantly affected the usual seasonal and annual patterns of dengue cases.</p>
<p><strong>Forecasting Strategies</strong></p>
<p>The study, presented by Thiyanga S. Talagala from the Department of Statistics at the University of Sri Jayewardenepura, Sri Lanka, investigates three modeling strategies to address this interruption in dengue case forecasting:</p>
<ol type="1">
<li><p><strong>Excluding the Interrupted Period</strong>: This approach involves using only post-COVID-19 data for model training, effectively ignoring the data from the interrupted period.</p></li>
<li><p><strong>Forecasting the Interrupted Period First</strong>: This method involves forecasting the interrupted period based on data up to 2019, then using the updated time series for model training.</p></li>
<li><p><strong>Down-Weighting the Interrupted Period</strong>: This strategy assigns lower weights to data points in the interrupted period, giving higher weights to uninterrupted periods.</p></li>
</ol>
<p>Data from 2007 to 2024 were used for model fitting, and data for 2025 served as the test set to evaluate the performance of these methods across 25 districts in Sri Lanka.</p>
<p><strong>Evaluating the Methods</strong></p>
<p>The study employed various accuracy measures, including Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), to compare the forecasting performance of each approach. The findings revealed that no single method outperformed across all districts. Instead, the effectiveness of each approach depended on the specific characteristics and historical patterns of each district.</p>
<p><strong>Insights and Implications</strong></p>
<p>The study’s insights underscore the importance of tailoring forecasting methods to the unique characteristics of each region. For instance, the down-weighting approach proved effective in areas where the usual dengue patterns persisted despite the interruption. In contrast, excluding the interrupted period worked best in districts that had shifted to a new normal post-COVID-19.</p>
<p>Furthermore, the study highlighted the influence of weather patterns on dengue transmission. Districts affected by specific monsoon periods or characterized by unique weather conditions showed distinct forecasting patterns.</p>
<p><strong>Conclusion</strong></p>
<p>Forecasting dengue cases amidst interruptions like COVID-19 is a complex task that requires adaptive approaches. The study by Talagala emphasizes that understanding the local context, including weather patterns and historical data, is crucial for accurate forecasting. This research not only contributes to improving dengue preparedness but also offers valuable insights for handling future public health interruptions.</p>
<p>For more detailed insights and to explore the methodologies used, you can access <a href="https://github.com/thiyangt/denguedatahub">the project on GitHub</a> and <a href="https://denguedatahub.netlify.app/">the main Dengue Data Hub site</a>.</p>


</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Epidemiology</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/dengue-forecasting-addressing-the-interrupted-effect-from-covid-19-cases/thumbnail-dengue.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Ethical Considerations of Contrasts in Statistical Modeling of Medical Equity</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pAx92roI3VE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="ethical-choices-in-regression-analysis-a-case-study-from-seattle-childrens-hospital" class="level2">
<h2 class="anchored" data-anchor-id="ethical-choices-in-regression-analysis-a-case-study-from-seattle-childrens-hospital">Ethical Choices in Regression Analysis: A Case Study from Seattle Children’s Hospital</h2>
<p>In the world of statistical modeling, the choice of coding schemes for categorical variables is not merely a technical consideration but a decision laden with ethical implications. This was the focus of a recent presentation during the R/Medicine 2025 conference by Dwight Barry, Principal Data Scientist at Seattle Children’s Hospital, and Nicole Chicoine, DO, MPH, also at Seattle Children’s Hospital. The talk revolved around how these choices can influence the inferences drawn from regression analyses and ultimately impact healthcare delivery and research.</p>
<section id="the-hospitals-language-diversity" class="level3">
<h3 class="anchored" data-anchor-id="the-hospitals-language-diversity">The Hospital’s Language Diversity</h3>
<p>Seattle Children’s Hospital is a bustling 400-bed facility that handles over half a million patient visits annually. With such a diverse patient base, the hospital encounters more than 130 languages, with Spanish being the most common after English. To accommodate this linguistic diversity, the hospital has initiated its first all-Spanish speaking operating room, ensuring equitable care for non-English speaking patients. This commitment to inclusivity is mirrored in their research methodologies, where the focus is on equitable outcomes across different patient groups.</p>
</section>
<section id="understanding-coding-schemes" class="level3">
<h3 class="anchored" data-anchor-id="understanding-coding-schemes">Understanding Coding Schemes</h3>
<p>The choice of coding schemes in regression models is crucial as it can shape the conclusions drawn from the data. Barry highlighted three coding schemes used in R: treatment contrast, sum contrast, and weighted effect coding. Each scheme presents categorical variables in different ways, affecting the interpretation of the data.</p>
<ol type="1">
<li><p><strong>Treatment Contrast</strong>: This is the default coding in R, where one category is used as a reference against which others are compared. In a clinical setting, this could inadvertently privilege a particular group, often aligning with the English-speaking, white demographic, which can skew the narrative towards existing inequities.</p></li>
<li><p><strong>Sum Contrast</strong>: Here, the grand mean of all categories is used as the reference point. This approach decouples any single category from being the norm, promoting a more balanced view. In the context of healthcare, it shifts the focus from a single dominant group to an aggregate understanding, which can be crucial in addressing biases.</p></li>
<li><p><strong>Weighted Effect Coding</strong>: This method is a variant of the sum contrast, where each category level is weighted by its sample size. Although not a built-in feature in base R, the <code>wec</code> package facilitates its implementation. This approach provides a nuanced view by factoring in the prevalence of each category, which can be especially useful in diverse patient populations.</p></li>
</ol>
</section>
<section id="implications-for-healthcare-research" class="level3">
<h3 class="anchored" data-anchor-id="implications-for-healthcare-research">Implications for Healthcare Research</h3>
<p>The choice of coding scheme is not just a statistical decision but an ethical one, as it affects how healthcare equity is perceived and addressed. Barry’s presentation underscored that while odds ratios may differ across coding schemes, the marginal effects remain consistent, suggesting that predictions are unaffected by these choices. However, the ethical ramifications are significant, as they influence which group is centered in the analysis.</p>
<p>In healthcare research, where categorical exposures like language group, race, or ethnicity lack a natural order, choosing the right coding scheme is vital. Sum contrasts, for instance, provide a means to avoid privileging any group, thereby promoting equity.</p>
</section>
<section id="broader-implications-and-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="broader-implications-and-recommendations">Broader Implications and Recommendations</h3>
<p>Barry’s insights extend beyond surgery to any healthcare condition where equity is a concern. The presentation emphasized the importance of presenting marginal effects alongside regression coefficients or odds ratios to provide a comprehensive view of the data. By decentering from a single reference point, researchers can challenge the dominant social narratives and highlight systemic inequities, paving the way for more inclusive and equitable healthcare practices.</p>
<p>In conclusion, the ethical dimensions of statistical modeling are as crucial as the statistical ones. As healthcare becomes increasingly data-driven, recognizing and addressing these ethical considerations is essential. By adopting coding schemes that promote equity, researchers and healthcare providers can ensure that their work contributes to a more just and equitable healthcare system.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/ethical-considerations-of-contrasts-in-statistical-modeling-of-medical-equity/thumbnail-ethical-considerations.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Model Evaluation: From Machine Learning to Generative AI</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Lq568n0pClc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="exploring-the-future-of-ai-evaluation-with-dr.-erin-ledell-at-rmedicine-2025" class="level1">
<h1>Exploring the Future of AI Evaluation with Dr.&nbsp;Erin LeDell at R/Medicine 2025</h1>
<p>As artificial intelligence evolves, so must the methodologies used to evaluate these systems. Dr.&nbsp;Erin LeDell, a prominent figure in the AI and R communities, addressed this critical transition in her keynote at R/Medicine 2025. Dr.&nbsp;LeDell, the Chief Scientist at Distributional, Inc.&nbsp;and founder of DataScientific, Inc., brings her extensive expertise to the forefront as she guides us through the intricate world of AI evaluation, moving from deterministic machine learning models to the more complex generative AI systems.</p>
<section id="from-deterministic-to-generative-a-paradigm-shift" class="level2">
<h2 class="anchored" data-anchor-id="from-deterministic-to-generative-a-paradigm-shift">From Deterministic to Generative: A Paradigm Shift</h2>
<p>In traditional machine learning (ML), models are deterministic – given the same input, they produce the same output. This predictability provides a clear framework for evaluation metrics such as accuracy, precision, recall, and others familiar to statisticians and data scientists. However, with the rise of large language models (LLMs) and generative AI, this predictability is challenged. These systems introduce non-determinism, meaning outputs can vary even with identical inputs, necessitating new evaluation frameworks.</p>
<p>Dr.&nbsp;LeDell emphasized that traditional accuracy-based metrics fall short when assessing generative AI systems. Instead, evaluation must consider coherence, consistency, and bias, along with the challenges of reproducibility in probabilistic AI systems. This shift leads to questions about how to ensure AI models are reliable and function as expected in real-world scenarios.</p>
</section>
<section id="dr.-erin-ledells-journey-with-r-and-ai" class="level2">
<h2 class="anchored" data-anchor-id="dr.-erin-ledells-journey-with-r-and-ai">Dr.&nbsp;Erin LeDell’s Journey with R and AI</h2>
<p>Dr.&nbsp;LeDell shared her journey from machine learning to generative AI, highlighting her longstanding experience with R. Since 2008, she has been deeply involved in machine learning, contributing to various R packages such as SuperLearner, Subsemble, and H2O, the latter of which she worked on extensively during her tenure at H2O.ai. Her work in AutoML led to the creation of the AutoML benchmark, setting standards for algorithm evaluation.</p>
<p>Her transition into generative AI coincided with the advent of tools like ChatGPT, pushing her to explore new methods for evaluating these complex systems. Dr.&nbsp;LeDell’s passion for using AI in healthcare was evident as she discussed her collaborations with medical companies, applying machine learning to tackle various health-related problems.</p>
</section>
<section id="evaluating-generative-ai-new-approaches" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-generative-ai-new-approaches">Evaluating Generative AI: New Approaches</h2>
<p>The talk delved into the architectural differences between traditional ML systems and modern AI applications, particularly generative AI systems. Dr.&nbsp;LeDell outlined the multi-component nature of these systems, where changes in one part can affect the whole, and the importance of monitoring these changes over time. She addressed the non-stationary behavior of generative AI, noting how external factors and updates from third-party providers can alter system performance.</p>
<p>A significant challenge with generative AI is its inherent non-determinism. Unlike traditional ML models, generative AI requires novel evaluation metrics that account for variability in outputs. Dr.&nbsp;LeDell introduced several frameworks and tools aimed at assessing these systems, emphasizing the role of humans in the evaluation process. Humans provide essential oversight, creating “golden” datasets and evaluating outputs, though this process is not always scalable.</p>
</section>
<section id="llm-as-judge-a-new-standard" class="level2">
<h2 class="anchored" data-anchor-id="llm-as-judge-a-new-standard">LLM as Judge: A New Standard</h2>
<p>One innovative approach Dr.&nbsp;LeDell highlighted is using LLMs themselves to evaluate AI outputs. This method involves deploying LLMs as judges to assess whether responses are correct, helpful, or safe. While this technique is automated and widely used, it presents challenges, such as potential biases if the same model is used for generation and evaluation. Dr.&nbsp;LeDell recommended using specialized LLMs designed for evaluation to mitigate these issues.</p>
</section>
<section id="practical-applications-and-tools" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications-and-tools">Practical Applications and Tools</h2>
<p>Dr.&nbsp;LeDell provided insights into practical applications of generative AI in healthcare, such as using LLMs for clinical note-taking and research acceleration. She described a retrieval-augmented generation (RAG) system for medical Q&amp;A, which combines traditional information retrieval with generative capabilities, enriching AI responses with context from specialized knowledge bases.</p>
<p>For those eager to explore AI evaluation further, Dr.&nbsp;LeDell pointed to several open-source tools, including the R package “vitals,” a port of the Python library “inspect,” developed by JJ Allaire. These tools provide a foundation for customizing evaluation metrics and integrating human oversight into the evaluation pipeline.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Dr.&nbsp;LeDell’s keynote at R/Medicine 2025 illuminated the evolving landscape of AI evaluation, underscoring the need for innovative methodologies to assess the next generation of AI models. Her insights into the intersection of AI and healthcare offer promising pathways for improving AI reliability and trustworthiness in critical applications.</p>
<p>As the R community continues to embrace these advancements, Dr.&nbsp;LeDell’s work encourages practitioners to think critically and creatively about AI evaluation.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/model-evaluation-from-machine-learning-to-generative-ai/thumbnail-keynote-day2-model-evaluation-ledell.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>nonprobsvy – An R package for modern methods for non-probability survey</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/MnEZlFcpmCE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unveiling-the-nonprobsvy-package-a-leap-in-non-probability-sample-inference-in-r" class="level1">
<h1>Unveiling the <code>nonprobsvy</code> Package: A Leap in Non-Probability Sample Inference in R</h1>
<p>Greetings R community! Today, we’re thrilled to delve into the details of <code>nonprobsvy</code>, an R package crafted for inference based on non-probability samples. Presented by Maciej Beręsewicz from the Poznań University of Economics and Business and the Statistical Office in Poznań, this package is a tool for statisticians dealing with the challenges of non-probability samples in various research domains.</p>
<section id="addressing-non-probability-sample-challenges" class="level2">
<h2 class="anchored" data-anchor-id="addressing-non-probability-sample-challenges">Addressing Non-Probability Sample Challenges</h2>
<p>The core motivation behind the development of <code>nonprobsvy</code> stems from the limitations often encountered in official statistics due to declining response rates and the growing reliance on non-probability surveys for population inference. Such surveys, including big data, opt-in web panels, and social media data, often introduce selection bias, complicating accurate population characteristic estimations.</p>
<p>Beręsewicz, deeply rooted in survey sampling and methodology, recognized these challenges through his work at the university and the Statistical Office in Poznań. This package is a testament to his commitment to providing robust statistical methods that correct selection bias, making it a resource for researchers worldwide.</p>
</section>
<section id="the-power-of-nonprobsvy" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-nonprobsvy">The Power of <code>nonprobsvy</code></h2>
<p><code>nonprobsvy</code> integrates with the popular <code>survey</code> package in R, offering a toolkit for addressing non-probability sample biases. It categorizes its approaches into three main groups: prediction-based approach, inverse probability weighting, and doubly robust approach. Here’s a closer look at what it provides:</p>
<ol type="1">
<li><strong>Inverse Probability Weighting (IPW):</strong> Allows for correction of selection bias using known population totals or survey designs.</li>
<li><strong>Mass Imputation Estimators:</strong> Employs methods such as regression imputation and nearest neighbors to estimate missing data.</li>
<li><strong>Doubly Robust Estimators:</strong> Combines the strengths of both IPW and outcome modeling for improved estimations.</li>
<li><strong>High-Dimensional Data Handling:</strong> Features variable selection using techniques like SCAD, LASSO, or MCP, crucial for handling administrative data or surveys with extensive questionnaires.</li>
</ol>
</section>
<section id="a-user-friendly-package" class="level2">
<h2 class="anchored" data-anchor-id="a-user-friendly-package">A User-Friendly Package</h2>
<p>The <code>nonprobsvy</code> package is designed with user-friendliness in mind. Its main function, <code>nonprop()</code>, mimics existing R functions by utilizing formulas, ensuring a smooth transition for users familiar with R’s ecosystem. The package supports both analytical and bootstrap variance estimators, providing flexibility and robustness in variance estimation.</p>
<section id="unique-features" class="level3">
<h3 class="anchored" data-anchor-id="unique-features">Unique Features</h3>
<ul>
<li><strong>Full Integration with the Survey Package:</strong> Ensures compatibility and extends the capabilities of existing survey methods.</li>
<li><strong>Advanced Estimators:</strong> Implements state-of-the-art methods, including those recently accepted for publication, ensuring users have access to the latest developments in survey sampling.</li>
<li><strong>Extensive Documentation:</strong> Provides detailed explanations, equations, and use cases, guiding users through implementation and interpretation.</li>
</ul>
</section>
</section>
<section id="looking-ahead-future-developments" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead-future-developments">Looking Ahead: Future Developments</h2>
<p>Beręsewicz and his team have ambitious plans for the future of <code>nonprobsvy</code>. They aim to incorporate overlapping samples, replicate weights, and expand mass imputation methods beyond parametric approaches. There is also a focus on developing inference methods for quantiles and integrating mixed-mode data handling, reflecting the dynamic needs of contemporary research.</p>
<section id="community-involvement" class="level3">
<h3 class="anchored" data-anchor-id="community-involvement">Community Involvement</h3>
<p>The development team encourages feedback and suggestions from the community. By engaging with users on GitHub, they aim to continuously refine and enhance the package. If you have innovative ideas or encounter challenges, they’re eager to hear from you.</p>
</section>
</section>
<section id="call-to-action" class="level2">
<h2 class="anchored" data-anchor-id="call-to-action">Call to Action</h2>
<p><code>nonprobsvy</code> is available on CRAN, and its development version is hosted on GitHub. We invite you to explore this powerful package, test its capabilities, and contribute to its evolution. Your insights and experiences are invaluable in shaping its future.</p>
<p>For researchers, statisticians, and R enthusiasts, <code>nonprobsvy</code> offers a robust solution to the complexities of non-probability samples. Whether you’re tackling big data, social media analytics, or opt-in web panels, this package equips you with the tools needed to derive accurate, reliable inferences.</p>
<p>To learn more about the package, visit the <a href="https://cran.r-project.org/package=nonprobsvy">CRAN page</a> or <a href="http://github.com/ncn-foreigners/nonprobsvy">GitHub repository</a>. Let’s work together in advancing statistical methodologies and making impactful contributions to the R community.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/nonprobsvy-an-r-package-for-modern-methods-for-non-probability-survey/thumbnail-nonprobsvy.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Opening Remarks - Day 2</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/opening-remarks-day-2/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/HWJH9RiGFsc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="rmedicine-2025-day-2-a-celebration-of-r-in-medicine" class="level1">
<h1>R/Medicine 2025 Day 2: A Celebration of R in Medicine</h1>
<p>The R/Medicine 2025 conference, a flagship event brought to the community by the R Consortium, continues to be a focus of innovation and collaboration between R programming and medicine. With participants joining from diverse corners of the globe, including, just to name a few read off by Zabor during the talk, the Netherlands, Romania, London, Germany, and from US states like Florida, California, Minnesota, and Pennsylvania, the event shines as a testament to the universal appeal and utility of R in medical research and practice.</p>
<section id="acknowledgments-and-gratitude" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments-and-gratitude">Acknowledgments and Gratitude</h2>
<p>The second day of the conference commenced with a welcome extended by Emily Zabor, the event’s chair and a dedicated biostatistician at the Cleveland Clinic.</p>
<p>Zabor emphasized that the success of R/Medicine 2025 owes much to the support of its financial sponsors, Genentech and Posit, alongside the invaluable backing of the R Consortium. Thanks are also due to the organizing committee, whose dedication and expertise have been instrumental in crafting this enriching experience. And, of course, to all participants who contribute time, knowledge and energy.</p>
</section>
<section id="recap-of-day-1-highlights" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-day-1-highlights">Recap of Day 1 Highlights</h2>
<p>The first day of the conference was marked by an array of insightful presentations and discussions. Attendees were treated to a keynote by Ziad Obermeyer, who delved into the transformative potential of AI in the realm of medicine. The day unfolded with 9 regular talks and 2 lightning talks that spanned topics such as reproducibility, compliance, workflow automation, and clinical epidemiological applications.</p>
<p>A notable highlight was the presentation of competition winners in both the student and professional categories. Their analysis of vaccination and measles case rates for 2025 provided critical insights, despite the somewhat concerning data trends. The rigor and clarity of their presentations underscored the power of data-driven decision-making in public health.</p>
<section id="video-availability" class="level3">
<h3 class="anchored" data-anchor-id="video-availability">Video Availability</h3>
<p>For those who missed the live sessions, most of the presentations will be made available on the <a href="https://www.youtube.com/playlist?list=PL4IzsxWztPdmU2q31ZrTCASr78e0jpKux">R Consortium’s YouTube channel</a>. Participants are encouraged to watch for communications regarding the release of these videos, which will serve as a valuable resource for continued learning and inspiration.</p>
</section>
</section>
<section id="day-2-exciting-lineup-of-keynotes-and-talks" class="level2">
<h2 class="anchored" data-anchor-id="day-2-exciting-lineup-of-keynotes-and-talks">Day 2: Exciting Lineup of Keynotes and Talks</h2>
<p>Day Two promises another engaging lineup, starting with a keynote by Erin LeDell, focusing on model evaluation from machine learning to generative AI. This is followed by 6 regular talks and 11 lightning talks. Sessions will cover a broad spectrum of topics, including:</p>
<ul>
<li>Packages and tools for data management</li>
<li>Cohorts and APIs</li>
<li>Visualization and communication</li>
<li>Clinical and epidemiological applications</li>
<li>Statistical modeling, inference, and methodology</li>
</ul>
<p>This diversity of topics reflects the multifaceted nature of R’s applications in medicine, ensuring that there is something of interest for every attendee.</p>
</section>
<section id="community-and-networking" class="level2">
<h2 class="anchored" data-anchor-id="community-and-networking">Community and Networking</h2>
<p>The conference provides an excellent platform for networking and community building. With a few minutes between sessions, attendees are encouraged to engage in discussions and share ideas. This interaction fosters a sense of camaraderie and collaboration, essential for advancing the field.</p>
</section>
<section id="looking-ahead-future-webinars" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead-future-webinars">Looking Ahead: Future Webinars</h2>
<p>The R/Medicine conference is not limited to annual gatherings. Throughout the year, the <a href="https://r-consortium.org/webinars/webinars.html">R Consortium hosts webinars</a> that delve deeper into specific topics of interest. Last year saw two mid-year R/Medicine webinars, and this tradition of continuous learning and engagement is set to continue. Participants should stay tuned for announcements.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>R/Medicine 2025 stands as a vibrant celebration of the role of R in advancing medical research and practice. With an agenda packed with insightful talks, expert speakers, and a global community of attendees, the event embodies the spirit of innovation and collaboration. Participants are encouraged to immerse themselves in the wealth of knowledge shared and to continue engaging with the R community beyond the conference.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Events</category>
  <guid>https://r-consortium.org/posts/opening-remarks-day-2/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/opening-remarks-day-2/thumbnail-opening-remarks-day2.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Optimizing Public Healthcare Cost Recovery with R: A Use Case from Argentina</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/BzYtr9dfHjQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="optimizing-argentinas-public-healthcare-system-with-r-a-case-study-in-efficiency-and-sustainability" class="level1">
<h1>Optimizing Argentina’s Public Healthcare System with R: A Case Study in Efficiency and Sustainability</h1>
<p>In the realm of public health, the need to do more with less is a constant challenge. This is particularly true in Argentina, where the healthcare system is fragmented into three subsystems: public, social security, and private sectors. Each of these subsystems serves different populations and has its unique funding mechanisms and challenges. However, in the spirit of equity and quality healthcare access, programs like SUMAR have emerged as vital tools for supporting the uninsured population by strengthening the public subsystem. SUMAR provides financial incentives to healthcare providers for each service rendered to individuals with exclusive public coverage, funded by external sources such as the World Bank.</p>
<p>In this context, the Ministry of Health of the City of Buenos Aires has undertaken an innovative approach to optimize cost recovery processes via the implementation of open-source tools, particularly R, showcasing a practical application of data science in public health settings. This effort is spearheaded by the Operational Management of Health Information and Statistics, a team that uses R to enhance healthcare efficiency and sustainability.</p>
<section id="understanding-argentinas-healthcare-landscape" class="level2">
<h2 class="anchored" data-anchor-id="understanding-argentinas-healthcare-landscape">Understanding Argentina’s Healthcare Landscape</h2>
<p>Argentina’s healthcare landscape is characterized by its division into three main sectors:</p>
<ol type="1">
<li><strong>Public Sector</strong>: Comprising national, provincial, and municipal hospitals offering free universal care regardless of a person’s insurance status.</li>
<li><strong>Social Security Sector</strong>: Funded through payroll and catering to workers, retirees, and individuals with disabilities, providing mandatory coverage linked to formal employment.</li>
<li><strong>Private Sector</strong>: Offering voluntary, prepaid plans for those seeking additional or alternative coverage.</li>
</ol>
<p>The SUMAR program comes into play as a national policy aimed at better financing public healthcare by tying financial incentives directly to the services provided to uninsured individuals. It operates on a results-based funding model, which allocates resources based on service provision and health outcomes, with funding sourced primarily from the World Bank.</p>
</section>
<section id="leveraging-technology-for-sustainable-healthcare" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-technology-for-sustainable-healthcare">Leveraging Technology for Sustainable Healthcare</h2>
<p>The City of Buenos Aires is at the forefront of utilizing technology to optimize healthcare processes. The widespread adoption of the Electronic Health Record (EHR) system, known as the Hospital Management System (HMS), is a game-changer. HMS seamlessly integrates administrative and clinical workflows across public healthcare facilities, ensuring uniform data collection and management.</p>
<p>The data extracted from HMS is crucial for automating the SUMAR program. Each night, ETL (Extract, Transform, Load) jobs extract relevant data tables, such as patient encounters and diagnostics, which are then loaded into a central data warehouse. This setup forms the backbone of the automated SUMAR workflow in Buenos Aires.</p>
</section>
<section id="automating-the-sumar-process-with-r" class="level2">
<h2 class="anchored" data-anchor-id="automating-the-sumar-process-with-r">Automating the SUMAR Process with R</h2>
<p>The automation of the SUMAR program is a testament to the power of open-source tools like R. The data science team within the Ministry of Health employs R to automate processes and generate reports, ensuring a smooth and efficient workflow. Key outputs of this automated process include PDF invoices, weekly Excel reports, and performance indicator summaries.</p>
<p>The R-based workflow comprises three critical stages:</p>
<ol type="1">
<li><strong>Enrollment</strong>: Identifying individuals with public coverage using national registries.</li>
<li><strong>Detection of Basic Effective Coverage Services</strong>: Applying regex and logic rules across data sources to pinpoint eligible health services.</li>
<li><strong>Analysis of Health Performance Indicators</strong>: Generating comprehensive reports through R Markdown, ensuring data is transformed into actionable insights.</li>
</ol>
<p>The team’s dedicated R environment, which includes an R Studio server and GitLab for version control, facilitates collaborative development, ensuring the process is both reproducible and auditable.</p>
</section>
<section id="the-impact-of-automation-and-open-source" class="level2">
<h2 class="anchored" data-anchor-id="the-impact-of-automation-and-open-source">The Impact of Automation and Open Source</h2>
<p>The automation of the SUMAR program in Buenos Aires is not merely about efficiency—it represents a paradigm shift in how public healthcare can be managed. The steady increase in detected health services from January 2021 to April 2025 is a testament to the robustness and scalability of the automated processes. Each detected service translates into real funding, enhancing the capacity and accountability of the public healthcare system.</p>
<p>The use of R, with libraries like Tidyverse, StringR, WriteXL, and TinyTex, underscores the adaptability and sustainability of open-source solutions in public health. This approach not only saves time but also expands service coverage, ensuring that more individuals benefit from essential healthcare services.</p>
</section>
<section id="future-directions-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="future-directions-and-opportunities">Future Directions and Opportunities</h2>
<p>The success of the SUMAR program’s automation opens up new possibilities for further innovation within the public healthcare sector. While the current focus is on generating tables and reports, there is potential for developing more interactive data visualizations and dashboards using tools like Shiny or R Markdown’s interactive capabilities. Such advancements could provide deeper insights and facilitate data-driven decision-making at various levels of government.</p>
<p>In conclusion, the use of R in automating the SUMAR program in Buenos Aires highlights the transformative potential of data science in public health. By optimizing administrative workflows and enhancing data traceability, this initiative not only improves cost recovery efforts but also sets a benchmark for other regions to follow. As we look to the future, the continued adoption of open-source tools in healthcare promises to drive innovation and sustainability, ultimately benefiting populations most in need.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/optimizing-public-healthcare-cost-recovery-with-r-a-use-case-from-argentina/thumbnail-optimizing-buenos-aires.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Preprocessing Electronic Health Records for Analysis-Ready Data in an Asthma Cohort</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EytsZg9Rqkg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="pre-processing-electronic-health-records-for-asthma-cohort-analysis-with-r" class="level1">
<h1>Pre-processing Electronic Health Records for Asthma Cohort Analysis with R</h1>
<p>Electronic health record (EHR) data has emerged as a critical tool for conducting large-scale biomedical research. However, the complexity, inconsistencies, and potential inaccuracies within EHR data pose significant challenges for researchers. Kimberly Lactaoen, a staff scientist at the University of Pennsylvania, sheds light on these challenges and offers solutions through her presentation at R/Medicine 2025. By utilizing the tidyverse suite in R, she demonstrates how to transform perplexing EHR data into analysis-ready datasets, focusing on an asthma cohort study.</p>
<section id="understanding-the-intricacies-of-ehr-data" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-intricacies-of-ehr-data">Understanding the Intricacies of EHR Data</h2>
<p>EHR data encompasses vast amounts of patient information, providing a realistic representation of patient populations. Despite its potential, EHR data is riddled with complexities, including inconsistent data entries, diverse formats, and missing values, which can misrepresent a patient’s true health status. Lactaoen’s presentation focuses on the importance of understanding how this data is collected to streamline exploratory analyses and reduce scripting stages.</p>
<section id="key-challenges-in-ehr-data-cleaning" class="level3">
<h3 class="anchored" data-anchor-id="key-challenges-in-ehr-data-cleaning">Key Challenges in EHR Data Cleaning</h3>
<ol type="1">
<li><p><strong>Encounter-Level vs.&nbsp;Patient-Level Data</strong>: One of the initial hurdles is discerning between encounter-level and patient-level data. For instance, demographic details like sex, race, and ethnicity remain constant across encounters, while variables like insurance and BMI may vary. Lactaoen highlights the significance of understanding data collection methods to efficiently script for the most recent demographic entries using functions such as <code>as_date()</code> from the <code>lubridate</code> package.</p></li>
<li><p><strong>Conflicting Patient Information</strong>: EHR datasets often contain conflicting information, especially in demographic variables like race and ethnicity. Lactaoen’s approach involved using the <code>case_when()</code> function from <code>dplyr</code> to resolve conflicts, ensuring consistent and distinct race and ethnicity variables.</p></li>
<li><p><strong>Inconsistent Diagnostic Codes</strong>: Diagnostic code descriptions can vary, complicating the grouping of patients based on diagnoses. Lactaoen addresses this by joining diagnostic codes with descriptions from the Center for Medicare and Medicaid Services using <code>left_join()</code>, ensuring consistency across datasets.</p></li>
<li><p><strong>Medication Relevance for Asthma Treatment</strong>: Selecting relevant medications for asthma treatment from EHR data is another challenge. Lactaoen’s team collaborated with asthma specialists to filter relevant medications, leveraging Excel and the <code>map_dfr()</code> function from the <code>purrr</code> package to compile a comprehensive list for analysis.</p></li>
<li><p><strong>Laboratory Test Result Variability</strong>: Laboratory test results, such as eosinophil data, often feature varying units of measurement. Lactaoen utilized the <code>case_when()</code> function to standardize these units, though issues like missing unit information remain a work in progress.</p></li>
</ol>
</section>
</section>
<section id="strategies-for-effective-ehr-data-pre-processing" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-effective-ehr-data-pre-processing">Strategies for Effective EHR Data Pre-processing</h2>
<p>Lactaoen’s presentation offers several strategies for overcoming these challenges:</p>
<ul>
<li><strong>Understand Data Collection</strong>: Familiarizing oneself with the data collection process is crucial for reducing exploratory analysis and scripting efforts.</li>
<li><strong>Identify and Resolve Conflicts</strong>: Be vigilant about conflicting information, which may not accurately reflect a patient’s health status.</li>
<li><strong>Collaborate with Domain Experts</strong>: Engaging with specialists, such as asthma experts, ensures that the data used is relevant and accurate for the study.</li>
<li><strong>Simplify and Standardize Data</strong>: Wherever possible, simplify data entries and standardize units to facilitate easier analysis.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Lactaoen’s insights into EHR data pre-processing underscore the importance of meticulous data cleaning and transformation. By leveraging R’s tidyverse suite, researchers can effectively prepare EHR data for analysis, paving the way for impactful biomedical research. Her emphasis on understanding data collection, resolving conflicts, collaborating with experts, and standardizing data provides a robust framework for researchers embarking on EHR-based studies.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Clinial Research</category>
  <guid>https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/preprocessing-electronic-health-records-for-analysis-ready-data-in-an-asthma-cohort/thumbnail-reprocessing-ehs-lactaoen.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>rainbowR: A community for LGBTQ+ folks who code in R</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gLlRaqNfjys" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="embracing-inclusivity-in-r-the-journey-of-rainbowr" class="level1">
<h1>Embracing Inclusivity in R: The Journey of rainbowR</h1>
<p>In the ever-evolving world of data science and statistical computing, R has become a beloved language, not just for its robustness and versatility, but also for its vibrant and inclusive community. A shining example of this inclusivity is rainbowR, a community dedicated to connecting, supporting, and promoting LGBTQ+ individuals who code in R. Founded by Ella Kaye of the University of Warwick, rainbowR has transformed into a thriving hub for LGBTQ+ coders and allies alike, fostering a sense of belonging and camaraderie through innovative initiatives and data-driven activism.</p>
<section id="origin-and-growth-of-rainbowr" class="level2">
<h2 class="anchored" data-anchor-id="origin-and-growth-of-rainbowr">Origin and Growth of rainbowR</h2>
<p>The inception of rainbowR dates back to the useR! Conference in 2017, when Ella Kaye engaged in a conversation that highlighted the need for a dedicated LGBTQ+ space within the R community. Fast forward to today, and rainbowR has grown exponentially, boasting a membership of over 100 individuals. This growth is not just a testament to the need for such a community but also to the welcoming atmosphere and the meaningful connections it fosters.</p>
</section>
<section id="monthly-meetups-and-buddy-scheme" class="level2">
<h2 class="anchored" data-anchor-id="monthly-meetups-and-buddy-scheme">Monthly Meetups and Buddy Scheme</h2>
<p>Central to rainbowR’s mission are its monthly online meetups, typically held on the fourth Wednesday of each month. These gatherings provide a relaxed and supportive environment where participants can discuss R-related topics, share resources, and showcase their work. The focus on creating a friendly space encourages open dialogue and fosters learning among members.</p>
<p>Another key initiative is the buddy scheme, which aims to facilitate deeper connections within the community. Every three months, members can opt into the scheme, where they are randomly paired with another member. An R script processes these pairings and generates personalized emails to introduce the paired individuals. This innovative approach not only eases the anxiety of meeting new people but also enriches the community fabric by fostering one-on-one connections.</p>
</section>
<section id="data-driven-activism" class="level2">
<h2 class="anchored" data-anchor-id="data-driven-activism">Data-Driven Activism</h2>
<p>rainbowR’s commitment to raising awareness about LGBTQ+ issues is further exemplified through its GitHub repository, Tidy Rainbow. This repository hosts a collection of LGBTQ+ datasets, providing valuable resources for data visualization and analysis. These datasets can be utilized for educational purposes, blog posts, or simply to practice data skills, making them a valuable asset for both community members and allies.</p>
</section>
<section id="engaging-with-literature-the-rainbow-r-book-club" class="level2">
<h2 class="anchored" data-anchor-id="engaging-with-literature-the-rainbow-r-book-club">Engaging with Literature: The Rainbow R Book Club</h2>
<p>In addition to its technical initiatives, rainbowR has ventured into the literary world with its book club. The club recently completed its first session, where participants delved into “Queer Data: Using Gender, Sex, and Sexuality Data for Action” by Kevin Gian. The success of this book club highlights the community’s commitment to broadening its understanding of LGBTQ+ issues through various mediums. Future book club sessions are in the pipeline, promising more engaging discussions and insights.</p>
</section>
<section id="future-plans-and-the-role-of-allies" class="level2">
<h2 class="anchored" data-anchor-id="future-plans-and-the-role-of-allies">Future Plans and the Role of Allies</h2>
<p>As rainbowR looks to the future, exciting plans are underway to ensure the community’s sustainability and impact. Ella Kaye, now a fellow of the Software Sustainability Institute, is utilizing her fellowship to nurture and solidify rainbowR’s foundations. This includes establishing clear engagement pathways, developing governance policies, and potentially becoming a legal entity.</p>
<p>A flagship event in the pipeline is the inaugural Rainbow R Conference, designed to bring the community together to share knowledge and celebrate diversity. Allies play a crucial role in this journey, and their involvement is highly valued within rainbowR. The conference organizing committee welcomes allies, further emphasizing the inclusive nature of this vibrant community.</p>
</section>
<section id="call-for-collaboration-and-community-building" class="level2">
<h2 class="anchored" data-anchor-id="call-for-collaboration-and-community-building">Call for Collaboration and Community Building</h2>
<p>rainbowR’s mission extends beyond its own community. By sharing knowledge and experiences with other R or queer communities, rainbowR aims to build a network of support and shared learning. Community managers interested in exploring best practices for community building are encouraged to reach out to Ella Kaye and explore potential collaborations.</p>
</section>
<section id="join-the-movement" class="level2">
<h2 class="anchored" data-anchor-id="join-the-movement">Join the Movement</h2>
<p>For those interested in joining this vibrant community, rainbowR offers an open invitation to LGBTQ+ individuals and allies. By visiting <a href="https://rainbow.org">rainbow.org</a>, you can learn more about the community, sign up for newsletters, and become part of a supportive network that celebrates diversity and inclusivity in the R ecosystem.</p>
<p>rainbowR is more than just a community; it’s a movement towards a more inclusive and supportive future for all who code in R. As the community continues to grow and evolve, it stands as a testament to the power of connection and the impact of collective action in the world of data science.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>LGBTQ+</category>
  <guid>https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rainbowr-a-community-for-lgbtq-folks-who-code-in-r/thumbnail-rainbowr.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>riskcalc.org: A Repository of Risk Calculators for Medical Decision Making</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4mo5V_rjUhM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-clinical-decision-making-with-riskcalc.org" class="level1">
<h1>Enhancing Clinical Decision-Making with Riskcalc.org</h1>
<p>In the rapidly evolving landscape of healthcare, the fusion of data science and clinical practice is creating unprecedented opportunities for personalized medicine. At the forefront of this intersection is <a href="https://riskcalc.org/">riskcalc.org</a>, a pioneering platform developed to aid clinicians and patients in making informed medical decisions. Alex Zajichek, a research data scientist at the Cleveland Clinic, recently provided an insightful overview of this platform at R/Medicine 2025, highlighting its capabilities, infrastructure, and future directions.</p>
<section id="the-genesis-of-riskcalc.org" class="level2">
<h2 class="anchored" data-anchor-id="the-genesis-of-riskcalc.org">The Genesis of Riskcalc.org</h2>
<p>Riskcalc.org emerged from the Cleveland Clinic’s Department of Quantitative Health Sciences, a hub of over 100 statisticians, data scientists, and researchers. This department is dedicated to providing quantitative support across various research activities, from clinical trials to precision medicine. The platform was conceptualized to serve as a free, accessible resource for clinicians and patients, facilitating individualized medical decision-making through a collection of predictive models.</p>
</section>
<section id="core-functionality-and-infrastructure" class="level2">
<h2 class="anchored" data-anchor-id="core-functionality-and-infrastructure">Core Functionality and Infrastructure</h2>
<p>At its core, riskcalc.org hosts a suite of clinical risk calculators, each designed as a standalone R Shiny application. These calculators are predominantly regression models derived from published research studies. The platform garners significant engagement, with a monthly user base of 10,000 to 15,000.</p>
<p>The development process involves creating applications locally using R and Shiny. The models are integrated into the applications either as stored R data objects or by hardcoding them directly into the app’s code. For transparency, the code is pushed to GitHub, allowing users to inspect the application’s backend functionality. The live interaction with riskcalc.org occurs via an open-source Shiny server hosted on AWS, a cost-effective infrastructure primarily incurring costs for compute resources.</p>
</section>
<section id="recent-developments-and-enhancements" class="level2">
<h2 class="anchored" data-anchor-id="recent-developments-and-enhancements">Recent Developments and Enhancements</h2>
<p>The platform has seen several recent enhancements. All source codes for the applications are now publicly accessible on the department’s GitHub page, with each application featuring a link to its source code. The homepage of riskcalc.org has undergone a redesign to improve user interface and navigation, with icons representing different disease areas leading users to relevant risk calculators.</p>
<p>Moreover, an R package has been developed to streamline the creation of risk calculators. The package’s main function, <code>risk_calculator</code>, allows users to generate a directory containing application files preconfigured with standard boilerplate elements. Users can then customize these files with specific model details, facilitating the rapid development of new calculators.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>Looking forward, several key areas for development and improvement have been identified:</p>
<ol type="1">
<li><p><strong>Integration and Workflow Enhancement</strong>: There is a push to more formally integrate GitHub into the workflow through CI/CD processes, ensuring that the code on GitHub is directly connected to the live website. This integration would aid in managing package versions and R itself on the server, mitigating compatibility issues during application development.</p></li>
<li><p><strong>Standardization and Expansion</strong>: Efforts are underway to generalize the concept of a risk calculator to include not just regression models but any mathematical object that predicts clinical outcomes, such as machine learning models. A standardized framework is being sought to power the backend consistently, regardless of model methodology.</p></li>
<li><p><strong>Model Monitoring and Updating</strong>: The team is exploring ways to monitor model performance over time, beyond the point of initial development. This ongoing evaluation would ensure that models remain relevant and accurate in clinical settings.</p></li>
<li><p><strong>Broader Community and Research Ecosystem</strong>: Riskcalc.org aims to become a one-stop shop for clinical risk prediction. This vision includes fostering community involvement for model validation and performance ranking, developing APIs for programmatic access to model outputs, and creating a research ecosystem to integrate and compare various models for improved clinical predictions.</p></li>
</ol>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>The platform has been a collaborative effort, with contributions from numerous co-developers and principal investigators. Special acknowledgment is given to Mike Kattan, the former department chair and a world-renowned expert in clinical risk prediction, whose vision and leadership were instrumental in the creation of riskcalc.org.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Riskcalc.org represents a significant stride towards integrating data science with clinical practice, providing a robust tool for personalized medical decision-making. With its ongoing developments and future plans, the platform is poised to enhance its impact and utility in the healthcare domain.</p>
<p>For more information on this talk and to access the slides, visit Alex Zajichek’s <a href="https://www.zajichekstats.com/presentations/riskcalc-a-repository-of-risk-calculators-for-medical-decision-making/">presentation</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Insurance/Risk</category>
  <guid>https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/riskcalcorg-a-repository-of-risk-calculators-for-medical-decision-making/thumbnail-riskcalc.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>R/Medicine 2025 - Closing Remarks - Final Day - Michael Kane</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ad5V0PBYl_M" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="closing-remarks-from-rmedicine-2025-by-michael-kane-md" class="level1">
<h1>Closing Remarks from R/Medicine 2025 by Michael Kane, MD</h1>
<p>As R/Medicine 2025 concludes its second and final day, Michael Kane, MD, from the Anderson Cancer Center, delivered the closing remarks, encapsulating the essence and future direction of this unique conference dedicated to the intersection of R programming and healthcare. Kane, a co-founder of R/Medicine, provided insights into the conference’s achievements and aspirations, leaving the audience with a sense of community and purpose.</p>
<section id="acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<p>Kane began by expressing gratitude to the organizing committee, with a special nod to Emily Zaber, who chaired this year’s event. The seamless execution of the conference, he noted, is a testament to the dedication and behind-the-scenes effort of the team. The importance of organization and meticulous planning cannot be overstated, and this year’s smooth proceedings are a reflection of such diligence.</p>
</section>
<section id="a-conference-for-the-community" class="level2">
<h2 class="anchored" data-anchor-id="a-conference-for-the-community">A Conference for the Community</h2>
<p>Emphasizing the core philosophy of R/Medicine, Kane reiterated that this conference is designed to be a platform for the community. The healthcare space is expansive, with myriad groups engaged in cutting-edge research that often goes underrepresented. R/Medicine aims to bridge this gap by providing a forum for practitioners and methodologists alike to share their work, explore collaborative opportunities, and contribute to ongoing projects.</p>
<p>The conference’s commitment to inclusivity was evident in the diverse international participation this year. Attendees from South America, Europe, and other regions enriched the discussions with their unique perspectives and innovations. This global engagement underscores the universal applicability and potential of R in transforming healthcare.</p>
</section>
<section id="towards-a-continuous-engagement" class="level2">
<h2 class="anchored" data-anchor-id="towards-a-continuous-engagement">Towards a Continuous Engagement</h2>
<p>Looking ahead, Kane shared the committee’s vision of making R/Medicine a continuous engagement rather than a once-a-year event. The introduction of periodic webinars is a step in this direction, allowing for ongoing dialogue and knowledge exchange throughout the year. By maintaining a steady flow of information and interaction, R/Medicine seeks to foster a vibrant and dynamic community that stays connected and informed about the latest developments in healthcare.</p>
</section>
<section id="invitation-to-participate" class="level2">
<h2 class="anchored" data-anchor-id="invitation-to-participate">Invitation to Participate</h2>
<p>In closing, Kane extended an open invitation to all participants to become more involved in R/Medicine. Whether by submitting proposals for future conferences, contributing to ongoing projects, or joining the organizing committee, the opportunities for involvement are numerous. The committee is keen on remaining dynamic and responsive to emerging healthcare challenges, and fresh perspectives are always welcome.</p>
<p>Kane’s remarks concluded with heartfelt thanks to all attendees and participants, with a promise of even more exciting developments in the coming year. As R/Medicine 2025 draws to a close, the community looks forward to another year of innovation, collaboration, and progress in using R to revolutionize healthcare.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <guid>https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rmedicine-2025-closing-remarks-final-day-michael-kane/thumbnail-closing-remarks-day2-finalday-michael-kane.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>R/Medicine Day 1 Closing Remarks</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/rmedicine-closing-remarks/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tF2Vej2mTKQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="wrapping-up-day-one-of-rmedicine-2025-with-peter-higgins" class="level1">
<h1>Wrapping Up Day One of R/Medicine 2025 with Peter Higgins</h1>
<p>As we draw the curtains on Day 1 - after 3 days of Demos and Workshops, the events shifted to Keynotes, Talks and Lightning Talks - of the R/Medicine 2025 conference, Peter Higgins from the University of Michigan delivered the closing remarks, emphasizing the wealth of knowledge shared throughout the day and the excitement building up for what’s to come.</p>
<p>The event has showcased the immense potential of the R language in revolutionizing medicine and healthcare.</p>
<section id="highlights-of-day-one" class="level2">
<h2 class="anchored" data-anchor-id="highlights-of-day-one">Highlights of Day One</h2>
<p>The day was packed with a myriad of topics that span across different facets of medicine and technology. From the integration of artificial intelligence in medicine to ensuring data consistency through harmonization and controlled vocabularies, the sessions were nothing short of enlightening. Participants had the opportunity to delve into statistical consistency with CIS ARS and the validation of Shiny apps, alongside discussions on Shiny lifecycle management.</p>
<p>One of the standout aspects of the day was the focus on reproducibility, emphasized through talks on the <code>rum</code> package. This package is pivotal for ensuring that medical research and practices are backed by reproducible and verifiable data. Furthermore, R’s capabilities in handling deep learning were highlighted, with particularly engaging discussions on applications in health, including asthma and other medical conditions.</p>
<p>The day also featured presentations from the winners of the R/Medicine data challenge. These individuals and teams showcased innovative solutions that have the potential to transform healthcare practices. The challenge not only sparked creativity but also encouraged collaboration among R enthusiasts, setting the stage for future competitions.</p>
</section>
<section id="looking-forward-to-day-two" class="level2">
<h2 class="anchored" data-anchor-id="looking-forward-to-day-two">Looking Forward to Day Two</h2>
<p>As the conference gears up for Day Two of talks and its final day, anticipation is high. The keynote will focus on model evaluation, a critical aspect of healthcare analytics that ensures the accuracy and reliability of predictive models. Attendees can also look forward to sessions on risk calculators and talks addressing nonprobability surveys, which are crucial in understanding population health dynamics.</p>
<p>The conference will also celebrate diversity and inclusivity with the rainbowR Community session, bringing to light the importance of diverse perspectives in the R community. Furthermore, the role of accelerometry as a biomarker will be explored, presenting new avenues for health monitoring and diagnosis.</p>
<p>The excitement doesn’t stop there. The introduction of a new package, <code>redquack</code>, which combines REDCap and DuckDB, is set to be a game-changer for data management in healthcare research. Additional sessions will cover a variety of packages, including <code>ggswim</code>, <code>kidney.epi</code>, <code>nix</code>, and <code>distanceHD</code>.</p>
<p>In the lightning talks, topics will range from bootstrapping to NHIS data, culminating in a deep dive into survival analysis with computation through deep learning. These sessions promise to be a treasure trove of insights and innovations.</p>
</section>
<section id="community-engagement-and-interactivity" class="level2">
<h2 class="anchored" data-anchor-id="community-engagement-and-interactivity">Community Engagement and Interactivity</h2>
<p>An exciting update for Day One is the activation of chat sessions during presentations. This feature is expected to enhance interactivity, allowing participants to engage in discussions, ask questions, and share their experiences in real-time.</p>
<p>This type of collaborative environment is one of the hallmarks of the R/Medicine conference, fostering a sense of community among attendees.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Peter Higgins’ closing remarks for Day One encapsulated the essence of the R/Medicine 2025 conference — a celebration of knowledge, innovation, and community. The event has provided a platform for sharing groundbreaking ideas and tools that have the potential to redefine medicine and healthcare practices.</p>
<p>As the conference concludes, it is hoped that participants are inspired to continue exploring and leveraging the power of R in their work. Whether through participating in future data challenges or developing new packages and tools, the possibilities are endless.</p>
<p>In case you missed any of the sessions, fear not! Almost all the content is recorded and will be available on the <a href="https://www.youtube.com/playlist?list=PL4IzsxWztPdmU2q31ZrTCASr78e0jpKux">R Consortium’s YouTube channel</a>. This ensures that the learning and inspiration derived from R/Medicine 2025 can continue to reach a wider audience, fostering growth and development within the R community.</p>
<p>For more information on the event and to access resources, visit the official <a href="https://rconsortium.github.io/RMedicine_website/">R/Medicine website</a> and the <a href="https://www.r-consortium.org/">R Consortium site</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Events</category>
  <guid>https://r-consortium.org/posts/rmedicine-closing-remarks/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/rmedicine-closing-remarks/thumbnail-closing-remarks-day1-higgins.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Swimmer Plots with ggswim</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/swimmer-plots-with-ggswim/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pbgNiq-KvIE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="making-swimmer-plots-effortless-with-ggswim-a-dive-into-rs-medical-visualization-toolkit" class="level1">
<h1>Making Swimmer Plots Effortless with ggswim: A Dive into R’s Medical Visualization Toolkit</h1>
<p>The R community is always on the lookout for innovative tools that can simplify complex data visualization tasks. Swimmer plots, known for their utility in visualizing treatment timelines in clinical trials, have long been a challenge to create in R due to their complexity. Enter ggswim, a package developed to ease the creation of swimmer plots while staying true to the grammar of graphics.</p>
<section id="the-challenge-of-swimmer-plots-in-r" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-of-swimmer-plots-in-r">The Challenge of Swimmer Plots in R</h2>
<p>Swimmer plots are invaluable in clinical and pharmaceutical research. They provide a compact, interpretable way to visualize patient data over time, highlighting key metrics such as adverse events and treatment durations. Despite their usefulness, generating swimmer plots using R’s ggplot2 can be technically demanding. The intricacies of scale alignment and legend composition require a deep understanding of ggplot2’s internals, which is often beyond the typical scope of a researcher’s expertise.</p>
<p>While there are existing packages that support swimmer plot development, none have fully bridged the gap between ease of use and compatibility with the grammar of graphics—until now.</p>
</section>
<section id="introducing-ggswim" class="level2">
<h2 class="anchored" data-anchor-id="introducing-ggswim">Introducing ggswim</h2>
<p>Developed as an extension to ggplot2, ggswim addresses the challenges of creating swimmer plots in R. Richard Hanna from the Children’s Hospital of Philadelphia, a data scientist with the Cell and Gene Therapy Informatics team, presented ggswim at the R/Medicine 2025 conference.</p>
<section id="the-motivation-behind-ggswim" class="level3">
<h3 class="anchored" data-anchor-id="the-motivation-behind-ggswim">The Motivation Behind ggswim</h3>
<p>The development of ggswim was driven by the need for a tool that simplifies the creation of swimmer plots while maintaining full compatibility with ggplot2. By introducing a streamlined grammar specifically for swimmer plots, ggswim organizes visual elements into two conceptual categories: lanes and markers. Lanes represent continuous durations, such as time on a study, while markers denote discrete events, such as adverse events or outcomes.</p>
<p>This framework integrates seamlessly with existing ggplot2 tools, allowing users to layer and label plot components using concise, intuitive syntax. This compatibility ensures that ggswim remains flexible and aesthetically pleasing, promoting reproducibility and transparency in medical research settings.</p>
</section>
<section id="a-closer-look-at-ggswims-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="a-closer-look-at-ggswims-capabilities">A Closer Look at ggswim’s Capabilities</h3>
<p>ggswim builds on ggplot2’s architecture without wrapping standard functions, ensuring that all parameters familiar to ggplot2 users are retained. The package features several key functions:</p>
<ul>
<li><strong>g_swim_lane</strong>: Wraps ggsegment methods for creating continuous durations.</li>
<li><strong>g_swim_marker</strong>: Wraps gg methods for discrete events.</li>
<li><strong>g_swim_arrow</strong>: A specialized gsegment wrapper for continuation arrows.</li>
<li><strong>scale_marker_discrete</strong>: The pivotal function for resolving legend output issues, allowing easy manipulation of legend components for clearer, more informative plots.</li>
</ul>
<p>Richard Hanna’s presentation highlighted how ggswim leverages ggplot2’s guide functionality, enabling users to manipulate legend outputs effectively. The package simplifies the process of creating swimmer plots with minimal additional code, providing a succinct and reproducible means of visualizing complex clinical data.</p>
</section>
<section id="practical-applications-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="practical-applications-and-future-directions">Practical Applications and Future Directions</h3>
<p>ggswim is designed to be user-friendly while offering powerful customization options. It supports various glyph formats, including emojis and certain font libraries, allowing users to create visually engaging plots. The package also includes theming functions to help users tailor their swimmer plots to specific needs.</p>
<p>While ggswim is currently focused on facilitating static visualizations suitable for publication in medical journals, the R community is keenly interested in exploring interactive capabilities. As Richard Hanna noted, future developments could include interactive features for web publication, potentially using tools like Plotly or ggiraph.</p>
<p>The ggswim package is still in its early stages, with plans to submit it to CRAN once it has been thoroughly tested and refined. The R community is encouraged to contribute feedback and suggestions to enhance the package’s functionality.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>ggswim fills a crucial gap in R’s visualization toolkit, making swimmer plots accessible to a broader audience without sacrificing the flexibility and aesthetics that ggplot2 offers. By reducing the technical overhead associated with swimmer plots, ggswim promotes effective collaboration in medical research and opens new possibilities for data visualization in R.</p>
<p>For those interested in exploring ggswim further, the package’s documentation and resources are available online. As the R community continues to innovate, tools like ggswim exemplify the power of open-source collaboration and the potential for R to transform data visualization in healthcare and beyond.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/swimmer-plots-with-ggswim/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/swimmer-plots-with-ggswim/thumbnail-swimmer-plogs-ggswim-hanna.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Unified Deep Learning Survival Analysis for Competing Risk Modeling with Functional Covariates</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/unified-deep-learning-survival-analysis-for-competing-risk-modeling-with-functional-covariates/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/aUtnSYosT2s" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="advancing-icu-patient-care-with-deep-learning-a-unified-approach-to-competing-risk-modeling" class="level1">
<h1>Advancing ICU Patient Care with Deep Learning: A Unified Approach to Competing Risk Modeling</h1>
<p>Discharging patients from the intensive care unit (ICU) is a critical step in their journey towards recovery. Yet, this transition does not eliminate the risks they continue to face, including the potential for ICU readmission or in-hospital death. These adverse outcomes not only prolong recovery but also increase healthcare costs and significantly affect the quality of life for patients. To transform post-ICU care, accurate predictive models are needed to identify at-risk patients early and customize their care to improve outcomes.</p>
<section id="the-challenge-of-icu-data" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-icu-data">The Challenge of ICU Data</h3>
<p>ICU data is inherently complex and multidimensional, encompassing demographic details, clinical information, and continuous waveform covariates such as blood pressure and respiratory rate. It also includes multiple competing risks like septic shock, ICU readmission, and mortality, with frequent instances of missing data complicating the scenario further. Traditional statistical models struggle to adequately manage these complexities, necessitating more advanced methodologies.</p>
</section>
<section id="a-new-deep-learning-framework" class="level3">
<h3 class="anchored" data-anchor-id="a-new-deep-learning-framework">A New Deep Learning Framework</h3>
<p>Yan Zou from Cleveland Clinic’s Cognitive Health Science Department presented a groundbreaking approach at R/Medicine 2025. Their research introduces a unified deep-learning framework specifically designed for competing risk analysis in ICU settings. This innovative model is built on discrete-time competing risk analysis techniques and integrates adaptive data-driven basis layers with micro neural networks for functional variables. Additionally, it employs an advanced Imputation-Regularized Optimization (IRO) method to efficiently handle missing data.</p>
<p>Unlike traditional basis representation methods that use Fourier or spline bases without leveraging outcome information during dimension reduction, this framework fully integrates outcome data, improving predictive capabilities.</p>
</section>
<section id="validating-the-model" class="level3">
<h3 class="anchored" data-anchor-id="validating-the-model">Validating the Model</h3>
<p>The model was validated using simulations and real-world ICU data from the MIMIC-4 database (over 12,000 patients) and Cleveland Clinic’s ICU records (over 25,000 patients). The results were impressive, with the deep-learning framework outperforming traditional methods in most clinical scenarios. The metrics used for validation, including the integrated Brier score and concordance index, confirmed the model’s superior predictive accuracy.</p>
</section>
<section id="key-innovations-of-the-framework" class="level3">
<h3 class="anchored" data-anchor-id="key-innovations-of-the-framework">Key Innovations of the Framework</h3>
<ol type="1">
<li><p><strong>Adaptive Basis Layer</strong>: This layer learns basis functions jointly with the survival network, tuning each basis to carry the most signal for readmission or death, rather than merely reconstructing the waveform curves.</p></li>
<li><p><strong>Imputation-Regularized Optimization (IRO)</strong>: This method treats missing data as latent parameters optimized jointly with network weights. It ensures that imputed values are both statistically sensible and clinically meaningful, enhancing predictive accuracy without relying on potentially biased imputed datasets.</p></li>
</ol>
<p>These innovations enable the model to handle complex, high-dimensional, and heterogeneous data effectively, offering robust predictions even in the presence of substantial missing data.</p>
</section>
<section id="real-world-applications-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="real-world-applications-and-future-directions">Real-World Applications and Future Directions</h3>
<p>The research team successfully demonstrated the model’s applicability across different datasets, including synthetic cohorts and real-world ICU data. Their framework showed consistent superiority in predicting ICU readmission and post-discharge deaths, proving its potential for real-world deployment.</p>
<p>Looking ahead, the team plans to expand their model’s validation across multi-center cohorts and incorporate real-time data streams for bedside risk updates. They also intend to conduct user-centered studies to enhance interpretability and facilitate clinician adoption.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>This unified deep-learning framework represents a significant advancement in ICU patient care. By enabling more precise and timely clinical decisions, it holds the promise of transforming post-ICU care and improving patient outcomes. The integration of sophisticated data analysis and machine learning techniques underscores the potential of technology to address complex healthcare challenges, paving the way for more personalized and effective patient care.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/unified-deep-learning-survival-analysis-for-competing-risk-modeling-with-functional-covariates/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/unified-deep-learning-survival-analysis-for-competing-risk-modeling-with-functional-covariates/thumbnail-unified-deep-learning-Zou.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>What to Do When Shiny Packages Don’t Fully Support Your Idea</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/what-to-do-when-shiny-packages-dont-fully-support-your-idea/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/qXa0eDy315M" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="breaking-the-limits-of-shiny-with-react.js-a-deep-dive-into-esqapp" class="level1">
<h1>Breaking the Limits of Shiny with React.js: A Deep Dive into ESQapp</h1>
<p>Anastasiia Kostiv from ESQlabs, who recently shared her insights at R/Medicine 2025 on how using React.js you can extend what Shiny apps are capable of. Her talk, “Shiny is great, but what if you need more flexibility and performance?” provides a roadmap for R developers who are looking to push the boundaries of what Shiny can offer by leveraging the power of modern web technologies.</p>
<section id="shiny-a-quick-overview" class="level2">
<h2 class="anchored" data-anchor-id="shiny-a-quick-overview">Shiny: A Quick Overview</h2>
<p>Shiny is a popular tool among R developers for building data-driven web applications. It excels in its simplicity and ability to quickly transform R scripts into interactive web apps. However, as applications grow in complexity, developers can bump into certain limitations. These include challenges with custom UI implementations, performance degradation with multiple reactive components, and a lack of support for highly interactive interfaces like spreadsheets or model editors.</p>
</section>
<section id="a-hybrid-approach-using-shiny-and-react.js-together" class="level2">
<h2 class="anchored" data-anchor-id="a-hybrid-approach-using-shiny-and-react.js-together">A Hybrid Approach: Using Shiny and React.js Together</h2>
<p>Anastasiia faced these exact challenges as she developed ESQapp, a highly interactive and scalable application. React.js is a widely used JavaScript library for building user interfaces. By utilizing the <code>reactR</code> package, Anastasiia was able to integrate React components into Shiny, combining Shiny’s robust data backend with React’s advanced UI capabilities. This hybrid approach opened up a new realm of possibilities for creating modern, responsive, and customizable web applications.</p>
<section id="why-react.js" class="level3">
<h3 class="anchored" data-anchor-id="why-react.js">Why React.js?</h3>
<p>React.js is known for its flexibility, performance, and ability to handle complex UIs. It allows developers to create reusable components, manage state efficiently, and ensure applications remain fast and responsive. By integrating React with Shiny, developers can sidestep the limitations of HTML widgets and avoid the reliance on jQuery plugins, which often require cumbersome workarounds.</p>
</section>
</section>
<section id="building-esqapp-a-case-study" class="level2">
<h2 class="anchored" data-anchor-id="building-esqapp-a-case-study">Building ESQapp: A Case Study</h2>
<p>Let’s take a closer look at how Anastasiia and her team at ESQlabs utilized React to expand Shiny’s capabilities.</p>
<section id="the-challenges" class="level3">
<h3 class="anchored" data-anchor-id="the-challenges">The Challenges</h3>
<p>As the ESQapp project grew, the team encountered several hurdles:</p>
<ul>
<li><strong>Custom UI Components</strong>: Shiny’s default components were not sufficient for the complex user interfaces required.</li>
<li><strong>Performance</strong>: The app’s performance suffered with the addition of multiple reactive components.</li>
<li><strong>Interactivity</strong>: The need for interactive features like editable tables, models, and visual editors was not supported out of the box by Shiny.</li>
</ul>
</section>
<section id="the-solution" class="level3">
<h3 class="anchored" data-anchor-id="the-solution">The Solution</h3>
<p>By integrating React.js via the <code>reactR</code> package, Anastasiia’s team was able to:</p>
<ul>
<li><strong>Create Custom Components</strong>: Develop lightweight React components, such as editable tables and model editors, that seamlessly integrate with Shiny’s reactive system.</li>
<li><strong>Improve Performance</strong>: React’s efficient rendering and state management improved the application’s responsiveness.</li>
<li><strong>Enhance Interactivity</strong>: Implement features like filterable selectors and validation logic that were previously unattainable with Shiny alone.</li>
</ul>
</section>
<section id="hands-on-table-editor-example" class="level3">
<h3 class="anchored" data-anchor-id="hands-on-table-editor-example">Hands-on Table Editor Example</h3>
<p>One of the standout components in ESQapp is the hands-on table editor. This component synchronizes with Shiny’s state using React, offering a fully reactive, fast, and customizable experience. It allows users to interact with data in a spreadsheet-like interface, delivering a modern and intuitive user experience.</p>
</section>
</section>
<section id="the-technical-setup" class="level2">
<h2 class="anchored" data-anchor-id="the-technical-setup">The Technical Setup</h2>
<p>The integration of React into Shiny involves a few key steps:</p>
<ol type="1">
<li><strong>Using Webpack</strong>: To bundle the React code efficiently.</li>
<li><strong>ReactR Package</strong>: This package wraps the compiled React output and exposes it to Shiny, allowing it to behave like any native Shiny input or output component.</li>
<li><strong>Fully Reactive System</strong>: Ensures that all components remain in sync with Shiny’s reactive data flow.</li>
</ol>
</section>
<section id="is-this-approach-right-for-your-project" class="level2">
<h2 class="anchored" data-anchor-id="is-this-approach-right-for-your-project">Is This Approach Right for Your Project?</h2>
<p>While extending Shiny with React.js offers tremendous benefits, it may not be suitable for every project. If your application requires advanced UI features, improved performance, and your team possesses React or front-end experience, this approach could be useful. However, for simpler applications, Shiny alone might suffice.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Anastasiia’s talk at R/Medicine 2025 underscores the potential of combining Shiny with modern web technologies like React.js. By thinking outside the box and embracing the flexibility of React, developers can extend Shiny to build powerful, beautiful, and responsive applications.</p>
<p>For those interested in exploring this approach, Anastasiia encourages you to check out a real-life example of ESQapp and see the integration in action. There is a QR code in the session video or the repo is available here: <a href="https://esqlabs.github.io/ESQapp/">https://esqlabs.github.io/ESQapp/</a></p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/what-to-do-when-shiny-packages-dont-fully-support-your-idea/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/what-to-do-when-shiny-packages-dont-fully-support-your-idea/thumbnail-shiny-packages-kostiv.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>{redquack}: An R Package for Memory Efficient REDCap-to-DuckDB Workflows</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/PWLRL0R7s3Y" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="breaking-through-memory-limitations-in-redcap-introducing-the-redquack-package" class="level1">
<h1>Breaking Through Memory Limitations in REDCap: Introducing the {redquack} Package</h1>
<p>In today’s data-driven healthcare environment, managing large datasets efficiently is crucial. The REDCap platform, a free electronic health record software, is widely used by over 7,000 institutions across the globe. Its ability to handle complex, longitudinal data and support multiple instruments or assessments makes it a favored choice for clinical research. However, with the exponential growth of data, researchers often encounter memory constraints when trying to extract and analyze vast amounts of information.</p>
<p>Dylan Pieper from the University of Pittsburgh addressed this challenge head-on at the R/Medicine 2025 conference. His innovative solution, the {redquack} package, is designed to optimize data workflows between REDCap and DuckDB, providing a memory-efficient alternative for processing large datasets.</p>
<section id="the-challenge-of-handling-large-datasets-in-redcap" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-of-handling-large-datasets-in-redcap">The Challenge of Handling Large Datasets in REDCap</h2>
<p>At the School of Pharmacy, University of Pittsburgh, data scientists manage a REDCap database containing clinical data from over 200 outpatient treatment centers. This database is extensive, with nearly 3 million rows across 400 columns. Such large datasets pose a significant challenge when using traditional methods like the {REDCapR} package, which attempts to load all data into memory, often resulting in failures due to hardware limitations.</p>
<p>REDCap stores its data using a MySQL backend, which is typically managed by an institution’s IT department. Direct interfacing with this database is not recommended, pushing researchers to rely on APIs and packages to access the data. However, as datasets grow, these methods become inefficient and sometimes infeasible.</p>
</section>
<section id="the-redquack-package-a-solution-for-seamless-data-extraction" class="level2">
<h2 class="anchored" data-anchor-id="the-redquack-package-a-solution-for-seamless-data-extraction">The {redquack} Package: A Solution for Seamless Data Extraction</h2>
<p>The {redquack} package emerged as a solution to these memory constraints by leveraging the power of DuckDB, a fast and portable SQL database management system. DuckDB’s columnar storage format makes it particularly suited for large-scale data processing, allowing data to be stored outside of R’s memory.</p>
<p>The package introduces a novel batch processing approach to data extraction. By breaking down data into manageable chunks, researchers can efficiently process portions of the dataset without ever exceeding memory limits. This method involves:</p>
<ol type="1">
<li><strong>Batch Processing</strong>: Data is extracted in configurable batches of record IDs, minimizing memory usage.</li>
<li><strong>Column Optimization</strong>: The package automatically optimizes column types across batches, enhancing query performance.</li>
<li><strong>Detailed Logging</strong>: Users can track extraction progress through comprehensive logs, aiding in debugging and process monitoring.</li>
<li><strong>Integration with Tidyverse</strong>: The resulting DuckDB connection can be seamlessly integrated with tidyverse workflows, allowing analysts to use familiar dplyr syntax for data manipulation.</li>
</ol>
</section>
<section id="practical-implementation-and-benefits" class="level2">
<h2 class="anchored" data-anchor-id="practical-implementation-and-benefits">Practical Implementation and Benefits</h2>
<p>Using {redquack} is straightforward. Researchers need to provide their REDCap API credentials and configuration preferences to the <code>redcap_to_duckdb()</code> function. This function handles the extraction process, and the resulting DuckDB connection can be immediately utilized for data analysis.</p>
<p>The package includes several quality-of-life features, such as sound notifications (a “quack” on success) for long-running operations. This user-friendly approach empowers researchers to work with datasets that exceed memory constraints without compromising their existing workflows.</p>
</section>
<section id="real-world-applications-at-the-university-of-pittsburgh" class="level2">
<h2 class="anchored" data-anchor-id="real-world-applications-at-the-university-of-pittsburgh">Real-World Applications at the University of Pittsburgh</h2>
<p>Dylan Pieper’s presentation showcased practical examples from the School of Pharmacy, where the {redquack} package has streamlined the data pipeline from REDCap to analysis. By eliminating memory constraints, the package has enabled clinical researchers, data scientists, and analysts to work more efficiently with large datasets. This is particularly beneficial for those handling complex, multi-form projects or longitudinal studies where traditional extraction methods fall short.</p>
<p>The package is designed to be scalable and consistent, ensuring reliable data exports as projects grow in size. While it currently focuses on data reading, there is potential for future enhancements, such as supporting additional database drivers and expanding its capabilities.</p>
</section>
<section id="a-collaborative-future" class="level2">
<h2 class="anchored" data-anchor-id="a-collaborative-future">A Collaborative Future</h2>
<p>The development of {redquack} highlights the importance of collaboration within the R community. By sharing insights and innovations, researchers can collectively overcome the challenges posed by large-scale data management. The package is available on CRAN and GitHub, inviting contributions and feedback from the wider community.</p>
<p>As REDCap continues to evolve, tools like {redquack} will play a pivotal role in ensuring that researchers can harness the full potential of their data without being hindered by technical limitations. Dylan Pieper’s work is a testament to the power of open-source collaboration and the continuous drive for innovation within the R ecosystem.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/</guid>
  <pubDate>Sat, 21 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/redquack-an-r-package-for-memory-efficient-redcap-to-duckdb-workflows/thumbnail-redquack.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>AOUSDOHtools: R Package for Social Determinants of Health Survey data in All of Us Research Program</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nQum-dWBM3I" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unraveling-the-aousdohtools-package-empowering-research-in-social-determinants-of-health" class="level1">
<h1>Unraveling the AOUSDOHtools Package: Empowering Research in Social Determinants of Health</h1>
<p>Hello, R community! Today we dive into the innovative R package, AOUSDOHtools, designed to streamline the analysis of Social Determinants of Health (SDOH) data. This package, presented by Zhirui Deng, a biostatistician from the University of Pittsburgh School of Nursing, is a game-changer for researchers working within the All of Us Research Program. Let’s explore how this tool enhances research efforts in health equity.</p>
<section id="understanding-the-all-of-us-research-program" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-all-of-us-research-program">Understanding the All of Us Research Program</h2>
<p>The All of Us Research Program, an initiative by the National Institutes of Health (NIH), aims to gather comprehensive data from over a million participants across the United States. This vast data collection includes health records, lab results, and survey responses, focusing significantly on health equity by enrolling participants traditionally underrepresented in research. The diversity and complexity of this data present unique challenges, particularly when it comes to analyzing SDOH data.</p>
</section>
<section id="challenges-with-sdoh-data" class="level2">
<h2 class="anchored" data-anchor-id="challenges-with-sdoh-data">Challenges with SDOH Data</h2>
<p>SDOH surveys collect detailed information on non-clinical factors impacting health, such as housing, education, stress, and social support. While invaluable, this data often comes in a raw, messy format, spread across multiple rows per participant, and lacking a built-in scoring system. Researchers face the daunting task of manually cleaning and computing these variables for analysis, a process fraught with potential inconsistencies.</p>
</section>
<section id="introducing-aousdohtools-the-r-package" class="level2">
<h2 class="anchored" data-anchor-id="introducing-aousdohtools-the-r-package">Introducing AOUSDOHtools: The R Package</h2>
<p>To address these challenges, Dre Dong and the team developed the AOUSDOHtools R package. This tool automates the entire process of recoding, scoring, and outputting clean, personal variables ready for analysis. Based on a user guide by Dr.&nbsp;Koleck and colleagues (2024), the package standardizes scoring logic across 14 SDOH constructs, such as Neighborhood Cohesion, Social Support, and Perceived Stress.</p>
<p>The package operates seamlessly within the All of Us Researcher Workbench, a secure cloud-based platform. It supports both RStudio and Jupyter environments, ensuring flexibility and ease of use for researchers. The package’s vibrant hex sticker, featuring symbols of housing, education, food, and income, embodies key SDOH components and adds a touch of whimsy for sticker enthusiasts.</p>
</section>
<section id="how-aousdohtools-works" class="level2">
<h2 class="anchored" data-anchor-id="how-aousdohtools-works">How AOUSDOHtools Works</h2>
<p>The package includes 30 functions for scoring 14 constructs across various SDOH domains, such as Neighborhood Cohesion, Neighborhood Disorder, Food Insecurity, Housing Insecurity, and Housing Quality. Each construct is thoughtfully organized, with some offering sub-scores for more granular analysis.</p>
<p>The workflow is simple: load the package and your SDOH survey data, and call one of the scoring functions like <code>calculate_cohesion</code> or <code>calculate_disorder</code>. The function outputs a tidy dataset—one row per person with the computed score. This straightforward process eliminates the need for manual data wrangling, allowing researchers to focus on analysis.</p>
</section>
<section id="a-peek-inside-the-scoring-functions" class="level2">
<h2 class="anchored" data-anchor-id="a-peek-inside-the-scoring-functions">A Peek Inside the Scoring Functions</h2>
<p>Take, for instance, the <code>calculate_cohesion</code> function. It extracts neighborhood-related questions, maps responses from “strongly agree” to “strongly disagree,” averages them, and returns a clean cohesion score for each participant. This automation relieves researchers from the burden of writing complex scoring algorithms, promoting consistency and reproducibility.</p>
</section>
<section id="staying-current-and-collaborative" class="level2">
<h2 class="anchored" data-anchor-id="staying-current-and-collaborative">Staying Current and Collaborative</h2>
<p>Released on March 26 and available on CRAN and GitHub, AOUSDOHtools is continuously updated to reflect changes in the All of Us platform. The development team welcomes feedback, feature requests, and collaboration ideas via email or GitHub issues. This open development approach fosters a thriving research community.</p>
</section>
<section id="why-aousdohtools-matters" class="level2">
<h2 class="anchored" data-anchor-id="why-aousdohtools-matters">Why AOUSDOHtools Matters</h2>
<p>By making SDOH data easier to use, share, and reproduce, AOUSDOHtools lays the groundwork for robust research in health equity. The package empowers researchers to explore how social factors like living conditions and social support influence health outcomes, aligning with the All of Us program’s mission.</p>
<p>Researchers can become registered All of Us researchers, access the survey data via the Researcher Workbench, and install the package from CRAN or GitHub. This accessibility encourages diverse research efforts and collaborations within the R community.</p>
</section>
<section id="engage-with-aousdohtools" class="level2">
<h2 class="anchored" data-anchor-id="engage-with-aousdohtools">Engage with AOUSDOHtools</h2>
<p>For those eager to contribute, the development team appreciates input via GitHub issues or direct email communication. They are open to feedback and committed to refining the package to meet the evolving needs of the research community.</p>
<p>In conclusion, AOUSDOHtools is a testament to the power of R in advancing research on social determinants of health. It simplifies complex data processes, enabling researchers to focus on impactful analyses and contribute to the broader goal of health equity. Thanks to Dre Dong and the development team for their dedication to this vital work.</p>
<p>For more information and to explore the package, visit the <a href="https://github.com/zhd52/AOUSDOHtools">GitHub repository</a> or <a href="https://cran.r-project.org/package=AOUSDOHtools">CRAN page</a>.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/aousdohtools-r-package-for-social-determinants-of-health-survey-data-in-all-of-us-research-program/thumbnail-AOUSDOHtools-deng.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Examining Factors Associated with Depressive Severity Among Cancer Survivors</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4vQJghIanQg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="understanding-the-psychological-burden-of-cancer-insights-into-depressive-symptoms-among-survivors" class="level1">
<h1>Understanding the Psychological Burden of Cancer: Insights into Depressive Symptoms Among Survivors</h1>
<p>Cancer, a formidable adversary in the realm of health, extends its profound impact beyond the physical, creeping into the psychological well-being of those it touches. The study presented by Andre Williams from the Christine E. Lynn College of Nursing at Florida Atlantic University, at R/Medicine 2025, dives deeply into this often overshadowed aspect of cancer survivorship—depression. This comprehensive analysis offers invaluable insights into the mental health challenges faced by cancer patients and survivors and underscores the need for integrated care models that address both physical and mental health.</p>
<section id="the-psychological-toll-of-cancer" class="level2">
<h2 class="anchored" data-anchor-id="the-psychological-toll-of-cancer">The Psychological Toll of Cancer</h2>
<p>Cancer survivors face a multitude of challenges that encompass the physical, emotional, and financial spectrums. While advancements in detection and treatment have increased survival rates, they have also prolonged the duration of living with the disease and its psychological ramifications. Among these, depression stands out as a significant concern, affecting not just the quality of life but also treatment adherence, physical health outcomes, and mortality rates. Cancer patients are particularly susceptible to depression due to a complex interplay of physiological and psychological factors.</p>
</section>
<section id="exploring-the-correlates-of-depression-in-cancer-survivors" class="level2">
<h2 class="anchored" data-anchor-id="exploring-the-correlates-of-depression-in-cancer-survivors">Exploring the Correlates of Depression in Cancer Survivors</h2>
<p>Despite the established link between cancer and depression, there remains a critical need to explore the specific demographic, socioeconomic, and health-related factors contributing to this mental health burden. Previous research, often limited by smaller sample sizes, has struggled to generalize findings across the broader U.S. cancer survivor population. Addressing this gap, Williams and his team leveraged the National Health Interview Survey (NHIS) data, a robust, nationally representative resource, to examine these factors.</p>
<section id="research-methodology" class="level3">
<h3 class="anchored" data-anchor-id="research-methodology">Research Methodology</h3>
<p>The study utilized NHIS data from 2022, focusing on individuals who reported a cancer diagnosis. The primary research question aimed to uncover the demographic, socioeconomic, and health-related factors associated with increased depressive symptomatology among these individuals. Depressive symptomatology was measured using the Patient Health Questionnaire-8 (PHQ-8), with a score of 10 or higher indicating moderate or greater depressive symptoms.</p>
<p>For the analysis, various R packages, including <code>survey</code>, <code>tidyverse</code>, <code>modelsummary</code>, and <code>data.table</code>, were employed. The team conducted survey logistic regression to evaluate the associations between depressive symptoms and various independent variables.</p>
</section>
<section id="key-findings" class="level3">
<h3 class="anchored" data-anchor-id="key-findings">Key Findings</h3>
<p>The analysis revealed several significant associations with moderate or greater depressive symptoms among cancer survivors:</p>
<ul>
<li><strong>Socioeconomic Factors</strong>: Poverty, lower levels of education, and lack of private health insurance were significantly associated with increased depressive symptoms, highlighting the impact of financial and educational disparities on mental health.</li>
<li><strong>Demographic Factors</strong>: Female gender, younger age, and living alone were demographic variables linked to heightened depressive symptoms, suggesting a greater vulnerability among certain groups.</li>
<li><strong>Healthcare Access and Utilization</strong>: Delays in care, unmet care needs due to cost, frequent emergency visits, and overnight hospitalizations were associated with increased depressive symptoms. These findings underscore the importance of accessible and affordable healthcare in addressing mental health issues.</li>
<li><strong>Co-occurring Conditions</strong>: Mild or greater anxiety symptomatology was significantly associated with increased depressive symptoms, emphasizing the interconnectedness of mental health conditions.</li>
</ul>
</section>
</section>
<section id="implications-for-healthcare-practice" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-healthcare-practice">Implications for Healthcare Practice</h2>
<p>The study’s findings have crucial implications for healthcare practice:</p>
<ol type="1">
<li><p><strong>Targeted Screening and Intervention</strong>: Routine use of validated tools like PHQ-8 or PHQ-9 for assessing depression is vital, alongside considering broader social determinants of health in patient evaluations.</p></li>
<li><p><strong>Holistic Support</strong>: Interventions should address not only psychological needs but also socioeconomic factors and healthcare access issues, advocating for a comprehensive approach to patient support.</p></li>
<li><p><strong>Integrated Care Models</strong>: Incorporating mental health support into oncology care is essential to ensure mental health is recognized and addressed as a vital component of cancer treatment and survivorship.</p></li>
</ol>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>As the discussion concluded, the need for further research was highlighted, including the potential to extend the study to pediatric cancer patients and include a control group for comparison. Such future endeavors would enrich the understanding of depressive symptoms in cancer survivors and inform targeted interventions.</p>
<p>This study, leveraging the power of R for data analysis, exemplifies the critical role of large-scale public health datasets in understanding the psychosocial challenges faced by cancer survivors. By integrating mental health considerations into cancer care, we can guide clinical decision-making and develop precision mental health interventions within oncology settings.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/examining-factors-associated-with-depressive-severity-among-cancer-survivors/thumbnail-examining-factors-williams.png" medium="image" type="image/png" height="81" width="144"/>
</item>
</channel>
</rss>
