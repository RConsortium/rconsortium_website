<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>R Consortium</title>
<link>https://r-consortium.org/blog/</link>
<atom:link href="https://r-consortium.org/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.7.33</generator>
<lastBuildDate>Tue, 29 Jul 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Julia Silge on Fostering a Technical, Inclusive R Community in Salt Lake City</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/</link>
  <description><![CDATA[ 





<p><a href="https://www.linkedin.com/in/juliasilge/">Julia Silge</a>, co-organizer of the <a href="https://www.meetup.com/slc-rug/">Salt Lake City R User Group</a>, recently talked to the R Consortium about sustaining an active R community in a region without a central tech hub. Julia shared how she discovered R and became deeply engaged with its open-source ecosystem. She discussed the group’s dual-format meetups, which include remote talks streamed via YouTube and quarterly in-person gatherings, as well as efforts to make the community inclusive for both local professionals and a wider audience. She also highlighted a recent session on advanced Git practices and an upcoming talk on sparse data structures in the tidymodels framework.</p>
<p><img src="https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/JuliaSilge.png" class="img-fluid"></p>
<section id="please-share-your-background-and-involvement-with-the-rugs-group." class="level2">
<h2 class="anchored" data-anchor-id="please-share-your-background-and-involvement-with-the-rugs-group.">Please share your background and involvement with the RUGS group.</h2>
<p>My academic background is in physics and astronomy. About ten years ago, I transitioned from a more academic career into data science, and that’s when I first discovered R. I wasn’t very familiar with it; I had only heard about it in passing. The aspects of R that immediately appealed to me were its functional approach to data analysis and its programming style, which has a Lispy flavor.</p>
<p>The R community played a significant role in my identifying it as a tool that was a good fit for me. This included engaging with the open-source community and contributing to open-source projects early in my R journey. Additionally, I became connected with groups such as R-Ladies, although there isn’t an R-Ladies chapter in my local city. I started attending a local RUG meetup around ten years ago in my town.</p>
<p>My city is a smaller US city—it’s not on the coasts and doesn’t have a large tech scene like the Bay Area. Finding people here to connect with and discuss our work was incredibly valuable for me.</p>
</section>
<section id="can-you-share-what-the-r-community-is-like-in-salt-lake-city" class="level2">
<h2 class="anchored" data-anchor-id="can-you-share-what-the-r-community-is-like-in-salt-lake-city">Can you share what the R community is like in Salt Lake City?</h2>
<p>Our city is significantly influenced by the presence of a large university, which serves as a significant hub for research, especially in the life sciences. A substantial number of people associated with the university contribute to the local community. Additionally, outside of the university, professionals work at healthcare systems, including the VA hospital, which serve the entire region.</p>
<p>Several life science startups in the area focus on drug discovery and other health science initiatives. Many individuals involved in these startups have university backgrounds, although they are no longer directly affiliated with their respective institutions. The use of R programming is quite prevalent in these environments.</p>
<p>Overall, our community is shaped not only by those engaged in pure research but also by entrepreneurs and professionals who apply their knowledge, especially in the field of health sciences, creating a dynamic intersection between academia and industry.</p>
</section>
<section id="do-you-host-online-or-in-person-meetups" class="level2">
<h2 class="anchored" data-anchor-id="do-you-host-online-or-in-person-meetups">Do you host online or in-person meetups?</h2>
<p>We try to have a meeting most months, although we slow down a bit during the summer. There are two types of meetings we hold. The first type features a speaker who gives a talk. Since the pandemic began, we have been hosting these talks remotely via Zoom, rather than in person. We’ve found that this format works very well, allowing us to connect with people from all over, not just those in the Salt Lake area.</p>
<p>These meetings are scheduled during lunchtime in our local time zone, allowing those of us in the area to take a break from work and join in to hear and learn about various topics. For our attendees in European time zones, the talks take place in the evening, which has worked out nicely.</p>
<p>The second type of meeting we have is an in-person gathering that occurs about once a quarter. There isn’t a speaker for these events; instead, we focus on networking and casual conversations about what everyone is working on. These in-person meetings are only for residents of our city.</p>
<p>Overall, this balance is working well for us. The online talks, which are also streamed to <a href="https://www.youtube.com/@slcrug/streams">YouTube</a>, make it easy for people to watch later if they’re interested. You can find all our recent discussions under the “Live” section on our channel. Meanwhile, the in-person meetings allow for valuable face-to-face interactions among local attendees.</p>
</section>
<section id="please-tell-us-about-the-organizing-team." class="level2">
<h2 class="anchored" data-anchor-id="please-tell-us-about-the-organizing-team.">Please tell us about the organizing team.</h2>
<p>Currently, <a href="https://www.linkedin.com/in/andrew-redd-202b5736/">Andrew Redd</a> and I are the only ones involved in organizing. We’ve had a few other people who have joined at various times but ultimately stepped away. Andrew was part of the team before I joined, back when he was at the university. Initially, our meetings took place on campus, but that posed challenges for those who didn’t work at the university. It was difficult to navigate, especially for newcomers who weren’t familiar with where to go and where to park.</p>
<p>About seven or eight years ago, we decided to switch to using Meetup, allowing us to meet in different locations around the city that are more accessible for those who work downtown or aren’t on campus all day. I started helping with organizing the events around the same time.</p>
<p>We’ve done reasonably well in terms of consistency, although we don’t have events every single month. We typically aim for most months, although we often take December and January off and slow down a bit in the summer. We strive to host either a talk or a networking event during those months, providing an opportunity for us to get together and connect.</p>
</section>
<section id="please-tell-us-about-a-recent-or-upcoming-event-from-your-group." class="level2">
<h2 class="anchored" data-anchor-id="please-tell-us-about-a-recent-or-upcoming-event-from-your-group.">Please tell us about a recent or upcoming event from your group.</h2>
<p>We have two upcoming meetings scheduled! For our discussion today, I’ll highlight one event that took place in the past, so people can watch the video, and one that is coming up for anyone who wants to join us.</p>
<p>Recently, we held a <a href="https://www.youtube.com/watch?v=IEAEvcnA9Hs">meetup in May</a>, with our primary focus on improving <a href="https://www.meetup.com/slc-rug/events/304955799/">Git practices</a>. We often find ourselves familiar only with the basic commands in Git—such as committing, pushing, and pulling—but there’s much more we can learn. The talk centered on enhancing our Git skills and strategies for troubleshooting difficult situations, which is something many of us struggle with.</p>
<p>The session was well-attended, and participants appreciated the practical skills shared during the event. It was a great example of how our group aims to provide applied knowledge that is genuinely useful.</p>
<p>Looking ahead, we have another exciting talk scheduled for the end of July. This presentation will delve into how we think about our data, specifically concerning data structures. We’ll explore the concept of <a href="https://www.meetup.com/slc-rug/events/307528267/">sparse data structures</a>, which are particularly common in machine learning contexts.</p>
<p>For instance, with text data, certain words are used frequently while many others appear only a few times. This creates sparse data structures, where the majority of elements in a matrix are zero. Often, we don’t consider how our data is represented, but understanding this is crucial.</p>
<p>This upcoming talk will explain how sparse data structures are integrated into the tidymodels framework, emphasizing the efficiency gains that can be achieved. By using sparse data structures, we can handle larger models that might otherwise be impossible to train on a standard computer due to memory constraints. I’m looking forward to this informative session!</p>
<p><img src="https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/SaltLakeCityOnlineMeetup.png" class="img-fluid"></p>
</section>
<section id="any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future" class="level2">
<h2 class="anchored" data-anchor-id="any-techniques-you-recommend-using-for-planning-for-or-during-the-event-github-zoom-other-can-these-techniques-be-used-to-make-your-group-more-inclusive-to-people-that-are-unable-to-attend-physical-events-in-the-future">Any techniques you recommend using for planning for or during the event? (Github, zoom, other) Can these techniques be used to make your group more inclusive to people that are unable to attend physical events in the future?</h2>
<p>A good approach for us is to block out time for planning. Instead of trying to plan every single month, we can dedicate time to creating a plan that covers the next four or five months. We always strive to highlight local speakers from the Salt Lake area, but not all of our speakers are local. So, we’ll consider who from our community has done something interesting recently.</p>
<p>Additionally, we keep an eye out for interesting blog posts that inspire potential speakers. Our group is very friendly and open, providing an excellent opportunity for members to present initial versions of talks they’re working on. If someone has a critical conference approaching, we often invite them to give a practice version of their presentation here before they present at a larger event. This setup is beneficial for both our group and the speaker.</p>
<p>We also stream our presentations on YouTube, making it easy for speakers to have a video link of their talk. If someone has a blog post they’ve created, we can help them by providing a video version of their work to share with their audience.</p>
<p>To sum up, some helpful techniques we use include planning for four to five months at a time, sending out emails to potential speakers, and considering topics based on our work or interesting discussions we’ve had. Lastly, we aim to find individuals who could benefit from practice opportunities or who want to share their work. These are some of the techniques we employ.</p>
</section>
<section id="how-do-i-build-an-r-user-group" class="level2">
<h2 class="anchored" data-anchor-id="how-do-i-build-an-r-user-group">How do I Build an R User Group?</h2>
<p>R Consortium’s R User Group and Small Conference Support Program (RUGS) provides grants to help R groups organize, share information, and support each other worldwide. We have given grants over the past four years, encompassing over 76,000 members in over 90 user groups in 39 countries. We would like to include you! Cash grants and meetup.com accounts are awarded based on the intended use of the funds and the amount of money available to distribute</p>
<p><a href="https://r-consortium.org/all-projects/rugsprogram.html">https://r-consortium.org/all-projects/rugsprogram.htm</a></p>


</section>

 ]]></description>
  <category>RUGS</category>
  <category>North America</category>
  <guid>https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/</guid>
  <pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/julia-silge-on-fostering-a-technical-inclusive-r-community-in-salt-lake-city/JuliaSilge-main-image.png" medium="image" type="image/png" height="95" width="144"/>
</item>
<item>
  <title>R for Health Technology Assessment (HTA): Identifying Needs, Streamlining Processes, Building Bridges</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/r-for-health-technology-assessment-hta-identifying-needs-streamlining-processes-building-bridges/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/CwCMO9D0mjE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The Health Technology Assessment (HTA) working group within the R Consortium <a href="https://r-consortium.org/posts/health-technology-assessment-hta-working-group-kickoff-meeting/index.html">was established</a> to support the use of R in HTA across academia, industry, and government authorities. This initiative aims to address key unmet needs in the field by mapping stakeholders, understanding processes, and identifying automatable streams.</p>
<p>The R Consortium’s commitment to supporting these initiatives is crucial in driving the adoption and development of R-based solutions in HTA. As the community continues to engage in discussions and contribute to the working group’s efforts, the vision of a unified, open-source approach to HTA analytics becomes increasingly attainable.</p>
<p>The recent webinar titled “R for Health Technology Assessment (HTA): Identifying Needs, Streamlining Processes, Building Bridges” provided valuable insights from experts in the field.</p>
<section id="the-role-of-r-in-health-economics" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-r-in-health-economics">The Role of R in Health Economics</h2>
<p>Rose Hart, Director and Health Economist at Dark Peak Analytics, emphasized the potential of R in health economics. She highlighted several advantages of adopting R, including:</p>
<ul>
<li>End-to-End Modeling: R allows for seamless updates in data, automatically reflecting changes throughout the economic calculations and reports without manual copying and pasting.<br>
</li>
<li>Version Control: R’s centralized model ensures consistency in country-specific adaptations, avoiding the pitfalls of outdated or incorrect versions.<br>
</li>
<li>Complex Functionality: Open-source R models invite scrutiny and improvement, enhancing transparency and trust.</li>
</ul>
<p>Despite these advantages, Rose acknowledged challenges such as unfamiliarity with R and entrenched Excel usage due to convenience and habit. She advocated for increased R uptake and collaboration across the industry to align priorities and create comprehensive guidelines for R model documentation and review.</p>
</section>
<section id="streamlining-hta-processes-with-r" class="level2">
<h2 class="anchored" data-anchor-id="streamlining-hta-processes-with-r">Streamlining HTA Processes with R</h2>
<p>Christian Haargaard Olsen from Novo Nordisk shared insights on streamlining HTA processes using R. He discussed the potential of R to improve efficiency and reduce duplication of efforts across the European Union (EU) HTA submissions. Christian drew parallels with the success of the Pharmaverse initiative in regulatory clinical reporting, highlighting the potential for R to achieve similar success in HTA.</p>
<p>Christian emphasized the need for a more orchestrated approach in the HTA space, potentially allowing for a faster transition from start to finish. He also pointed out the importance of defining data extraction interfaces, ensuring that AI or other tools can integrate seamlessly with R-based workflows.</p>
</section>
<section id="automating-hta-processes-challenges-and-opportunities" class="level2">
<h2 class="anchored" data-anchor-id="automating-hta-processes-challenges-and-opportunities">Automating HTA Processes: Challenges and Opportunities</h2>
<p>Karolin Struck from SmartStep provided a detailed overview of the JCA HTA process, highlighting challenges and opportunities for automation. She outlined the complexity of managing multiple PICO scenarios and emphasized the need for early access to study data and updated data cuts.</p>
<p>Karolin identified key challenges and pain points, such as the large number of analyses required for different PICO scenarios and the need for automation to handle frequent changes in output formats. She stressed the importance of standardizing input and output formats to facilitate collaboration across teams and vendors.</p>
</section>
<section id="leveraging-ai-and-r-in-hta" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-ai-and-r-in-hta">Leveraging AI and R in HTA</h2>
<p>The discussion also touched on the intersection of AI and R in HTA. While AI can assist in programming and data extraction, challenges remain in ensuring reliability and completeness of results. The speakers recognized the complementary roles of AI and R, suggesting that a well-defined data structure can facilitate integration with various tools, regardless of the underlying technology.</p>
</section>
<section id="conclusion-building-bridges-in-hta-with-r" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-building-bridges-in-hta-with-r">Conclusion: Building Bridges in HTA with R</h2>
<p>The webinar underscored the potential of R to transform HTA processes, enhancing efficiency, transparency, and collaboration. By addressing key challenges and fostering a culture of open-source collaboration, the HTA working group aims to build bridges across academia, industry, and authorities.</p>
<p>The HTA working group will take the interactions and knowledge gained to focus and refine a strategy for standardization or automation and incorporate it as a part of the HTA process. If you are interested in joining our working group, please contact us!</p>
<p>For those interested in joining the conversation and contributing to the HTA working group, visit the <a href="https://github.com/RConsortium/HTA-wg">R Consortium’s HTA Working Group repository</a> and explore opportunities for collaboration. The <a href="https://youtu.be/CwCMO9D0mjE?feature=shared">full webinar video - with Q&amp;A session at the end - is available here</a>.</p>


</section>

 ]]></description>
  <category>Events</category>
  <category>Working Groups</category>
  <guid>https://r-consortium.org/posts/r-for-health-technology-assessment-hta-identifying-needs-streamlining-processes-building-bridges/</guid>
  <pubDate>Fri, 11 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/r-for-health-technology-assessment-hta-identifying-needs-streamlining-processes-building-bridges/hta-main-image.png" medium="image" type="image/png" height="72" width="144"/>
</item>
<item>
  <title>R+AI Call for Proposals</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/r_plus_ai_call_for_proposals/</link>
  <description><![CDATA[ 





<p><img src="https://r-consortium.org/posts/r_plus_ai_call_for_proposals/CFP_now_open.png" class="img-fluid"></p>
<section id="call-for-proposals" class="level3">
<h3 class="anchored" data-anchor-id="call-for-proposals">Call for Proposals</h3>
<p>Join us at <strong>R+AI 2025</strong>, our inaugural conference dedicated to the open-source R community and every facet of artificial intelligence. Whether you’re just getting started with machine learning, experimenting with large language models in R, leveraging GenAI tools to accelerate your code, part of an industry team deploying AI solutions in finance, healthcare, or marketing, or a researcher pushing the boundaries of deep learning or responsible AI—there’s something here for you. Experience inspiring keynotes and talks, hands-on workshops, lightning talks, and panel discussions designed to educate, connect, and empower R users at every level.</p>
<section id="submit-your-proposal-here" class="level4">
<h4 class="anchored" data-anchor-id="submit-your-proposal-here"><a href="https://forms.gle/SUbQVNMpp11g7vbTA">Submit your proposal here</a></h4>
</section>
</section>
<section id="cfp-dates-open-7102025---closes-09052025" class="level2">
<h2 class="anchored" data-anchor-id="cfp-dates-open-7102025---closes-09052025">CFP dates: OPEN 7/10/2025 - CLOSES: 09/05/2025</h2>
<p>We are now inviting proposals for talks and workshops in all these areas:</p>
<div class="cell">
<div class="cell-output-display">
<div id="ldnnfqojew" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#ldnnfqojew table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#ldnnfqojew thead, #ldnnfqojew tbody, #ldnnfqojew tfoot, #ldnnfqojew tr, #ldnnfqojew td, #ldnnfqojew th {
  border-style: none;
}

#ldnnfqojew p {
  margin: 0;
  padding: 0;
}

#ldnnfqojew .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ldnnfqojew .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#ldnnfqojew .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ldnnfqojew .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ldnnfqojew .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ldnnfqojew .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ldnnfqojew .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ldnnfqojew .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ldnnfqojew .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ldnnfqojew .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ldnnfqojew .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ldnnfqojew .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ldnnfqojew .gt_spanner_row {
  border-bottom-style: hidden;
}

#ldnnfqojew .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#ldnnfqojew .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ldnnfqojew .gt_from_md > :first-child {
  margin-top: 0;
}

#ldnnfqojew .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ldnnfqojew .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ldnnfqojew .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ldnnfqojew .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ldnnfqojew .gt_row_group_first td {
  border-top-width: 2px;
}

#ldnnfqojew .gt_row_group_first th {
  border-top-width: 2px;
}

#ldnnfqojew .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ldnnfqojew .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ldnnfqojew .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ldnnfqojew .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ldnnfqojew .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ldnnfqojew .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ldnnfqojew .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#ldnnfqojew .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ldnnfqojew .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ldnnfqojew .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ldnnfqojew .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ldnnfqojew .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ldnnfqojew .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ldnnfqojew .gt_left {
  text-align: left;
}

#ldnnfqojew .gt_center {
  text-align: center;
}

#ldnnfqojew .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ldnnfqojew .gt_font_normal {
  font-weight: normal;
}

#ldnnfqojew .gt_font_bold {
  font-weight: bold;
}

#ldnnfqojew .gt_font_italic {
  font-style: italic;
}

#ldnnfqojew .gt_super {
  font-size: 65%;
}

#ldnnfqojew .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#ldnnfqojew .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ldnnfqojew .gt_indent_1 {
  text-indent: 5px;
}

#ldnnfqojew .gt_indent_2 {
  text-indent: 10px;
}

#ldnnfqojew .gt_indent_3 {
  text-indent: 15px;
}

#ldnnfqojew .gt_indent_4 {
  text-indent: 20px;
}

#ldnnfqojew .gt_indent_5 {
  text-indent: 25px;
}

#ldnnfqojew .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#ldnnfqojew div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="2" class="gt_heading gt_title gt_font_normal gt_bottom_border">R+AI 2025 Call for Proposals: Technical Areas</th>
</tr>
<tr class="gt_col_headings even">
<th id="Topic" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Topic</th>
<th id="Title-and-Description" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" style="font-weight: bold" scope="col">Title and Description</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_center" headers="Topic">1</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Foundations of AI &amp; ML in R</strong><br>Tutorials and primers that help R users grasp core concepts, algorithms, and the modern R toolchain for GenAI, machine learning and deep learning.</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Topic">2</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Using large-language models inside R</strong><br>E.g., packages and tools that help you call LLMs from R, prompt engineering for data science, how LLM conversations work.</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Topic">3</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>AI-assisted Development for R</strong><br>E.g., techniques and tools, Shiny Assistant, RStudio plug ins, comparison of different model capabilities.</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Topic">4</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Machine learning &amp; Deep Learning in R</strong><br>Education about popular R packages, workflows and toolchains, what sorts of problems they apply to, how and when to use them. Introduction to new R packages or algorithms.</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Topic">5</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Industry Case Studies: R+AI in Action</strong><br>Applications of GenAI, ML and DL using R across Finance, healthcare, marketing, manufacturing, research labs, and more—real-world success stories and lessons learned.</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Topic">6</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Responsible, Fair &amp; Explainable AI + Governance with R</strong><br>Model interpretability, reproducibility, bias detection, privacy-preserving ML, governance and ethics for the use of R+AI.</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Topic">7</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>AIOps/MLOps &amp; Production Deployment with R</strong><br>Frameworks, toolchains and techniques for putting AI/ML into production. Case studies on successful deployments and lessons learned are also welcome.</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Topic">8</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Future Trends &amp; Research Frontiers for R+AI</strong><br>E.g., Emerging Models &amp; Architectures, Auto-Data Science, Low-Code AI—from the R user’s or developer’s perspective.</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Topic">9</td>
<td class="gt_row gt_left" headers="Title and Description"><strong>Building &amp; Orchestrating AI Agents in R</strong><br>Learn how to design and deploy autonomous agents that combine R functions, APIs, and LLMs to automate multi-step data science workflows.</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Whether you’re an R user new to AI or developing next-generation algorithms, <strong>R+AI 2025</strong> is your chance to learn, share, and collaborate with fellow R enthusiasts. Submit your talk or workshop proposal today and help shape the future of R+AI!</p>
<section id="please-note" class="level3">
<h3 class="anchored" data-anchor-id="please-note">Please note:</h3>
<ul>
<li>Event is 100% online</li>
<li>Talks will be recorded</li>
<li>Speakers participate in live Q&amp;A</li>
<li>Schedule is US Eastern time zone</li>
</ul>
<section id="submit-your-proposal-here-1" class="level4">
<h4 class="anchored" data-anchor-id="submit-your-proposal-here-1"><a href="https://forms.gle/SUbQVNMpp11g7vbTA">Submit your proposal here</a></h4>


</section>
</section>
</section>

 ]]></description>
  <category>Events</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/r_plus_ai_call_for_proposals/</guid>
  <pubDate>Thu, 10 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/r_plus_ai_call_for_proposals/CFP_now_open.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Teaching R to investigative journalists in Brazil</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/</link>
  <description><![CDATA[ 





<p><img src="https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/abraji_ceremony_2024_1.jpg" class="img-fluid"></p>
<p><em>credit for photos: Luciana Vassoler/Abraji</em></p>
<p>The <a href="https://abraji.org.br/english">Brazilian Association of Investigative Journalism (Abraji)</a>’s annual international congress will take place on July 10th-13th in São Paulo, Brazil. And the final day is dedicated to data. Traditionally called “Domingo de Dados” (Data Sunday), it’s a full day for journalist professionals and students from all over the country to take part in seven simultaneous labs with workshops and panels and learn new skills to apply data science in their investigations and coverage.</p>
<p>One of the labs will be entirely dedicated to teaching R. Participants will spend the morning in an introductory session to R led by R-Ladies São Paulo volunteer instructors and TAs, especially designed for statistical analysis considering the specifics of journalism and using Brazilian electoral data.</p>
<p><img src="https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/data-sunday-2024.png" class="img-fluid"></p>
<p>In the afternoon, they will learn how to use the R packages <code>censobr</code> and <code>geobr</code>, two o f the most used ones for Brazilian census and geospatial data. The workshop will be given by Rafael Pereira, Chief of Data for Ipea, the Brazilian Institute for Applied Economic Research, who created both packages. They will also get to practice the new skills and interview official government databases to try and find news stories, with the help of the instructors.</p>
<p>Because of its proximity to statistical analysis, R is one of the languages chosen by journalists on their first steps in acquiring data science skills to take their investigative work to a higher level. The investment in their training brings invaluable results in the form of news articles that expose detrimental public policies, fraud and other risks to our democracy, helping hold governments accountable and reduce social and economic inequality.</p>
<p><img src="https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/ddados2024_R-Bootcamp_1.jpeg" class="img-fluid"></p>
<p>For the second consecutive year, R Consortium is one of the partners at the Abraji International Congress. In its 20th edition, it has become the largest journalists event in Brazil, gathering over 1,800 participants in the four days of activities.</p>
<p><img src="https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/abraji_r-consortium_logo_2024.jpeg" class="img-fluid"></p>



 ]]></description>
  <category>Events</category>
  <guid>https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/</guid>
  <pubDate>Mon, 07 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/teaching-r-to-investigative-journalists-in-brazil/data-sunday-2024.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>Strength in Numbers</title>
  <dc:creator>Virginia Department of Environmental Quality</dc:creator>
  <link>https://r-consortium.org/posts/strength-in-numbers/</link>
  <description><![CDATA[ 





<p><img src="https://r-consortium.org/posts/strength-in-numbers/vadeq-main-image.png" class="img-fluid"></p>
<section id="about-deq" class="level3">
<h3 class="anchored" data-anchor-id="about-deq">About DEQ</h3>
<p>The Virginia Department of Environmental Quality (DEQ) is responsible for administering laws and regulations associated with air quality, water quality and supply, renewable energy, and land protection in the Commonwealth of Virginia. These responsibilities generate tremendous quantities of data from monitoring environmental quality, managing permitting processes across environmental media, responding to pollution events, and more. The data collected by DEQ requires management and analysis to gain insight, inform decision making, and meet legal and public obligations.</p>
</section>
<section id="an-emphasis-on-analytics" class="level3">
<h3 class="anchored" data-anchor-id="an-emphasis-on-analytics">An Emphasis on Analytics</h3>
<section id="analytics-community" class="level4">
<h4 class="anchored" data-anchor-id="analytics-community"><em>Analytics Community</em></h4>
<p>Throughout the last 10 years, DEQ staff have worked to develop an analytics community to advocate for access to preferred tools, create content governance, facilitate training, share best practices, and collaborate across analytics platforms. DEQ staff have created technology-specific teams to help bridge the gap between the agency’s IT group, the Office of Information Services (OIS), and analytical tool users. Building these connections between OIS and staff shortens enterprise tool incident response times, ensures buy-in when decisions are made that impact users, amplifies program-specific technology/analytical needs, and promotes collaboration among colleagues. Formalizing content management and software maintenance processes through these teams helps address security concerns and promote trust between management, OIS, and end users. This, in turn, has created a greater emphasis on analytics at DEQ, which contributes to a willingness to invest in resources to support our enterprise analytical tools.</p>
<p>The analytics environments that OIS manages include Posit, Esri’s ArcGIS, and Tableau. Here, we will focus on the integration of our Posit and ArcGIS environments to modernize data collection methods for water quality monitoring. We’ll begin with a review of these environments and how they have structurally changed as a function of this emphasis on analytics. Then, we’ll present work describing how these environments were leveraged to modernize mobile data collection at DEQ.</p>
</section>
<section id="posit" class="level4">
<h4 class="anchored" data-anchor-id="posit"><em>Posit</em></h4>
<p>DEQ staff have been using R since the early 2000’s, gradually growing the userbase with new hires and internal training. The increasing need for shared content and an internal hosting environment culminated with a single instance of Posit Connect being released in 2019. However, this environment relied on program staff for administration. With the growth in desktop R usage and Posit Connect content, program staff created a team of R users to create governance and processes to support the long-term maintenance of the server and hosted content. As R content grew, OIS recognized the need for dedicated support for the Posit Connect environment.</p>
<p>In 2024, OIS filled a new position dedicated to analytics administration and began work on upgrading the Posit environment. This upgrade involved moving to Red Hat Enterprise Linux 9, upgrading enterprise versions of R, expanding the environment to include a Test and Production instance of Posit Connect, and investing in Posit Package Manager. Today, DEQ’s R users leverage desktop RStudio to support data management and analysis workflows. DEQ uses Posit Package Manager to ensure that staff are working off of the same date-versioned CRAN snapshot, which simplifies collaboration. GitLab is used for version control. Shiny applications, markdown and quarto documents, as well as pinned datasets are developed in RStudio locally, and deployed to Posit Connect Test, and then our Production instance after the completion of relevant requirements.</p>
</section>
<section id="esri" class="level4">
<h4 class="anchored" data-anchor-id="esri"><em>Esri</em></h4>
<p>As of Winter 2023, DEQ implemented a fully federated ArcGIS Enterprise deployment, which encompasses both Test and Production environments. This deployment includes ArcGIS Server, Portal for ArcGIS, ArcGIS Data Store, ArcGIS Survey123, and ArcGIS Web Adaptor. The environments are hosted across two virtual machines with corresponding Enterprise Geodatabases serving as the primary repository for nearly all agency GIS data.</p>
<p>Data from these central GIS enterprise databases are routinely transferred to various File Geodatabases or processed through nightly Python ETL (Extract, Transform, Load) scripts. These scripts facilitate public access to GIS data and enable updates to DEQ’s Comprehensive Environmental Data System (CEDS), which includes both a front-end user interface and an underlying database.</p>
</section>
</section>
<section id="modernizing-mobile-data-collection-at-deq" class="level3">
<h3 class="anchored" data-anchor-id="modernizing-mobile-data-collection-at-deq">Modernizing Mobile Data Collection at DEQ</h3>
<section id="history-of-mobile-data-collection" class="level4">
<h4 class="anchored" data-anchor-id="history-of-mobile-data-collection"><em>History of Mobile Data Collection</em></h4>
<p>The primary method of data collection at DEQ relies on printing a waterproof data sheet generated from CEDS and filling it out with a black ink pen. When in the field, the data is read from the screen of a multiparameter sonde system and handwritten onto the field sheet. As an example, DEQ’s lake protocols include producing a profile of water quality parameters at every meter, from the surface to the bottom of an impoundment. After returning to a workstation, a data collector types this data from a field sheet into the CEDS front end, which then moves the data into the CEDS database. This method requires a keen eye and clear focus to avoid making transpositional errors. Even with excellent data input skills, these standard operations take a significant amount of time to execute. This created an opportunity to try a new digital data collection method with the goal of improving not only the quality of data, but the speed at which it can be securely collected and stored.</p>
</section>
<section id="the-solution" class="level4">
<h4 class="anchored" data-anchor-id="the-solution"><em>The Solution</em></h4>
<section id="arcgis-survey123" class="level5">
<h5 class="anchored" data-anchor-id="arcgis-survey123">ArcGIS Survey123</h5>
<p>To implement a mobile data collection solution, DEQ modified its ArcGIS Enterprise infrastructure to include a Survey123 website hosted on internal servers. Additionally, DEQ established a new branch-versioned database connection, enabling publication services from DEQ’s Enterprise Geodatabase for use in ArcGIS Survey123 Connect to build monitoring surveys.</p>
<p>The mobile data collection process begins with the preparation of ArcGIS Survey123 Connect forms in XLSX format, which are populated with the upcoming year’s monitoring plan. This plan, which is now generated in R, consolidates all monitoring sites into discrete monitoring runs, scheduled at regular intervals to meet program objectives. The monitoring team uses R to query DEQ’s internal database (CEDS) for this information, identifying specific monitoring runs (e.g.&nbsp;lake vs.&nbsp;biological monitoring), to populate surveys with accurate information. Geospatial data from DEQ’s internal GIS portal is then accessed via the R-ArcGIS Bridge (specifically the arcgisutils and arcgislayers packages), then joined to the CEDS data in R to provide additional station information. Once finalized, the monitoring team publishes the surveys to the internal GIS portal through ArcGIS Survey123 Connect and distributes them annually to field teams.</p>
</section>
<section id="data-collection" class="level5">
<h5 class="anchored" data-anchor-id="data-collection">Data Collection</h5>
<p>Monitoring teams collect field data using these customized surveys on field-ready devices. They often use the software’s offline capabilities, storing data locally until they have service to send completed surveys to the internal ArcGIS portal. The surveys include quality assurance (QA) checks that enforce numeric thresholds and minimum data requirements, ensuring accuracy and compliance with database rules. For lake surveys, where sample profiles of multiple parameters are collected at depth, teams can visualize the data in real-time to confirm accuracy. Once data is entered and equipment passes calibration post checks, the teams submit the data to the ArcGIS portal and prepare samples for shipment to a lab for further analysis.</p>
<p><img src="https://r-consortium.org/posts/strength-in-numbers/WQM-lake-survey.png" class="img-fluid"></p>
<p><em>Caption: Example Lake Survey with real time data table thanks to Angie Reed. (<a href="https://r-consortium.org/posts/aligning-belief-and-profession-using-r-in-protecting-the-penobscot-nation-traditional-lifeways-r-consortium/">link to her R Consortium blog post</a>)</em></p>
</section>
<section id="extract-transform-and-load" class="level5">
<h5 class="anchored" data-anchor-id="extract-transform-and-load">Extract, Transform, and Load</h5>
<p>Each evening, after all monitoring activities are published to the internal ArcGIS portal, a custom Python script processes the newly collected data using the ArcPy library. The script retrieves only the samples entered that day, joining them with critical metadata from CEDS. The data is then pulled into R using the R-ArcGIS Bridge. These data then undergo a series of quality assurance (QA) checks in R to ensure they meet minimum requirements. Once the data passes all QA steps, the script appends the new information in the CEDS database for ultimate storage. This process streamlines data management, automating the extraction, transformation, and loading of water quality data from the field into CEDS, while maintaining data integrity, and minimizing human error.</p>
</section>
<section id="posit-connect-visualizing-the-results" class="level5">
<h5 class="anchored" data-anchor-id="posit-connect-visualizing-the-results">Posit Connect: Visualizing the Results</h5>
<p>This field data is used the next morning by the centralized laboratory to track samples staged for analysis at the lab. These data are also made accessible in CEDS by the ETL process described above, which enables our Posit environment to query this information. Monitoring teams and managers can visualize data using custom Posit Connect hosted shiny applications. These applications streamline data querying and management by providing a user-friendly database front end. Simplifying data querying and management through Posit Connect hosted shiny applications helps DEQ staff respond to internal and public data inquiries.</p>
<p><img src="https://r-consortium.org/posts/strength-in-numbers/internal-deq-shiny-app.png" class="img-fluid"></p>
<p><em>Caption: Water monitoring data is available the next morning in an internal DEQ shiny application that acts as a database front end.</em></p>
</section>
<section id="supporting-the-water-quality-assessment-process" class="level5">
<h5 class="anchored" data-anchor-id="supporting-the-water-quality-assessment-process">Supporting the Water Quality Assessment Process</h5>
<p>Every two years, DEQ must assess all applicable data in order to report on the status of water quality throughout the Commonwealth per Clean Water Act mandates. The assessment data analytics team coalesces water quality data across multiple data sources using R, documenting all steps from data querying and cleaning through data analysis and summarization. DEQ utilizes a hybrid approach to automating the Water Quality Assessment process, leveraging desktop R to organize and suggest results for millions of data records, then scientists further investigate these results through a suite of customized Posit Connect-hosted shiny applications built to visualize raw data and analyzed results. These human-verified assessments are stored in an assessment-specific module of DEQ’s CEDS database that gets shared with EPA to complete reporting requirements.</p>
<p>[Caption: Water Quality Assessment staff use this shiny application to explore and understand water quality data.]</p>
</section>
</section>
<section id="benefits-of-change" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-change"><em>Benefits of Change</em></h4>
<p>During the initial stages of this data collection modernization project, which was isolated to a single DEQ region, staff digitally collected over 91,427 data points across 225 sites across 657 sampling events. This data had enhanced QA applied to them both in the ArcGIS Survey123 interface and via the integration with R and Python-based QA and Posit Connect hosted shiny applications. This direct connection between the data and DEQ’s database undoubtedly removed manual transcription errors and saved at least 127 hours of staff time spent solely on data re-entry. Growing this effort to encompass more regions and more sampling programs has the potential to massively increase time savings and improve data quality.</p>
<p>DEQ has taken steps throughout the past several years to empower and grow its analytics community and enterprise tools. These investments enable staff to better collaborate on projects across analytical platforms, creatively solving business problems and overcoming barriers that have previously seemed insurmountable. The adoption of these modern strategies allows greater efficiency and flexibility for both data collectors and end users. Ultimately these tools will allow for new growth as legacy processes can be reimagined in a digital landscape.</p>


</section>
</section>

 ]]></description>
  <category>Environment</category>
  <category>Software Development</category>
  <category>North America</category>
  <guid>https://r-consortium.org/posts/strength-in-numbers/</guid>
  <pubDate>Tue, 01 Jul 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/strength-in-numbers/vadeq-main-image.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>“Visualise, Optimise, Parameterise!” - Writing dataviz code - UPDATED</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/visualise-optimise-parameterise-writing-dataviz-code-updated/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tdaMw6NcNFM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="visualize-optimize-parameterize-enhancing-r-visualizations-for-impact" class="level1">
<h1>Visualize, Optimize, Parameterize: Enhancing R Visualizations for Impact</h1>
<p>Creating compelling and clear visualizations is an art that requires careful planning and execution. Cara Thompson, a data visualization consultant, recently led a workshop titled “Visualize, Optimize, Parameterize” aimed at enhancing participants’ skills in building reusable and adaptable visualizations with R. With an emphasis on parameterization, Cara shared insights on how to transform static plots into dynamic tools that can adapt to varied datasets and storytelling needs.</p>
<section id="building-memorable-graphs" class="level2">
<h2 class="anchored" data-anchor-id="building-memorable-graphs">Building Memorable Graphs</h2>
<p>To create memorable graphs, it’s crucial to select the right type of visualization and apply colors, fonts, and styling that complement the narrative. The workshop emphasized the importance of:</p>
<ul>
<li><strong>Choosing Appropriate Graph Types</strong>: Selecting the right graph type that aligns with the data story is fundamental.</li>
<li><strong>Color and Font Choices</strong>: These should enhance readability and convey the right message. Tools like the <code>monochroma</code> package and the Shiny app can help create harmonious color palettes.</li>
<li><strong>Annotations</strong>: Adding data-driven annotations can highlight key patterns and points of interest.</li>
</ul>
</section>
<section id="the-power-of-reusability" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-reusability">The Power of Reusability</h2>
<p>One of the key takeaways from the workshop was the importance of creating reusable functions and vectors. This approach minimizes repetitive copy-pasting and allows for easy updates and maintenance. Cara demonstrated how to:</p>
<ul>
<li><strong>Turn Styling Code into Functions</strong>: By encapsulating styling choices into a function, users can apply consistent branding across multiple plots with ease.</li>
<li><strong>Parameterize Plots</strong>: This involves creating a function that can take different datasets or parameters, making it adaptable for future use cases.</li>
</ul>
</section>
<section id="adding-interactivity" class="level2">
<h2 class="anchored" data-anchor-id="adding-interactivity">Adding Interactivity</h2>
<p>Incorporating interactivity into visualizations enhances user engagement and allows for deeper exploration of the data. Cara introduced the <code>ggiraph</code> package, which helps transform static ggplot2 charts into interactive plots, making it an accessible way to add interactivity without extensive rework.</p>
</section>
<section id="parameterizing-for-flexibility" class="level2">
<h2 class="anchored" data-anchor-id="parameterizing-for-flexibility">Parameterizing for Flexibility</h2>
<p>Parameterizing plots allows users to easily adapt their visualizations to different datasets or scenarios. Throughout the session, Cara encouraged participants to think about:</p>
<ul>
<li><strong>Dataset Variations</strong>: How to quickly adapt plots for new or updated data without reworking the entire codebase.</li>
<li><strong>Presentation Contexts</strong>: Adjusting visualizations for different formats such as presentations or publications with changes in text size and font.</li>
<li><strong>Additional Functionality</strong>: Adding features like conditional formatting or exporting options to enhance the plot’s utility.</li>
</ul>
</section>
<section id="avoiding-common-pitfalls" class="level2">
<h2 class="anchored" data-anchor-id="avoiding-common-pitfalls">Avoiding Common Pitfalls</h2>
<p>Cara highlighted several common pitfalls when parameterizing plots, such as:</p>
<ul>
<li><strong>Inconsistent Color Mapping</strong>: Colors should be stable across different datasets to maintain consistency. This can be achieved by using named vectors for color assignments.</li>
<li><strong>Axis Limits Management</strong>: Decide whether to keep axis limits consistent or allow them to adapt based on the data’s range.</li>
<li><strong>Annotation Placement</strong>: Ensure annotations are positioned correctly by using programmatic methods that adjust based on the data.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The workshop equipped participants with the skills to create impactful and adaptable visualizations in R. By focusing on parameterization, attendees learned to streamline their workflow, reduce redundancy, and enhance their data storytelling capabilities. Cara Thompson’s expertise in data visualization provided valuable insights into making visualizations both functional and aesthetically pleasing.</p>
<p>For those looking to delve deeper, resources from the workshop, including code snippets and additional readings, are available on Cara’s website.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/visualise-optimise-parameterise-writing-dataviz-code-updated/</guid>
  <pubDate>Sun, 29 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/visualise-optimise-parameterise-writing-dataviz-code-updated/thumbnail-dataviz-cara.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>A Framework for Cohort Building in R - Nuria Mercade-Besora and Edward Burn</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/a-framework-for-cohort-building-in-r-nuria-mercade-besora-and-edward-burn/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/6-4diWLaE6w" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="cohortconstructor-simplifying-patient-cohort-management-with-r" class="level1">
<h1>CohortConstructor: Simplifying Patient Cohort Management with R</h1>
<p>In the ever-evolving field of healthcare data analysis, managing patient cohorts efficiently is crucial. The CohortConstructor package in R provides an innovative solution for building and managing patient cohorts using real-world health data mapped to the OMOP Common Data Model (CDM). Developed by Nuria Mercade-Besora and Edward Burn, this package streamlines the process, allowing users to apply both common and complex inclusion criteria, combine cohorts, update cohort entry and exit dates, and track groups of patients—all without the need to write complicated code.</p>
<section id="background-and-need-for-a-common-data-model" class="level2">
<h2 class="anchored" data-anchor-id="background-and-need-for-a-common-data-model">Background and Need for a Common Data Model</h2>
<p>In the realm of healthcare data, researchers often face the challenge of transforming disparate sources of data into reliable evidence. Traditional processes involve lengthy data transformations to make data research-ready, followed by the application of statistical methods. The introduction of a common data model, such as the OMOP CDM, simplifies this process by standardizing healthcare data. This allows researchers to focus on querying the standardized data to generate reliable evidence, without needing to handle the intricacies of data transformation themselves.</p>
<section id="key-benefits-of-the-omop-common-data-model" class="level3">
<h3 class="anchored" data-anchor-id="key-benefits-of-the-omop-common-data-model">Key Benefits of the OMOP Common Data Model:</h3>
<ul>
<li><strong>Standardization:</strong> Different source systems can be converted to the same common data model, enabling the use of consistent pipelines across various databases.</li>
<li><strong>Interoperability:</strong> The OMOP CDM allows for international network studies, where analytic code is distributed to data partners who run it locally, keeping patient data secure and aggregated results are shared.</li>
<li><strong>Reproducibility:</strong> The common vocabulary and standardized format ensure that studies are reproducible across different geographies and healthcare systems.</li>
</ul>
</section>
</section>
<section id="the-cohortconstructor-package" class="level2">
<h2 class="anchored" data-anchor-id="the-cohortconstructor-package">The CohortConstructor Package</h2>
<p>CohortConstructor is designed to make cohort work more transparent and reproducible. It offers a comprehensive set of tools for cohort curation, all within a tidyverse-style framework. The package does not require users to have expertise in the OMOP CDM, making it accessible to anyone working with healthcare data in R.</p>
<section id="core-features-of-cohortconstructor" class="level3">
<h3 class="anchored" data-anchor-id="core-features-of-cohortconstructor">Core Features of CohortConstructor:</h3>
<ol type="1">
<li><p><strong>Base Cohort Creation:</strong></p>
<ul>
<li><strong>Demographic Cohorts:</strong> Define cohorts based on age, sex, and observation periods.</li>
<li><strong>Concept and Measurement Cohorts:</strong> Use clinical concepts and measurements to define cohorts.</li>
<li><strong>Death Cohorts:</strong> Create cohorts based on recorded deaths in the database.</li>
</ul></li>
<li><p><strong>Cohort Curation Tools:</strong></p>
<ul>
<li>Apply inclusion criteria based on demographics and other factors.</li>
<li>Update cohort entry and exit dates using pre-defined functions.</li>
<li>Transform and combine cohorts, allowing for complex cohort constructions such as intersections and unions.</li>
</ul></li>
<li><p><strong>Reproducibility and Transparency:</strong></p>
<ul>
<li><strong>Cohort Settings:</strong> Associate each cohort with a name and variables for easy reference.</li>
<li><strong>Attrition Tracking:</strong> Document the inclusion criteria and the impact of each criterion on the cohort size.</li>
<li><strong>Cohort Code List:</strong> Maintain a record of the clinical codes used to define each cohort.</li>
</ul></li>
</ol>
</section>
</section>
<section id="practical-demonstration-and-use-cases" class="level2">
<h2 class="anchored" data-anchor-id="practical-demonstration-and-use-cases">Practical Demonstration and Use Cases</h2>
<p>The webinar, presented by Nuria Mercade-Besora and Edward Burn, provided practical examples of how the CohortConstructor package can be used. From creating base cohorts to applying complex inclusion criteria, the session demonstrated the package’s versatility in handling healthcare data.</p>
<section id="example-workflow" class="level3">
<h3 class="anchored" data-anchor-id="example-workflow">Example Workflow:</h3>
<ol type="1">
<li><strong>Base Cohort Creation:</strong> Using concepts and demographics to create initial cohorts.</li>
<li><strong>Applying Inclusion Criteria:</strong> Filtering cohorts based on required demographic and clinical criteria.</li>
<li><strong>Transforming and Combining Cohorts:</strong> Using functions to intersect and merge cohorts, creating complex patient groupings tailored to specific research questions.</li>
</ol>
</section>
</section>
<section id="additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="additional-resources">Additional Resources</h2>
<p>For those interested in exploring the CohortConstructor package further, the full abstract, setup instructions, and demo slides are available on the <a href="https://github.com/OHDSI/CohortConstructor">GitHub page</a>. The package is also available on <a href="https://cran.r-project.org/web/packages/CohortConstructor/index.html">CRAN</a> for easy installation.</p>
<p>Ed Burn has also authored a book on programming with the OMOP Common Data Model in R, which is freely available online. This resource provides a deeper dive into working with databases in R, beyond just the OMOP CDM.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The CohortConstructor package represents a significant advancement in the management of patient cohorts using R. By simplifying the process and making it accessible to a wider audience, it empowers researchers to focus on deriving insights from healthcare data, rather than being bogged down by data management tasks. Whether you are a seasoned data scientist or a healthcare professional delving into data analysis, CohortConstructor offers the tools needed to streamline your workflow and enhance the reproducibility of your research.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Epidemiology</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/a-framework-for-cohort-building-in-r-nuria-mercade-besora-and-edward-burn/</guid>
  <pubDate>Tue, 24 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/a-framework-for-cohort-building-in-r-nuria-mercade-besora-and-edward-burn/thumbnail-cohortconstructor-burn-and-mercade-bosora.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>In the Nix of Time: Creating a reproducible analytical environment with Nix and {rix}</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/in-the-nix-of-time-creating-a-reproducible-analytical-environment-with-nix-and-rix/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/-NARVwViEwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="turbocharging-shiny-app-development-with-nix-and-rix" class="level3">
<h3 class="anchored" data-anchor-id="turbocharging-shiny-app-development-with-nix-and-rix">Turbocharging Shiny App Development with Nix and {rix}</h3>
<p>In the realm of data science, particularly for medical research, the integration of open-source tools has dramatically accelerated the development and deployment of sophisticated analytical applications. Among these tools, R has established itself as a powerhouse for statistical computing and data visualization, especially with its ability to create interactive web applications using Shiny. However, as developers push the boundaries of what’s possible, ensuring reproducibility and handling complex dependencies become crucial challenges. This is where the Nix package manager and the {rix} R package, authored by Bruno Rodrigues and Philipp Baumann, come into play.</p>
<p>Eric Nantz, a seasoned statistician, developer, and the host of the R-Podcast, recently shared his insights at the R/Medicine 2025 conference on how these tools have revolutionized his workflow in developing robust production-quality Shiny applications. His demonstration highlighted the synergy between Nix and Shiny, presenting a compelling case for their combined use in data science projects.</p>
<section id="the-reproducibility-challenge" class="level4">
<h4 class="anchored" data-anchor-id="the-reproducibility-challenge">The Reproducibility Challenge</h4>
<p>Shiny applications, while powerful, often require a myriad of dependencies. These range from R packages like {reactable} for table visualizations to system-level dependencies and external services such as APIs. Traditionally, tools like {renv} have been used to manage R package dependencies, while Docker has been employed to handle system-level dependencies. However, this combination can sometimes fall short, particularly in complex environments or when deploying across different systems.</p>
</section>
<section id="enter-nix-and-rix" class="level4">
<h4 class="anchored" data-anchor-id="enter-nix-and-rix">Enter Nix and {rix}</h4>
<p>The Nix package manager offers a comprehensive solution by managing the full dependency stack of software projects. It provides a sandboxed environment where dependencies can be installed and managed without interfering with the host system. This is particularly advantageous for Shiny applications, which can have intricate dependencies spread across different languages and systems.</p>
<p>The {rix} package simplifies the integration of Nix with R projects. It allows developers to create project-specific sandboxes that include both R packages and system dependencies, all managed via Nix. This ensures that all team members can work in a consistent environment, reducing the “it works on my machine” syndrome.</p>
</section>
<section id="key-features-of-nix-and-rix" class="level4">
<h4 class="anchored" data-anchor-id="key-features-of-nix-and-rix">Key Features of Nix and {rix}</h4>
<ul>
<li><p><strong>Comprehensive Package Management</strong>: Nix manages over 120,000 software packages, ensuring that all dependencies, including system libraries, are automatically resolved and installed.</p></li>
<li><p><strong>Immutable and Reproducible Environments</strong>: By creating an immutable file system, Nix ensures that the development environment remains consistent, preventing accidental changes that can affect reproducibility.</p></li>
<li><p><strong>Cross-Platform Compatibility</strong>: Nix can be installed on Linux, macOS, and Windows (via Windows Subsystem for Linux), making it accessible to a wide range of users.</p></li>
<li><p><strong>Integration with {rix}</strong>: The {rix} package allows easy configuration of R-specific environments, including access to CRAN and Bioconductor packages, as well as GitHub-hosted packages.</p></li>
</ul>
</section>
<section id="shiny-and-nix-a-perfect-match" class="level4">
<h4 class="anchored" data-anchor-id="shiny-and-nix-a-perfect-match">Shiny and Nix: A Perfect Match</h4>
<p>Eric Nantz’s demonstration showcased a Shiny application developed using the Nix and {rix} workflow. The app, which explored data from the National Health and Nutrition Examination Survey, was developed using the Golem package to convert the Shiny app into a package format—a best practice that enhances maintainability and scalability.</p>
<p>One of the standout features of this workflow was the ability to run a Shiny application with all its dependencies managed by Nix, without R being installed on the host system. This was possible through the use of a Nix shell, which provided a sandboxed environment where R and its packages were available. This not only ensured a consistent development environment but also facilitated easy deployment via Docker for hosting on cloud platforms.</p>
</section>
<section id="overcoming-challenges" class="level4">
<h4 class="anchored" data-anchor-id="overcoming-challenges">Overcoming Challenges</h4>
<p>While the benefits of using Nix and {rix} are substantial, there are some challenges to be aware of. The learning curve associated with Nix’s domain-specific language can be steep, and managing storage space for the Nix store is necessary. Additionally, some packages that write to temporary directories may not play well with Nix’s immutable file system. However, the advantages of reproducibility and ease of deployment often outweigh these hurdles.</p>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>The integration of Nix and {rix} into Shiny app development represents a significant advancement in creating reproducible and scalable data science projects. By leveraging Nix’s powerful package management capabilities and {rix}’s seamless integration with R, developers can ensure their applications are robust, consistent, and easy to deploy across various environments.</p>
<p>Eric Nantz’s insights and demonstration provide a valuable resource for R developers looking to enhance their workflow with these cutting-edge tools. As the R community continues to innovate and evolve, the combination of Shiny, Nix, and {rix} is poised to play a pivotal role in shaping the future of data science applications.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/in-the-nix-of-time-creating-a-reproducible-analytical-environment-with-nix-and-rix/</guid>
  <pubDate>Tue, 24 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/in-the-nix-of-time-creating-a-reproducible-analytical-environment-with-nix-and-rix/thumbnail-rix-and-nix-nantz.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>REDCapSync and RosyREDCap for standardized data pipelines and exploratory data analysis</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/redcapsync-and-rosyredcap-for-standardized-data-pipelines-and-exploratory-data-analysis/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/rkT6SParLO0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-clinical-research-with-redcapsync-and-rosyredcap" class="level2">
<h2 class="anchored" data-anchor-id="enhancing-clinical-research-with-redcapsync-and-rosyredcap">Enhancing Clinical Research with REDCapSync and RosyREDCap</h2>
<p>In the realm of clinical research and trials, the synergy between R and REDCap is transforming data management and analysis. REDCapSync and RosyREDCap, two innovative R packages, are at the forefront of this transformation, offering a streamlined approach to data pipelines and exploratory data analysis using the REDCap API.</p>
<section id="understanding-redcapsync-rosyredcap" class="level3">
<h3 class="anchored" data-anchor-id="understanding-redcapsync-rosyredcap">Understanding REDCapSync &amp; RosyREDCap</h3>
<p><strong>REDCapSync</strong> is a robust R package designed to facilitate the synchronization of data from one or multiple REDCap projects. The package introduces several core functions, such as <code>setup_project</code> and <code>sync_project</code>, which simplify the process of metadata and data extraction. By leveraging a cache of the last project save, a designated file directory, and the REDCap log, REDCapSync efficiently updates only the data that has changed since the last API call. This functionality is crucial, especially for large datasets, ensuring that users do not repeatedly download the entire dataset, thereby saving time and server load.</p>
<p>Key Features of REDCapSync:</p>
<ul>
<li><strong>Efficient Data Updates:</strong> Utilizes REDCap logs to update only modified records, reducing server load and improving speed.</li>
<li><strong>Standardized R List Objects:</strong> Maintains data as R list objects for easy downstream processing.</li>
<li><strong>Experimental Functions:</strong> Includes features for adding derived variables, merging forms, and generating data subsets that refresh with <code>sync_project</code>.</li>
<li><strong>Upload Capabilities:</strong> Allows for uploading labeled data via the API, a feature not available through the REDCap website.</li>
</ul>
<p><strong>RosyREDCap</strong>, on the other hand, is an exploratory data analysis tool. It is a Shiny application designed to load previous projects set up with REDCapSync. Users can navigate between projects, anonymize data, and perform ad-hoc visualizations effortlessly.</p>
<p>Core Features of RosyREDCap:</p>
<ul>
<li><strong>Interactive Interface:</strong> Provides a user-friendly interface for toggling between projects, ideal for exploratory data analysis.</li>
<li><strong>Data De-identification:</strong> Ensures confidentiality by allowing data de-identification within the application.</li>
<li><strong>Visualization Tools:</strong> Facilitates data visualization through intuitive tools, enhancing data interpretation and presentation.</li>
</ul>
</section>
<section id="the-power-of-r-and-redcap-in-clinical-research" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-r-and-redcap-in-clinical-research">The Power of R and REDCap in Clinical Research</h3>
<p>The integration of R with REDCap through these packages offers multiple advantages for researchers:</p>
<ul>
<li><strong>Reproducibility and Efficiency:</strong> By maintaining a standardized data structure and using efficient synchronization methods, researchers can ensure reproducibility and save time.</li>
<li><strong>Enhanced Data Analysis:</strong> With functions tailored for clinical data, users can perform complex analyses and visualizations, leading to more insightful research outcomes.</li>
<li><strong>Accessibility for New Users:</strong> Even those new to R can leverage the power of REDCapSync and RosyREDCap without needing in-depth knowledge of the REDCap API.</li>
</ul>
</section>
<section id="real-world-applications-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="real-world-applications-and-future-directions">Real-World Applications and Future Directions</h3>
<p>Dr.&nbsp;Brandon Rose, developer of these packages, brings extensive experience in hematology, oncology, and clinical informatics. His work on the Fire Fighter Cancer Cohort Study and UK BioBank research underscores the practical applications of these tools in real-world scenarios.</p>
<p>At the R Medicine conference, Dr.&nbsp;Rose plans to showcase various examples and use cases of REDCapSync and RosyREDCap. These demonstrations will highlight how the combined strengths of R and REDCap can streamline clinical data pipelines, ultimately enhancing research quality and patient care.</p>
<p>For those interested in the development and application of these packages, Dr.&nbsp;Rose offers support and collaboration opportunities. By generalizing code and sharing tools, researchers can contribute to a community of practice that enhances data management and analysis across various domains.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>REDCapSync and RosyREDCap represent significant strides in the integration of R and REDCap, providing powerful tools for clinical data management and analysis. These packages not only simplify the technical aspects of data synchronization and analysis but also empower researchers to focus on the insights and outcomes of their work. As these tools continue to evolve, they hold the promise of further transforming the landscape of clinical research and healthcare data management.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <category>Healthcare</category>
  <guid>https://r-consortium.org/posts/redcapsync-and-rosyredcap-for-standardized-data-pipelines-and-exploratory-data-analysis/</guid>
  <pubDate>Tue, 24 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/redcapsync-and-rosyredcap-for-standardized-data-pipelines-and-exploratory-data-analysis/thumbnail-redcap-rose.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>The power of {targets} package for reproducible data science</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/the-power-of-targets-package-for-reproducible-data-science/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/2BtXjPRLGkQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="enhancing-reproducible-data-science-with-the-targets-package-in-r" class="level1">
<h1>Enhancing Reproducible Data Science with the <code>targets</code> Package in R</h1>
<p>Reproducibility is a non-negotiable pillar in the realm of data science, ensuring that analyses can be reliably replicated and shared. This commitment to reproducibility is vital for building trust and credibility in the outcomes of data-driven projects. In the R ecosystem, the <code>targets</code> package stands out as a powerful tool designed to streamline and enhance reproducibility in data science workflows.</p>
<section id="the-power-of-targets" class="level2">
<h2 class="anchored" data-anchor-id="the-power-of-targets">The Power of <code>targets</code></h2>
<p>The <code>targets</code> package in R offers a robust framework for pipeline management, enabling efficient dependency tracking, automated pipeline execution, and clear documentation of the entire data analysis process. This package ensures that complex pipelines execute consistently in isolated environments.</p>
<p>When combined with tools like <code>{renv}</code> and Docker, <code>targets</code> eliminates the common “it works on my machine” problem. This synergy fosters reproducibility across diverse computational environments, empowering data scientists to create scalable and maintainable projects.</p>
</section>
<section id="workshop-overview" class="level2">
<h2 class="anchored" data-anchor-id="workshop-overview">Workshop Overview</h2>
<p>The workshop, led by Rahul Sangole, a Senior Data Science Manager at Apple, was designed for data scientists and analysts eager to enhance their pipeline management skills. Through hands-on exercises and real-world examples, attendees learned how to leverage <code>targets</code> to build reproducible data science workflows.</p>
<section id="key-topics-covered" class="level3">
<h3 class="anchored" data-anchor-id="key-topics-covered">Key Topics Covered</h3>
<ol type="1">
<li><strong>Pipeline Basics and Functions</strong>:
<ul>
<li>Transitioning from a script-based approach to a <code>targets</code> pipeline involves converting each variable into a “target.”</li>
<li>Using functions to keep pipelines clean and maintainable.</li>
<li>Visualizing pipelines to understand dependencies and execution flow.</li>
</ul></li>
<li><strong>Handling Files</strong>:
<ul>
<li>Managing input and output files within a <code>targets</code> pipeline.</li>
<li>Utilizing <code>format = "file"</code> to track file changes and ensure pipeline validity.</li>
<li>Incorporating Quarto documents for literate programming within pipelines.</li>
</ul></li>
<li><strong>Parallel Computing</strong>:
<ul>
<li>Accelerating pipelines by utilizing multiple workers with the <code>crew</code> package.</li>
<li>Monitoring pipeline execution in real-time with <code>tar_watch()</code>.</li>
</ul></li>
<li><strong>Dynamic Branching</strong>:
<ul>
<li>Utilizing dynamic branching to handle scenarios where the number of models or data sets is not known beforehand.</li>
<li>Implementing <code>pattern = map</code> and <code>pattern = cross</code> to create flexible and scalable pipelines.</li>
</ul></li>
<li><strong>Database Integration</strong>:
<ul>
<li>Connecting to databases, querying data, and writing results back to databases within a <code>targets</code> pipeline.</li>
<li>Using <code>withr</code> for clean database connections and disconnections.</li>
</ul></li>
<li><strong>Comprehensive Example</strong>:
<ul>
<li>Organizing code into clear, maintainable structures with separate functions and pipelines.</li>
<li>Building a full-fledged example of a machine learning pipeline using <code>targets</code> to manage data cleaning, modeling, and reporting.</li>
</ul></li>
</ol>
</section>
<section id="resources" class="level3">
<h3 class="anchored" data-anchor-id="resources">Resources</h3>
<ul>
<li><strong>Setup Instructions</strong> for the workshop: <a href="https://rsangole.netlify.app/talks/2025-06-09_rmedicine-targets/doc.html#setup-instructions">Workshop Setup</a></li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The <code>targets</code> package is an invaluable asset for data scientists committed to reproducibility. By adopting <code>targets</code>, data professionals can build transparent, trustable, and reproducible data workflows. The workshop provided a comprehensive introduction to <code>targets</code>, equipping participants with the knowledge and skills to implement these practices in their projects.</p>
<p><strong>Rahul Sangole’s</strong> expertise and passion for reproducible data science were evident throughout the session, offering participants a deep dive into the capabilities of <code>targets</code>. This workshop is a stepping stone for data scientists to enhance their pipeline management and scale their analytical workflows effectively.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/the-power-of-targets-package-for-reproducible-data-science/</guid>
  <pubDate>Tue, 24 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/the-power-of-targets-package-for-reproducible-data-science/thumbnail-targets-rahul.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>First Steps with SQL in R: Making Data Talk</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/first-steps-with-sql-in-r-making-data-talk/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1t0DvqGD9nM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="unlocking-sqls-potential-in-r-a-beginners-guide" class="level1">
<h1>Unlocking SQL’s Potential in R: A Beginner’s Guide</h1>
<p>In the ever-evolving landscape of data science and analytics, SQL (Structured Query Language) remains a steadfast tool for extracting and organizing data. For those entrenched in the world of R, particularly within clinical research and healthcare settings, integrating SQL skills can be a game changer. The recent workshop hosted by Chris Battiston, a seasoned REDCap administrator and research data analyst at Women’s College Hospital, Toronto, underscored the immense potential of SQL when used alongside R, especially for those managing complex data sets in clinical environments.</p>
<section id="why-sql" class="level2">
<h2 class="anchored" data-anchor-id="why-sql">Why SQL?</h2>
<p>SQL’s longevity and widespread use across industries underscore its utility. Developed in the 1970s, SQL was designed for querying relational databases, which makes it perfect for managing structured data. In clinical research, where data integrity and accessibility are paramount, SQL acts as a bridge between raw data and meaningful insights.</p>
<p>SQL is particularly beneficial for:</p>
<ul>
<li><strong>Data Extraction and Transformation</strong>: SQL efficiently handles large datasets, enabling the extraction of specific data points without overwhelming memory resources.</li>
<li><strong>Relational Data Handling</strong>: Ideal for linking tables and datasets, SQL simplifies the process of combining disparate data sources for a comprehensive analysis.</li>
<li><strong>Portability and Familiarity</strong>: As a universal language for data queries, SQL skills are transferable across various platforms and systems, making it a valuable addition to any data analyst’s toolkit.</li>
</ul>
</section>
<section id="sql-in-the-r-environment" class="level2">
<h2 class="anchored" data-anchor-id="sql-in-the-r-environment">SQL in the R Environment</h2>
<p>Chris Battiston’s workshop, “First Steps in SQL with R: Making Data Talk,” offered an in-depth look at how the <code>sqldf</code> package in R can be used to run SQL queries directly on R data frames. This integration allows R users to take advantage of SQL’s strengths without leaving the R environment, streamlining workflows and enhancing productivity.</p>
<p>Key learnings from the workshop included:</p>
<ul>
<li><strong>SQL Basics</strong>: Understanding SQL syntax, including commands like SELECT, FROM, WHERE, ORDER BY, GROUP BY, and JOIN.</li>
<li><strong>Comparative Analysis</strong>: Using SQL alongside <code>dplyr</code> for common data tasks, highlighting scenarios where SQL might offer a more efficient or intuitive solution.</li>
<li><strong>Hands-on Practice</strong>: Participants engaged in live coding exercises, writing SQL queries to filter, sort, group, and join data frames in R.</li>
</ul>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<p>The workshop provided practical examples using real-world data from New York City hospitals, demonstrating how SQL queries can surface valuable insights quickly. For instance, participants learned to:</p>
<ul>
<li>Identify the top hospitals by procedure type using SQL’s GROUP BY and ORDER BY clauses.</li>
<li>Analyze demographic variations in healthcare charges across different counties.</li>
<li>Understand the nuances of joins, such as inner joins and left joins, to merge datasets effectively.</li>
</ul>
<p>These examples showcased SQL’s ability to handle complex queries and provide actionable insights, essential for clinical data managers and researchers.</p>
</section>
<section id="complementary-tools" class="level2">
<h2 class="anchored" data-anchor-id="complementary-tools">Complementary Tools</h2>
<p>While SQL excels in data extraction and organization, R shines in statistical analysis and visualization. The workshop encouraged participants to think of SQL and R as complementary tools rather than competing ones. For instance, SQL can be used to preprocess and clean data, which can then be fed into R for advanced modeling and visualization.</p>
</section>
<section id="conclusion-and-next-steps" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-and-next-steps">Conclusion and Next Steps</h2>
<p>By the end of the workshop, participants gained confidence in using SQL within R, learning to write queries that enhance data analysis workflows. The session emphasized that while SQL is a powerful tool, its true potential is realized when used to tell a story with data. In clinical research, this means transforming raw data into narratives that drive understanding and inform decision-making.</p>
<p>For those looking to deepen their SQL skills within R, Chris Battiston provided a wealth of resources, including practice queries, cheat sheets, and access to the Spark dataset from New York State. These tools offer a solid foundation for further exploration and mastery of SQL in R.</p>
<p>As the data landscape continues to evolve, the ability to integrate SQL into R workflows will undoubtedly remain a valuable skill, opening doors to more efficient data management and richer insights.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/first-steps-with-sql-in-r-making-data-talk/</guid>
  <pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/first-steps-with-sql-in-r-making-data-talk/thumbnail-SQL-in-R-chris.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Quarto Dashboards: from zero to publish in one hour</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/quarto-dashboards-from-zero-to-publish-in-one-hour/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/NoOU_nzeAGk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="from-zero-to-quarto-dashboards-a-comprehensive-guide" class="level1">
<h1>From Zero to Quarto Dashboards: A Comprehensive Guide</h1>
<p>In the ever-evolving landscape of data science and statistical analysis, Quarto offers a novel approach to creating and sharing interactive dashboards. Quarto Dashboards provide an intuitive platform that is both elegant and efficient, making it easier than ever to present data in a visually appealing format. Professor Mine Çetinkaya-Rundel from Duke University recently demonstrated the power of Quarto Dashboards at the R/Medicine 2025 conference, showcasing how to build and publish a dashboard from scratch in just an hour.</p>
<section id="the-essence-of-quarto-dashboards" class="level2">
<h2 class="anchored" data-anchor-id="the-essence-of-quarto-dashboards">The Essence of Quarto Dashboards</h2>
<p>Quarto is an open-source scientific and technical publishing system designed to enhance the process of creating and collaborating on data projects. It seamlessly combines narrative text and code to produce outputs such as HTML, PDF, Word documents, and dashboards. Quarto Dashboards, in particular, have been available since version 1.4, with the latest pre-release version being 1.8. These dashboards are built using a variety of components, including static graphics, interactive widgets, and tabular data. They are responsive, ensuring that they look great on devices of all sizes.</p>
<section id="key-features-of-quarto-dashboards" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-quarto-dashboards">Key Features of Quarto Dashboards</h3>
<ol type="1">
<li><p><strong>Component Flexibility</strong>: Users can incorporate static graphics, interactive widgets, tabular data, value boxes, and text annotations into their dashboards, offering a comprehensive range of visualization tools.</p></li>
<li><p><strong>Responsive Design</strong>: With intelligent resizing, Quarto Dashboards offer optimal viewing experiences on any device, whether it’s a smartphone, tablet, or desktop.</p></li>
<li><p><strong>Markdown Comfort</strong>: The ability to author dashboards in plain text markdown with any text editor makes Quarto Dashboards accessible for users familiar with markdown syntax.</p></li>
<li><p><strong>Cross-Language Compatibility</strong>: While the demo primarily used R, Quarto Dashboards support computations in Python and Julia as well, with only minor syntax adjustments needed for code cells.</p></li>
<li><p><strong>Theming and Customization</strong>: Users can define custom themes, including light and dark modes, by utilizing brand YAML files and SCSS rules, allowing for extensive personalization.</p></li>
</ol>
</section>
</section>
<section id="building-a-quarto-dashboard-a-step-by-step-approach" class="level2">
<h2 class="anchored" data-anchor-id="building-a-quarto-dashboard-a-step-by-step-approach">Building a Quarto Dashboard: A Step-by-Step Approach</h2>
<section id="starting-point" class="level3">
<h3 class="anchored" data-anchor-id="starting-point">Starting Point</h3>
<p>The process begins with a basic Quarto document. This document is then transformed into a dashboard by changing the document format to <code>dashboard</code>. The output of each R code cell becomes a card within the dashboard. The organization of these cards can be customized through rows and columns, offering a structured way to present data.</p>
</section>
<section id="creating-value-boxes" class="level3">
<h3 class="anchored" data-anchor-id="creating-value-boxes">Creating Value Boxes</h3>
<p>Value boxes are a key feature of Quarto Dashboards, providing a succinct way to display summary statistics. In the demo, value boxes were used to present the number of keynotes, tutorials, and other session types. Each value box is created by setting the content of a code cell to <code>value-box</code>, with customizable titles, icons, and colors.</p>
</section>
<section id="plot-sizing" class="level3">
<h3 class="anchored" data-anchor-id="plot-sizing">Plot Sizing</h3>
<p>An important aspect of dashboard design is ensuring that plots are appropriately sized. Quarto Dashboards allow users to specify figure heights and widths, ensuring plots are legible and well-integrated into the dashboard layout.</p>
</section>
<section id="light-and-dark-themes" class="level3">
<h3 class="anchored" data-anchor-id="light-and-dark-themes">Light and Dark Themes</h3>
<p>A standout feature of Quarto Dashboards is the ability to switch between light and dark themes. This is achieved through the use of brand YAML files, which define the color palettes for different components. Additionally, users can specify separate plot renderings for each theme, ensuring visual consistency.</p>
</section>
<section id="tab-sets-and-tables" class="level3">
<h3 class="anchored" data-anchor-id="tab-sets-and-tables">Tab Sets and Tables</h3>
<p>For dashboards that require the presentation of multiple tables or plots, Quarto Dashboards support the use of tab sets. This feature allows users to organize content into tabs, providing a cleaner and more interactive user experience. Tables can also be customized with light and dark themes, with helper functions available to streamline the process.</p>
</section>
</section>
<section id="the-future-of-quarto-dashboards" class="level2">
<h2 class="anchored" data-anchor-id="the-future-of-quarto-dashboards">The Future of Quarto Dashboards</h2>
<p>Quarto Dashboards represent a significant advancement in data visualization within the R community. Their flexibility, ease of use, and cross-language compatibility make them a valuable tool for data scientists, educators, and researchers alike. As the Quarto platform continues to evolve, we can expect even more features and enhancements that will further streamline the process of creating interactive and visually appealing dashboards.</p>
<p>Professor Mine Çetinkaya-Rundel’s demonstration at the R/Medicine 2025 conference highlighted the practical applications of Quarto Dashboards, providing attendees with the knowledge and tools needed to create their own dashboards. Her work in statistics and data science pedagogy, particularly her focus on open-source education and student-centered learning, continues to inspire and empower the R community.</p>
<p>For those interested in exploring Quarto Dashboards further, resources and examples are available through the R Consortium and related projects. Whether you’re looking to enhance your teaching materials, share research findings, or simply present data in a new way, Quarto Dashboards offer a robust and versatile solution.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The introduction of Quarto Dashboards marks a new era in data visualization and reporting. By combining the power of R with the flexibility of Quarto, users can create dashboards that are not only informative but also visually stunning. As the R community continues to innovate and collaborate, tools like Quarto Dashboards will undoubtedly play a pivotal role in shaping the future of data science.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <guid>https://r-consortium.org/posts/quarto-dashboards-from-zero-to-publish-in-one-hour/</guid>
  <pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/quarto-dashboards-from-zero-to-publish-in-one-hour/thumbnail-quarto-mine.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Supporting R learners on the job during interesting times: A panel of R educators</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/supporting-r-learners-on-the-job-during-interesting-times-a-panel-of-r-educators/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KKRbA2VYOb4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="navigating-the-seas-of-r-education-insights-from-rmedicine-2025" class="level1">
<h1>Navigating the Seas of R Education: Insights from R/Medicine 2025</h1>
<p>In an ever-evolving world where technology and data science are at the forefront of innovation, the need for effective education in tools like R is more critical than ever. The recent panel discussion at R/Medicine 2025 brought together a group of seasoned educators and practitioners who shared their insights on the challenges and opportunities in teaching R, especially outside the traditional classroom setting. This post delves into the key takeaways from the panel, offering a glimpse into the future of R education and how we can collectively support learners during these interesting times.</p>
<section id="meet-the-panelists" class="level2">
<h2 class="anchored" data-anchor-id="meet-the-panelists">Meet the Panelists</h2>
<p>The panel was composed of esteemed educators with diverse backgrounds, each bringing unique perspectives to the table:</p>
<ul>
<li><p><strong>Ray Balise</strong>: An Associate Professor of Biostatistics and Bioinformatics at the University of Miami, Ray has a long history of teaching statistical programming and is passionate about teaching smart people to think about data.</p></li>
<li><p><strong>Silvia Canelón</strong>: From Penn Medicine Center for Health Justice, Silvia is an advocate for data literacy, communication, and accessibility, with a focus on supporting others in their data-driven journeys.</p></li>
<li><p><strong>Meghan Santiago Harris</strong>: Known for her work in public health and data science education, Meghan emphasizes the importance of self-teaching and mentoring in her field.</p></li>
<li><p><strong>Ted Laderas</strong>: As the Director of Training and Community for the Office of the Chief Data Officer at Fred Hutch Cancer Center, Ted is focused on changing data culture through education and training.</p></li>
<li><p><strong>Joy Payton</strong>: A dedicated data science educator in biomedicine, Joy has been instrumental in building capacity and fostering community among learners.</p></li>
</ul>
</section>
<section id="the-challenge-of-interesting-times" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-of-interesting-times">The Challenge of Interesting Times</h2>
<p>Joy Payton opened the discussion by acknowledging the “interesting times” we are living in. With cognitive load at an all-time high due to various global and local challenges, learners and educators alike must navigate these turbulent waters. The panelists echoed this sentiment, emphasizing the need for flexibility, adaptability, and a supportive community to help learners thrive.</p>
</section>
<section id="the-role-of-ai-and-llms-in-r-education" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-ai-and-llms-in-r-education">The Role of AI and LLMs in R Education</h2>
<p>One of the hot topics discussed was the role of AI and large language models (LLMs) in learning and coding. While AI tools like ChatGPT and Claude can assist learners by handling syntax and providing quick answers, the panelists stressed the importance of understanding the underlying mental models and logic behind coding. They agreed that while LLMs are here to stay, educators must teach students how to use these tools effectively without compromising foundational skills.</p>
<p>Ted Laderas highlighted the importance of cognitive load theory and psychological safety in education, advocating for a balance between leveraging AI tools and maintaining the integrity of the learning process. Ray Balise added that teaching prompt engineering and proper use of LLMs should be integrated into the curriculum to ensure students are equipped for the modern workforce.</p>
</section>
<section id="supporting-learners-in-uncertain-times" class="level2">
<h2 class="anchored" data-anchor-id="supporting-learners-in-uncertain-times">Supporting Learners in Uncertain Times</h2>
<p>The panelists shared their strategies for supporting learners amidst uncertainty. Meghan Santiago Harris emphasized the value of integrating R into existing work or projects that learners are passionate about. This approach not only aids retention but also makes the learning process more enjoyable and relevant.</p>
<p>Silvia Canelón pointed out the importance of community and collaboration, noting that much of her learning came from engaging with others in the R community. For educators, fostering an environment where learners can share their experiences and learn from each other is crucial.</p>
</section>
<section id="resources-and-tools-for-r-learners" class="level2">
<h2 class="anchored" data-anchor-id="resources-and-tools-for-r-learners">Resources and Tools for R Learners</h2>
<p>The panelists also discussed their favorite resources for teaching and learning R:</p>
<ul>
<li><strong>Big Book of R</strong>: A comprehensive collection of online R books covering various topics.</li>
<li><strong>R OpenSci Trainings</strong>: Focused on research contexts, these resources are invaluable for developing R skills.</li>
<li><strong>Our Ladies YouTube Channel</strong>: Offers a wealth of tutorials and workshops on different R topics.</li>
<li><strong>Urban Institute’s Do No Harm Project</strong>: Provides guidance on equity and accessibility in data visualization.</li>
</ul>
<p>Joy Payton introduced <strong>Bent</strong>, a data education navigator tool, and <strong>Leoscript</strong>, a markdown renderer for creating educational resources. These tools exemplify the innovative approaches educators are taking to enhance the learning experience.</p>
</section>
<section id="building-a-community-of-r-educators" class="level2">
<h2 class="anchored" data-anchor-id="building-a-community-of-r-educators">Building a Community of R Educators</h2>
<p>In closing, Joy Payton urged attendees to be gate openers, highlighting that everyone has something to contribute to the R community. Whether you’re a seasoned educator or a beginner, sharing your knowledge and experiences can help build a robust network of engaged and supportive R learners and educators.</p>
<p>As we look to the future, the insights from R/Medicine 2025 remind us of the importance of adaptability, community, and thoughtful integration of technology in education. By embracing these principles, we can empower the next generation of R users to navigate the complexities of data science with confidence and creativity.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <guid>https://r-consortium.org/posts/supporting-r-learners-on-the-job-during-interesting-times-a-panel-of-r-educators/</guid>
  <pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/supporting-r-learners-on-the-job-during-interesting-times-a-panel-of-r-educators/supporting-r-learners-panel.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Using R shiny to perform and automate decision-analytic modeling for cost-effectiveness analysis</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/using-r-shiny-to-perform-and-automate-decision-analytic-modeling-for-cost-effectiveness-analysis/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/UMdN9SgQbLA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="leveraging-r-shiny-for-automated-decision-analytic-modeling-in-cost-effectiveness-analysis" class="level1">
<h1>Leveraging R Shiny for Automated Decision-Analytic Modeling in Cost-Effectiveness Analysis</h1>
<p>The landscape of health economic evaluation is increasingly influenced by computational tools, and R is playing a pivotal role in this transformation. Mahip Acharya, an assistant professor at the University of Arkansas for Medical Sciences, has showcased the power of R and R Shiny in automating decision-analytic modeling for cost-effectiveness analysis. This innovative approach provides a flexible and efficient method of evaluating economic outcomes, particularly in the healthcare sector.</p>
<section id="understanding-cost-effectiveness-analysis" class="level2">
<h2 class="anchored" data-anchor-id="understanding-cost-effectiveness-analysis">Understanding Cost-Effectiveness Analysis</h2>
<p>Cost-effectiveness analysis (CEA) is a form of economic evaluation that compares the relative costs and outcomes (effects) of different courses of action. It is commonly used in healthcare to determine the value of interventions, such as medications or surgical procedures, by assessing how much benefit they provide relative to their cost. The benefits are typically measured in terms of life years gained or quality-adjusted life years (QALYs).</p>
<p>In CEA, the incremental cost-effectiveness ratio (ICER) is a crucial metric. It represents the additional cost per additional unit of benefit (e.g., per QALY). Decision-makers often compare the ICER to a willingness-to-pay threshold to determine if an intervention is cost-effective. For instance, in the United States, thresholds can range from $50,000 to $150,000 per QALY.</p>
</section>
<section id="the-role-of-markov-models" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-markov-models">The Role of Markov Models</h2>
<p>Markov models are frequently employed in CEA to simulate the progression of diseases over time. They are particularly useful for modeling chronic conditions where the disease state changes over a long period. In a Markov model, patients transition between different health states at specified probabilities, which can be influenced by interventions.</p>
<p>In his demonstration, Mahip Acharya utilized a Markov model to evaluate the cost-effectiveness of a treatment for hypertension. The model included various health states, such as myocardial infarction, heart failure, stroke, and death. Patients transition between these states based on predefined probabilities, and the model calculates the associated costs and QALYs.</p>
</section>
<section id="automating-the-process-with-r-shiny" class="level2">
<h2 class="anchored" data-anchor-id="automating-the-process-with-r-shiny">Automating the Process with R Shiny</h2>
<p>R Shiny offers an interactive platform for building web applications directly from R. Mahip leveraged Shiny to automate the process of decision-analytic modeling, making it accessible for users without extensive programming expertise. The application allows users to input various parameters, such as transition probabilities, costs, and health utilities, through a user-friendly interface.</p>
<section id="key-features-of-the-shiny-application" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-the-shiny-application">Key Features of the Shiny Application</h3>
<ul>
<li><p><strong>Model Structure Visualization</strong>: Users can upload a PDF depicting the Markov model structure. The application reads the state names directly from the file, eliminating the need for manual input.</p></li>
<li><p><strong>Data Input Flexibility</strong>: The app accepts multiple data inputs, including transition rates, hazard ratios, treatment costs, and health utilities. These inputs can be adjusted to explore different scenarios.</p></li>
<li><p><strong>Interactive Output</strong>: The application calculates and displays key outputs, such as total costs, total QALYs, and ICERs. Users can adjust the model parameters, such as the discount rate and model cycle length, to see how these changes affect the results.</p></li>
<li><p><strong>Generalizability and Adaptability</strong>: While the current model focuses on hypertension, the framework can be adapted to other chronic conditions by modifying the disease states and transition probabilities.</p></li>
</ul>
</section>
</section>
<section id="challenges-and-future-work" class="level2">
<h2 class="anchored" data-anchor-id="challenges-and-future-work">Challenges and Future Work</h2>
<p>While the application serves as a robust proof of concept, Mahip acknowledges several areas for future improvement:</p>
<ul>
<li><p><strong>Expanding File Format Support</strong>: Currently, the model structure must be uploaded as a PDF. Adding support for other image formats like PNG or JPEG would enhance usability.</p></li>
<li><p><strong>Incorporating Sensitivity Analyses</strong>: Implementing deterministic and probabilistic sensitivity analyses would provide deeper insights into the model’s robustness.</p></li>
<li><p><strong>Enhancing User Inputs</strong>: Allowing users to specify different cycle lengths (e.g., annual or monthly) and starting cohorts would increase the model’s flexibility.</p></li>
<li><p><strong>Supporting Multiple Treatment Groups</strong>: The current version of the app supports only one treatment group. Expanding to multiple groups would accommodate more complex analyses.</p></li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The integration of R Shiny with decision-analytic modeling marks a significant advancement in the field of health economic evaluation. By automating processes and providing a user-friendly interface, Mahip Acharya’s approach empowers researchers and decision-makers to conduct comprehensive cost-effectiveness analyses with greater efficiency and precision. As the application evolves, it promises to become an invaluable tool in the evaluation of healthcare interventions, ultimately contributing to more informed and cost-effective healthcare decisions.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Healthcare</category>
  <category>Clinical Research</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/using-r-shiny-to-perform-and-automate-decision-analytic-modeling-for-cost-effectiveness-analysis/</guid>
  <pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/using-r-shiny-to-perform-and-automate-decision-analytic-modeling-for-cost-effectiveness-analysis/thumbnail-using-r-shiny-mahip.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Visualising data for patients: create accessible charts</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/visualising-data-for-patients-create-accessible-charts/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/j6iwGeYj-xU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="creating-accessible-and-clear-charts-in-r-a-guide-to-inclusion" class="level3">
<h3 class="anchored" data-anchor-id="creating-accessible-and-clear-charts-in-r-a-guide-to-inclusion">Creating Accessible and Clear Charts in R: A Guide to Inclusion</h3>
<p>In today’s world, patients can access a plethora of health data through various applications. However, visualizing this data in a manner that is understandable and inclusive remains a challenge. Dr.&nbsp;Rita Giordano from Visual Data Studio / Clarum presented a compelling demonstration on how to create charts in R that are not only clear but also accessible to a wider audience, including those with visual impairments like color blindness and autism.</p>
<section id="key-takeaways-from-the-demonstration" class="level4">
<h4 class="anchored" data-anchor-id="key-takeaways-from-the-demonstration">Key Takeaways from the Demonstration:</h4>
<ul>
<li><p><strong>Decluttering and Accessibility</strong>: The importance of decluttering charts and making them accessible by choosing the right color palettes and fonts was emphasized. This ensures that even those without a scientific or medical background can understand the data presented to them.</p></li>
<li><p><strong>Colorblind-Friendly Palettes</strong>: Attendees learned how to create colorblind-friendly palettes in R. Using packages like <code>RColorBrewer</code>, <code>colorspace</code>, and <code>colorblindr</code>, one can quickly generate palettes that are inclusive to those with color vision deficiencies.</p></li>
<li><p><strong>Autism-Friendly Color Schemes</strong>: Dr.&nbsp;Giordano highlighted the significance of using autism-friendly colors, which are calming shades of green and blue. The choice of colors can significantly impact how individuals on the autism spectrum perceive and interact with data.</p></li>
<li><p><strong>Font Readability</strong>: Selecting fonts with high readability is crucial, especially for those with visual impairments. Google Fonts such as Roboto, Lexend, and OpenDyslexic were recommended for their legibility and accessibility.</p></li>
</ul>
</section>
<section id="practical-demonstration" class="level4">
<h4 class="anchored" data-anchor-id="practical-demonstration">Practical Demonstration:</h4>
<p>Dr.&nbsp;Giordano provided a hands-on demonstration using R packages to create accessible charts:</p>
<ul>
<li><p><strong>Using RColorBrewer and Colorblindr</strong>: The session showcased how to apply colorblind-friendly palettes to a dataset using <code>ggplot2</code>. The <code>RColorBrewer</code> package was highlighted for its wide range of palettes that cater to different types of visual impairments.</p></li>
<li><p><strong>Color Contrast Testing</strong>: Ensuring sufficient contrast between text and background colors is essential. Tools like <code>coloratio</code> and <code>colorspace</code> were demonstrated to test and adjust color contrasts, ensuring they meet accessibility standards.</p></li>
<li><p><strong>Recolorize Package</strong>: For those needing to adjust brand colors to be more inclusive, the <code>recolorize</code> package was introduced. By tweaking saturation and brightness, existing palettes can be modified to become colorblind-friendly without losing brand identity.</p></li>
<li><p><strong>Interactive Tools for Palette Selection</strong>: The <code>colorspace</code> package includes a GUI tool that allows users to select palettes and instantly see how they appear to individuals with different types of color blindness.</p></li>
</ul>
</section>
<section id="importance-of-accessibility" class="level4">
<h4 class="anchored" data-anchor-id="importance-of-accessibility">Importance of Accessibility:</h4>
<p>The session underscored the moral and ethical responsibility of data scientists to make data accessible to everyone. Whether it’s a report for an elderly arthritis patient or a dashboard for diabetic monitoring, accessibility should be a primary consideration.</p>
<p>In conclusion, creating accessible visualizations is not merely about compliance but about inclusivity and empathy towards all data consumers. Dr.&nbsp;Giordano’s demonstration serves as a vital reminder and guide on how this can be achieved effectively in R.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <guid>https://r-consortium.org/posts/visualising-data-for-patients-create-accessible-charts/</guid>
  <pubDate>Mon, 23 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/visualising-data-for-patients-create-accessible-charts/thumbnail-accessible-charts-giordano.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Advanced Distance Metrics for High-Dimensional Clustering: introducing ‘distanceHD’ R-package</title>
  <dc:creator>R Consortium, Software Development</dc:creator>
  <link>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EC_vTG-_XCQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="distancehd-a-new-frontier-in-high-dimensional-clustering" class="level1">
<h1>DistanceHD: A New Frontier in High-Dimensional Clustering</h1>
<p>Greetings, data enthusiasts and R aficionados! Today, we delve into development in the realm of high-dimensional clustering with the introduction of the <code>distanceHD</code> package. This tool, crafted by Jung Ae Lee, Assistant Professor of Biostatistics at the University of Massachusetts Chan Medical School, addresses the need for robust, scalable, and statistically sound distance measures tailored specifically for high-dimensional settings.</p>
<section id="why-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="why-distancehd">Why <code>distanceHD</code>?</h2>
<p>Traditional distance metrics such as Euclidean or Mahalanobis distances often falter in high-dimensional spaces. These conventional methods, while effective in lower dimensions, struggle to detect meaningful clusters or outliers when faced with the complexity of high-dimensional data. This gap is particularly evident in fields like genomics, where the number of features (variables) often exceeds the number of samples.</p>
<p>The <code>distanceHD</code> package introduces three innovative distance metrics designed for high-dimensional clustering and outlier detection: the centroid distance, ridge Mahalanobis distance, and maximal data piling (MDP) distance. Each of these metrics offers unique benefits, making them invaluable tools in the data scientist’s arsenal.</p>
</section>
<section id="the-three-pillars-of-distancehd" class="level2">
<h2 class="anchored" data-anchor-id="the-three-pillars-of-distancehd">The Three Pillars of <code>distanceHD</code></h2>
<section id="centroid-distance" class="level3">
<h3 class="anchored" data-anchor-id="centroid-distance">1. Centroid Distance</h3>
<p>Centroid distance, also known as Euclidean distance, calculates the distance between the centers of two groups. It is a straightforward metric but can be limited in high-dimensional spaces with correlated variables. However, it remains effective when variables are uncorrelated.</p>
</section>
<section id="ridge-mahalanobis-distance" class="level3">
<h3 class="anchored" data-anchor-id="ridge-mahalanobis-distance">2. Ridge Mahalanobis Distance</h3>
<p>The ridge Mahalanobis distance introduces a ridge correction constant, alpha, to ensure the covariance matrix is invertible — a common issue in high-dimensional analysis due to singularity problems. This adjustment allows for a more stable calculation of distances, bridging the gap between the centroid and MDP distances. When alpha is large, the ridge Mahalanobis distance approximates the centroid distance, while a smaller alpha brings it closer to the MDP distance.</p>
</section>
<section id="maximal-data-piling-mdp-distance" class="level3">
<h3 class="anchored" data-anchor-id="maximal-data-piling-mdp-distance">3. Maximal Data Piling (MDP) Distance</h3>
<p>The MDP distance is perhaps the most novel of the three metrics. It computes the orthogonal distance between the affine spaces spanned by each class, offering a unique direction vector that maximizes the distance between class projections. This metric shines in situations with highly correlated variables, such as gene expression data, and is particularly effective for classification problems.</p>
</section>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<p>The <code>distanceHD</code> package is not just a theoretical construct; it has real-world applications in clustering, classification, and outlier detection. For instance, in the context of outlier identification, the MDP distance can effectively discern outliers by maximizing the projection distance in a unique direction. This capability is demonstrated through sequential simulations, such as gene expression data with multiple features and patients, where traditional metrics may fall short.</p>
<p>In classification tasks, the MDP distance provides a high-dimensional, low-sample-size version of Fisher’s discriminant analysis, offering a powerful tool for binary predictions, such as disease status classification.</p>
</section>
<section id="future-directions" class="level2">
<h2 class="anchored" data-anchor-id="future-directions">Future Directions</h2>
<p>While the <code>distanceHD</code> package is a significant leap forward, Jung Ae Lee plans to expand its functionalities further. Upcoming updates will focus on improving outlier detection processes and incorporating additional distance metrics to enhance the package’s versatility and applicability in various high-dimensional contexts.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The <code>distanceHD</code> package represents a significant advancement in the field of high-dimensional data analysis, offering robust tools for clustering, classification, and outlier detection. With its innovative metrics and practical applications, it is poised to become an essential resource for researchers and practitioners working with complex, high-dimensional datasets.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Software Development</category>
  <guid>https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/advanced-distance-metrics-for-high-dimensional-clustering-introducing-distancehd-r-package/thumbnail-advanced-distance-metrics-lee.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>An Accelerometry Biomarker Framework with Application in Vigilance in UK Biobank Data</title>
  <dc:creator>R Consortium, Healthcare</dc:creator>
  <link>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KiQAySB2rF4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="exploring-vigilance-with-accelerometry-insights-from-the-uk-biobank" class="level1">
<h1>Exploring Vigilance with Accelerometry: Insights from the UK Biobank</h1>
<p>Accelerometry data from wearable devices have opened new horizons in non-invasive health monitoring, providing a continuous and objective measure of physical activity. Michael Kane, MD Anderson Cancer Center, alongside Dmitri Wolson and Francesco Onarati at Takeda Pharmaceuticals, delves into using accelerometry as a biomarker for assessing vigilance, focusing on the potential to identify non-vigilant states such as excessive daytime sleepiness or narcolepsy-like symptoms. This analysis is rooted in data from the UK Biobank, a rich resource encompassing accelerometry, demographic, and lifestyle data of approximately 78,500 participants.</p>
<section id="understanding-the-data-and-its-challenges" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-data-and-its-challenges">Understanding the Data and Its Challenges</h2>
<p>The UK Biobank’s accelerometry data provides a wealth of information, with measurements taken at 100 Hz over a week for each participant. These data offer a high-resolution view of daily activity patterns, recorded across three axes (X, Y, Z) in milligravities. However, this study’s foundational challenge lies in its observational nature and reliance on self-reported outcomes to define vigilance states.</p>
<p>Vigilance and non-vigilance were distinguished using self-reported symptoms of narcolepsy and frequency of daytime naps. Non-vigilant participants reported narcolepsy symptoms often or always and took frequent naps, while vigilant participants did not report these symptoms or behaviors. Despite a robust overall dataset, the non-vigilant group comprised only 679 individuals, necessitating a careful matching process to ensure comparable analysis groups.</p>
</section>
<section id="propensity-score-matching-for-balanced-analysis" class="level2">
<h2 class="anchored" data-anchor-id="propensity-score-matching-for-balanced-analysis">Propensity Score Matching for Balanced Analysis</h2>
<p>To address imbalances and potential confounders in the observational data, propensity score matching was employed. This method allowed for the creation of matched pairs of vigilant and non-vigilant participants based on physical and lifestyle characteristics, including age, sex, ethnicity, BMI, smoking habits, alcohol use, and more. This rigorous matching resulted in 95 well-matched pairs, setting the stage for a focused exploration of accelerometry’s potential in assessing vigilance.</p>
</section>
<section id="transforming-accelerometry-data-into-spectral-images" class="level2">
<h2 class="anchored" data-anchor-id="transforming-accelerometry-data-into-spectral-images">Transforming Accelerometry Data into Spectral Images</h2>
<p>A critical step in the analysis involved transforming raw accelerometry data into a structured format conducive to machine learning. The data were downsampled to 33 Hz to focus on relevant daily movement frequencies. Subsequently, the data were segmented into five-minute blocks, and a Discrete Fourier Transform was applied to each block. This transformation yielded sorted spectral images, representing the energy expended at different frequencies without capturing the precise timing of activities within a day.</p>
</section>
<section id="convolutional-neural-network-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network-for-classification">Convolutional Neural Network for Classification</h2>
<p>Inspired by the architecture of AlexNet, a simplified convolutional neural network (CNN) was developed to classify participants as vigilant or non-vigilant based on the spectral images. The CNN architecture included convolutional layers, max pooling, and dense layers with dropout to prevent overfitting. Training involved 20-fold cross-validation at the subject level, ensuring that predictions were genuinely out-of-sample.</p>
<p>The CNN yielded an out-of-sample F1 score of 0.576 and an AUC of 0.539 at the sample level for participants aged 65 or younger. At the subject level, the F1 score was 0.539, and the AUC was 0.564. While these results indicate a weak association between accelerometry-derived biomarkers and vigilance states, they underscore the potential for further refinement and application in broader contexts.</p>
</section>
<section id="potential-applications-and-future-directions" class="level2">
<h2 class="anchored" data-anchor-id="potential-applications-and-future-directions">Potential Applications and Future Directions</h2>
<p>The study highlights accelerometry’s promise as a non-invasive tool for assessing cognitive states and movement-related disorders. The association between accelerometry and vigilance, albeit modest, opens avenues for monitoring conditions where non-vigilance is a co-morbidity, such as sleep disorders, neurological conditions, and psychiatric disorders.</p>
<p>The findings also suggest potential applications in monitoring the effectiveness of treatments for conditions like narcolepsy, where stimulant medications may influence accelerometry patterns. Furthermore, the study indicates that stratifying by age could enhance the model’s predictive accuracy, given that younger participants tend to exhibit more movement.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Kane’s exploration into accelerometry as a biomarker for vigilance represents an exciting step forward in leveraging wearable technology for health monitoring. While the association between accelerometry and vigilance is currently weak, the study underscores the potential for accelerometry-derived insights to inform interventions across a range of conditions. The use of R for analysis and presentation further demonstrates the language’s versatility in handling complex datasets and machine learning models.</p>
<p>As the R community continues to evolve and embrace cutting-edge methodologies, studies like this exemplify the innovative applications of R in advancing healthcare research. The integration of accelerometry data into clinical and research settings promises to enhance our understanding of human physiology and behavior, paving the way for more personalized and effective health interventions.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/an-accelerometry-biomarker-framework-with-application-in-vigilance-in-uk-biobank-data/thumbnail-kane-accelerometry.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Application of attention mechanism to improve performance of llm/mllm used across R/Medicine</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/application-of-attention-mechanism-to-improve-performance-of-llmmllm-used-across-rmedicine/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/aGvAE7Z1XJ0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="rmedicine-2025-enhancing-regulatory-submissions-with-attention-mechanisms" class="level1">
<h1>R/Medicine 2025: Enhancing Regulatory Submissions with Attention Mechanisms</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the rapidly evolving field of medicine, the integration of technology and data science is ushering in transformative changes. At the R/Medicine 2025 conference, Robert Devine from Johnson &amp; Johnson Companies presented an insightful demonstration on the “Application of attention mechanism to improve performance of surveyed llm/mllm used across R/Medicine.” This session provided a deep dive into how attention mechanisms, a component of transformer architectures, can enhance the efficiency and accuracy of regulatory submissions in the medical field.</p>
</section>
<section id="the-role-of-attention-mechanisms" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-attention-mechanisms">The Role of Attention Mechanisms</h2>
<p>Attention mechanisms have been pivotal in the field of natural language processing (NLP) since their emergence in 2014. Initially used in neural machine translation tasks, they have since been refined and expanded, particularly following significant advancements by Google in 2017. In the context of medicine, attention mechanisms help improve the performance of large language models (LLMs) and multi-modal large language models (MLLMs), facilitating tasks such as the generation of descriptive vignettes for analytical datasets and the auto-generation of the Analysis Data Reviewer’s Guide (ADRG).</p>
<section id="transformer-architecture-in-rmedicine" class="level3">
<h3 class="anchored" data-anchor-id="transformer-architecture-in-rmedicine">Transformer Architecture in R/Medicine</h3>
<p>The session included a comprehensive overview of the transformer architecture, focusing on the attention mechanism’s role in R/Medicine. This architecture allows models to evaluate which parts of the input data are most relevant at each step of the process, thereby enhancing the model’s ability to generate accurate and contextually relevant outputs.</p>
</section>
</section>
<section id="demonstration-highlights" class="level2">
<h2 class="anchored" data-anchor-id="demonstration-highlights">Demonstration Highlights</h2>
<ol type="1">
<li><p><strong>Vignette Generation for Analysis Dataset Descriptions</strong>: The demonstration showcased how attention mechanisms can automate the creation of detailed vignettes for analysis datasets. These vignettes are crucial for providing context and understanding of safety and efficacy data used in the R Consortium Pilot Series with the FDA.</p></li>
<li><p><strong>Public Repository for Community Participation</strong>: A public repository was introduced to encourage community engagement. This resource allows participants to access and contribute to the development of working examples that hold clinical importance for analytics and regulatory submissions.</p></li>
<li><p><strong>Private-Public Partnerships</strong>: The session highlighted the ongoing collaboration between private entities and regulatory agencies to foster the adoption of mandated submission guidelines. This collaboration is crucial for aligning industry practices with regulatory requirements and accelerating the conformance to technical guidelines.</p></li>
</ol>
</section>
<section id="the-importance-of-r-consortium-pilot-series" class="level2">
<h2 class="anchored" data-anchor-id="the-importance-of-r-consortium-pilot-series">The Importance of R Consortium Pilot Series</h2>
<p>The R Consortium Pilot Series with the FDA plays a vital role in advancing the adoption of modern technical submission standards. These pilot studies focus on demonstrating the practical applications of LLMs/MLLMs in regulatory submissions, aiming to improve efficiency and accuracy while ensuring compliance with regulatory standards.</p>
<p>Reference: <a href="https://r-consortium.org/posts/submissions-wg-pilot5-pilot6-and-more/index.html#progress-reports-and-future-plans">R Submissions Working Group: Pilot 5 Launch and more!</a></p>
<section id="key-achievements-and-future-directions" class="level3">
<h3 class="anchored" data-anchor-id="key-achievements-and-future-directions">Key Achievements and Future Directions</h3>
<ul>
<li><p><strong>Pilot Studies</strong>: The pilot studies have successfully demonstrated the potential of LLMs/MLLMs in automating various aspects of regulatory submissions. These include generating vignettes, auto-generating ADRGs, and streamlining the overall submission process.</p></li>
<li><p><strong>Ongoing Developments</strong>: The session emphasized the need for continuous development and collaboration within the R community. By leveraging the public repository, participants can contribute to ongoing projects, ensuring that advancements in technology are effectively integrated into regulatory practices.</p></li>
</ul>
</section>
</section>
<section id="the-broader-implications-of-attention-mechanisms" class="level2">
<h2 class="anchored" data-anchor-id="the-broader-implications-of-attention-mechanisms">The Broader Implications of Attention Mechanisms</h2>
<p>The application of attention mechanisms extends beyond regulatory submissions. In clinical trials and patient engagement, these mechanisms enable more accurate data analysis and improved patient outcomes. For example, attention mechanisms can identify significant interactions in complex biological systems, such as protein folding, which are critical for understanding disease mechanisms and developing new treatments.</p>
<section id="interoperability-and-data-sharing" class="level3">
<h3 class="anchored" data-anchor-id="interoperability-and-data-sharing">Interoperability and Data Sharing</h3>
<p>The session also touched upon the importance of interoperability and data sharing in the medical field. The 21st Century Cures Act, which promotes interoperability between different technologies, was highlighted as a critical component for facilitating data sharing and enhancing patient care. The use of universal APIs allows patients to share their electronic health records seamlessly, promoting collaboration between clinicians, researchers, and pharmaceutical companies.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Robert Devine’s presentation at R/Medicine 2025 underscored the transformative potential of attention mechanisms in the field of regulatory submissions. By automating complex tasks and enhancing data analysis, these mechanisms pave the way for more efficient and accurate regulatory processes. The R Consortium’s ongoing collaboration with the FDA and industry sponsors is crucial for driving the adoption of these technologies and ensuring that regulatory practices keep pace with technological advancements.</p>
<p>As the R community continues to explore and develop these capabilities, the potential for improving patient outcomes and streamlining regulatory processes becomes increasingly tangible. By embracing these innovations, the medical field can look forward to a future where technology and data science work hand in hand to deliver better healthcare solutions.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Submissions</category>
  <guid>https://r-consortium.org/posts/application-of-attention-mechanism-to-improve-performance-of-llmmllm-used-across-rmedicine/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/application-of-attention-mechanism-to-improve-performance-of-llmmllm-used-across-rmedicine/thumbnail-devine-application-of-attention-mechanism.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Bedside to Bench - Reinventing medicine with AI</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/OPib-OztZQc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="reinventing-medicine-with-ai-a-new-pathway-to-discovery" class="level1">
<h1>Reinventing Medicine with AI: A New Pathway to Discovery</h1>
<p>The landscape of medical research and discovery is ripe for a seismic shift, one that is being catalyzed by the integration of artificial intelligence (AI) into the healthcare domain. This paradigm shift was the core focus of Dr.&nbsp;Ziad Obermeyer’s keynote at R/Medicine 2025, where he explored the potential of AI to resurrect and revolutionize the “bedside to bench” pathway for medical discovery.</p>
<section id="from-bench-to-bedside-the-traditional-model" class="level2">
<h2 class="anchored" data-anchor-id="from-bench-to-bedside-the-traditional-model">From Bench to Bedside: The Traditional Model</h2>
<p>The traditional model of medical discovery often starts at the molecular level, focusing on genes, proteins, and signaling pathways. This approach has led to significant breakthroughs, particularly in areas like cancer and immunology, where targeted therapies have been transformative. However, this model is not without its limitations. As Dr.&nbsp;Obermeyer pointed out, many complex medical problems remain unsolved, and the traditional bench-to-bedside approach has largely overshadowed the alternative pathway — one that begins with observations at the bedside.</p>
</section>
<section id="ai-a-new-lens-for-medical-discovery" class="level2">
<h2 class="anchored" data-anchor-id="ai-a-new-lens-for-medical-discovery">AI: A New Lens for Medical Discovery</h2>
<p>AI, with its ability to process vast amounts of data and detect patterns invisible to the human eye, offers a powerful alternative. Dr.&nbsp;Obermeyer provided compelling examples of how AI can generate novel empirical observations from real-world data, thereby reinvigorating the bedside-to-bench pathway.</p>
<section id="the-case-of-knee-pain" class="level3">
<h3 class="anchored" data-anchor-id="the-case-of-knee-pain">The Case of Knee Pain</h3>
<p>One of the illustrative examples Dr.&nbsp;Obermeyer discussed was knee pain, a condition that has long eluded effective treatment through traditional molecular approaches. Historically, research on knee pain has zoomed in at a molecular level, focusing on inflammation markers and cartilage degradation. However, this approach has not significantly alleviated the widespread issue of knee pain, leading to an over-reliance on opioids as a treatment.</p>
<p>Dr.&nbsp;Obermeyer’s team leveraged AI to analyze knee X-rays, not to replicate human radiologist interpretations, but to predict patient-reported pain scores directly from the image data. This approach uncovered new insights into the anatomical and physiological factors contributing to knee pain, particularly among Black patients, thus addressing a known disparity in pain management and treatment outcomes.</p>
</section>
<section id="sudden-cardiac-death-predicting-the-unpredictable" class="level3">
<h3 class="anchored" data-anchor-id="sudden-cardiac-death-predicting-the-unpredictable">Sudden Cardiac Death: Predicting the Unpredictable</h3>
<p>Another poignant example involved the use of AI to predict sudden cardiac death, a condition notorious for its unpredictability. By analyzing ECG data linked to patient outcomes in Sweden, Dr.&nbsp;Obermeyer’s team developed a model that could identify individuals at high risk of sudden cardiac death with greater accuracy than traditional metrics. This predictive capability has the potential to optimize the allocation of defibrillators, ensuring they reach those most in need.</p>
</section>
</section>
<section id="implications-for-the-future-of-medicine" class="level2">
<h2 class="anchored" data-anchor-id="implications-for-the-future-of-medicine">Implications for the Future of Medicine</h2>
<p>The implications of these findings are profound. By turning complex medical images into actionable data, AI not only enhances diagnostic precision but also opens new avenues for therapeutic interventions. This approach allows for a re-examination of established medical knowledge, potentially leading to new standards of care.</p>
<section id="bridging-disciplines" class="level3">
<h3 class="anchored" data-anchor-id="bridging-disciplines">Bridging Disciplines</h3>
<p>The integration of AI into medical research also underscores the importance of interdisciplinary collaboration. As Dr.&nbsp;Obermeyer noted, insights from fields such as computer science, economics, and behavioral science can enrich our understanding of health and disease, leading to more holistic and effective healthcare solutions.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Dr.&nbsp;Obermeyer’s keynote at R/Medicine 2025 highlighted the transformative potential of AI in medicine. By enabling a new cycle of discovery that starts at the bedside, AI promises to uncover new abstractions and insights, ultimately improving patient care and outcomes. As the R community continues to explore these frontiers, the collaborative efforts between data scientists, clinicians, and researchers will be crucial in unlocking the full potential of AI in healthcare.</p>
<p>With the power of AI and the collective wisdom of diverse disciplines, the future of medical discovery has the potential for advancements that were once thought unattainable.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>AI</category>
  <guid>https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bedside-to-bench-reinventing-medicine-with-ai/thumbnail-ai-ziad.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Bootstrap inference made easy: p-values and confidence intervals in one line of code</title>
  <dc:creator>R Consortium</dc:creator>
  <link>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</link>
  <description><![CDATA[ 





<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EeAtvWF3twA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package" class="level3">
<h3 class="anchored" data-anchor-id="simplifying-bootstrap-inference-in-r-with-the-boot.pval-package">Simplifying Bootstrap Inference in R with the boot.pval Package</h3>
<p>In the realm of statistical analysis, ensuring the reliability of p-values and confidence intervals is paramount, especially when classical assumptions about data distribution do not hold. This is where bootstrap methods come into play, offering a robust alternative by relying on data-driven, empirical distributions rather than theoretical assumptions. Despite their utility, bootstrap methods are often underutilized due to perceived complexities in implementation. However, with advancements in R packages like <code>boot.pval</code>, bootstrap inference has become more accessible than ever.</p>
<section id="the-bootstrap-approach" class="level4">
<h4 class="anchored" data-anchor-id="the-bootstrap-approach">The Bootstrap Approach</h4>
<p>Introduced by Bradley Efron in 1979, the bootstrap method revolutionizes statistical inference by focusing on the empirical distribution of the data itself. Unlike traditional methods that start with a distributional assumption (e.g., normality), bootstrap methods begin with the actual data distribution. By resampling from this empirical distribution and calculating the test statistic repeatedly, we obtain an accurate approximation of its distribution. This allows for the computation of p-values and confidence intervals without reliance on stringent assumptions about data normality.</p>
</section>
<section id="the-role-of-boot.pval" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-boot.pval">The Role of boot.pval</h4>
<p>The <code>boot.pval</code> package in R, developed by Måns Thulin from Thulin Consulting AB, simplifies the process of applying bootstrap methods to a variety of statistical tests and models. From t-tests to regression coefficients in linear models, GLMs, survival models, and mixed models, <code>boot.pval</code> enables users to compute bootstrap p-values and confidence intervals efficiently—often with just a single line of code.</p>
</section>
<section id="key-features-and-benefits" class="level4">
<h4 class="anchored" data-anchor-id="key-features-and-benefits">Key Features and Benefits</h4>
<ul>
<li><strong>Ease of Use</strong>: The package allows for straightforward computation of bootstrap p-values and confidence intervals without needing to write complex custom functions.</li>
<li><strong>Integration</strong>: Built on top of established R packages like <code>boot</code>, <code>car</code>, <code>lme4</code>, and <code>survival</code>, it ensures compatibility and extends functionality.</li>
<li><strong>Customizability</strong>: Users can create custom bootstrap tests for unique statistical measures.</li>
<li><strong>Consistency</strong>: It ensures that the derived p-values and confidence intervals are consistent, addressing discrepancies often found in other implementations.</li>
</ul>
</section>
<section id="practical-application-a-case-study" class="level4">
<h4 class="anchored" data-anchor-id="practical-application-a-case-study">Practical Application: A Case Study</h4>
<p>Using the sleep dataset in R, Thulin demonstrates how to replace a classic t-test with a bootstrap t-test using <code>boot.pval</code>. This approach not only simplifies the code but also enhances the robustness of the test against non-normal data distributions. The output from <code>boot.pval</code> mirrors that from traditional tests but is derived from a more reliable, data-centric approach.</p>
</section>
<section id="extending-beyond-simple-tests" class="level4">
<h4 class="anchored" data-anchor-id="extending-beyond-simple-tests">Extending Beyond Simple Tests</h4>
<p>The <code>boot.pval</code> package is not limited to simple t-tests; it supports complex models including linear regressions and survival models. By fitting a model using standard R functions like <code>lm()</code> or <code>glm()</code>, users can then apply <code>boot.summary()</code> from <code>boot.pval</code> to obtain detailed summaries including estimates, confidence intervals, and p-values—all bootstrapped for enhanced reliability.</p>
</section>
<section id="conclusion" class="level4">
<h4 class="anchored" data-anchor-id="conclusion">Conclusion</h4>
<p>Bootstrap methods provide a powerful tool for statistical inference when traditional assumptions do not hold. With packages like <code>boot.pval</code>, R users can integrate robust bootstrap techniques into their daily analysis workflows effortlessly. Whether dealing with straightforward comparisons or complex multivariable models, <code>boot.pval</code> offers a user-friendly yet powerful solution for making informed statistical decisions based on solid empirical evidence.</p>
<p>For those interested in delving deeper into bootstrap methods or seeking practical applications within R, exploring further resources such as <a href="https://www.modernstatisticswithr.com/">Thulin’s book “Modern Statistics with R”</a> or foundational texts on bootstrap methodology can be incredibly beneficial.</p>


</section>
</section>

 ]]></description>
  <category>R/Medicine 2025</category>
  <category>Clinical Research</category>
  <guid>https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/</guid>
  <pubDate>Sun, 22 Jun 2025 00:00:00 GMT</pubDate>
  <media:content url="https://r-consortium.org/posts/bootstrap-inference-made-easy-p-values-and-confidence-intervals-in-one-line-of-code/thumbnail-bootstrap-inference-thulin.png" medium="image" type="image/png" height="81" width="144"/>
</item>
</channel>
</rss>
